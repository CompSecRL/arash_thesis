{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f653b00-c8d6-40b2-b5d3-791c7ccdde9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "Seed was set to: 567\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install python-docx\n",
    "# !pip install antropy\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "import math as math\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "import statsmodels.stats.api as sms\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import asdict\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, accuracy_score, make_scorer, auc\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Lambda,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling1D,\n",
    "    Activation\n",
    ")\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Ftrl, Nadam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import concatenate as keras_concat\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import median_absolute_deviation\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_widths\n",
    "# from scipy.special import entr\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "get_new_scaler_dict = {\"StandardScaler\": StandardScaler, \"MinMaxScaler\": MinMaxScaler, \"Normalizer\": Normalizer, \n",
    "                       \"MaxAbsScaler\": MaxAbsScaler, \"RobustScaler\": RobustScaler, \"PowerTransformer\": PowerTransformer}\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc\n",
    "# import antropy as ant\n",
    "import time\n",
    "# import docx\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "# Global utitlity functions are in separate notebook\n",
    "%run ./Classification_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "print(f\"Seed was set to: {SEED}\")\n",
    "\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cc83fb-4d1e-4675-90bc-f8a762f11dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Experiments Parameter set. Used as identifier for charts etc.\n",
    "\n",
    "    # Data / Splitting:\n",
    "    frequency: int\n",
    "    feature_cols: list  # Columns used as features\n",
    "    max_subjects: int\n",
    "    user_ids: list\n",
    "    num_sample_points_per_exp: int\n",
    "    exp_begin_cutoff_idx: int\n",
    "    exp_end_cutoff_idx: int\n",
    "        \n",
    "#     exclude_subjects: list  # Don't load data from those users\n",
    "    n_valid_train_subjects: int\n",
    "    n_valid_test_subjects: int\n",
    "    n_test_train_subjects: int\n",
    "    n_test_test_subjects: int\n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    task_types: list  # Limit scenarios to [1, 3, 5] for sitting or [2, 4, 6] for walking, or don't limit (None)\n",
    "\n",
    "    # Reshaping\n",
    "    window_size: int  # After resampling\n",
    "    nn_step_width: int\n",
    "    ocsvm_step_width: int\n",
    "\n",
    "    # Normalization\n",
    "    scaler: str  # {\"std\", \"robust\", \"minmax\"}\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # scale training and testing sets at once (True), or fit scaler on training only (False)\n",
    "\n",
    "    # Siamese Network\n",
    "    max_pairs_per_session: int  # Max. number of pairs per session\n",
    "    margin: float  # Contrastive Loss Margin\n",
    "    model_variant: str  # {\"1d\", \"2d\"} Type of architecture\n",
    "    filters: list  # List of length 4, containing number of filters for conv layers\n",
    "    epochs_best: int  # Train epochs to for final model\n",
    "    epochs_max: int\n",
    "    batch_size: int\n",
    "    optimizer: str  # Optimizer to use for Siamese Network\n",
    "    optimizer_lr: float  # Learning Rate\n",
    "    optimizer_decay: float\n",
    "\n",
    "    # OCSVM\n",
    "    ocsvm_kernel: str # ocsvm kernel\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "\n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        # Number of samples per _session_ used for training:\n",
    "        self.samples_per_subject_train = math.ceil(\n",
    "            (self.seconds_per_subject_train * 100)\n",
    "            / (100 / self.frequency)\n",
    "            / self.window_size\n",
    "        )\n",
    "\n",
    "        # Number of samples per _session_ used for testing:\n",
    "        self.samples_per_subject_test = math.ceil(\n",
    "            (self.seconds_per_subject_test * 100)\n",
    "            / (100 / self.frequency)\n",
    "            / self.window_size\n",
    "        )\n",
    "\n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_MINMAX (2D Filters)\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_2D = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX-2D\",\n",
    "#     # Data / Splitting\n",
    "    frequency=100,\n",
    "    feature_cols=[\n",
    "        \"acc_x\",\n",
    "        \"acc_y\",\n",
    "        \"acc_z\",\n",
    "        \"gyr_x\",\n",
    "        \"gyr_y\",\n",
    "        \"gyr_z\"\n",
    "    ],\n",
    "    max_subjects=29,\n",
    "    user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49],\n",
    "    num_sample_points_per_exp=21000,\n",
    "    exp_begin_cutoff_idx=500,\n",
    "    exp_end_cutoff_idx=-500,\n",
    "    n_valid_train_subjects=40,\n",
    "    n_valid_test_subjects=10,\n",
    "    n_test_train_subjects=10,\n",
    "    n_test_test_subjects=30,\n",
    "    seconds_per_subject_train=67.5,\n",
    "    seconds_per_subject_test=67.5,\n",
    "    task_types=None,\n",
    "    # Reshaping\n",
    "    window_size=100 * 1,  #1 sec\n",
    "    nn_step_width=125,\n",
    "    ocsvm_step_width=125,\n",
    "    # Normalization\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    # Siamese Network\n",
    "    model_variant=\"2d\",\n",
    "    filters=[32, 64, 128, 32],\n",
    "#     filters=[32, 64, 128, 64],\n",
    "    epochs_best=35,\n",
    "    epochs_max=40,\n",
    "    batch_size=200,\n",
    "    optimizer=\"sgd\",\n",
    "    optimizer_lr=0.01,\n",
    "    optimizer_decay=0,\n",
    "    max_pairs_per_session=60,  # => 4min\n",
    "    margin=0.2,\n",
    "    # OCSVM\n",
    "    ocsvm_kernel=\"rbf\",\n",
    "    ocsvm_nu=0.092,\n",
    "    ocsvm_gamma=1.151,\n",
    ")  # <END NAIVE_APPROACH>\n",
    "\n",
    "# VALID_MINMAX (2D)\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_2D = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-MINMAX-2D\",\n",
    "    task_types=None,\n",
    "    scaler_global=False,\n",
    "    epochs_max=40,\n",
    "    ocsvm_nu=0.110,\n",
    "    ocsvm_gamma=59.636,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST (2D)\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_2D = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"NAIVE-ROBUST-2D\",\n",
    "    scaler=\"robust\",\n",
    "    optimizer=\"sgd\",\n",
    "    optimizer_lr=0.05, # Decreased, to avoid \"all zeros\" prediction\n",
    "    optimizer_decay=0.002,\n",
    "    epochs_best=5,\n",
    "    ocsvm_nu=0.214,\n",
    "    ocsvm_gamma=2.354,\n",
    ")\n",
    "\n",
    "# VALID_ROBUST (2D)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_2D = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-ROBUST-2D\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=False,\n",
    "    epochs_best=6,\n",
    "    epochs_max=20,\n",
    "    optimizer=\"sgd\",\n",
    "    optimizer_lr=0.05,  # Decrease LR, to avoid \"all zeros\" prediction\n",
    "    optimizer_decay=0.002,\n",
    "    ocsvm_nu=0.190,\n",
    "    ocsvm_gamma=0.069,\n",
    ")\n",
    "\n",
    "# VALID_ROBUST (1D)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_1D = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-ROBUST-1D\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=False,\n",
    "    model_variant=\"1d\", \n",
    "    filters=[32, 64, 128, 64],    \n",
    "    epochs_best=9,\n",
    "    epochs_max=20,\n",
    "    ocsvm_nu=0.156,\n",
    "    ocsvm_gamma=33.932,\n",
    ")\n",
    "\n",
    "# FCN_ROBUST (1D)\n",
    "# -----------------------------------------------------------\n",
    "VALID_FCN_ROBUST_125 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=125,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "VALID_FCN_ROBUST_250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=250,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "VALID_FCN_ROBUST_500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=500,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "VALID_FCN_ROBUST_750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=750,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "VALID_FCN_ROBUST_1000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=1000,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "VALID_FCN_ROBUST_1250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=1250,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "\n",
    "VALID_FCN_ROBUST_1500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=1500,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "VALID_FCN_ROBUST_1750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=1750,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")\n",
    "\n",
    "\n",
    "VALID_FCN_ROBUST_2000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_2D,\n",
    "    name=\"VALID-FCN-ROBUST-FINAL\",\n",
    "    task_types=[1, 2],\n",
    "    feature_cols=[\"acc_x\", \"acc_y\", \"acc_z\", 'gyr_x', 'gyr_y', 'gyr_z'], \n",
    "    frequency=100,\n",
    "    window_size=2000,\n",
    "\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    seconds_per_subject_train=60 * 10,\n",
    "    seconds_per_subject_test=60 * 10,\n",
    "    max_pairs_per_session=60 * 10,\n",
    "    model_variant=\"fcn\",\n",
    "    filters=[32, 64, 32],\n",
    "    optimizer=\"adam\",\n",
    "    optimizer_lr=0.00001,\n",
    "#     optimizer_lr=0.0001,\n",
    "#     optimizer_lr=0.001,\n",
    "#     optimizer_lr=0.01,\n",
    "    optimizer_decay=None,\n",
    "    batch_size=300,\n",
    "    margin=1,\n",
    "#     margin=.2,\n",
    "    epochs_best=40,\n",
    "    epochs_max=80,\n",
    "    ocsvm_nu=0.007,\n",
    "    ocsvm_gamma=0.002,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ea1959-5266-40c7-845d-45986195bf66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>VALID-FCN-ROBUST-FINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_cols</th>\n",
       "      <td>[acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_subjects</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_ids</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sample_points_per_exp</th>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_begin_cutoff_idx</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_end_cutoff_idx</th>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_valid_train_subjects</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_valid_test_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_test_train_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_test_test_subjects</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_train</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_test</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_types</th>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_step_width</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_step_width</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_scope</th>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_global</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_pairs_per_session</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_variant</th>\n",
       "      <td>fcn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters</th>\n",
       "      <td>[32, 64, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs_best</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs_max</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer</th>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_lr</th>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimizer_decay</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_kernel</th>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_nu</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_gamma</th>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Value\n",
       "name                                                  VALID-FCN-ROBUST-FINAL\n",
       "frequency                                                                100\n",
       "feature_cols                      [acc_x, acc_y, acc_z, gyr_x, gyr_y, gyr_z]\n",
       "max_subjects                                                              29\n",
       "user_ids                   [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...\n",
       "num_sample_points_per_exp                                              21000\n",
       "exp_begin_cutoff_idx                                                     500\n",
       "exp_end_cutoff_idx                                                      -500\n",
       "n_valid_train_subjects                                                    40\n",
       "n_valid_test_subjects                                                     10\n",
       "n_test_train_subjects                                                     10\n",
       "n_test_test_subjects                                                      30\n",
       "seconds_per_subject_train                                                600\n",
       "seconds_per_subject_test                                                 600\n",
       "task_types                                                            [1, 2]\n",
       "window_size                                                             1000\n",
       "nn_step_width                                                            500\n",
       "ocsvm_step_width                                                         500\n",
       "scaler                                                          RobustScaler\n",
       "scaler_scope                                                         subject\n",
       "scaler_global                                                          False\n",
       "max_pairs_per_session                                                    600\n",
       "margin                                                                     1\n",
       "model_variant                                                            fcn\n",
       "filters                                                         [32, 64, 32]\n",
       "epochs_best                                                               40\n",
       "epochs_max                                                                80\n",
       "batch_size                                                               300\n",
       "optimizer                                                               adam\n",
       "optimizer_lr                                                         0.00001\n",
       "optimizer_decay                                                         None\n",
       "ocsvm_kernel                                                             rbf\n",
       "ocsvm_nu                                                               0.007\n",
       "ocsvm_gamma                                                            0.002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n",
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n",
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n",
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n",
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n",
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n",
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n",
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n",
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n",
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n",
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n",
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n",
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n",
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n",
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n",
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n",
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n",
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n",
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n",
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n",
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n",
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n",
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n",
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n",
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n",
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n",
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n",
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n",
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n",
      "Loading exp3 data:\n",
      "1) accel_count: 16768, gyro_count: 18638\n",
      "2) accel_count: 21921, gyro_count: 24176\n",
      "3) accel_count: 21194, gyro_count: 22743\n",
      "4) accel_count: 11512, gyro_count: 11193\n",
      "5) accel_count: 20395, gyro_count: 20569\n",
      "6) accel_count: 14765, gyro_count: 14431\n",
      "7) accel_count: 10445, gyro_count: 10297\n",
      "8) accel_count: 8015, gyro_count: 7982\n",
      "19) accel_count: 20289, gyro_count: 20676\n",
      "21) accel_count: 30543, gyro_count: 32161\n",
      "22) accel_count: 19803, gyro_count: 20493\n",
      "26) accel_count: 14917, gyro_count: 15790\n",
      "27) accel_count: 14586, gyro_count: 14605\n",
      "28) accel_count: 17023, gyro_count: 17626\n",
      "29) accel_count: 12325, gyro_count: 12742\n",
      "35) accel_count: 18494, gyro_count: 19450\n",
      "36) accel_count: 24186, gyro_count: 24438\n",
      "37) accel_count: 16901, gyro_count: 16533\n",
      "38) accel_count: 10998, gyro_count: 10909\n",
      "39) accel_count: 23301, gyro_count: 23385\n",
      "40) accel_count: 15512, gyro_count: 16300\n",
      "41) accel_count: 14111, gyro_count: 13784\n",
      "42) accel_count: 13932, gyro_count: 14170\n",
      "43) accel_count: 11288, gyro_count: 11936\n",
      "44) accel_count: 22966, gyro_count: 24134\n",
      "45) accel_count: 29070, gyro_count: 30055\n",
      "46) accel_count: 15691, gyro_count: 16092\n",
      "48) accel_count: 17791, gyro_count: 18681\n",
      "49) accel_count: 0, gyro_count: 0\n",
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n",
      "47) accel_count: 17718, gyro_count: 18353\n",
      "Loading exp3 data:\n",
      "47) accel_count: 13528, gyro_count: 13303\n",
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "P = VALID_FCN_ROBUST_1000\n",
    "# utils_ppp(P)\n",
    "# P = VALID_ROBUST_1D\n",
    "# utils_ppp(P)\n",
    "# P = NAIVE_MINMAX_2D\n",
    "\n",
    "P.nn_step_width = int(P.window_size * .5)\n",
    "P.ocsvm_step_width = int(P.window_size * .5)\n",
    "P.scaler = 'RobustScaler'\n",
    "# P.scaler = 'MinMaxScaler'\n",
    "# P.scaler = 'Normalizer'\n",
    "# P.scaler = 'StandardScaler'\n",
    "\n",
    "utils_ppp(P)\n",
    "\n",
    "df_exps_dict = load_data_frames(P.user_ids, P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, P.num_sample_points_per_exp, is_exp3=True)\n",
    "dfList_exp1, dfList_exp2, dfList_exp3 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2'], df_exps_dict['dfList_exp3']\n",
    "\n",
    "raw_dfList_exp1 = dfList_exp1\n",
    "raw_dfList_exp2 = dfList_exp2\n",
    "raw_dfList_exp3 = dfList_exp3\n",
    "\n",
    "\n",
    "num_sample_points_per_exp_user_47 = 18000\n",
    "df_exps_dict_user_47 = load_data_frames([47], P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, num_sample_points_per_exp_user_47, is_exp3=True)\n",
    "dfList_exp1_user_47, dfList_exp2_user_47, dfList_exp3_user_47 = \\\n",
    "df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2'], df_exps_dict_user_47['dfList_exp3']\n",
    "\n",
    "raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "raw_dfList_exp2_user_47 = dfList_exp2_user_47\n",
    "raw_dfList_exp3_user_47 = dfList_exp3_user_47\n",
    "\n",
    "raw_dfList_exp3=raw_dfList_exp3[:-1]\n",
    "\n",
    "randomized_data_idx = list(range(len(P.user_ids)))\n",
    "random.Random(SEED).shuffle(randomized_data_idx)\n",
    "split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "train_set = randomized_data_idx[: split_idx]\n",
    "test_set = randomized_data_idx[split_idx: ]\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413872e-1513-474d-a050-8ed15d2127d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "P.model_variant = 'multi_head_fcn'\n",
    "P.tuning_metric=\"eer_val\"\n",
    "\n",
    "# SCNN_1_5_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[8, 16, 32, 64, 128]],\n",
    "#     \"kernels_streams\": [[7, 7, 5, 5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3, 3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\", \"l2\", \"l1\", \"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1, 1, 1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"causal\", \"causal\", \"causal\", \"causal\", \"causal\"]],\n",
    "#     \"dropouts_streams\": [[0.1, 0.2, 0.3, 0.4, 0.5]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "# SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "#                              [\"glorot_normal\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"]],\n",
    "#     \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.3], [.3], [.3]], #5**3\n",
    "#     \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [32],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l2\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_normal\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 5.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-2,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "    \n",
    "# }\n",
    "\n",
    "# SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0], #5**3\n",
    "#     \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "#                              [\"glorot_normal\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[None], [None], [None]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[None],[None], [\"l2\"]],\n",
    "#     \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[0], [0], [0]], #5**3\n",
    "#     \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [32],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[10],\n",
    "#     \"dense_kernel_regularizer\":[\"l2\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_normal\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 5.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-2,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "    \n",
    "# }\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0, 0, 0], #5**3\n",
    "    \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3.0], [3.0], [3.0]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(.0005,)],[(.0005,)], [(.0005,)]],\n",
    "\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.1], [0.1], [0.1]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [32],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3.0],\n",
    "    \"dense_kernel_regularizer\":[\"l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(.0005,)],\n",
    "\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_3_2_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[32, 32], [32, 32], [32, 32]], #6**3\n",
    "    \"kernels_streams\": [[7, 3], [5, 3], [3, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\", \"glorot_normal\"], [\"glorot_normal\", \"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[1, 1], [1, 1], [1, 1]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\", \"l2\"],[\"l2\", \"l2\"], [\"l2\", \"l2\"]],\n",
    "    \"strides_streams\": [[1, 1], [1, 1], [1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\", \"same\"], [\"same\", \"same\"], [\"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.3, .5], [.3, .5], [.3, .5]], #5**3\n",
    "    \"activations_streams\": [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [32],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[1],\n",
    "    \"dense_kernel_regularizer\":[\"l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_3_1_conv_2_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"]],\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.3], [.3], [.3]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \n",
    "    \"dense_layers\": [32, 64],\n",
    "    \"dense_kernel_Max_Norm_constraints\": [3, 3],\n",
    "    \"dense_kernel_regularizer\":[\"l2\", \"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_normal\", \"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.3, 0.4], \n",
    "    \"dense_activations\": ['tanh', \"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "# SCNN_3_1_conv_3_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0], #5**3\n",
    "#     \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "#                              [\"glorot_normal\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[10], [10], [10]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"]],\n",
    "#     \"strides_streams\": [[3], [2], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[0], [0], [0]], #5**3\n",
    "#     \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \n",
    "#     \"dense_layers\": [32, 64, 84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3, 3, 3],\n",
    "#     \"dense_kernel_regularizer\":[\"l2\", \"l2\", \"l2\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_normal\", \"glorot_normal\", \"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0, 0, 0], \n",
    "#     \"dense_activations\": ['tanh', 'tanh', \"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-2,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "    \n",
    "# }\n",
    "\n",
    "SCNN_4_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.0, .0, .0, .0], #5**3\n",
    "    \"filters_streams\": [[32], [32], [32], [32]], #6**3\n",
    "    \"kernels_streams\": [[9], [7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"], [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"], [\"l2\"]],\n",
    "    \"strides_streams\": [[1], [1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.2], [.2], [.2], [.2]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_5_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32], [32], [32], [32]], #6**3\n",
    "    \"kernels_streams\": [[11], [9], [7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"], [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\"], [\"l2\"],[\"l2\"], [\"l2\"], [\"l2\"]],\n",
    "    \"strides_streams\": [[1], [1], [1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.3], [.3], [.3], [.3], [.3]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "# SCNN_4_1234_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[16], [16, 32], [16, 32, 64], [16, 32, 64, 128]], #6**3\n",
    "#     \"kernels_streams\": [[3], [5, 3], [7, 5, 3], [9, 7, 5, 3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], #8**3\n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"],\n",
    "#                             [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3], [3, 3, 3, 3]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\"], [\"l2\",\"l1\"], [\"l1\",\"l2\", \"l1\"], [\"l2\", \"l1\", \"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1], [1, 1], [1, 1, 1], [1, 1, 1, 1]], #4**3\n",
    "#     \"paddings_streams\": [[\"causal\"], [\"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\", \"causal\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.2], [.2, .3], [.2, .3, .4], [.2, .3, .4, .5]], #5**3\n",
    "#     \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "SCNN_4_1234_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32, 64], [32, 64, 64], [32, 64, 64, 64]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3], [9, 7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\", \"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\", \"glorot_normal\", \"glorot_normal\"],\n",
    "                            [\"glorot_normal\", \"glorot_normal\", \"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3], [3, 3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"], [\"l1_l2\",\"l1_l2\"], [\"l1_l2\",\"l1_l2\", \"l1_l2\"], [\"l1_l2\", \"l1_l2\", \"l1_l2\", \"l1_l2\"]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1], [1, 1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"causal\"], [\"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\", \"causal\"]], #2*3\n",
    "    \"dropouts_streams\": [[.2], [.2, .3], [.2, .3, .4], [.2, .3, .4, .5]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh'], ['tanh', 'tanh', 'tanh', 'tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.3], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# SCNN_3_123_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[64], [64, 128], [64, 128, 256]], #6**3\n",
    "#     \"kernels_streams\": [[3], [5, 3], [7, 5, 3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], #8**3\n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\"], [\"l2\",\"l1\"], [\"l1\",\"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1], [1, 1], [1, 1, 1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\", \"same\"], [\"same\", \"same\", \"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.4], [.3, .4], [.2, .3, .4]], #5**3\n",
    "#     \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "SCNN_3_123_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[64], [64, 64], [64, 64, 64]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], #8**3\n",
    "                             [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"], [\"l1_l2\",\"l1_l2\"], [\"l1_l2\",\"l1_l2\", \"l1_l2\"]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\", \"same\"], [\"same\", \"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.3], [.3, .4], [.3, .4, .5]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# SCNN_1_3_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[64, 128, 256]],\n",
    "#     \"kernels_streams\": [[7, 5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.3, 0.4, 0.5]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "SCNN_1_3_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0],\n",
    "    \"filters_streams\": [[32, 32, 32]],\n",
    "    \"kernels_streams\": [[7, 5, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\", \"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\",\"l2\", \"l2\"]],\n",
    "    \"strides_streams\": [[1, 1, 1]],\n",
    "    \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "    \"dropouts_streams\": [[0.3, 0.4, 0.5]],\n",
    "    \"activations_streams\": [['tanh', 'tanh', 'tanh']],\n",
    "    \n",
    "    \"dense_layers\": [32],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "# SCNN_1_2_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[32, 64]],\n",
    "#     \"kernels_streams\": [[5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\"]],\n",
    "#     \"strides_streams\": [[1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.2, 0.3]],\n",
    "#     \"activations_streams\": [['relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "    \n",
    "\n",
    "# }\n",
    "\n",
    "# SCNN_1_1_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[64]],\n",
    "#     \"kernels_streams\": [[3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3]],\n",
    "#     \"strides_streams\": [[1]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\"]],\n",
    "#     \"paddings_streams\": [[\"same\"]],\n",
    "#     \"dropouts_streams\": [[0.2]],\n",
    "#     \"activations_streams\": [['relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "# SCNN_1_2_conv_2_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[64, 128]],\n",
    "#     \"kernels_streams\": [[5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\"]],\n",
    "#     \"strides_streams\": [[1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.2, 0.3]],\n",
    "#     \"activations_streams\": [['relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [32, 32],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3, 3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\", \"l2\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\", \"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2, 0.2], \n",
    "#     \"dense_activations\": ['relu', \"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "pool_dict= {\n",
    "    \"num_filters_pool\": [8, 16, 32, 64, 128, 256],\n",
    "    \"kernel_size_pool\": [3, 5, 7, 9],\n",
    "    \"kernel_init_pool\": ['truncated_normal', 'orthogonal', 'uniform', 'lecun_normal', 'lecun_uniform', 'normal', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n",
    "    \"stride_pool\": [1 ,2 ,3 , 4],\n",
    "    \"padding_pool\": [\"valid\", \"same\", \"causal\"], # \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t+1:]. \n",
    "    # Useful when modeling temporal data where the model should not violate the temporal order. See WaveNet: A Generative Model for Raw Audio, section 2.1.\n",
    "    \"dropout_pool\": [0, .1, .2, .3, .4, .5],\n",
    "    \"activation_pool\": ['softplus', 'softsign', 'relu', 'elu', 'gelu', 'selu', 'swish', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear', \"LeakyReLU\"],\n",
    "    \"num_dense_neuron_pool\": [8, 16, 32, 64, 84, 128, 256],\n",
    "    \"kernel_Max_Norm_constraints_pool\": [3, 4, 5],\n",
    "    \"kernel_regularizer_pool\": [\"l1\", \"l2\", \"l1_l2\"],\n",
    "    \n",
    "    \"optimizer_name_pool\": [\"Adam\", \"Nadam\" , \"RMSprop\", \"Adadelta\", \"Adagrad\", \"Adamax\"],#SGD\n",
    "    \"optimizer_lr_pool\": [1e-5, 5e-5 ,1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1],#1e-5, 5e-5, [1e-4, 2e-4, 3e-4, 4e-4, 5e-4], #\n",
    "    \"batch_size_pool\": [32, 64, 128, 256, 512, 1024],\n",
    "    \"contrastive_loss_margin_pool\": [.5, .6, .7, .8, .9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5],\n",
    "    \n",
    "}\n",
    "# try model hyperparameter optimization using the updated method (reduceLROnPlateau) instead of early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aba261-cb95-483e-901a-8011f995ecb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "P.model_variant = 'multi_head_fcn'\n",
    "P.tuning_metric=\"eer_val\"\n",
    "\n",
    "# SCNN_1_5_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[8, 16, 32, 64, 128]],\n",
    "#     \"kernels_streams\": [[7, 7, 5, 5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3, 3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\", \"l2\", \"l1\", \"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1, 1, 1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"causal\", \"causal\", \"causal\", \"causal\", \"causal\"]],\n",
    "#     \"dropouts_streams\": [[0.1, 0.2, 0.3, 0.4, 0.5]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\"], #8**3\n",
    "                             [\"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"]],\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.3], [.3], [.3]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [32],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 5.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_3_1_conv_2_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\"], #8**3\n",
    "                             [\"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.3], [.3], [.3]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "    \n",
    "    \"dense_layers\": [32, 32],\n",
    "    \"dense_kernel_Max_Norm_constraints\": [3, 3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\", \"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"he_normal\", \"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.2, 0.2], \n",
    "    \"dense_activations\": ['relu', \"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_4_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[9], [7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\"], #8**3\n",
    "                             [\"he_normal\"], [\"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1\"], [\"l2\"], [\"l1\"]],\n",
    "    \"strides_streams\": [[1], [1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.2], [.2], [.2], [.2]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.3], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_5_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[11], [9], [7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\"], [\"he_normal\"], #8**3\n",
    "                             [\"he_normal\"], [\"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"], [\"l1_l2\"],[\"l1\"], [\"l2\"], [\"l1\"]],\n",
    "    \"strides_streams\": [[1], [1], [1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.2], [.2], [.2], [.2], [.2]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu'], ['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.3], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "# SCNN_4_1234_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[16], [16, 32], [16, 32, 64], [16, 32, 64, 128]], #6**3\n",
    "#     \"kernels_streams\": [[3], [5, 3], [7, 5, 3], [9, 7, 5, 3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], #8**3\n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"],\n",
    "#                             [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3], [3, 3, 3, 3]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\"], [\"l2\",\"l1\"], [\"l1\",\"l2\", \"l1\"], [\"l2\", \"l1\", \"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1], [1, 1], [1, 1, 1], [1, 1, 1, 1]], #4**3\n",
    "#     \"paddings_streams\": [[\"causal\"], [\"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\", \"causal\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.2], [.2, .3], [.2, .3, .4], [.2, .3, .4, .5]], #5**3\n",
    "#     \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "SCNN_4_1234_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32, 64], [32, 64, 64], [32, 64, 64, 64]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3], [9, 7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\", \"he_normal\"], #8**3\n",
    "                             [\"he_normal\", \"he_normal\", \"he_normal\"],\n",
    "                            [\"he_normal\", \"he_normal\", \"he_normal\", \"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3], [3, 3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"], [\"l1_l2\",\"l1_l2\"], [\"l1_l2\",\"l1_l2\", \"l1_l2\"], [\"l1_l2\", \"l1_l2\", \"l1_l2\", \"l1_l2\"]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1], [1, 1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"causal\"], [\"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\", \"causal\"]], #2*3\n",
    "    \"dropouts_streams\": [[.2], [.2, .3], [.2, .3, .4], [.2, .3, .4, .5]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.3], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# SCNN_3_123_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[64], [64, 128], [64, 128, 256]], #6**3\n",
    "#     \"kernels_streams\": [[3], [5, 3], [7, 5, 3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], #8**3\n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\"], [\"l2\",\"l1\"], [\"l1\",\"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1], [1, 1], [1, 1, 1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\", \"same\"], [\"same\", \"same\", \"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.4], [.3, .4], [.2, .3, .4]], #5**3\n",
    "#     \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "SCNN_3_123_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[64], [64, 64], [64, 64, 64]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\", \"he_normal\"], #8**3\n",
    "                             [\"he_normal\", \"he_normal\", \"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"], [\"l1_l2\",\"l1_l2\"], [\"l1_l2\",\"l1_l2\", \"l1_l2\"]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\", \"same\"], [\"same\", \"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.4], [.3, .4], [.2, .3, .4]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.3], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# SCNN_1_3_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[64, 128, 256]],\n",
    "#     \"kernels_streams\": [[7, 5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\", \"l1\"]],\n",
    "#     \"strides_streams\": [[1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.3, 0.4, 0.5]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "SCNN_1_3_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2],\n",
    "    \"filters_streams\": [[64, 64, 64]],\n",
    "    \"kernels_streams\": [[7, 5, 3]],\n",
    "    \"kernels_init_streams\": [[\"he_normal\", \"he_normal\", \"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\",\"l1_l2\", \"l1_l2\"]],\n",
    "    \"strides_streams\": [[1, 1, 1]],\n",
    "    \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "    \"dropouts_streams\": [[0.3, 0.3, 0.3]],\n",
    "    \"activations_streams\": [['relu', 'relu', 'relu']],\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.3], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "# SCNN_1_2_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[32, 64]],\n",
    "#     \"kernels_streams\": [[5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\"]],\n",
    "#     \"strides_streams\": [[1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.2, 0.3]],\n",
    "#     \"activations_streams\": [['relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "    \n",
    "\n",
    "# }\n",
    "\n",
    "# SCNN_1_1_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[64]],\n",
    "#     \"kernels_streams\": [[3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3]],\n",
    "#     \"strides_streams\": [[1]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\"]],\n",
    "#     \"paddings_streams\": [[\"same\"]],\n",
    "#     \"dropouts_streams\": [[0.2]],\n",
    "#     \"activations_streams\": [['relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "# }\n",
    "\n",
    "# SCNN_1_2_conv_2_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[64, 128]],\n",
    "#     \"kernels_streams\": [[5, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3]],\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\"]],\n",
    "#     \"strides_streams\": [[1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.2, 0.3]],\n",
    "#     \"activations_streams\": [['relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [32, 32],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3, 3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1\", \"l2\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\", \"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2, 0.2], \n",
    "#     \"dense_activations\": ['relu', \"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-3,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "pool_dict= {\n",
    "    \"num_filters_pool\": [8, 16, 32, 64, 128, 256],\n",
    "    \"kernel_size_pool\": [3, 5, 7, 9],\n",
    "    \"kernel_init_pool\": ['truncated_normal', 'orthogonal', 'uniform', 'lecun_normal', 'lecun_uniform', 'normal', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n",
    "    \"stride_pool\": [1 ,2 ,3 , 4],\n",
    "    \"padding_pool\": [\"valid\", \"same\", \"causal\"], # \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t+1:]. \n",
    "    # Useful when modeling temporal data where the model should not violate the temporal order. See WaveNet: A Generative Model for Raw Audio, section 2.1.\n",
    "    \"dropout_pool\": [0, .1, .2, .3, .4, .5],\n",
    "    \"activation_pool\": ['softplus', 'softsign', 'relu', 'elu', 'gelu', 'selu', 'swish', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear', \"LeakyReLU\"],\n",
    "    \"num_dense_neuron_pool\": [8, 16, 32, 64, 84, 128, 256],\n",
    "    \"kernel_Max_Norm_constraints_pool\": [3, 4, 5],\n",
    "    \"kernel_regularizer_pool\": [\"l1\", \"l2\", \"l1_l2\"],\n",
    "    \n",
    "    \"optimizer_name_pool\": [\"Adam\", \"Nadam\" , \"RMSprop\", \"Adadelta\", \"Adagrad\", \"Adamax\"],#SGD\n",
    "    \"optimizer_lr_pool\": [1e-5, 5e-5 ,1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1],#1e-5, 5e-5, [1e-4, 2e-4, 3e-4, 4e-4, 5e-4], #\n",
    "    \"batch_size_pool\": [32, 64, 128, 256, 512, 1024],\n",
    "    \"contrastive_loss_margin_pool\": [.5, .6, .7, .8, .9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5],\n",
    "    \n",
    "}\n",
    "# try model hyperparameter optimization using the updated method (reduceLROnPlateau) instead of early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fca4d6-48f9-486a-8d54-8f8e02d6dc49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cnn_arch_dict = {\n",
    "#                 \"SCNN_1_3_conv_1_dense_arg_dict_default\": SCNN_1_3_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_3_123_conv_1_dense_arg_dict_default\": SCNN_3_123_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_3_1_conv_1_dense_arg_dict_default\": SCNN_3_1_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_1_2_conv_1_dense_arg_dict_default\": SCNN_1_2_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_1_1_conv_1_dense_arg_dict_default\": SCNN_1_1_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_1_2_conv_2_dense_arg_dict_default\": SCNN_1_2_conv_2_dense_arg_dict_default,\n",
    "#                 \"SCNN_1_5_conv_1_dense_arg_dict_default\": SCNN_1_5_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_4_1234_conv_1_dense_arg_dict_default\": SCNN_4_1234_conv_1_dense_arg_dict_default,\n",
    "# }\n",
    "# cnn_arch_dict = {\n",
    "                # \"SCNN_simple_1_5_conv_1_dense_arg_dict_default\": SCNN_simple_1_5_conv_1_dense_arg_dict_default,\n",
    "                 # \"SCNN_1_5_conv_1_dense_arg_dict_default\": SCNN_1_5_conv_1_dense_arg_dict_default,\n",
    "                # \"SCNN_4_1234_conv_1_dense_arg_dict_default\": SCNN_4_1234_conv_1_dense_arg_dict_default}\n",
    "\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.02,)],[(0.02,)], [(0.02,)]],\n",
    "\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.5], [0.5], [0.5]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [32],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.02,)],\n",
    "\n",
    "    \"dense_kernel_inits\": [\"glorot_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"tanh\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01)],[(0.01,0.01)], [(0.01,0.01)]],\n",
    "\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.5], [0.5], [0.5]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "\n",
    "    \"dense_kernel_inits\": [\"glorot_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"relu\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\"], #8**3\n",
    "                             [\"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01)],[(0.01,0.01)], [(0.01,0.01)]],\n",
    "\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.25], [0.25], [0.25]], #5**3\n",
    "    \"activations_streams\": [['elu'], ['elu'], ['elu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "\n",
    "    \"dense_kernel_inits\": [\"he_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"elu\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\"], #8**3\n",
    "                             [\"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01)],[(0.01,0.01)], [(0.01,0.01)]],\n",
    "\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.25], [0.25], [0.25]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "\n",
    "    \"dense_kernel_inits\": [\"he_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"linear\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"he_normal\"], [\"he_normal\"], #8**3\n",
    "                             [\"he_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[5], [5], [5]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.001,0.01)],[(0.001,0.01)], [(0.001,0.01)]],\n",
    "\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.25], [0.25], [0.25]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[5],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.005,0.01)],\n",
    "\n",
    "    \"dense_kernel_inits\": [\"he_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"linear\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "# SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "#     \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"lecun_normal\"], [\"lecun_normal\"], #8**3\n",
    "#                              [\"lecun_normal\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "#     \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01)],[(0.01,0.01)], [(0.01,0.01)]],\n",
    "\n",
    "#     \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[0.25], [0.25], [0.25]], #5**3\n",
    "#     \"activations_streams\": [['selu'], ['selu'], ['selu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [64],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "#     \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "#     \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "\n",
    "#     \"dense_kernel_inits\": [\"lecun_normal\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"selu\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-2,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "    \n",
    "# }\n",
    "\n",
    "# SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0], #5**3\n",
    "#     \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "#                              [\"glorot_normal\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3.0], [3.0], [3.0]], #3**3\n",
    "#     \"conv_kernel_regularizer_streams\": [[\"l2\"],[\"l2\"], [\"l2\"]],\n",
    "#     \"conv_kernel_regularizer_strength_streams\": [[(.0005,)],[(.0005,)], [(.0005,)]],\n",
    "\n",
    "#     \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[0.1], [0.1], [0.1]], #5**3\n",
    "#     \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [32],\n",
    "#     \"dense_kernel_Max_Norm_constraints\":[3.0],\n",
    "#     \"dense_kernel_regularizer\":[\"l2\"],\n",
    "#     \"dense_kernel_regularizer_strength\":[(.0005,)],\n",
    "\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 1e-2,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 512,\n",
    "    \n",
    "# }\n",
    "cnn_arch_dict = {\n",
    "                    # \"SCNN_3_123_conv_1_dense_arg_dict_default\": SCNN_3_123_conv_1_dense_arg_dict_default,\n",
    "                    # \"SCNN_3_1_conv_1_dense_arg_dict_default\": SCNN_3_1_conv_1_dense_arg_dict_default,\n",
    "\n",
    "                # \"SCNN_1_3_conv_1_dense_arg_dict_default\": SCNN_1_3_conv_1_dense_arg_dict_default,\n",
    "                # \"SCNN_3_1_conv_3_dense_arg_dict_default\": SCNN_3_1_conv_3_dense_arg_dict_default,\n",
    "                # \"SCNN_3_2_conv_1_dense_arg_dict_default\": SCNN_3_2_conv_1_dense_arg_dict_default,\n",
    "                \"SCNN_3_1_conv_1_dense_arg_dict_default\": SCNN_3_1_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_4_1_conv_1_dense_arg_dict_default\": SCNN_4_1_conv_1_dense_arg_dict_default,\n",
    "\n",
    "#                 \"SCNN_3_1_conv_2_dense_arg_dict_default\": SCNN_3_1_conv_2_dense_arg_dict_default,\n",
    "#                 \"SCNN_5_1_conv_1_dense_arg_dict_default\": SCNN_5_1_conv_1_dense_arg_dict_default,\n",
    "        \n",
    "#                 # \"SCNN_4_1234_conv_1_dense_arg_dict_default\": SCNN_4_1234_conv_1_dense_arg_dict_default,\n",
    "#                 \"SCNN_3_123_conv_1_dense_arg_dict_default\": SCNN_3_123_conv_1_dense_arg_dict_default,\n",
    "}\n",
    "%run ./Classification_utility-functions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9172453c-2c3e-4fc9-8996-8bfa100cb89d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n"
     ]
    }
   ],
   "source": [
    "P.model_variant = 'multi_head_fcn'\n",
    "P.tuning_metric=\"eer_val\"\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01, 0.01)],[(0.01,0.01)], [(0.01,0.01)]],\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.25], [0.25], [0.25]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[5],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "    \"dense_kernel_inits\": [\"he_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"linear\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SCNN_3_2_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[32, 32], [32, 32], [32, 32]], #6**3\n",
    "    \"kernels_streams\": [[7, 3], [5, 3], [3, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\", \"glorot_normal\"], [\"glorot_normal\", \"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3], [3, 3], [3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\", \"l1_l2\"],[\"l1_l2\", \"l1_l2\"], [\"l1_l2\", \"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01), (0.01,0.01)],[(0.01,0.01), (0.01,0.01)], [(0.01,0.01), (0.01,0.01)]],\n",
    "    \"strides_streams\": [[1, 1], [1, 1], [1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\", \"same\"], [\"same\", \"same\"], [\"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.25, .25], [.25, .25], [.25, .25]], #5**3\n",
    "    \"activations_streams\": [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[5],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "    \"dense_kernel_inits\": [\"he_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"linear\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "SCNN_3_123_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32, 32], [32, 32, 32]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\", \"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\", \"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"], [\"l1_l2\",\"l1_l2\"], [\"l1_l2\",\"l1_l2\", \"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01)],[(0.01,0.01), (0.01,0.01)], [(0.01,0.01), (0.01,0.01), (0.01,0.01)]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\", \"same\"], [\"same\", \"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.25], [.25, .25], [.25, .25, .25]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[5],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "    \"dense_kernel_inits\": [\"he_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"linear\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SCNN_1_3_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2],\n",
    "    \"filters_streams\": [[64, 64, 64]],\n",
    "    \"kernels_streams\": [[7, 5, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\", \"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\", \"l1_l2\", \"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01), (0.01,0.01), (0.01,0.01)]],\n",
    "    \"strides_streams\": [[1, 1, 1]],\n",
    "    \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "    \"dropouts_streams\": [[0.25, 0.25, 0.25]],\n",
    "    \"activations_streams\": [['tanh', 'tanh', 'tanh']],\n",
    "    \n",
    "    \"dense_layers\": [64],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[5],\n",
    "    \"dense_kernel_regularizer\":[\"l1_l2\"],\n",
    "    \"dense_kernel_regularizer_strength\":[(0.01,0.01)],\n",
    "    \"dense_kernel_inits\": [\"he_normal\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"linear\"],\n",
    "\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "SCNN_3_1_conv_0_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"],[\"l1_l2\"], [\"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01, 0.01)],[(0.01,0.01)], [(0.01,0.01)]],\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[0.25], [0.25], [0.25]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh'], ['tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[],\n",
    "    \"dense_kernel_regularizer\":[],\n",
    "    \"dense_kernel_regularizer_strength\":[],\n",
    "    \"dense_kernel_inits\": [],\n",
    "    \"dense_dropouts\": [], \n",
    "    \"dense_activations\": [],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SCNN_3_2_conv_0_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2, 0.2, 0.2], #5**3\n",
    "    \"filters_streams\": [[32, 32], [32, 32], [32, 32]], #6**3\n",
    "    \"kernels_streams\": [[7, 3], [5, 3], [3, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\", \"glorot_normal\"], [\"glorot_normal\", \"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3], [3, 3], [3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\", \"l1_l2\"],[\"l1_l2\", \"l1_l2\"], [\"l1_l2\", \"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.0,0.01), (0.01,0.01)],[(0.0,0.01), (0.01,0.01)], [(0.0,0.01), (0.01,0.01)]],\n",
    "    \"strides_streams\": [[1, 1], [1, 1], [1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\", \"same\"], [\"same\", \"same\"], [\"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.25, .25], [.25, .25], [.25, .25]], #5**3\n",
    "    \"activations_streams\": [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[],\n",
    "    \"dense_kernel_regularizer\":[],\n",
    "    \"dense_kernel_regularizer_strength\":[],\n",
    "    \"dense_kernel_inits\": [],\n",
    "    \"dense_dropouts\": [], \n",
    "    \"dense_activations\": [],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_3_123_conv_0_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[32], [32, 32], [32, 32, 32]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\"], [\"glorot_normal\", \"glorot_normal\"], #8**3\n",
    "                             [\"glorot_normal\", \"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\"], [\"l1_l2\",\"l1_l2\"], [\"l1_l2\",\"l1_l2\", \"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01)],[(0.01,0.01), (0.01,0.01)], [(0.01,0.01), (0.01,0.01), (0.01,0.01)]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\", \"same\"], [\"same\", \"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.25], [.25, .25], [.25, .25, .25]], #5**3\n",
    "    \"activations_streams\": [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[],\n",
    "    \"dense_kernel_regularizer\":[],\n",
    "    \"dense_kernel_regularizer_strength\":[],\n",
    "    \"dense_kernel_inits\": [],\n",
    "    \"dense_dropouts\": [], \n",
    "    \"dense_activations\": [],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "SCNN_1_3_conv_0_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2],\n",
    "    \"filters_streams\": [[64, 64, 64]],\n",
    "    \"kernels_streams\": [[7, 5, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_normal\", \"glorot_normal\", \"glorot_normal\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1_l2\", \"l1_l2\", \"l1_l2\"]],\n",
    "    \"conv_kernel_regularizer_strength_streams\": [[(0.01,0.01), (0.01,0.01), (0.01,0.01)]],\n",
    "    \"strides_streams\": [[1, 1, 1]],\n",
    "    \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "    \"dropouts_streams\": [[0.25, 0.25, 0.25]],\n",
    "    \"activations_streams\": [['tanh', 'tanh', 'tanh']],\n",
    "    \n",
    "    \"dense_layers\": [],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[],\n",
    "    \"dense_kernel_regularizer\":[],\n",
    "    \"dense_kernel_regularizer_strength\":[],\n",
    "    \"dense_kernel_inits\": [],\n",
    "    \"dense_dropouts\": [], \n",
    "    \"dense_activations\": [],\n",
    "\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": .5,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-3,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 256,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "cnn_arch_dict = {\n",
    "                \"SCNN_3_1_conv_1_dense_arg_dict_default\": SCNN_3_1_conv_1_dense_arg_dict_default,\n",
    "                \"SCNN_3_2_conv_1_dense_arg_dict_default\": SCNN_3_2_conv_1_dense_arg_dict_default,\n",
    "                \"SCNN_1_3_conv_1_dense_arg_dict_default\": SCNN_1_3_conv_1_dense_arg_dict_default,\n",
    "                \"SCNN_3_123_conv_1_dense_arg_dict_default\": SCNN_3_123_conv_1_dense_arg_dict_default,\n",
    "    \n",
    "                # \"SCNN_3_1_conv_0_dense_arg_dict_default\": SCNN_3_1_conv_0_dense_arg_dict_default,\n",
    "                # \"SCNN_1_3_conv_0_dense_arg_dict_default\": SCNN_1_3_conv_0_dense_arg_dict_default,\n",
    "                # \"SCNN_3_2_conv_0_dense_arg_dict_default\": SCNN_3_2_conv_0_dense_arg_dict_default,\n",
    "                # \"SCNN_3_123_conv_0_dense_arg_dict_default\": SCNN_3_123_conv_0_dense_arg_dict_default,\n",
    "\n",
    "}\n",
    "%run ./Classification_utility-functions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4112fe1-e78f-4aca-9a9a-319c2887cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_config_dict(desc=''):\n",
    "    dir_name = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_dir = f\"siamese_cnn_results_final\"\n",
    "    with open(f\"{save_dir}/results_dict_{desc}{dir_name}.json\", 'w') as file:\n",
    "            results_dict_json = json.dumps(results_dict)\n",
    "            file.write(results_dict_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d74b47-bdd4-4776-804a-97a13b319048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "# direct=\"results_dict_Butter33-SMA20-cv1-1000-SCNN_1_3_conv_1_dense_arg_dict_default\"\n",
    "# with open(f\"siamese_cnn_results_final/{direct}.json\", 'r') as file:\n",
    "#     results_dict=json.load(file)\n",
    "    \n",
    "def save_training_config_dict(desc=''):\n",
    "    dir_name = '' # temprarily disable time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_dir = f\"siamese_cnn_results_final\"\n",
    "    with open(f\"{save_dir}/results_dict_{desc}{dir_name}.json\", 'w') as file:\n",
    "            results_dict_json = json.dumps(results_dict)\n",
    "            file.write(results_dict_json)\n",
    "           \n",
    "P.smoothing=None\n",
    "P.cut_off_freq=None\n",
    "# report_dict={    \n",
    "#             # \"Training_samples\": str(np.unique(y_train, return_counts=True)),\n",
    "#             # \"Validation_samples\": str(np.unique(y_valid, return_counts=True)),\n",
    "#             \"smoothing\": P.smoothing,\n",
    "#             # \"EMA_span\": P.span if \"EMA\" in P.smoothing else None ,\n",
    "#             \"Butter_cut_off_freq\": P.cut_off_freq,\n",
    "#             \"scaler\": P.scaler,\n",
    "#     }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1d5217-918f-4415-8b02-363c05563121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_arr_exp3=np.array(train_set)\n",
    "# # randomized_data_idx\n",
    "# # Remove the element with the value 3\n",
    "# bool_idx = (train_set_arr_exp3 != 28)# corresponds to user 49\n",
    "# filterred_train_set_arr_exp3 = train_set_arr_exp3[bool_idx]\n",
    "# filterred_train_set_arr_exp3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c199eca-e9ac-4c42-a5c8-7ed45797f3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['125', '250', '500', '750', '1000'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911bf360-da86-46b6-a126-078dd3fa9903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1000': {}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b054712-b826-465c-8345-7a40307e05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(15, 50, 5))\n",
    "train_set=THREE_FOLD_CV[0][0]\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1ba23-3f56-4f35-9b71-447072e1f0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n",
      "Seed was set to: 567\n",
      "cut_off_freq: 33, winsize: 20\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "using flipped data\n",
      "674\n",
      "0.002847387931565832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 12/12 [12:58<00:00, 64.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n",
      "0.014797171763421357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [01:29<00:00, 12.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   31104, shape: (31104, 125, 6), class balance: (array([0., 1.], dtype=float32), array([15576, 15528]))\n",
      "Validation samples: 23520, shape: (23520, 125, 6), class balance: (array([0., 1.], dtype=float32), array([11760, 11760]))\n",
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "Using Model variant multi_head_fcn...\n",
      "0.001\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[(0.01, 0.01)], [(0.01, 0.01)], [(0.01, 0.01)]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [(0.01, 0.01)], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 22:35:50.332057: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-30 22:35:51.172975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43490 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:ca:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================[ Initial State ]================================"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-30 22:35:54.717006: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-07-30 22:35:56.233280: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2023-07-30 22:35:57.467253: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-30 22:35:57.508843: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-30 22:35:57.508901: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2023-07-30 22:35:57.511084: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-30 22:35:57.511270: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-07-30 22:35:58.644087: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN: roc_auc: 0.7105, eer: 0.3430, thres: 0.3075 => acc: 0.6571, f1: 0.6567\n",
      "\n",
      "\n",
      "VALID: roc_auc: 0.8972, eer: 0.1704, thres: 0.3723 => acc: 0.8296, f1: 0.8296\n",
      "\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 7s 30ms/step - loss: 22.5760 - val_loss: 11.4295\n",
      "================================[   Epoch 0   ]================================\n",
      "TRAIN: roc_auc: 0.5421, eer: 0.4793, thres: 0.9310 => acc: 0.5208, f1: 0.5204\n",
      "loss: 22.576, val_loss: 11.429\n",
      "\n",
      "VALID: roc_auc: 0.7405, eer: 0.3220, thres: 1.2873 => acc: 0.6780, f1: 0.6780\n",
      "loss: 22.576, val_loss: 11.429\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 13.8215 - val_loss: 7.0065\n",
      "================================[   Epoch 1   ]================================\n",
      "TRAIN: roc_auc: 0.5259, eer: 0.4884, thres: 1.1477 => acc: 0.5116, f1: 0.5112\n",
      "loss: 13.822, val_loss: 7.007\n",
      "\n",
      "VALID: roc_auc: 0.6530, eer: 0.3630, thres: 1.4641 => acc: 0.6370, f1: 0.6370\n",
      "loss: 13.822, val_loss: 7.007\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 3s 27ms/step - loss: 7.7621 - val_loss: 3.0451\n",
      "================================[   Epoch 2   ]================================\n",
      "TRAIN: roc_auc: 0.5248, eer: 0.4877, thres: 0.7846 => acc: 0.5123, f1: 0.5119\n",
      "loss: 7.762, val_loss: 3.045\n",
      "\n",
      "VALID: roc_auc: 0.6852, eer: 0.3499, thres: 1.0191 => acc: 0.6501, f1: 0.6501\n",
      "loss: 7.762, val_loss: 3.045\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 3s 21ms/step - loss: 3.0248 - val_loss: 0.9433\n",
      "================================[   Epoch 3   ]================================\n",
      "TRAIN: roc_auc: 0.5336, eer: 0.4823, thres: 0.2995 => acc: 0.5178, f1: 0.5174\n",
      "loss: 3.025, val_loss: 0.943\n",
      "\n",
      "VALID: roc_auc: 0.7462, eer: 0.3285, thres: 0.4048 => acc: 0.6716, f1: 0.6715\n",
      "loss: 3.025, val_loss: 0.943\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.7239 - val_loss: 0.3384\n",
      "================================[   Epoch 4   ]================================\n",
      "TRAIN: roc_auc: 0.7776, eer: 0.2890, thres: 0.0521 => acc: 0.7111, f1: 0.7107\n",
      "loss: 0.724, val_loss: 0.338\n",
      "\n",
      "VALID: roc_auc: 0.8934, eer: 0.1827, thres: 0.0666 => acc: 0.8173, f1: 0.8173\n",
      "loss: 0.724, val_loss: 0.338\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 6s 51ms/step - loss: 0.2531 - val_loss: 0.1729\n",
      "================================[   Epoch 5   ]================================\n",
      "TRAIN: roc_auc: 0.7966, eer: 0.2772, thres: 0.1257 => acc: 0.7228, f1: 0.7225\n",
      "loss: 0.253, val_loss: 0.173\n",
      "\n",
      "VALID: roc_auc: 0.8719, eer: 0.2099, thres: 0.1749 => acc: 0.7902, f1: 0.7902\n",
      "loss: 0.253, val_loss: 0.173\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 6s 51ms/step - loss: 0.1489 - val_loss: 0.1050\n",
      "================================[   Epoch 6   ]================================\n",
      "TRAIN: roc_auc: 0.8116, eer: 0.2599, thres: 0.1601 => acc: 0.7401, f1: 0.7398\n",
      "loss: 0.149, val_loss: 0.105\n",
      "\n",
      "VALID: roc_auc: 0.9064, eer: 0.1600, thres: 0.2240 => acc: 0.8400, f1: 0.8400\n",
      "loss: 0.149, val_loss: 0.105\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 0.1022 - val_loss: 0.0753\n",
      "================================[   Epoch 7   ]================================\n",
      "TRAIN: roc_auc: 0.8151, eer: 0.2578, thres: 0.1735 => acc: 0.7422, f1: 0.7419\n",
      "loss: 0.102, val_loss: 0.075\n",
      "\n",
      "VALID: roc_auc: 0.8983, eer: 0.1689, thres: 0.2460 => acc: 0.8311, f1: 0.8311\n",
      "loss: 0.102, val_loss: 0.075\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 5s 41ms/step - loss: 0.0790 - val_loss: 0.0582\n",
      "================================[   Epoch 8   ]================================\n",
      "TRAIN: roc_auc: 0.8170, eer: 0.2527, thres: 0.1744 => acc: 0.7473, f1: 0.7470\n",
      "loss: 0.079, val_loss: 0.058\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1636, thres: 0.2388 => acc: 0.8364, f1: 0.8364\n",
      "loss: 0.079, val_loss: 0.058\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 0.0673 - val_loss: 0.0520\n",
      "================================[   Epoch 9   ]================================\n",
      "TRAIN: roc_auc: 0.8177, eer: 0.2532, thres: 0.1883 => acc: 0.7468, f1: 0.7466\n",
      "loss: 0.067, val_loss: 0.052\n",
      "\n",
      "VALID: roc_auc: 0.9026, eer: 0.1650, thres: 0.2564 => acc: 0.8351, f1: 0.8351\n",
      "loss: 0.067, val_loss: 0.052\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 6s 45ms/step - loss: 0.0622 - val_loss: 0.0502\n",
      "================================[   Epoch 10   ]================================\n",
      "TRAIN: roc_auc: 0.8160, eer: 0.2559, thres: 0.1874 => acc: 0.7442, f1: 0.7439\n",
      "loss: 0.062, val_loss: 0.050\n",
      "\n",
      "VALID: roc_auc: 0.9026, eer: 0.1639, thres: 0.2595 => acc: 0.8361, f1: 0.8361\n",
      "loss: 0.062, val_loss: 0.050\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 5s 45ms/step - loss: 0.0606 - val_loss: 0.0447\n",
      "================================[   Epoch 11   ]================================\n",
      "TRAIN: roc_auc: 0.8172, eer: 0.2561, thres: 0.1734 => acc: 0.7440, f1: 0.7437\n",
      "loss: 0.061, val_loss: 0.045\n",
      "\n",
      "VALID: roc_auc: 0.9090, eer: 0.1552, thres: 0.2342 => acc: 0.8448, f1: 0.8448\n",
      "loss: 0.061, val_loss: 0.045\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 6s 46ms/step - loss: 0.0595 - val_loss: 0.0461\n",
      "================================[   Epoch 12   ]================================\n",
      "TRAIN: roc_auc: 0.8187, eer: 0.2528, thres: 0.1734 => acc: 0.7471, f1: 0.7468\n",
      "loss: 0.059, val_loss: 0.046\n",
      "\n",
      "VALID: roc_auc: 0.9069, eer: 0.1604, thres: 0.2411 => acc: 0.8397, f1: 0.8397\n",
      "loss: 0.059, val_loss: 0.046\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 0.0593 - val_loss: 0.0487\n",
      "================================[   Epoch 13   ]================================\n",
      "TRAIN: roc_auc: 0.8200, eer: 0.2533, thres: 0.1822 => acc: 0.7467, f1: 0.7464\n",
      "loss: 0.059, val_loss: 0.049\n",
      "\n",
      "VALID: roc_auc: 0.8977, eer: 0.1721, thres: 0.2515 => acc: 0.8278, f1: 0.8277\n",
      "loss: 0.059, val_loss: 0.049\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 5s 43ms/step - loss: 0.0525 - val_loss: 0.0405\n",
      "================================[   Epoch 14   ]================================\n",
      "TRAIN: roc_auc: 0.8202, eer: 0.2525, thres: 0.1811 => acc: 0.7475, f1: 0.7472\n",
      "loss: 0.053, val_loss: 0.041\n",
      "\n",
      "VALID: roc_auc: 0.9024, eer: 0.1639, thres: 0.2499 => acc: 0.8361, f1: 0.8361\n",
      "loss: 0.053, val_loss: 0.041\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 0.0521 - val_loss: 0.0394\n",
      "================================[   Epoch 15   ]================================\n",
      "TRAIN: roc_auc: 0.8203, eer: 0.2519, thres: 0.1757 => acc: 0.7481, f1: 0.7478\n",
      "loss: 0.052, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9041, eer: 0.1615, thres: 0.2435 => acc: 0.8385, f1: 0.8385\n",
      "loss: 0.052, val_loss: 0.039\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 8s 62ms/step - loss: 0.0520 - val_loss: 0.0407\n",
      "================================[   Epoch 16   ]================================\n",
      "TRAIN: roc_auc: 0.8203, eer: 0.2522, thres: 0.1794 => acc: 0.7478, f1: 0.7475\n",
      "loss: 0.052, val_loss: 0.041\n",
      "\n",
      "VALID: roc_auc: 0.9023, eer: 0.1642, thres: 0.2502 => acc: 0.8358, f1: 0.8358\n",
      "loss: 0.052, val_loss: 0.041\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 3s 27ms/step - loss: 0.0522 - val_loss: 0.0406\n",
      "================================[   Epoch 17   ]================================\n",
      "TRAIN: roc_auc: 0.8204, eer: 0.2522, thres: 0.1802 => acc: 0.7477, f1: 0.7475\n",
      "loss: 0.052, val_loss: 0.041\n",
      "\n",
      "VALID: roc_auc: 0.9033, eer: 0.1634, thres: 0.2514 => acc: 0.8366, f1: 0.8366\n",
      "loss: 0.052, val_loss: 0.041\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 4s 31ms/step - loss: 0.0503 - val_loss: 0.0380\n",
      "================================[   Epoch 18   ]================================\n",
      "TRAIN: roc_auc: 0.8209, eer: 0.2521, thres: 0.1783 => acc: 0.7478, f1: 0.7475\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9044, eer: 0.1616, thres: 0.2483 => acc: 0.8383, f1: 0.8382\n",
      "loss: 0.050, val_loss: 0.038\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 3s 27ms/step - loss: 0.0504 - val_loss: 0.0382\n",
      "================================[   Epoch 19   ]================================\n",
      "TRAIN: roc_auc: 0.8212, eer: 0.2515, thres: 0.1788 => acc: 0.7485, f1: 0.7482\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9040, eer: 0.1623, thres: 0.2492 => acc: 0.8376, f1: 0.8376\n",
      "loss: 0.050, val_loss: 0.038\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 4s 36ms/step - loss: 0.0503 - val_loss: 0.0387\n",
      "================================[   Epoch 20   ]================================\n",
      "TRAIN: roc_auc: 0.8212, eer: 0.2517, thres: 0.1800 => acc: 0.7483, f1: 0.7480\n",
      "loss: 0.050, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9034, eer: 0.1632, thres: 0.2516 => acc: 0.8369, f1: 0.8369\n",
      "loss: 0.050, val_loss: 0.039\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 4s 31ms/step - loss: 0.0497 - val_loss: 0.0381\n",
      "================================[   Epoch 21   ]================================\n",
      "TRAIN: roc_auc: 0.8213, eer: 0.2515, thres: 0.1799 => acc: 0.7486, f1: 0.7483\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9035, eer: 0.1633, thres: 0.2510 => acc: 0.8368, f1: 0.8368\n",
      "loss: 0.050, val_loss: 0.038\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 4s 31ms/step - loss: 0.0497 - val_loss: 0.0380\n",
      "================================[   Epoch 22   ]================================\n",
      "TRAIN: roc_auc: 0.8213, eer: 0.2519, thres: 0.1796 => acc: 0.7482, f1: 0.7479\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1632, thres: 0.2507 => acc: 0.8368, f1: 0.8368\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 4s 33ms/step - loss: 0.0497 - val_loss: 0.0378\n",
      "================================[   Epoch 23   ]================================\n",
      "TRAIN: roc_auc: 0.8212, eer: 0.2518, thres: 0.1794 => acc: 0.7482, f1: 0.7479\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1633, thres: 0.2503 => acc: 0.8367, f1: 0.8367\n",
      "loss: 0.050, val_loss: 0.038\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 4s 35ms/step - loss: 0.0498 - val_loss: 0.0379\n",
      "================================[   Epoch 24   ]================================\n",
      "TRAIN: roc_auc: 0.8212, eer: 0.2517, thres: 0.1796 => acc: 0.7483, f1: 0.7480\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1633, thres: 0.2505 => acc: 0.8368, f1: 0.8368\n",
      "loss: 0.050, val_loss: 0.038\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 4s 34ms/step - loss: 0.0497 - val_loss: 0.0378\n",
      "================================[   Epoch 25   ]================================\n",
      "TRAIN: roc_auc: 0.8212, eer: 0.2517, thres: 0.1794 => acc: 0.7483, f1: 0.7480\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1635, thres: 0.2502 => acc: 0.8365, f1: 0.8365\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 4s 32ms/step - loss: 0.0495 - val_loss: 0.0378\n",
      "================================[   Epoch 26   ]================================\n",
      "TRAIN: roc_auc: 0.8212, eer: 0.2514, thres: 0.1794 => acc: 0.7486, f1: 0.7483\n",
      "loss: 0.049, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1635, thres: 0.2502 => acc: 0.8364, f1: 0.8364\n",
      "loss: 0.049, val_loss: 0.038\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8212, eer: 0.2514, thres: 0.1794 => acc: 0.7486, f1: 0.7483\n",
      "loss: 0.049, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1635, thres: 0.2502 => acc: 0.8364, f1: 0.8364\n",
      "loss: 0.049, val_loss: 0.038\n",
      "{'loss': [22.575986862182617, 13.821513175964355, 7.762075424194336, 3.024827480316162, 0.7239426374435425, 0.25314825773239136, 0.14892476797103882, 0.10217344760894775, 0.07903514802455902, 0.06726275384426117, 0.062150564044713974, 0.060618530958890915, 0.05946832895278931, 0.059261471033096313, 0.052546657621860504, 0.05207185819745064, 0.05202816054224968, 0.05220980569720268, 0.05032844468951225, 0.05039925500750542, 0.05025755241513252, 0.04971511289477348, 0.04973066970705986, 0.04971684515476227, 0.04979827255010605, 0.04972200468182564, 0.04948350042104721], 'val_loss': [11.42949104309082, 7.006502628326416, 3.045114755630493, 0.9432796835899353, 0.3383597135543823, 0.1729339361190796, 0.10504155606031418, 0.07529731839895248, 0.05819587782025337, 0.05199667066335678, 0.05023440346121788, 0.04466909170150757, 0.0460546649992466, 0.048708751797676086, 0.040519408881664276, 0.03940722346305847, 0.04072881117463112, 0.040634192526340485, 0.03798888251185417, 0.03824807330965996, 0.0386827178299427, 0.03809588775038719, 0.037982575595378876, 0.03784613683819771, 0.03785477206110954, 0.037806954234838486, 0.03778602182865143]}\n",
      "Training History:\n",
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "Using Model variant multi_head_fcn...\n",
      "0.001\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[(0.01, 0.01), (0.01, 0.01)], [(0.01, 0.01), (0.01, 0.01)], [(0.01, 0.01), (0.01, 0.01)]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [(0.01, 0.01)], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7196, eer: 0.3364, thres: 0.4101 => acc: 0.6636, f1: 0.6632\n",
      "\n",
      "\n",
      "VALID: roc_auc: 0.8920, eer: 0.1793, thres: 0.4986 => acc: 0.8207, f1: 0.8207\n",
      "\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 23s 85ms/step - loss: 28.0585 - val_loss: 18.2859\n",
      "================================[   Epoch 0   ]================================\n",
      "TRAIN: roc_auc: 0.5298, eer: 0.4872, thres: 1.4837 => acc: 0.5129, f1: 0.5125\n",
      "loss: 28.058, val_loss: 18.286\n",
      "\n",
      "VALID: roc_auc: 0.6597, eer: 0.3649, thres: 1.8836 => acc: 0.6351, f1: 0.6351\n",
      "loss: 28.058, val_loss: 18.286\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 18.5579 - val_loss: 12.0093\n",
      "================================[   Epoch 1   ]================================\n",
      "TRAIN: roc_auc: 0.5214, eer: 0.4917, thres: 1.4477 => acc: 0.5083, f1: 0.5079\n",
      "loss: 18.558, val_loss: 12.009\n",
      "\n",
      "VALID: roc_auc: 0.6020, eer: 0.4286, thres: 1.5548 => acc: 0.5715, f1: 0.5715\n",
      "loss: 18.558, val_loss: 12.009\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 8s 63ms/step - loss: 11.7860 - val_loss: 6.5819\n",
      "================================[   Epoch 2   ]================================\n",
      "TRAIN: roc_auc: 0.5239, eer: 0.4898, thres: 1.1345 => acc: 0.5102, f1: 0.5098\n",
      "loss: 11.786, val_loss: 6.582\n",
      "\n",
      "VALID: roc_auc: 0.6129, eer: 0.4139, thres: 1.2473 => acc: 0.5861, f1: 0.5861\n",
      "loss: 11.786, val_loss: 6.582\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 6s 48ms/step - loss: 6.7862 - val_loss: 3.2411\n",
      "================================[   Epoch 3   ]================================\n",
      "TRAIN: roc_auc: 0.5302, eer: 0.4856, thres: 0.7348 => acc: 0.5144, f1: 0.5140\n",
      "loss: 6.786, val_loss: 3.241\n",
      "\n",
      "VALID: roc_auc: 0.6367, eer: 0.3823, thres: 0.8882 => acc: 0.6177, f1: 0.6177\n",
      "loss: 6.786, val_loss: 3.241\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 4s 34ms/step - loss: 3.3825 - val_loss: 1.4047\n",
      "================================[   Epoch 4   ]================================\n",
      "TRAIN: roc_auc: 0.5306, eer: 0.4849, thres: 0.3647 => acc: 0.5152, f1: 0.5148\n",
      "loss: 3.382, val_loss: 1.405\n",
      "\n",
      "VALID: roc_auc: 0.7339, eer: 0.3274, thres: 0.4934 => acc: 0.6726, f1: 0.6726\n",
      "loss: 3.382, val_loss: 1.405\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 1.2895 - val_loss: 0.6260\n",
      "================================[   Epoch 5   ]================================\n",
      "TRAIN: roc_auc: 0.5465, eer: 0.4733, thres: 0.1078 => acc: 0.5267, f1: 0.5263\n",
      "loss: 1.290, val_loss: 0.626\n",
      "\n",
      "VALID: roc_auc: 0.7414, eer: 0.3188, thres: 0.1436 => acc: 0.6812, f1: 0.6812\n",
      "loss: 1.290, val_loss: 0.626\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 0.4969 - val_loss: 0.3521\n",
      "================================[   Epoch 6   ]================================\n",
      "TRAIN: roc_auc: 0.7358, eer: 0.3287, thres: 0.0907 => acc: 0.6713, f1: 0.6710\n",
      "loss: 0.497, val_loss: 0.352\n",
      "\n",
      "VALID: roc_auc: 0.8260, eer: 0.2631, thres: 0.1011 => acc: 0.7369, f1: 0.7369\n",
      "loss: 0.497, val_loss: 0.352\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 0.2860 - val_loss: 0.2161\n",
      "================================[   Epoch 7   ]================================\n",
      "TRAIN: roc_auc: 0.8151, eer: 0.2626, thres: 0.1310 => acc: 0.7375, f1: 0.7372\n",
      "loss: 0.286, val_loss: 0.216\n",
      "\n",
      "VALID: roc_auc: 0.8891, eer: 0.1871, thres: 0.1718 => acc: 0.8129, f1: 0.8129\n",
      "loss: 0.286, val_loss: 0.216\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 4s 36ms/step - loss: 0.1931 - val_loss: 0.1475\n",
      "================================[   Epoch 8   ]================================\n",
      "TRAIN: roc_auc: 0.8117, eer: 0.2610, thres: 0.1557 => acc: 0.7390, f1: 0.7387\n",
      "loss: 0.193, val_loss: 0.148\n",
      "\n",
      "VALID: roc_auc: 0.8959, eer: 0.1719, thres: 0.2086 => acc: 0.8281, f1: 0.8281\n",
      "loss: 0.193, val_loss: 0.148\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 5s 38ms/step - loss: 0.1392 - val_loss: 0.1070\n",
      "================================[   Epoch 9   ]================================\n",
      "TRAIN: roc_auc: 0.8143, eer: 0.2583, thres: 0.1641 => acc: 0.7417, f1: 0.7414\n",
      "loss: 0.139, val_loss: 0.107\n",
      "\n",
      "VALID: roc_auc: 0.9012, eer: 0.1668, thres: 0.2209 => acc: 0.8332, f1: 0.8332\n",
      "loss: 0.139, val_loss: 0.107\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 8s 64ms/step - loss: 0.1079 - val_loss: 0.0857\n",
      "================================[   Epoch 10   ]================================\n",
      "TRAIN: roc_auc: 0.8163, eer: 0.2549, thres: 0.1845 => acc: 0.7451, f1: 0.7448\n",
      "loss: 0.108, val_loss: 0.086\n",
      "\n",
      "VALID: roc_auc: 0.8999, eer: 0.1662, thres: 0.2482 => acc: 0.8339, f1: 0.8340\n",
      "loss: 0.108, val_loss: 0.086\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 7s 54ms/step - loss: 0.0890 - val_loss: 0.0688\n",
      "================================[   Epoch 11   ]================================\n",
      "TRAIN: roc_auc: 0.8141, eer: 0.2615, thres: 0.1589 => acc: 0.7385, f1: 0.7382\n",
      "loss: 0.089, val_loss: 0.069\n",
      "\n",
      "VALID: roc_auc: 0.8959, eer: 0.1745, thres: 0.2117 => acc: 0.8255, f1: 0.8255\n",
      "loss: 0.089, val_loss: 0.069\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 5s 42ms/step - loss: 0.0786 - val_loss: 0.0604\n",
      "================================[   Epoch 12   ]================================\n",
      "TRAIN: roc_auc: 0.8142, eer: 0.2588, thres: 0.1598 => acc: 0.7412, f1: 0.7409\n",
      "loss: 0.079, val_loss: 0.060\n",
      "\n",
      "VALID: roc_auc: 0.9042, eer: 0.1628, thres: 0.2114 => acc: 0.8372, f1: 0.8372\n",
      "loss: 0.079, val_loss: 0.060\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 6s 50ms/step - loss: 0.0728 - val_loss: 0.0586\n",
      "================================[   Epoch 13   ]================================\n",
      "TRAIN: roc_auc: 0.8133, eer: 0.2593, thres: 0.1710 => acc: 0.7407, f1: 0.7404\n",
      "loss: 0.073, val_loss: 0.059\n",
      "\n",
      "VALID: roc_auc: 0.8954, eer: 0.1767, thres: 0.2235 => acc: 0.8231, f1: 0.8231\n",
      "loss: 0.073, val_loss: 0.059\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 8s 67ms/step - loss: 0.0695 - val_loss: 0.0557\n",
      "================================[   Epoch 14   ]================================\n",
      "TRAIN: roc_auc: 0.8171, eer: 0.2577, thres: 0.1738 => acc: 0.7423, f1: 0.7421\n",
      "loss: 0.070, val_loss: 0.056\n",
      "\n",
      "VALID: roc_auc: 0.8953, eer: 0.1742, thres: 0.2300 => acc: 0.8258, f1: 0.8258\n",
      "loss: 0.070, val_loss: 0.056\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 4s 34ms/step - loss: 0.0680 - val_loss: 0.0524\n",
      "================================[   Epoch 15   ]================================\n",
      "TRAIN: roc_auc: 0.8199, eer: 0.2527, thres: 0.1680 => acc: 0.7473, f1: 0.7470\n",
      "loss: 0.068, val_loss: 0.052\n",
      "\n",
      "VALID: roc_auc: 0.9031, eer: 0.1635, thres: 0.2197 => acc: 0.8365, f1: 0.8365\n",
      "loss: 0.068, val_loss: 0.052\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 10s 79ms/step - loss: 0.0658 - val_loss: 0.0521\n",
      "================================[   Epoch 16   ]================================\n",
      "TRAIN: roc_auc: 0.8143, eer: 0.2581, thres: 0.1643 => acc: 0.7419, f1: 0.7416\n",
      "loss: 0.066, val_loss: 0.052\n",
      "\n",
      "VALID: roc_auc: 0.8985, eer: 0.1704, thres: 0.2118 => acc: 0.8295, f1: 0.8295\n",
      "loss: 0.066, val_loss: 0.052\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 8s 62ms/step - loss: 0.0648 - val_loss: 0.0493\n",
      "================================[   Epoch 17   ]================================\n",
      "TRAIN: roc_auc: 0.8130, eer: 0.2582, thres: 0.1472 => acc: 0.7418, f1: 0.7415\n",
      "loss: 0.065, val_loss: 0.049\n",
      "\n",
      "VALID: roc_auc: 0.9063, eer: 0.1594, thres: 0.2006 => acc: 0.8404, f1: 0.8404\n",
      "loss: 0.065, val_loss: 0.049\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 5s 42ms/step - loss: 0.0646 - val_loss: 0.0488\n",
      "================================[   Epoch 18   ]================================\n",
      "TRAIN: roc_auc: 0.8208, eer: 0.2526, thres: 0.1677 => acc: 0.7474, f1: 0.7471\n",
      "loss: 0.065, val_loss: 0.049\n",
      "\n",
      "VALID: roc_auc: 0.9115, eer: 0.1527, thres: 0.2186 => acc: 0.8474, f1: 0.8474\n",
      "loss: 0.065, val_loss: 0.049\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 0.0647 - val_loss: 0.0504\n",
      "================================[   Epoch 19   ]================================\n",
      "TRAIN: roc_auc: 0.8182, eer: 0.2537, thres: 0.1532 => acc: 0.7463, f1: 0.7460\n",
      "loss: 0.065, val_loss: 0.050\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1621, thres: 0.2011 => acc: 0.8381, f1: 0.8381\n",
      "loss: 0.065, val_loss: 0.050\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 4s 34ms/step - loss: 0.0652 - val_loss: 0.0525\n",
      "================================[   Epoch 20   ]================================\n",
      "TRAIN: roc_auc: 0.8145, eer: 0.2569, thres: 0.1772 => acc: 0.7430, f1: 0.7427\n",
      "loss: 0.065, val_loss: 0.053\n",
      "\n",
      "VALID: roc_auc: 0.9062, eer: 0.1617, thres: 0.2437 => acc: 0.8382, f1: 0.8382\n",
      "loss: 0.065, val_loss: 0.053\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 0.0550 - val_loss: 0.0409\n",
      "================================[   Epoch 21   ]================================\n",
      "TRAIN: roc_auc: 0.8185, eer: 0.2541, thres: 0.1609 => acc: 0.7459, f1: 0.7456\n",
      "loss: 0.055, val_loss: 0.041\n",
      "\n",
      "VALID: roc_auc: 0.9025, eer: 0.1656, thres: 0.2109 => acc: 0.8345, f1: 0.8345\n",
      "loss: 0.055, val_loss: 0.041\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 5s 44ms/step - loss: 0.0543 - val_loss: 0.0397\n",
      "================================[   Epoch 22   ]================================\n",
      "TRAIN: roc_auc: 0.8184, eer: 0.2537, thres: 0.1531 => acc: 0.7463, f1: 0.7460\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.9055, eer: 0.1615, thres: 0.2010 => acc: 0.8385, f1: 0.8385\n",
      "loss: 0.054, val_loss: 0.040\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 4s 35ms/step - loss: 0.0542 - val_loss: 0.0408\n",
      "================================[   Epoch 23   ]================================\n",
      "TRAIN: roc_auc: 0.8190, eer: 0.2538, thres: 0.1592 => acc: 0.7462, f1: 0.7459\n",
      "loss: 0.054, val_loss: 0.041\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1617, thres: 0.2127 => acc: 0.8384, f1: 0.8384\n",
      "loss: 0.054, val_loss: 0.041\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 4s 34ms/step - loss: 0.0543 - val_loss: 0.0401\n",
      "================================[   Epoch 24   ]================================\n",
      "TRAIN: roc_auc: 0.8199, eer: 0.2535, thres: 0.1545 => acc: 0.7465, f1: 0.7462\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.9055, eer: 0.1614, thres: 0.2058 => acc: 0.8386, f1: 0.8386\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 5s 44ms/step - loss: 0.0517 - val_loss: 0.0382\n",
      "================================[   Epoch 25   ]================================\n",
      "TRAIN: roc_auc: 0.8198, eer: 0.2526, thres: 0.1618 => acc: 0.7474, f1: 0.7471\n",
      "loss: 0.052, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9045, eer: 0.1639, thres: 0.2142 => acc: 0.8362, f1: 0.8362\n",
      "loss: 0.052, val_loss: 0.038\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.0512 - val_loss: 0.0385\n",
      "================================[   Epoch 26   ]================================\n",
      "TRAIN: roc_auc: 0.8194, eer: 0.2535, thres: 0.1637 => acc: 0.7465, f1: 0.7462\n",
      "loss: 0.051, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9032, eer: 0.1658, thres: 0.2170 => acc: 0.8342, f1: 0.8342\n",
      "loss: 0.051, val_loss: 0.038\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 6s 45ms/step - loss: 0.0514 - val_loss: 0.0380\n",
      "================================[   Epoch 27   ]================================\n",
      "TRAIN: roc_auc: 0.8199, eer: 0.2525, thres: 0.1595 => acc: 0.7475, f1: 0.7472\n",
      "loss: 0.051, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9035, eer: 0.1647, thres: 0.2106 => acc: 0.8352, f1: 0.8352\n",
      "loss: 0.051, val_loss: 0.038\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 5s 44ms/step - loss: 0.0512 - val_loss: 0.0382\n",
      "================================[   Epoch 28   ]================================\n",
      "TRAIN: roc_auc: 0.8198, eer: 0.2526, thres: 0.1611 => acc: 0.7474, f1: 0.7471\n",
      "loss: 0.051, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9037, eer: 0.1645, thres: 0.2130 => acc: 0.8356, f1: 0.8356\n",
      "loss: 0.051, val_loss: 0.038\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.0513 - val_loss: 0.0386\n",
      "================================[   Epoch 29   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2530, thres: 0.1649 => acc: 0.7471, f1: 0.7468\n",
      "loss: 0.051, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9038, eer: 0.1646, thres: 0.2184 => acc: 0.8353, f1: 0.8353\n",
      "loss: 0.051, val_loss: 0.039\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 5s 44ms/step - loss: 0.0505 - val_loss: 0.0378\n",
      "================================[   Epoch 30   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2532, thres: 0.1632 => acc: 0.7468, f1: 0.7466\n",
      "loss: 0.050, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9035, eer: 0.1651, thres: 0.2159 => acc: 0.8349, f1: 0.8349\n",
      "loss: 0.050, val_loss: 0.038\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 4s 36ms/step - loss: 0.0505 - val_loss: 0.0376\n",
      "================================[   Epoch 31   ]================================\n",
      "TRAIN: roc_auc: 0.8194, eer: 0.2532, thres: 0.1624 => acc: 0.7468, f1: 0.7466\n",
      "loss: 0.051, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9035, eer: 0.1650, thres: 0.2154 => acc: 0.8351, f1: 0.8351\n",
      "loss: 0.051, val_loss: 0.038\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.0505 - val_loss: 0.0375\n",
      "================================[   Epoch 32   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2530, thres: 0.1612 => acc: 0.7470, f1: 0.7467\n",
      "loss: 0.051, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9036, eer: 0.1649, thres: 0.2140 => acc: 0.8351, f1: 0.8351\n",
      "loss: 0.051, val_loss: 0.038\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 4s 34ms/step - loss: 0.0506 - val_loss: 0.0375\n",
      "================================[   Epoch 33   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2527, thres: 0.1622 => acc: 0.7473, f1: 0.7470\n",
      "loss: 0.051, val_loss: 0.037\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1644, thres: 0.2152 => acc: 0.8358, f1: 0.8359\n",
      "loss: 0.051, val_loss: 0.037\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 3s 27ms/step - loss: 0.0508 - val_loss: 0.0375\n",
      "================================[   Epoch 34   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2530, thres: 0.1621 => acc: 0.7470, f1: 0.7467\n",
      "loss: 0.051, val_loss: 0.038\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1645, thres: 0.2148 => acc: 0.8356, f1: 0.8356\n",
      "loss: 0.051, val_loss: 0.038\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 3s 26ms/step - loss: 0.0506 - val_loss: 0.0374\n",
      "================================[   Epoch 35   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2528, thres: 0.1617 => acc: 0.7472, f1: 0.7469\n",
      "loss: 0.051, val_loss: 0.037\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1645, thres: 0.2142 => acc: 0.8352, f1: 0.8351\n",
      "loss: 0.051, val_loss: 0.037\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.0504 - val_loss: 0.0374\n",
      "================================[   Epoch 36   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2530, thres: 0.1616 => acc: 0.7470, f1: 0.7467\n",
      "loss: 0.050, val_loss: 0.037\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1646, thres: 0.2142 => acc: 0.8353, f1: 0.8353\n",
      "loss: 0.050, val_loss: 0.037\n",
      "Epoch 38/50\n",
      "122/122 [==============================] - 4s 34ms/step - loss: 0.0506 - val_loss: 0.0373\n",
      "================================[   Epoch 37   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2528, thres: 0.1617 => acc: 0.7471, f1: 0.7469\n",
      "loss: 0.051, val_loss: 0.037\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1646, thres: 0.2141 => acc: 0.8353, f1: 0.8353\n",
      "loss: 0.051, val_loss: 0.037\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 39/50\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.0504 - val_loss: 0.0373\n",
      "================================[   Epoch 38   ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2529, thres: 0.1614 => acc: 0.7471, f1: 0.7468\n",
      "loss: 0.050, val_loss: 0.037\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1646, thres: 0.2141 => acc: 0.8353, f1: 0.8353\n",
      "loss: 0.050, val_loss: 0.037\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8195, eer: 0.2529, thres: 0.1614 => acc: 0.7471, f1: 0.7468\n",
      "loss: 0.050, val_loss: 0.037\n",
      "\n",
      "VALID: roc_auc: 0.9039, eer: 0.1646, thres: 0.2141 => acc: 0.8353, f1: 0.8353\n",
      "loss: 0.050, val_loss: 0.037\n",
      "{'loss': [28.05845069885254, 18.557918548583984, 11.786001205444336, 6.786174297332764, 3.3824920654296875, 1.2895421981811523, 0.4968723952770233, 0.286009818315506, 0.19305363297462463, 0.1391989290714264, 0.10787931084632874, 0.08895955979824066, 0.07855638861656189, 0.0727897435426712, 0.06952846050262451, 0.06797091662883759, 0.06583068519830704, 0.06483600288629532, 0.06457845866680145, 0.06470661610364914, 0.06516105681657791, 0.055012013763189316, 0.05430102348327637, 0.05422553792595863, 0.05428270250558853, 0.051680535078048706, 0.0512072779238224, 0.05136849731206894, 0.05117148905992508, 0.05125996097922325, 0.050496142357587814, 0.05054613575339317, 0.05051898583769798, 0.050560612231492996, 0.05076286196708679, 0.05062307417392731, 0.0504225417971611, 0.050554193556308746, 0.0504322350025177], 'val_loss': [18.285850524902344, 12.009268760681152, 6.58189058303833, 3.241102933883667, 1.40468168258667, 0.6260210871696472, 0.3520869314670563, 0.21605859696865082, 0.14754939079284668, 0.10698480904102325, 0.08569443970918655, 0.06882983446121216, 0.0603632926940918, 0.05863065645098686, 0.05568791180849075, 0.05238916352391243, 0.05211615934967995, 0.049345869570970535, 0.04880213737487793, 0.05035380646586418, 0.05253332853317261, 0.04086067155003548, 0.039737749844789505, 0.04079538583755493, 0.04013288393616676, 0.038226597011089325, 0.03845888376235962, 0.03799639642238617, 0.03818491846323013, 0.03857509419322014, 0.037766262888908386, 0.0376378633081913, 0.03751629590988159, 0.0374889150261879, 0.03752570226788521, 0.03737477958202362, 0.03735367953777313, 0.03734844550490379, 0.03731795400381088]}\n",
      "Training History:\n",
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "Using Model variant multi_head_fcn...\n",
      "0.001\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[(0.01, 0.01), (0.01, 0.01), (0.01, 0.01)]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [(0.01, 0.01)], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7062, eer: 0.3476, thres: 0.3025 => acc: 0.6525, f1: 0.6521\n",
      "\n",
      "\n",
      "VALID: roc_auc: 0.8921, eer: 0.1844, thres: 0.3532 => acc: 0.8157, f1: 0.8157\n",
      "\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 7s 33ms/step - loss: 32.7805 - val_loss: 20.0275\n",
      "================================[   Epoch 0   ]================================\n",
      "TRAIN: roc_auc: 0.5211, eer: 0.4895, thres: 1.2304 => acc: 0.5105, f1: 0.5101\n",
      "loss: 32.780, val_loss: 20.027\n",
      "\n",
      "VALID: roc_auc: 0.6887, eer: 0.3602, thres: 1.5913 => acc: 0.6398, f1: 0.6397\n",
      "loss: 32.780, val_loss: 20.027\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 19.5289 - val_loss: 10.2653\n",
      "================================[   Epoch 1   ]================================\n",
      "TRAIN: roc_auc: 0.5241, eer: 0.4884, thres: 0.9761 => acc: 0.5116, f1: 0.5112\n",
      "loss: 19.529, val_loss: 10.265\n",
      "\n",
      "VALID: roc_auc: 0.5865, eer: 0.4502, thres: 0.9445 => acc: 0.5499, f1: 0.5499\n",
      "loss: 19.529, val_loss: 10.265\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 11.4509 - val_loss: 6.0766\n",
      "================================[   Epoch 2   ]================================\n",
      "TRAIN: roc_auc: 0.5218, eer: 0.4872, thres: 1.0731 => acc: 0.5129, f1: 0.5125\n",
      "loss: 11.451, val_loss: 6.077\n",
      "\n",
      "VALID: roc_auc: 0.6002, eer: 0.4340, thres: 1.0367 => acc: 0.5659, f1: 0.5659\n",
      "loss: 11.451, val_loss: 6.077\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 3s 29ms/step - loss: 6.9427 - val_loss: 2.8764\n",
      "================================[   Epoch 3   ]================================\n",
      "TRAIN: roc_auc: 0.5319, eer: 0.4797, thres: 0.5524 => acc: 0.5203, f1: 0.5199\n",
      "loss: 6.943, val_loss: 2.876\n",
      "\n",
      "VALID: roc_auc: 0.6743, eer: 0.3719, thres: 0.6216 => acc: 0.6281, f1: 0.6281\n",
      "loss: 6.943, val_loss: 2.876\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 3s 24ms/step - loss: 3.2645 - val_loss: 1.3968\n",
      "================================[   Epoch 4   ]================================\n",
      "TRAIN: roc_auc: 0.5315, eer: 0.4825, thres: 0.2476 => acc: 0.5175, f1: 0.5171\n",
      "loss: 3.264, val_loss: 1.397\n",
      "\n",
      "VALID: roc_auc: 0.6937, eer: 0.3617, thres: 0.2848 => acc: 0.6382, f1: 0.6382\n",
      "loss: 3.264, val_loss: 1.397\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 1.2428 - val_loss: 0.6828\n",
      "================================[   Epoch 5   ]================================\n",
      "TRAIN: roc_auc: 0.5834, eer: 0.4488, thres: 0.0675 => acc: 0.5512, f1: 0.5508\n",
      "loss: 1.243, val_loss: 0.683\n",
      "\n",
      "VALID: roc_auc: 0.7617, eer: 0.3187, thres: 0.0723 => acc: 0.6813, f1: 0.6813\n",
      "loss: 1.243, val_loss: 0.683\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 3s 23ms/step - loss: 0.5353 - val_loss: 0.4044\n",
      "================================[   Epoch 6   ]================================\n",
      "TRAIN: roc_auc: 0.7956, eer: 0.2797, thres: 0.0591 => acc: 0.7203, f1: 0.7200\n",
      "loss: 0.535, val_loss: 0.404\n",
      "\n",
      "VALID: roc_auc: 0.8398, eer: 0.2407, thres: 0.0779 => acc: 0.7592, f1: 0.7592\n",
      "loss: 0.535, val_loss: 0.404\n",
      "Epoch 8/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.3396 - val_loss: 0.2803\n",
      "================================[   Epoch 7   ]================================\n",
      "TRAIN: roc_auc: 0.7919, eer: 0.2855, thres: 0.1152 => acc: 0.7145, f1: 0.7142\n",
      "loss: 0.340, val_loss: 0.280\n",
      "\n",
      "VALID: roc_auc: 0.8402, eer: 0.2420, thres: 0.1501 => acc: 0.7580, f1: 0.7580\n",
      "loss: 0.340, val_loss: 0.280\n",
      "Epoch 9/50\n",
      "122/122 [==============================] - 3s 27ms/step - loss: 0.2519 - val_loss: 0.2083\n",
      "================================[   Epoch 8   ]================================\n",
      "TRAIN: roc_auc: 0.7921, eer: 0.2825, thres: 0.1444 => acc: 0.7176, f1: 0.7172\n",
      "loss: 0.252, val_loss: 0.208\n",
      "\n",
      "VALID: roc_auc: 0.8410, eer: 0.2406, thres: 0.1797 => acc: 0.7595, f1: 0.7595\n",
      "loss: 0.252, val_loss: 0.208\n",
      "Epoch 10/50\n",
      "122/122 [==============================] - 3s 24ms/step - loss: 0.1910 - val_loss: 0.1577\n",
      "================================[   Epoch 9   ]================================\n",
      "TRAIN: roc_auc: 0.8010, eer: 0.2732, thres: 0.1698 => acc: 0.7266, f1: 0.7263\n",
      "loss: 0.191, val_loss: 0.158\n",
      "\n",
      "VALID: roc_auc: 0.8459, eer: 0.2359, thres: 0.2155 => acc: 0.7641, f1: 0.7640\n",
      "loss: 0.191, val_loss: 0.158\n",
      "Epoch 11/50\n",
      "122/122 [==============================] - 3s 23ms/step - loss: 0.1490 - val_loss: 0.1226\n",
      "================================[   Epoch 10   ]================================\n",
      "TRAIN: roc_auc: 0.8051, eer: 0.2711, thres: 0.1644 => acc: 0.7289, f1: 0.7286\n",
      "loss: 0.149, val_loss: 0.123\n",
      "\n",
      "VALID: roc_auc: 0.8573, eer: 0.2190, thres: 0.2061 => acc: 0.7811, f1: 0.7811\n",
      "loss: 0.149, val_loss: 0.123\n",
      "Epoch 12/50\n",
      "122/122 [==============================] - 6s 49ms/step - loss: 0.1213 - val_loss: 0.1073\n",
      "================================[   Epoch 11   ]================================\n",
      "TRAIN: roc_auc: 0.8021, eer: 0.2735, thres: 0.1975 => acc: 0.7265, f1: 0.7262\n",
      "loss: 0.121, val_loss: 0.107\n",
      "\n",
      "VALID: roc_auc: 0.8421, eer: 0.2390, thres: 0.2600 => acc: 0.7610, f1: 0.7610\n",
      "loss: 0.121, val_loss: 0.107\n",
      "Epoch 13/50\n",
      "122/122 [==============================] - 5s 42ms/step - loss: 0.1019 - val_loss: 0.0834\n",
      "================================[   Epoch 12   ]================================\n",
      "TRAIN: roc_auc: 0.7946, eer: 0.2793, thres: 0.1520 => acc: 0.7206, f1: 0.7203\n",
      "loss: 0.102, val_loss: 0.083\n",
      "\n",
      "VALID: roc_auc: 0.8660, eer: 0.2138, thres: 0.1809 => acc: 0.7862, f1: 0.7862\n",
      "loss: 0.102, val_loss: 0.083\n",
      "Epoch 14/50\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 0.0913 - val_loss: 0.0740\n",
      "================================[   Epoch 13   ]================================\n",
      "TRAIN: roc_auc: 0.7971, eer: 0.2802, thres: 0.1366 => acc: 0.7198, f1: 0.7195\n",
      "loss: 0.091, val_loss: 0.074\n",
      "\n",
      "VALID: roc_auc: 0.8760, eer: 0.1997, thres: 0.1778 => acc: 0.8004, f1: 0.8004\n",
      "loss: 0.091, val_loss: 0.074\n",
      "Epoch 15/50\n",
      "122/122 [==============================] - 5s 44ms/step - loss: 0.0848 - val_loss: 0.0746\n",
      "================================[   Epoch 14   ]================================\n",
      "TRAIN: roc_auc: 0.8016, eer: 0.2737, thres: 0.1738 => acc: 0.7263, f1: 0.7260\n",
      "loss: 0.085, val_loss: 0.075\n",
      "\n",
      "VALID: roc_auc: 0.8527, eer: 0.2279, thres: 0.2245 => acc: 0.7721, f1: 0.7720\n",
      "loss: 0.085, val_loss: 0.075\n",
      "Epoch 16/50\n",
      "122/122 [==============================] - 7s 54ms/step - loss: 0.0812 - val_loss: 0.0683\n",
      "================================[   Epoch 15   ]================================\n",
      "TRAIN: roc_auc: 0.8042, eer: 0.2716, thres: 0.1386 => acc: 0.7284, f1: 0.7281\n",
      "loss: 0.081, val_loss: 0.068\n",
      "\n",
      "VALID: roc_auc: 0.8615, eer: 0.2203, thres: 0.1842 => acc: 0.7796, f1: 0.7796\n",
      "loss: 0.081, val_loss: 0.068\n",
      "Epoch 17/50\n",
      "122/122 [==============================] - 8s 63ms/step - loss: 0.0793 - val_loss: 0.0691\n",
      "================================[   Epoch 16   ]================================\n",
      "TRAIN: roc_auc: 0.8004, eer: 0.2772, thres: 0.1497 => acc: 0.7228, f1: 0.7225\n",
      "loss: 0.079, val_loss: 0.069\n",
      "\n",
      "VALID: roc_auc: 0.8591, eer: 0.2220, thres: 0.1948 => acc: 0.7780, f1: 0.7780\n",
      "loss: 0.079, val_loss: 0.069\n",
      "Epoch 18/50\n",
      "122/122 [==============================] - 8s 62ms/step - loss: 0.0798 - val_loss: 0.0691\n",
      "================================[   Epoch 17   ]================================\n",
      "TRAIN: roc_auc: 0.8032, eer: 0.2729, thres: 0.1533 => acc: 0.7271, f1: 0.7268\n",
      "loss: 0.080, val_loss: 0.069\n",
      "\n",
      "VALID: roc_auc: 0.8659, eer: 0.2187, thres: 0.2000 => acc: 0.7813, f1: 0.7813\n",
      "loss: 0.080, val_loss: 0.069\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 19/50\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 0.0617 - val_loss: 0.0472\n",
      "================================[   Epoch 18   ]================================\n",
      "TRAIN: roc_auc: 0.8145, eer: 0.2616, thres: 0.1456 => acc: 0.7385, f1: 0.7382\n",
      "loss: 0.062, val_loss: 0.047\n",
      "\n",
      "VALID: roc_auc: 0.8804, eer: 0.2004, thres: 0.1921 => acc: 0.7995, f1: 0.7995\n",
      "loss: 0.062, val_loss: 0.047\n",
      "Epoch 20/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.0599 - val_loss: 0.0471\n",
      "================================[   Epoch 19   ]================================\n",
      "TRAIN: roc_auc: 0.8146, eer: 0.2639, thres: 0.1265 => acc: 0.7362, f1: 0.7359\n",
      "loss: 0.060, val_loss: 0.047\n",
      "\n",
      "VALID: roc_auc: 0.8843, eer: 0.1977, thres: 0.1682 => acc: 0.8023, f1: 0.8023\n",
      "loss: 0.060, val_loss: 0.047\n",
      "Epoch 21/50\n",
      "122/122 [==============================] - 2s 19ms/step - loss: 0.0597 - val_loss: 0.0476\n",
      "================================[   Epoch 20   ]================================\n",
      "TRAIN: roc_auc: 0.8177, eer: 0.2598, thres: 0.1543 => acc: 0.7403, f1: 0.7399\n",
      "loss: 0.060, val_loss: 0.048\n",
      "\n",
      "VALID: roc_auc: 0.8886, eer: 0.1918, thres: 0.2051 => acc: 0.8082, f1: 0.8082\n",
      "loss: 0.060, val_loss: 0.048\n",
      "Epoch 22/50\n",
      "122/122 [==============================] - 3s 23ms/step - loss: 0.0596 - val_loss: 0.0477\n",
      "================================[   Epoch 21   ]================================\n",
      "TRAIN: roc_auc: 0.8173, eer: 0.2608, thres: 0.1434 => acc: 0.7392, f1: 0.7389\n",
      "loss: 0.060, val_loss: 0.048\n",
      "\n",
      "VALID: roc_auc: 0.8835, eer: 0.1991, thres: 0.1887 => acc: 0.8009, f1: 0.8009\n",
      "loss: 0.060, val_loss: 0.048\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 23/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.0547 - val_loss: 0.0404\n",
      "================================[   Epoch 22   ]================================\n",
      "TRAIN: roc_auc: 0.8253, eer: 0.2517, thres: 0.1386 => acc: 0.7483, f1: 0.7480\n",
      "loss: 0.055, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.8987, eer: 0.1735, thres: 0.1806 => acc: 0.8266, f1: 0.8266\n",
      "loss: 0.055, val_loss: 0.040\n",
      "Epoch 24/50\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.0540 - val_loss: 0.0404\n",
      "================================[   Epoch 23   ]================================\n",
      "TRAIN: roc_auc: 0.8244, eer: 0.2533, thres: 0.1479 => acc: 0.7467, f1: 0.7464\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.8988, eer: 0.1736, thres: 0.1965 => acc: 0.8265, f1: 0.8265\n",
      "loss: 0.054, val_loss: 0.040\n",
      "Epoch 25/50\n",
      "122/122 [==============================] - 4s 29ms/step - loss: 0.0543 - val_loss: 0.0399\n",
      "================================[   Epoch 24   ]================================\n",
      "TRAIN: roc_auc: 0.8252, eer: 0.2531, thres: 0.1480 => acc: 0.7469, f1: 0.7466\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.9031, eer: 0.1662, thres: 0.1992 => acc: 0.8338, f1: 0.8338\n",
      "loss: 0.054, val_loss: 0.040\n",
      "Epoch 26/50\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.0541 - val_loss: 0.0397\n",
      "================================[   Epoch 25   ]================================\n",
      "TRAIN: roc_auc: 0.8256, eer: 0.2516, thres: 0.1465 => acc: 0.7484, f1: 0.7481\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.9031, eer: 0.1662, thres: 0.1949 => acc: 0.8338, f1: 0.8338\n",
      "loss: 0.054, val_loss: 0.040\n",
      "Epoch 27/50\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0539 - val_loss: 0.0403\n",
      "================================[   Epoch 26   ]================================\n",
      "TRAIN: roc_auc: 0.8247, eer: 0.2537, thres: 0.1485 => acc: 0.7464, f1: 0.7461\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.9004, eer: 0.1728, thres: 0.1979 => acc: 0.8273, f1: 0.8272\n",
      "loss: 0.054, val_loss: 0.040\n",
      "Epoch 28/50\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 0.0543 - val_loss: 0.0402\n",
      "================================[   Epoch 27   ]================================\n",
      "TRAIN: roc_auc: 0.8251, eer: 0.2531, thres: 0.1416 => acc: 0.7469, f1: 0.7466\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "VALID: roc_auc: 0.8999, eer: 0.1723, thres: 0.1867 => acc: 0.8277, f1: 0.8277\n",
      "loss: 0.054, val_loss: 0.040\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 29/50\n",
      "122/122 [==============================] - 5s 44ms/step - loss: 0.0528 - val_loss: 0.0389\n",
      "================================[   Epoch 28   ]================================\n",
      "TRAIN: roc_auc: 0.8250, eer: 0.2521, thres: 0.1453 => acc: 0.7479, f1: 0.7476\n",
      "loss: 0.053, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9006, eer: 0.1711, thres: 0.1939 => acc: 0.8289, f1: 0.8289\n",
      "loss: 0.053, val_loss: 0.039\n",
      "Epoch 30/50\n",
      "122/122 [==============================] - 5s 38ms/step - loss: 0.0528 - val_loss: 0.0390\n",
      "================================[   Epoch 29   ]================================\n",
      "TRAIN: roc_auc: 0.8253, eer: 0.2519, thres: 0.1454 => acc: 0.7481, f1: 0.7478\n",
      "loss: 0.053, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9004, eer: 0.1712, thres: 0.1949 => acc: 0.8289, f1: 0.8289\n",
      "loss: 0.053, val_loss: 0.039\n",
      "Epoch 31/50\n",
      "122/122 [==============================] - 6s 45ms/step - loss: 0.0524 - val_loss: 0.0387\n",
      "================================[   Epoch 30   ]================================\n",
      "TRAIN: roc_auc: 0.8257, eer: 0.2513, thres: 0.1453 => acc: 0.7486, f1: 0.7483\n",
      "loss: 0.052, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9016, eer: 0.1686, thres: 0.1935 => acc: 0.8313, f1: 0.8313\n",
      "loss: 0.052, val_loss: 0.039\n",
      "Epoch 32/50\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0528 - val_loss: 0.0388\n",
      "================================[   Epoch 31   ]================================\n",
      "TRAIN: roc_auc: 0.8258, eer: 0.2518, thres: 0.1447 => acc: 0.7482, f1: 0.7479\n",
      "loss: 0.053, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9013, eer: 0.1690, thres: 0.1938 => acc: 0.8311, f1: 0.8311\n",
      "loss: 0.053, val_loss: 0.039\n",
      "Epoch 33/50\n",
      "122/122 [==============================] - 3s 26ms/step - loss: 0.0526 - val_loss: 0.0388\n",
      "================================[   Epoch 32   ]================================\n",
      "TRAIN: roc_auc: 0.8254, eer: 0.2523, thres: 0.1457 => acc: 0.7477, f1: 0.7474\n",
      "loss: 0.053, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9012, eer: 0.1690, thres: 0.1943 => acc: 0.8310, f1: 0.8310\n",
      "loss: 0.053, val_loss: 0.039\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 34/50\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 0.0526 - val_loss: 0.0386\n",
      "================================[   Epoch 33   ]================================\n",
      "TRAIN: roc_auc: 0.8256, eer: 0.2518, thres: 0.1448 => acc: 0.7482, f1: 0.7479\n",
      "loss: 0.053, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9012, eer: 0.1693, thres: 0.1931 => acc: 0.8307, f1: 0.8306\n",
      "loss: 0.053, val_loss: 0.039\n",
      "Epoch 35/50\n",
      "122/122 [==============================] - 2s 20ms/step - loss: 0.0525 - val_loss: 0.0386\n",
      "================================[   Epoch 34   ]================================\n",
      "TRAIN: roc_auc: 0.8257, eer: 0.2521, thres: 0.1449 => acc: 0.7479, f1: 0.7476\n",
      "loss: 0.052, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9009, eer: 0.1701, thres: 0.1930 => acc: 0.8300, f1: 0.8300\n",
      "loss: 0.052, val_loss: 0.039\n",
      "Epoch 36/50\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 0.0524 - val_loss: 0.0386\n",
      "================================[   Epoch 35   ]================================\n",
      "TRAIN: roc_auc: 0.8256, eer: 0.2519, thres: 0.1448 => acc: 0.7481, f1: 0.7478\n",
      "loss: 0.052, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9010, eer: 0.1700, thres: 0.1927 => acc: 0.8301, f1: 0.8301\n",
      "loss: 0.052, val_loss: 0.039\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 37/50\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 0.0523 - val_loss: 0.0386\n",
      "================================[   Epoch 36   ]================================\n",
      "TRAIN: roc_auc: 0.8257, eer: 0.2519, thres: 0.1445 => acc: 0.7481, f1: 0.7478\n",
      "loss: 0.052, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9010, eer: 0.1702, thres: 0.1920 => acc: 0.8298, f1: 0.8298\n",
      "loss: 0.052, val_loss: 0.039\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8257, eer: 0.2519, thres: 0.1445 => acc: 0.7481, f1: 0.7478\n",
      "loss: 0.052, val_loss: 0.039\n",
      "\n",
      "VALID: roc_auc: 0.9010, eer: 0.1702, thres: 0.1920 => acc: 0.8298, f1: 0.8298\n",
      "loss: 0.052, val_loss: 0.039\n",
      "{'loss': [32.780452728271484, 19.528900146484375, 11.450859069824219, 6.942687034606934, 3.264465093612671, 1.2428499460220337, 0.5353426933288574, 0.33962589502334595, 0.2519141435623169, 0.19101716578006744, 0.1490049958229065, 0.1213008314371109, 0.1018599420785904, 0.09133484959602356, 0.08478876948356628, 0.08124315738677979, 0.0793076902627945, 0.07980865985155106, 0.06168954446911812, 0.05989815294742584, 0.05967152118682861, 0.059602413326501846, 0.05470739305019379, 0.05404170975089073, 0.054335255175828934, 0.05406561121344566, 0.053921960294246674, 0.05430074408650398, 0.05278322473168373, 0.052778180688619614, 0.05237192288041115, 0.0528271347284317, 0.05264006182551384, 0.05259629711508751, 0.052486203610897064, 0.05242110416293144, 0.052270252257585526], 'val_loss': [20.0274600982666, 10.265297889709473, 6.076594829559326, 2.8763978481292725, 1.3968349695205688, 0.6828389763832092, 0.40442049503326416, 0.28031301498413086, 0.2082580178976059, 0.15771108865737915, 0.12260454893112183, 0.10733076930046082, 0.083373062312603, 0.07396091520786285, 0.07456899434328079, 0.06831134110689163, 0.06914515048265457, 0.06905627995729446, 0.047239743173122406, 0.04713541641831398, 0.047553908079862595, 0.04769107699394226, 0.04035890847444534, 0.0403650626540184, 0.0399349145591259, 0.039703939110040665, 0.040304362773895264, 0.04018213972449303, 0.03888560086488724, 0.03896619379520416, 0.03873900696635246, 0.03879955783486366, 0.03880356252193451, 0.03857158124446869, 0.038612548261880875, 0.038601282984018326, 0.03855927288532257]}\n",
      "Training History:\n",
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "Using Model variant multi_head_fcn...\n",
      "0.001\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[(0.01, 0.01)], [(0.01, 0.01), (0.01, 0.01)], [(0.01, 0.01), (0.01, 0.01), (0.01, 0.01)]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [(0.01, 0.01)], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.6952, eer: 0.3546, thres: 0.4231 => acc: 0.6454, f1: 0.6451\n",
      "\n",
      "\n",
      "VALID: roc_auc: 0.8930, eer: 0.1802, thres: 0.5225 => acc: 0.8198, f1: 0.8198\n",
      "\n",
      "Epoch 1/50\n",
      "122/122 [==============================] - 14s 59ms/step - loss: 28.4745 - val_loss: 18.7479\n",
      "================================[   Epoch 0   ]================================\n",
      "TRAIN: roc_auc: 0.5261, eer: 0.4888, thres: 1.4921 => acc: 0.5112, f1: 0.5108\n",
      "loss: 28.474, val_loss: 18.748\n",
      "\n",
      "VALID: roc_auc: 0.6684, eer: 0.3592, thres: 1.9464 => acc: 0.6408, f1: 0.6408\n",
      "loss: 28.474, val_loss: 18.748\n",
      "Epoch 2/50\n",
      "122/122 [==============================] - 8s 65ms/step - loss: 18.7475 - val_loss: 11.9186\n",
      "================================[   Epoch 1   ]================================\n",
      "TRAIN: roc_auc: 0.5241, eer: 0.4879, thres: 1.4022 => acc: 0.5121, f1: 0.5117\n",
      "loss: 18.747, val_loss: 11.919\n",
      "\n",
      "VALID: roc_auc: 0.6256, eer: 0.4068, thres: 1.5657 => acc: 0.5932, f1: 0.5931\n",
      "loss: 18.747, val_loss: 11.919\n",
      "Epoch 3/50\n",
      "122/122 [==============================] - 3s 23ms/step - loss: 11.9436 - val_loss: 6.9741\n",
      "================================[   Epoch 2   ]================================\n",
      "TRAIN: roc_auc: 0.5236, eer: 0.4878, thres: 1.2337 => acc: 0.5122, f1: 0.5118\n",
      "loss: 11.944, val_loss: 6.974\n",
      "\n",
      "VALID: roc_auc: 0.6114, eer: 0.4239, thres: 1.3072 => acc: 0.5761, f1: 0.5761\n",
      "loss: 11.944, val_loss: 6.974\n",
      "Epoch 4/50\n",
      "122/122 [==============================] - 3s 22ms/step - loss: 6.9357 - val_loss: 3.3007\n",
      "================================[   Epoch 3   ]================================\n",
      "TRAIN: roc_auc: 0.5250, eer: 0.4857, thres: 0.7612 => acc: 0.5143, f1: 0.5139\n",
      "loss: 6.936, val_loss: 3.301\n",
      "\n",
      "VALID: roc_auc: 0.6367, eer: 0.3910, thres: 0.8663 => acc: 0.6090, f1: 0.6090\n",
      "loss: 6.936, val_loss: 3.301\n",
      "Epoch 5/50\n",
      "122/122 [==============================] - 9s 71ms/step - loss: 3.4549 - val_loss: 1.5550\n",
      "================================[   Epoch 4   ]================================\n",
      "TRAIN: roc_auc: 0.5300, eer: 0.4828, thres: 0.4266 => acc: 0.5172, f1: 0.5168\n",
      "loss: 3.455, val_loss: 1.555\n",
      "\n",
      "VALID: roc_auc: 0.7133, eer: 0.3320, thres: 0.5470 => acc: 0.6680, f1: 0.6680\n",
      "loss: 3.455, val_loss: 1.555\n",
      "Epoch 6/50\n",
      "122/122 [==============================] - 5s 38ms/step - loss: 1.4935 - val_loss: 0.6627\n",
      "================================[   Epoch 5   ]================================\n",
      "TRAIN: roc_auc: 0.5559, eer: 0.4626, thres: 0.0975 => acc: 0.5374, f1: 0.5370\n",
      "loss: 1.493, val_loss: 0.663\n",
      "\n",
      "VALID: roc_auc: 0.7689, eer: 0.3181, thres: 0.1173 => acc: 0.6819, f1: 0.6819\n",
      "loss: 1.493, val_loss: 0.663\n",
      "Epoch 7/50\n",
      "122/122 [==============================] - 6s 53ms/step - loss: 0.5284 - val_loss: 0.3444\n",
      "================================[   Epoch 6   ]================================\n",
      "TRAIN: roc_auc: 0.7846, eer: 0.2852, thres: 0.0768 => acc: 0.7148, f1: 0.7145\n",
      "loss: 0.528, val_loss: 0.344\n",
      "\n",
      "VALID: roc_auc: 0.8739, eer: 0.2043, thres: 0.1055 => acc: 0.7957, f1: 0.7957\n",
      "loss: 0.528, val_loss: 0.344\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    \n",
    "    train_set, test_set=THREE_FOLD_CV[cv_fold_idx]\n",
    "    print(f\"train_set: {train_set}\")\n",
    "    print(f\"test_set: {test_set}\")\n",
    "\n",
    "    results_dict={}\n",
    "    for window_size in [125, 250, 500, 750, 1000]: #125, 250, 500, 750, 1000, 1250, 1500, 1750, \n",
    "        np.random.seed(SEED)\n",
    "        tf.random.set_seed(SEED)\n",
    "        print(f\"Seed was set to: {SEED}\")\n",
    "\n",
    "        if str(window_size) not in results_dict:\n",
    "            results_dict[str(window_size)]={}\n",
    "\n",
    "        P.window_size=window_size\n",
    "        P.nn_step_width = int(P.window_size * .5)\n",
    "        P.ocsvm_step_width = int(P.window_size * .5)\n",
    "        P.scaler = 'RobustScaler'\n",
    "\n",
    "\n",
    "        P.SMA_per_win_winsize=None\n",
    "        P.EMA_per_win_span=None\n",
    "        P.Butter_per_win_argdict=None\n",
    "        P.cut_off_freq=None\n",
    "        P.span=None\n",
    "        P.winsize=None\n",
    "\n",
    "        P.filter_order=10\n",
    "        P.sampling_freq=100\n",
    "        P.filtfilt=1\n",
    "\n",
    "        # continue from 1000\n",
    "        # P.Butter_per_win_argdict={\n",
    "        #     \"filter_order\": P.filter_order,\n",
    "        #     \"cut_off_freq\": P.cut_off_freq,\n",
    "        #     \"sampling_freq\": P.sampling_freq,\n",
    "        #     \"filtfilt\": P.filtfilt,\n",
    "        #     }\n",
    "\n",
    "        # report_dict={    \n",
    "        #     # \"Training_samples\": str(np.unique(y_train, return_counts=True)),\n",
    "        #     # \"Validation_samples\": str(np.unique(y_valid, return_counts=True)),\n",
    "        #     \"smoothing\": P.smoothing,\n",
    "        #     # \"EMA_span\": P.span if \"EMA\" in P.smoothing else None ,\n",
    "        #     \"Butter_cut_off_freq\": P.cut_off_freq,\n",
    "        #     \"scaler\": P.scaler,\n",
    "        #     \"Butter_per_win_argdict\": P.Butter_per_win_argdict,\n",
    "        # }  \n",
    "\n",
    "\n",
    "        # --------------butter33-SMA20----------------------\n",
    "        P.winsize=20\n",
    "        P.cut_off_freq=33\n",
    "\n",
    "        P.Butter_per_win_argdict={\n",
    "            \"filter_order\": P.filter_order,\n",
    "            \"cut_off_freq\": P.cut_off_freq,\n",
    "            \"sampling_freq\": P.sampling_freq,\n",
    "            \"filtfilt\": P.filtfilt,\n",
    "             }   \n",
    "        P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "        print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "        SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "        \n",
    "        # only if user 47 in train_set\n",
    "        if 29 in train_set:\n",
    "            ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "            SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "        # --------------butter33-SMA20----------------------\n",
    "    \n",
    "    \n",
    "        #--------------butter33-EMA20----------------------\n",
    "\n",
    "#         P.cut_off_freq=33\n",
    "#         P.span=20\n",
    "\n",
    "#         P.Butter_per_win_argdict={\n",
    "#             \"filter_order\": P.filter_order,\n",
    "#             \"cut_off_freq\": P.cut_off_freq,\n",
    "#             \"sampling_freq\": P.sampling_freq,\n",
    "#             \"filtfilt\": P.filtfilt,\n",
    "#             }   \n",
    "\n",
    "#         P.EMA_per_win_span=P.span\n",
    "\n",
    "#         print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "#         ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "#         EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "#         if 29 in train_set:\n",
    "#             ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "#             EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "            \n",
    "        #--------------butter33-EMA20----------------------\n",
    "\n",
    "\n",
    "#         #--------------butter33----------------------\n",
    "#         P.cut_off_freq=33\n",
    "        \n",
    "#         P.Butter_per_win_argdict={\n",
    "#             \"filter_order\": P.filter_order,\n",
    "#             \"cut_off_freq\": P.cut_off_freq,\n",
    "#             \"sampling_freq\": P.sampling_freq,\n",
    "#             \"filtfilt\": P.filtfilt,\n",
    "#             }   \n",
    "\n",
    "\n",
    "#         print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "        \n",
    "#         ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "        \n",
    "#         if 29 in train_set:\n",
    "#             ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "            \n",
    "        \n",
    "#         #--------------butter33----------------------\n",
    "\n",
    "        # separate user 47 which has 29 index by default from the other users as 47 has shorter time series\n",
    "        if 29 in train_set:\n",
    "\n",
    "            user_idx_set_without_user_47 = train_set - {29}\n",
    "\n",
    "        else:\n",
    "\n",
    "            user_idx_set_without_user_47 = train_set\n",
    "        \n",
    "        \n",
    "        X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=get_raw_windows(dfList_exp1=raw_dfList_exp1,\n",
    "                                                                                            dfList_exp2=SMAed_dfList_exp2, #EMAed_dfList_exp2, #SMAed_dfList_exp2, #, #ffted_dfList_exp2, \n",
    "                                                                                            window_size=window_size, \n",
    "                                                                                            step_width=P.nn_step_width, \n",
    "                                                                                            user_idx_set=user_idx_set_without_user_47, \n",
    "                                                                                            scaler=P.scaler, \n",
    "                                                                                            num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "                                                                                            EMA_per_win_span=P.EMA_per_win_span, \n",
    "                                                                                            SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "                                                                                            Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "                                                                                            verbose=0)\n",
    "\n",
    "        if 29 in train_set:\n",
    "        # user 47 with index 29 is not present in the first cv fold\n",
    "            X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47=get_raw_windows_user_47(dfList_exp1_user_47=raw_dfList_exp1_user_47,\n",
    "                                                                                                                                dfList_exp2_user_47=SMAed_dfList_exp2_user_47, #EMAed_dfList_exp2_user_47, #SMAed_dfList_exp2_user_47, \n",
    "                                                                                                                                window_size=window_size, \n",
    "                                                                                                                                step_width=P.nn_step_width, \n",
    "                                                                                                                                scaler=P.scaler, \n",
    "                                                                                                                                num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "                                                                                                                                EMA_per_win_span=P.EMA_per_win_span, \n",
    "                                                                                                                                SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "                                                                                                                                Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "                                                                                                                                verbose=0)\n",
    "\n",
    "            X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=append_user_47_to_data(X_exp1_dict=X_train_exp1_dict, \n",
    "                                                                                                       X_exp2_dict=X_train_exp2_dict, \n",
    "                                                                                                       fitted_scaler_exp2_dict=fitted_scaler_train_exp2_dict, \n",
    "                                                                                                       all_user_set=user_idx_set_without_user_47, \n",
    "                                                                                                       X_exp1_dict_user_47=X_train_exp1_dict_user_47, \n",
    "                                                                                                       X_exp2_dict_user_47=X_train_exp2_dict_user_47, \n",
    "                                                                                                       fitted_scaler_exp2_dict_user_47=fitted_scaler_train_exp2_dict_user_47, \n",
    "                                                                                                       verbose=0)\n",
    "            #--------------------\n",
    "\n",
    "        ## butter\n",
    "\n",
    "    #     ### main\n",
    "    #     # preparing train data\n",
    "    #     X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=get_raw_windows(dfList_exp1=raw_dfList_exp1, \n",
    "    #                                                                                         dfList_exp2=raw_dfList_exp2, \n",
    "    #                                                                                         window_size=window_size, \n",
    "    #                                                                                         step_width=P.nn_step_width, \n",
    "    #                                                                                         user_idx_set=train_set, \n",
    "    #                                                                                         scaler=P.scaler, \n",
    "    #                                                                                         num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "    #                                                                                         EMA_per_win_span=P.EMA_per_win_span, \n",
    "    #                                                                                         SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "    #                                                                                         Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "    #                                                                                         verbose=0)\n",
    "\n",
    "    #     X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47=get_raw_windows_user_47(dfList_exp1_user_47=raw_dfList_exp1_user_47, \n",
    "    #                                                                                                                         dfList_exp2_user_47=raw_dfList_exp2_user_47, \n",
    "    #                                                                                                                         window_size=window_size, \n",
    "    #                                                                                                                         step_width=P.nn_step_width, \n",
    "    #                                                                                                                         scaler=P.scaler, \n",
    "    #                                                                                                                         num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "    #                                                                                                                         EMA_per_win_span=P.EMA_per_win_span, \n",
    "    #                                                                                                                         SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "    #                                                                                                                         Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "    #                                                                                                                         verbose=0)\n",
    "\n",
    "    #     X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=append_user_47_to_data(X_exp1_dict=X_train_exp1_dict, \n",
    "    #                                                                                                X_exp2_dict=X_train_exp2_dict, \n",
    "    #                                                                                                fitted_scaler_exp2_dict=fitted_scaler_train_exp2_dict, \n",
    "    #                                                                                                all_user_set=P.user_ids, \n",
    "    #                                                                                                X_exp1_dict_user_47=X_train_exp1_dict_user_47, \n",
    "    #                                                                                                X_exp2_dict_user_47=X_train_exp2_dict_user_47, \n",
    "    #                                                                                                fitted_scaler_exp2_dict_user_47=fitted_scaler_train_exp2_dict_user_47, \n",
    "    #                                                                                                verbose=0)\n",
    "\n",
    "    #     ### end main\n",
    "\n",
    "    #         ##butter\n",
    "    #         ffted_dfList_exp3 = get_ffted_dfList(raw_dfList_exp3, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    #         ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    #         ffted_dfList_exp3_user_47 = get_ffted_dfList(raw_dfList_exp3_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    #         ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    #         ### new\n",
    "    #         # preparing train data\n",
    "    #         X_train_exp30_dict, X_train_exp23_dict, fitted_scaler_train_exp23_dict=get_raw_windows(\\\n",
    "    #                                                                                                dfList_exp1=raw_dfList_exp3, \n",
    "    #                                                                                                dfList_exp2=raw_dfList_exp2, \n",
    "    #                                                                                                window_size=window_size, \n",
    "    #                                                                                                step_width=P.nn_step_width, \n",
    "    #                                                                                                user_idx_set=filterred_train_set_arr_exp3, \n",
    "    #                                                                                                scaler=P.scaler, \n",
    "    #                                                                                                num_sample_points_per_exp=6000, \n",
    "    #                                                                                                EMA_per_win_span=P.EMA_per_win_span, \n",
    "    #                                                                                                SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "    #                                                                                                Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "    #                                                                                                verbose=0)\n",
    "\n",
    "\n",
    "    #         ### end new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        spliter = 2*len(X_train_exp2_dict)//3\n",
    "        cnn_train_exp2 = {key: X_train_exp2_dict[key] for key in list(X_train_exp2_dict.keys())[:spliter]}\n",
    "        cnn_train_exp1 = {key: X_train_exp1_dict[key] for key in list(X_train_exp1_dict.keys())[:spliter]}\n",
    "        cnn_valid_exp2 = {key: X_train_exp2_dict[key] for key in list(X_train_exp2_dict.keys())[spliter:]}\n",
    "        cnn_valid_exp1 = {key: X_train_exp1_dict[key] for key in list(X_train_exp1_dict.keys())[spliter:]}\n",
    "\n",
    "\n",
    "        # #### new\n",
    "        # cnn_train_exp23 = {key: X_train_exp23_dict[key] for key in list(X_train_exp23_dict.keys())[:spliter-1]}\n",
    "        # cnn_train_exp30 = {key: X_train_exp30_dict[key] for key in list(X_train_exp30_dict.keys())[:spliter-1]}\n",
    "        # cnn_valid_exp23 = {key: X_train_exp23_dict[key] for key in list(X_train_exp23_dict.keys())[spliter-1:]}\n",
    "        # cnn_valid_exp30 = {key: X_train_exp30_dict[key] for key in list(X_train_exp30_dict.keys())[spliter-1:]}\n",
    "        # #### end new\n",
    "\n",
    "    #     train_pairs_dict = prep_X_y_pair_robust_minmax(cnn_train_exp2, cnn_train_exp1, list(cnn_train_exp2.keys()), \n",
    "    #                                                    fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp2_dict, \n",
    "    #                                                    num_pair_limit=2*NUM_PAIR_LIMIT_TRAIN_2000)\n",
    "    #     #(2*num_samples)//3)\n",
    "    #     X_train, y_train, X_train_distro_dic = train_pairs_dict[\"X\"], train_pairs_dict[\"y\"], train_pairs_dict[\"X_dic\"]\n",
    "\n",
    "    #     valid_pairs_dict = prep_X_y_pair_robust_minmax(cnn_valid_exp2, cnn_valid_exp1, list(cnn_valid_exp2.keys()), \n",
    "    #                                                    fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp2_dict, \n",
    "    #                                                    num_pair_limit=2*NUM_PAIR_LIMIT_VALID_2000)\n",
    "    #     #num_samples//3)\n",
    "    #     X_valid, y_valid, X_valid_distro_dic = valid_pairs_dict[\"X\"], valid_pairs_dict[\"y\"], valid_pairs_dict[\"X_dic\"]\n",
    "\n",
    "\n",
    "        # # using -1 samples\n",
    "        print(\"using flipped data\")\n",
    "        train_pairs_dict = prep_X_y_pair_robust_minmax(X_exp2_dic=cnn_train_exp2, \n",
    "                                                       X_exp1_dic=cnn_train_exp1, \n",
    "                                                       user_id_list=list(cnn_train_exp2.keys()), \n",
    "                                                       fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp2_dict, \n",
    "                                                       is_train=True, # this will include -1 samples\n",
    "                                                       # 2X the sample size as each window makes another flipped sign window\n",
    "                                                       num_pair_limit=3*NUM_PAIR_LIMIT_TRAIN_2000)\n",
    "\n",
    "        # print(\"NOT using flipped data\")\n",
    "        # train_pairs_dict = prep_X_y_pair_robust_minmax(X_exp2_dic=cnn_train_exp2, \n",
    "        #                                                X_exp1_dic=cnn_train_exp1, \n",
    "        #                                                user_id_list=list(cnn_train_exp2.keys()), \n",
    "        #                                                fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp2_dict, \n",
    "        #                                                is_train=False,\n",
    "        #                                                num_pair_limit=2*NUM_PAIR_LIMIT_TRAIN_2000)\n",
    "\n",
    "        X_train, y_train, X_train_distro_dic = train_pairs_dict[\"X\"], train_pairs_dict[\"y\"], train_pairs_dict[\"X_dic\"]\n",
    "\n",
    "        valid_pairs_dict = prep_X_y_pair_robust_minmax(X_exp2_dic=cnn_valid_exp2, \n",
    "                                                       X_exp1_dic=cnn_valid_exp1, \n",
    "                                                       user_id_list=list(cnn_valid_exp2.keys()), \n",
    "                                                       fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp2_dict, \n",
    "                                                       is_train=False,\n",
    "                                                       num_pair_limit=NUM_PAIR_LIMIT_VALID_1000)\n",
    "\n",
    "        X_valid, y_valid, X_valid_distro_dic = valid_pairs_dict[\"X\"], valid_pairs_dict[\"y\"], valid_pairs_dict[\"X_dic\"]\n",
    "        # using -1 samples\n",
    "\n",
    "\n",
    "    #         ##### new\n",
    "    #         train_pairs_dict = prep_X_y_pair_robust_minmax(cnn_train_exp23, cnn_train_exp30, list(cnn_train_exp23.keys()), \n",
    "    #                                                        fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp23_dict, \n",
    "    #                                                        is_train=True,\n",
    "    #                                                        num_pair_limit=2*NUM_PAIR_LIMIT_TRAIN_2000)\n",
    "\n",
    "\n",
    "    #         X_train23, y_train23 = train_pairs_dict[\"X\"], train_pairs_dict[\"y\"]\n",
    "\n",
    "    #         valid_pairs_dict = prep_X_y_pair_robust_minmax(cnn_valid_exp23, cnn_valid_exp30, list(cnn_valid_exp23.keys()), \n",
    "    #                                                        fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp23_dict, \n",
    "    #                                                        is_train=False,\n",
    "    #                                                        num_pair_limit=2*NUM_PAIR_LIMIT_VALID_2000)\n",
    "\n",
    "\n",
    "    #         X_valid23, y_valid23 = valid_pairs_dict[\"X\"], valid_pairs_dict[\"y\"]\n",
    "\n",
    "    #         X_left = np.concatenate([X_train[0], X_train23[0]])\n",
    "    #         X_right = np.concatenate([X_train[1], X_train23[1]])\n",
    "    #         y_train = np.concatenate([y_train, y_train23])\n",
    "\n",
    "    #         X_left, X_right, y_train = sklearn_shuffle(X_left, X_right, y_train, random_state=SEED)\n",
    "\n",
    "    #         X_train = [X_left, X_right]\n",
    "\n",
    "\n",
    "\n",
    "    #         X_left = np.concatenate([X_valid[0], X_valid23[0]])\n",
    "    #         X_right = np.concatenate([X_valid[1], X_valid23[1]])\n",
    "    #         y_valid = np.concatenate([y_valid, y_valid23])\n",
    "\n",
    "    #         X_left, X_right, y_valid = sklearn_shuffle(X_left, X_right, y_valid, random_state=SEED)\n",
    "\n",
    "    #         X_valid = [X_left, X_right]\n",
    "\n",
    "    #         ##### end new\n",
    "\n",
    "\n",
    "        # X_final_train, y_train = prep_X_y_pair(X_train_exp2_dict, X_train_exp1_dict, list(X_train_exp2_dict.keys()), fitted_scaler_train_exp2_dict, num_pair_limit=num_pair_limit_train_2000)\n",
    "\n",
    "        # 2D Filter Model needs flat 4th dimension\n",
    "        if P.model_variant == \"2d\":\n",
    "            X_train[0] = X_train[0].reshape((*X_train[0].shape, 1))\n",
    "            X_train[1] = X_train[1].reshape((*X_train[1].shape, 1))\n",
    "            X_valid[0] = X_valid[0].reshape((*X_valid[0].shape, 1))\n",
    "            X_valid[1] = X_valid[1].reshape((*X_valid[1].shape, 1))\n",
    "\n",
    "        print(\n",
    "            f\"Training samples:   {y_train.shape[0]}, shape: {X_train[0].shape},\"\n",
    "            + f\" class balance: {np.unique(y_train, return_counts=True)}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Validation samples: {y_valid.shape[0]}, shape: {X_valid[0].shape},\"\n",
    "            + f\" class balance: {np.unique(y_valid, return_counts=True)}\"\n",
    "        )\n",
    "        data_dict = {}\n",
    "        data_dict[\"X_valid\"], data_dict[\"y_valid\"], data_dict[\"X_train\"], data_dict[\"y_train\"] = X_valid, y_valid, X_train, y_train\n",
    "\n",
    "\n",
    "    #     X_left = np.concatenate([X_train[0], X_valid[0]])\n",
    "    #     X_right = np.concatenate([X_train[1], X_valid[1]])\n",
    "    #     y_train_valid = np.concatenate([y_train, y_valid])\n",
    "\n",
    "    #     X_left, X_right, y_train_valid = sklearn_shuffle(X_left, X_right, y_train_valid, random_state=SEED)\n",
    "\n",
    "    #     X_train_valid = [X_left, X_right]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        report_dict={    \n",
    "            \"Training_samples\": str(np.unique(y_train, return_counts=True)),\n",
    "            \"Validation_samples\": str(np.unique(y_valid, return_counts=True)),\n",
    "            \"smoothing\": P.smoothing if P.smoothing!=None else None,\n",
    "            # \"EMA_span\": P.span if \"EMA\" in P.smoothing else None ,\n",
    "            \"Butter_cut_off_freq\": P.cut_off_freq if P.cut_off_freq!=None else P.cut_off_freq,\n",
    "            \"scaler\": P.scaler,\n",
    "            \"Butter_per_win_argdict\": P.Butter_per_win_argdict,\n",
    "            \"P.SMA_per_win_winsize\": P.SMA_per_win_winsize, \n",
    "            \"P.EMA_per_win_span\": P.EMA_per_win_span, \n",
    "            \"P.Butter_per_win_argdict\": P.Butter_per_win_argdict, \n",
    "            \"P.cut_off_freq\": P.cut_off_freq, \n",
    "            \"P.span\": P.span,\n",
    "        }\n",
    "\n",
    "        for arg_dict_name in cnn_arch_dict:\n",
    "            if arg_dict_name not in results_dict[str(window_size)]:\n",
    "                np.random.seed(SEED)\n",
    "                tf.random.set_seed(SEED)\n",
    "                print(arg_dict_name)\n",
    "                arg_dict=cnn_arch_dict[arg_dict_name]\n",
    "\n",
    "\n",
    "                create_model_func = get_create_model_func(P.model_variant, P.window_size, P.feature_cols)\n",
    "\n",
    "                arg_dict[\"optimizer_lr\"]=0.001\n",
    "                arg_dict[\"batch_size\"]=256\n",
    "                arg_dict[\"contrastive_loss_margin\"]=.5\n",
    "                arg_dict[\"optimizer_name\"]=\"Adam\"\n",
    "\n",
    "    #             if 1250>window_size>750:\n",
    "    #                 # arg_dict[\"batch_size\"]=256\n",
    "    #                 # arg_dict[\"optimizer_lr\"]=0.001\n",
    "    #                 arg_dict[\"batch_size\"]=256\n",
    "    #                 arg_dict[\"optimizer_lr\"]=0.001\n",
    "\n",
    "    #             elif  1500>=window_size>=1250:\n",
    "    #                 arg_dict[\"batch_size\"]=128\n",
    "    #                 arg_dict[\"optimizer_lr\"]=0.001\n",
    "\n",
    "    #             elif window_size>1500:\n",
    "    #                 arg_dict[\"batch_size\"]=64\n",
    "    #                 arg_dict[\"optimizer_lr\"]=0.0001\n",
    "\n",
    "\n",
    "                # arg_dict[\"optimizer_lr\"]=0.0001\n",
    "\n",
    "                lr_epoch_log_dict={}\n",
    "                ReduceLROnPlateau_args={'mointored_metric': \"val_loss\", \"factor\": 0.2, \"patience\": 2, \"verbose\": 1, \"min_lr\": 1e-6}\n",
    "                # ReduceLROnPlateau_args={'mointored_metric': \"val_loss\", \"factor\": 0.5, \"patience\": 2, \"verbose\": 1, \"min_lr\": 1e-6}\n",
    "\n",
    "                print(arg_dict[\"optimizer_lr\"])\n",
    "                print(arg_dict)\n",
    "                loss_record_dict = {'loss': [], 'val_loss': []}\n",
    "                metric_record_dict = {}\n",
    "                model = create_model_func(arg_dict)\n",
    "\n",
    "                # Train\n",
    "                history = model.fit(\n",
    "                    x=X_train,\n",
    "                    y=y_train,\n",
    "                    batch_size=arg_dict[\"batch_size\"],\n",
    "                    epochs=50,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    shuffle=True,\n",
    "                    callbacks=[MetricsCallback((X_valid, y_valid, X_train, y_train), epoch_evaluate_freq=1, \n",
    "                                               loss_record_dict=loss_record_dict, metric_record_dict=metric_record_dict, \n",
    "                                               save_plots=True, print_interm_epochs=True, early_stoping=False,\n",
    "                                               ReduceLROnPlateau_args=ReduceLROnPlateau_args, lr_epoch_log_dict=lr_epoch_log_dict)]#, reduce_lr],\n",
    "                )\n",
    "                print(loss_record_dict)\n",
    "                print(\"Training History:\")\n",
    "                loss_fig = utils_plot_training_loss(loss_record_dict)\n",
    "\n",
    "                results_dict[str(window_size)][arg_dict_name]={\n",
    "                                                        \"lr_epoch_log_dict\": str(lr_epoch_log_dict),\n",
    "                                                        \"loss_record_dict\": loss_record_dict,\n",
    "                                                        \"metric_record_dict\": metric_record_dict,\n",
    "                                                        \"report_dict\": report_dict,\n",
    "                                                        \"ReduceLROnPlateau_args\": ReduceLROnPlateau_args,\n",
    "                                                        \"arg_dict\": arg_dict,\n",
    "                }\n",
    "\n",
    "                save_training_config_dict(f\"Butter{P.cut_off_freq}-SMA{P.SMA_per_win_winsize}-cv{cv_fold_idx}-{window_size}-{arg_dict_name}\")\n",
    "                del model\n",
    "                del history\n",
    "                K.clear_session()\n",
    "                tf.compat.v1.reset_default_graph()\n",
    "                \n",
    "                gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2e83b-0a62-4a2a-abb4-59ae0fa2a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsize of 10\n",
    "Epoch 20/40\n",
    "121/121 [==============================] - 9s 76ms/step - loss: 0.0292 - val_loss: 0.0162\n",
    "================================[   Epoch 19   ]================================\n",
    "TRAIN: roc_auc: 0.9425, eer: 0.1151, thres: 0.1890 => acc: 0.8850, f1: 0.8852\n",
    "loss: 0.029, val_loss: 0.016\n",
    "\n",
    "VALID: roc_auc: 0.9920, eer: 0.0395, thres: 0.2498 => acc: 0.9602, f1: 0.9602\n",
    "loss: 0.029, val_loss: 0.016\n",
    "\n",
    "# winsize of 2\n",
    "121/121 [==============================] - 9s 74ms/step - loss: 0.0319 - val_loss: 0.0211\n",
    "================================[   Epoch 19   ]================================\n",
    "TRAIN: roc_auc: 0.9434, eer: 0.1222, thres: 0.1898 => acc: 0.8778, f1: 0.8781\n",
    "loss: 0.032, val_loss: 0.021\n",
    "\n",
    "VALID: roc_auc: 0.9893, eer: 0.0530, thres: 0.2023 => acc: 0.9470, f1: 0.9470\n",
    "loss: 0.032, val_loss: 0.021\n",
    "Epoch 21/40\n",
    "121/121 [==============================] - 9s 74ms/step - loss: 0.0318 - val_loss: 0.0211\n",
    "\n",
    "# reduced input droput to 0.05\n",
    "484/484 [==============================] - 10s 20ms/step - loss: 0.0292 - val_loss: 0.0241\n",
    "================================[   Epoch 27   ]================================\n",
    "TRAIN: roc_auc: 0.9611, eer: 0.0921, thres: 0.1729 => acc: 0.9079, f1: 0.9081\n",
    "loss: 0.029, val_loss: 0.024\n",
    "\n",
    "VALID: roc_auc: 0.9814, eer: 0.0634, thres: 0.2602 => acc: 0.9367, f1: 0.9366\n",
    "loss: 0.029, val_loss: 0.024\n",
    "Epoch 29/30\n",
    "\n",
    "# random_normal\n",
    "121/121 [==============================] - 8s 65ms/step - loss: 0.0303 - val_loss: 0.0305\n",
    "================================[   Epoch 28   ]================================\n",
    "TRAIN: roc_auc: 0.9552, eer: 0.1081, thres: 0.1659 => acc: 0.8918, f1: 0.8921\n",
    "loss: 0.030, val_loss: 0.030\n",
    "\n",
    "VALID: roc_auc: 0.9651, eer: 0.0906, thres: 0.2583 => acc: 0.9093, f1: 0.9092\n",
    "loss: 0.030, val_loss: 0.030\n",
    "\n",
    "\n",
    "# He uniform for all\n",
    "121/121 [==============================] - 8s 65ms/step - loss: 0.0338 - val_loss: 0.0282\n",
    "================================[   Epoch 26   ]================================\n",
    "TRAIN: roc_auc: 0.9388, eer: 0.1265, thres: 0.1645 => acc: 0.8735, f1: 0.8738\n",
    "loss: 0.034, val_loss: 0.028\n",
    "\n",
    "VALID: roc_auc: 0.9740, eer: 0.0812, thres: 0.2714 => acc: 0.9189, f1: 0.9188\n",
    "loss: 0.034, val_loss: 0.028\n",
    "\n",
    "# glorot  uniform for convs, and he normal for fully connected\n",
    "121/121 [==============================] - 7s 61ms/step - loss: 0.0334 - val_loss: 0.0322\n",
    "================================[   Epoch 26   ]================================\n",
    "TRAIN: roc_auc: 0.9562, eer: 0.1031, thres: 0.1660 => acc: 0.8969, f1: 0.8971\n",
    "loss: 0.033, val_loss: 0.032\n",
    "\n",
    "VALID: roc_auc: 0.9677, eer: 0.0873, thres: 0.2687 => acc: 0.9130, f1: 0.9129\n",
    "loss: 0.033, val_loss: 0.032\n",
    "Epoch 28/30\n",
    "\n",
    "# glorot normal for conv layers\n",
    "121/121 [==============================] - 7s 60ms/step - loss: 0.0324 - val_loss: 0.0255\n",
    "================================[   Epoch 25   ]================================\n",
    "TRAIN: roc_auc: 0.9448, eer: 0.1257, thres: 0.1617 => acc: 0.8743, f1: 0.8746\n",
    "loss: 0.032, val_loss: 0.025\n",
    "\n",
    "VALID: roc_auc: 0.9808, eer: 0.0616, thres: 0.2837 => acc: 0.9384, f1: 0.9384\n",
    "loss: 0.032, val_loss: 0.025\n",
    "\n",
    "# without negative samples\n",
    "81/81 [==============================] - 5s 62ms/step - loss: 0.0304 - val_loss: 0.0334\n",
    "================================[   Epoch 29   ]================================\n",
    "TRAIN: roc_auc: 0.9608, eer: 0.1031, thres: 0.1546 => acc: 0.8968, f1: 0.8971\n",
    "loss: 0.030, val_loss: 0.033\n",
    "\n",
    "VALID: roc_auc: 0.9536, eer: 0.1012, thres: 0.2139 => acc: 0.8990, f1: 0.8988\n",
    "loss: 0.030, val_loss: 0.033\n",
    "\n",
    "# self attention between conv and activation\n",
    "================================[   Epoch 26   ]================================\n",
    "TRAIN: roc_auc: 0.8956, eer: 0.1855, thres: 0.1604 => acc: 0.8145, f1: 0.8149\n",
    "loss: 0.037, val_loss: 0.028\n",
    "\n",
    "VALID: roc_auc: 0.9646, eer: 0.0785, thres: 0.2277 => acc: 0.9215, f1: 0.9214\n",
    "loss: 0.037, val_loss: 0.028\n",
    "\n",
    "# tanh + linear + max_pooling and average pooling\n",
    "================================[ Final State ]================================\n",
    "TRAIN: roc_auc: 0.9337, eer: 0.1365, thres: 0.1530 => acc: 0.8634, f1: 0.8637\n",
    "loss: 0.034, val_loss: 0.028\n",
    "\n",
    "VALID: roc_auc: 0.9726, eer: 0.0638, thres: 0.2659 => acc: 0.9363, f1: 0.9362\n",
    "loss: 0.034, val_loss: 0.028\n",
    "\n",
    "# tanh + linear + max_pooling\n",
    "81/81 [==============================] - 5s 64ms/step - loss: 0.0348 - val_loss: 0.0261\n",
    "================================[   Epoch 21   ]================================\n",
    "TRAIN: roc_auc: 0.9374, eer: 0.1292, thres: 0.1649 => acc: 0.8709, f1: 0.8711\n",
    "loss: 0.035, val_loss: 0.026\n",
    "\n",
    "VALID: roc_auc: 0.9790, eer: 0.0604, thres: 0.2798 => acc: 0.9397, f1: 0.9396\n",
    "loss: 0.035, val_loss: 0.026\n",
    "Epoch 23/30\n",
    "\n",
    "# tanh + linear\n",
    "81/81 [==============================] - 5s 63ms/step - loss: 0.0357 - val_loss: 0.0292\n",
    "================================[   Epoch 20   ]================================\n",
    "TRAIN: roc_auc: 0.9324, eer: 0.1393, thres: 0.1659 => acc: 0.8607, f1: 0.8610\n",
    "loss: 0.036, val_loss: 0.029\n",
    "\n",
    "VALID: roc_auc: 0.9715, eer: 0.0773, thres: 0.2831 => acc: 0.9228, f1: 0.9227\n",
    "loss: 0.036, val_loss: 0.029\n",
    "\n",
    "# tanh\n",
    "Epoch 20/20\n",
    "81/81 [==============================] - 5s 63ms/step - loss: 0.0335 - val_loss: 0.0404\n",
    "================================[   Epoch 19   ]================================\n",
    "TRAIN: roc_auc: 0.9406, eer: 0.1262, thres: 0.1822 => acc: 0.8738, f1: 0.8741\n",
    "loss: 0.033, val_loss: 0.040\n",
    "\n",
    "VALID: roc_auc: 0.9106, eer: 0.1667, thres: 0.1619 => acc: 0.8329, f1: 0.8327\n",
    "loss: 0.033, val_loss: 0.040\n",
    "\n",
    "#elu\n",
    "================================[   Epoch 24   ]================================\n",
    "TRAIN: roc_auc: 0.9370, eer: 0.1410, thres: 0.1578 => acc: 0.8590, f1: 0.8593\n",
    "loss: 0.039, val_loss: 0.044\n",
    "\n",
    "VALID: roc_auc: 0.9540, eer: 0.0892, thres: 0.2395 => acc: 0.9107, f1: 0.9106\n",
    "loss: 0.039, val_loss: 0.044\n",
    "\n",
    "Epoch 25: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
    "Epoch 26/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264037d-ed17-45e0-963b-2f56788123ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selu\n",
    "===============================[   Epoch 13   ]================================\n",
    "TRAIN: roc_auc: 0.9258, eer: 0.1496, thres: 0.1637 => acc: 0.8503, f1: 0.8506\n",
    "loss: 0.042, val_loss: 0.056\n",
    "\n",
    "VALID: roc_auc: 0.9411, eer: 0.1201, thres: 0.2568 => acc: 0.8801, f1: 0.8799\n",
    "loss: 0.042, val_loss: 0.056\n",
    "Epoch 15/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272d64f-5a7f-445f-87eb-13dc80886d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .5 epoch\n",
    "81/81 [==============================] - 4s 44ms/step - loss: 0.0270 - val_loss: 0.0346\n",
    "================================[   Epoch 9   ]================================\n",
    "TRAIN: roc_auc: 0.9761, eer: 0.0768, thres: 0.1995 => acc: 0.9232, f1: 0.9233\n",
    "loss: 0.027, val_loss: 0.035\n",
    "\n",
    "VALID: roc_auc: 0.9432, eer: 0.1507, thres: 0.2885 => acc: 0.8493, f1: 0.8492\n",
    "loss: 0.027, val_loss: 0.035\n",
    "Epoch 11/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38695411-e781-4dd3-9d87-2fda87346c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average poling\n",
    "Epoch 11/11\n",
    "171/171 [==============================] - 7s 43ms/step - loss: 0.0611 - val_loss: 0.1359\n",
    "================================[   Epoch 10   ]================================\n",
    "TRAIN: roc_auc: 0.9939, eer: 0.0370, thres: 0.4411 => acc: 0.9630, f1: 0.9630\n",
    "loss: 0.061, val_loss: 0.136\n",
    "\n",
    "VALID: roc_auc: 0.9191, eer: 0.1722, thres: 0.4860 => acc: 0.8278, f1: 0.8278\n",
    "loss: 0.061, val_loss: 0.136\n",
    "\n",
    "# the following were all with max pooling\n",
    "# tanh stopped too early, maybe try again later\n",
    "171/171 [==============================] - 8s 46ms/step - loss: 0.0640 - val_loss: 0.1398\n",
    "================================[   Epoch 6   ]================================\n",
    "TRAIN: roc_auc: 0.9938, eer: 0.0347, thres: 0.4186 => acc: 0.9653, f1: 0.9653\n",
    "loss: 0.064, val_loss: 0.140\n",
    "\n",
    "VALID: roc_auc: 0.9048, eer: 0.1929, thres: 0.4396 => acc: 0.8071, f1: 0.8071\n",
    "loss: 0.064, val_loss: 0.140\n",
    "Epoch 8/11\n",
    "\n",
    "# linear with he normal and .1 input droput\n",
    "171/171 [==============================] - 7s 39ms/step - loss: 0.0650 - val_loss: 0.1223\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9960, eer: 0.0315, thres: 0.4199 => acc: 0.9685, f1: 0.9685\n",
    "loss: 0.065, val_loss: 0.122\n",
    "\n",
    "VALID: roc_auc: 0.9445, eer: 0.1338, thres: 0.5698 => acc: 0.8662, f1: 0.8662\n",
    "loss: 0.065, val_loss: 0.122\n",
    "Epoch 13/30\n",
    "\n",
    "# relu with he normal works better:\n",
    "171/171 [==============================] - 7s 42ms/step - loss: 0.0714 - val_loss: 0.1072\n",
    "================================[   Epoch 6   ]================================\n",
    "TRAIN: roc_auc: 0.9772, eer: 0.0763, thres: 0.4146 => acc: 0.9237, f1: 0.9237\n",
    "loss: 0.071, val_loss: 0.107\n",
    "\n",
    "VALID: roc_auc: 0.9639, eer: 0.0990, thres: 0.5798 => acc: 0.9010, f1: 0.9010\n",
    "loss: 0.071, val_loss: 0.107\n",
    "Epoch 8/30\n",
    "\n",
    "# sigmoid wins vs relu both glorot normal\n",
    "171/171 [==============================] - 8s 45ms/step - loss: 0.0546 - val_loss: 0.1042\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9968, eer: 0.0277, thres: 0.4133 => acc: 0.9723, f1: 0.9723\n",
    "loss: 0.055, val_loss: 0.104\n",
    "\n",
    "VALID: roc_auc: 0.9606, eer: 0.1138, thres: 0.4263 => acc: 0.8863, f1: 0.8863\n",
    "loss: 0.055, val_loss: 0.104\n",
    "Epoch 13/30\n",
    "\n",
    "# relu with glorot normla\n",
    "================================[   Epoch 7   ]================================\n",
    "TRAIN: roc_auc: 0.9873, eer: 0.0521, thres: 0.4474 => acc: 0.9479, f1: 0.9479\n",
    "loss: 0.064, val_loss: 0.137\n",
    "\n",
    "VALID: roc_auc: 0.9472, eer: 0.1192, thres: 0.5647 => acc: 0.8808, f1: 0.8808\n",
    "loss: 0.064, val_loss: 0.137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e8715-6b5d-4cdc-8101-e9a77e6b0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3b624-935d-4b81-924e-ee81626573ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "    \n",
    "# with -1 and with droput .5\n",
    "81/81 [==============================] - 3s 43ms/step - loss: 0.0851 - val_loss: 0.1162\n",
    "================================[   Epoch 4   ]================================\n",
    "TRAIN: roc_auc: 0.9777, eer: 0.0733, thres: 0.3914 => acc: 0.9267, f1: 0.9269\n",
    "loss: 0.085, val_loss: 0.116\n",
    "\n",
    "VALID: roc_auc: 0.9397, eer: 0.1585, thres: 0.3132 => acc: 0.8417, f1: 0.8415\n",
    "loss: 0.085, val_loss: 0.116\n",
    "Epoch 6/30\n",
    "81/81 [=========================\n",
    "       \n",
    "# without -1 samples\n",
    "================================[   Epoch 8   ]================================\n",
    "TRAIN: roc_auc: 0.9954, eer: 0.0231, thres: 0.3856 => acc: 0.9769, f1: 0.9769\n",
    "loss: 0.049, val_loss: 0.112\n",
    "\n",
    "VALID: roc_auc: 0.9413, eer: 0.1496, thres: 0.4100 => acc: 0.8504, f1: 0.8502\n",
    "loss: 0.049, val_loss: 0.112\n",
    "Epoch 10/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734067a-f045-4ca1-9077-5f949b5959a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict={}\n",
    "if str(window_size) not in results_dict:\n",
    "    results_dict[str(window_size)]={}\n",
    "for arg_dict_name in cnn_arch_dict:\n",
    "    if arg_dict_name not in results_dict[str(window_size)]:\n",
    "        np.random.seed(SEED)\n",
    "        tf.random.set_seed(SEED)\n",
    "        print(arg_dict_name)\n",
    "        arg_dict=cnn_arch_dict[arg_dict_name]\n",
    "\n",
    "\n",
    "        create_model_func = get_create_model_func(P.model_variant, P.window_size, P.feature_cols)\n",
    "\n",
    "        arg_dict[\"optimizer_lr\"]=0.001\n",
    "        arg_dict[\"batch_size\"]=256\n",
    "        arg_dict[\"contrastive_loss_margin\"]=.5\n",
    "        arg_dict[\"optimizer_name\"]=\"Adam\"\n",
    "\n",
    "#             if 1250>window_size>750:\n",
    "#                 # arg_dict[\"batch_size\"]=256\n",
    "#                 # arg_dict[\"optimizer_lr\"]=0.001\n",
    "#                 arg_dict[\"batch_size\"]=256\n",
    "#                 arg_dict[\"optimizer_lr\"]=0.001\n",
    "\n",
    "#             elif  1500>=window_size>=1250:\n",
    "#                 arg_dict[\"batch_size\"]=128\n",
    "#                 arg_dict[\"optimizer_lr\"]=0.001\n",
    "\n",
    "#             elif window_size>1500:\n",
    "#                 arg_dict[\"batch_size\"]=64\n",
    "#                 arg_dict[\"optimizer_lr\"]=0.0001\n",
    "\n",
    "\n",
    "        # arg_dict[\"optimizer_lr\"]=0.0001\n",
    "\n",
    "        lr_epoch_log_dict={}\n",
    "        # ReduceLROnPlateau_args={'mointored_metric': \"val_loss\", \"factor\": 0.2, \"patience\": 1, \"verbose\": 1, \"min_lr\": 1e-6}\n",
    "        ReduceLROnPlateau_args={'mointored_metric': \"val_loss\", \"factor\": 0.2, \"patience\": 2, \"verbose\": 1, \"min_lr\": 1e-6}\n",
    "        # ReduceLROnPlateau_args={'mointored_metric': \"val_loss\", \"factor\": 0.5, \"patience\": 2, \"verbose\": 1, \"min_lr\": 1e-6}\n",
    "\n",
    "        print(arg_dict[\"optimizer_lr\"])\n",
    "        print(arg_dict)\n",
    "        loss_record_dict = {'loss': [], 'val_loss': []}\n",
    "        metric_record_dict = {}\n",
    "        model = create_model_func(arg_dict)\n",
    "\n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train,\n",
    "            batch_size=arg_dict[\"batch_size\"],\n",
    "            epochs=30,\n",
    "            verbose=1,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            shuffle=True,\n",
    "            callbacks=[MetricsCallback((X_valid, y_valid, X_train, y_train), epoch_evaluate_freq=1, \n",
    "                                       loss_record_dict=loss_record_dict, metric_record_dict=metric_record_dict, \n",
    "                                       save_plots=True, print_interm_epochs=True, early_stoping=False,\n",
    "                                       ReduceLROnPlateau_args=ReduceLROnPlateau_args, lr_epoch_log_dict=lr_epoch_log_dict)]#, reduce_lr],\n",
    "        )\n",
    "        print(loss_record_dict)\n",
    "        print(\"Training History:\")\n",
    "        loss_fig = utils_plot_training_loss(loss_record_dict)\n",
    "\n",
    "        results_dict[str(window_size)][arg_dict_name]={\n",
    "                                                \"lr_epoch_log_dict\": str(lr_epoch_log_dict),\n",
    "                                                \"loss_record_dict\": loss_record_dict,\n",
    "                                                \"metric_record_dict\": metric_record_dict,\n",
    "                                                \"report_dict\": report_dict,\n",
    "                                                \"ReduceLROnPlateau_args\": ReduceLROnPlateau_args,\n",
    "                                                \"arg_dict\": arg_dict,\n",
    "        }\n",
    "\n",
    "        save_training_config_dict(f\"{window_size}-{arg_dict_name}\")\n",
    "        del model\n",
    "        del history\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dcc3e6-d9a0-4adc-b080-40c239b93644",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa062c1d-9d51-44fc-8135-30d7f85666ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03264e1a-7799-427e-93a9-e2953d67f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 of 0.0005\n",
    "================================[   Epoch 15   ]================================\n",
    "TRAIN: roc_auc: 0.9955, eer: 0.0274, thres: 0.3949 => acc: 0.9727, f1: 0.9728\n",
    "loss: 0.075, val_loss: 0.101\n",
    "\n",
    "VALID: roc_auc: 0.9752, eer: 0.0732, thres: 0.4997 => acc: 0.9268, f1: 0.9267\n",
    "loss: 0.075, val_loss: 0.101\n",
    "Epoch 17/30\n",
    "\n",
    "#max constraint =1\n",
    "81/81 [==============================] - 3s 42ms/step - loss: 0.0604 - val_loss: 0.1004\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9960, eer: 0.0235, thres: 0.4180 => acc: 0.9765, f1: 0.9765\n",
    "loss: 0.060, val_loss: 0.100\n",
    "\n",
    "VALID: roc_auc: 0.9661, eer: 0.0952, thres: 0.5121 => acc: 0.9048, f1: 0.9047\n",
    "loss: 0.060, val_loss: 0.100\n",
    "\n",
    "# l2 = 0.0005 wtih .2 dropout max constraint 3\n",
    "81/81 [==============================] - 4s 44ms/step - loss: 0.0626 - val_loss: 0.1008\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9958, eer: 0.0230, thres: 0.4229 => acc: 0.9769, f1: 0.9770\n",
    "loss: 0.063, val_loss: 0.101\n",
    "\n",
    "VALID: roc_auc: 0.9682, eer: 0.0897, thres: 0.5148 => acc: 0.9103, f1: 0.9102\n",
    "loss: 0.063, val_loss: 0.101\n",
    "\n",
    "# l2 = 0.0005 wtih .2 dropout\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9958, eer: 0.0247, thres: 0.4053 => acc: 0.9753, f1: 0.9754\n",
    "loss: 0.064, val_loss: 0.099\n",
    "\n",
    "VALID: roc_auc: 0.9679, eer: 0.0910, thres: 0.4796 => acc: 0.9091, f1: 0.9090\n",
    "loss: 0.064, val_loss: 0.099\n",
    "Epoch 13/30\n",
    "\n",
    "# l2 = 0.001 wtih .2 dropout\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9957, eer: 0.0260, thres: 0.4132 => acc: 0.9740, f1: 0.9740\n",
    "loss: 0.064, val_loss: 0.102\n",
    "\n",
    "VALID: roc_auc: 0.9644, eer: 0.0935, thres: 0.4823 => acc: 0.9065, f1: 0.9064\n",
    "loss: 0.064, val_loss: 0.102\n",
    "Epoch 13/30\n",
    "\n",
    "#manhattan l2=0.1\n",
    "81/81 [==============================] - 3s 38ms/step - loss: 0.0823 - val_loss: 0.0964\n",
    "================================[   Epoch 15   ]================================\n",
    "TRAIN: roc_auc: 0.9802, eer: 0.0677, thres: 0.3879 => acc: 0.9321, f1: 0.9323\n",
    "loss: 0.082, val_loss: 0.096\n",
    "\n",
    "VALID: roc_auc: 0.9731, eer: 0.0904, thres: 0.6025 => acc: 0.9095, f1: 0.9094\n",
    "loss: 0.082, val_loss: 0.096\n",
    "\n",
    "# manhattan l2=0.01\n",
    "81/81 [==============================] - 3s 43ms/step - loss: 0.0542 - val_loss: 0.1062\n",
    "================================[   Epoch 13   ]================================\n",
    "TRAIN: roc_auc: 0.9962, eer: 0.0233, thres: 0.4390 => acc: 0.9767, f1: 0.9768\n",
    "loss: 0.054, val_loss: 0.106\n",
    "\n",
    "VALID: roc_auc: 0.9600, eer: 0.1071, thres: 0.5374 => acc: 0.8928, f1: 0.8927\n",
    "loss: 0.054, val_loss: 0.106\n",
    "Epoch 15/30\n",
    "\n",
    "# manhattan l2=0.001\n",
    "81/81 [==============================] - 3s 36ms/step - loss: 0.0538 - val_loss: 0.1149\n",
    "================================[   Epoch 14   ]================================\n",
    "TRAIN: roc_auc: 0.9986, eer: 0.0162, thres: 0.4246 => acc: 0.9838, f1: 0.9838\n",
    "loss: 0.054, val_loss: 0.115\n",
    "\n",
    "VALID: roc_auc: 0.9536, eer: 0.1121, thres: 0.5310 => acc: 0.8879, f1: 0.8878\n",
    "loss: 0.054, val_loss: 0.115\n",
    "Epoch 16/30\n",
    "\n",
    "#manhattan l2=0.0001\n",
    "81/81 [==============================] - 3s 42ms/step - loss: 0.0841 - val_loss: 0.0993\n",
    "================================[   Epoch 2   ]================================\n",
    "TRAIN: roc_auc: 0.9779, eer: 0.0705, thres: 0.3093 => acc: 0.9295, f1: 0.9296\n",
    "loss: 0.084, val_loss: 0.099\n",
    "\n",
    "VALID: roc_auc: 0.9639, eer: 0.1030, thres: 0.4808 => acc: 0.8970, f1: 0.8969\n",
    "loss: 0.084, val_loss: 0.099\n",
    "Epoch 4/30\n",
    "81/81 [======================\n",
    "\n",
    "================================[   Epoch 13   ]================================\n",
    "TRAIN: roc_auc: 0.9937, eer: 0.0339, thres: 0.4101 => acc: 0.9661, f1: 0.9662\n",
    "loss: 0.064, val_loss: 0.108\n",
    "\n",
    "VALID: roc_auc: 0.9538, eer: 0.1208, thres: 0.5487 => acc: 0.8789, f1: 0.8788\n",
    "loss: 0.064, val_loss: 0.108\n",
    "Epoch 15/30\n",
    "\n",
    "\n",
    "# euclideain no reg\n",
    "================================[   Epoch 23   ]================================\n",
    "TRAIN: roc_auc: 0.9971, eer: 0.0186, thres: 0.3852 => acc: 0.9814, f1: 0.9815\n",
    "loss: 0.040, val_loss: 0.088\n",
    "\n",
    "VALID: roc_auc: 0.9728, eer: 0.0759, thres: 0.5412 => acc: 0.9242, f1: 0.9241\n",
    "loss: 0.040, val_loss: 0.088\n",
    "\n",
    "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
    "\n",
    "# manhattan no reg\n",
    "===============================[   Epoch 1   ]================================\n",
    "TRAIN: roc_auc: 0.9126, eer: 0.1571, thres: 0.2605 => acc: 0.8429, f1: 0.8432\n",
    "loss: 0.147, val_loss: 0.140\n",
    "\n",
    "VALID: roc_auc: 0.9143, eer: 0.1628, thres: 0.3754 => acc: 0.8373, f1: 0.8371\n",
    "loss: 0.147, val_loss: 0.140\n",
    "Epoch 3/30\n",
    "\n",
    "# minkp=5 and no regulariztion\n",
    "================================[   Epoch 15   ]================================\n",
    "TRAIN: roc_auc: 0.9986, eer: 0.0145, thres: 0.3754 => acc: 0.9855, f1: 0.9856\n",
    "loss: 0.040, val_loss: 0.077\n",
    "\n",
    "VALID: roc_auc: 0.9797, eer: 0.0705, thres: 0.4651 => acc: 0.9294, f1: 0.9293\n",
    "loss: 0.040, val_loss: 0.077\n",
    "\n",
    "# increase all filter sizes to 64 # dropout =.3 and l2=.05\n",
    "================================[   Epoch 9   ]================================\n",
    "TRAIN: roc_auc: 0.9894, eer: 0.0432, thres: 0.3875 => acc: 0.9567, f1: 0.9568\n",
    "loss: 0.081, val_loss: 0.082\n",
    "\n",
    "VALID: roc_auc: 0.9810, eer: 0.0601, thres: 0.5036 => acc: 0.9399, f1: 0.9398\n",
    "loss: 0.081, val_loss: 0.082\n",
    "\n",
    "# increase all filter sizes to 64 # dropout =.3 and l2=.05\n",
    "================================[   Epoch 15   ]================================\n",
    "TRAIN: roc_auc: 0.9847, eer: 0.0574, thres: 0.4115 => acc: 0.9426, f1: 0.9427\n",
    "loss: 0.080, val_loss: 0.083\n",
    "\n",
    "VALID: roc_auc: 0.9786, eer: 0.0684, thres: 0.5358 => acc: 0.9316, f1: 0.9315\n",
    "loss: 0.080, val_loss: 0.083\n",
    "Epoch 17/30\n",
    "\n",
    "# incrased FC layer to 64:\n",
    "================================[   Epoch 16   ]================================\n",
    "TRAIN: roc_auc: 0.9815, eer: 0.0623, thres: 0.4021 => acc: 0.9377, f1: 0.9378\n",
    "loss: 0.081, val_loss: 0.094\n",
    "\n",
    "VALID: roc_auc: 0.9708, eer: 0.0755, thres: 0.5588 => acc: 0.9246, f1: 0.9245\n",
    "loss: 0.081, val_loss: 0.094\n",
    "\n",
    "# dropout =.3 and l2=.05\n",
    "================================[   Epoch 20   ]================================\n",
    "TRAIN: roc_auc: 0.9822, eer: 0.0622, thres: 0.4002 => acc: 0.9378, f1: 0.9379\n",
    "loss: 0.081, val_loss: 0.086\n",
    "\n",
    "VALID: roc_auc: 0.9733, eer: 0.0741, thres: 0.4901 => acc: 0.9260, f1: 0.9259\n",
    "loss: 0.081, val_loss: 0.086\n",
    "Epoch 22/30\n",
    "\n",
    "# dropout =.3 and l2=.5\n",
    "================================[   Epoch 19   ]================================\n",
    "TRAIN: roc_auc: 0.9685, eer: 0.0839, thres: 0.3605 => acc: 0.9160, f1: 0.9161\n",
    "loss: 0.095, val_loss: 0.091\n",
    "\n",
    "VALID: roc_auc: 0.9695, eer: 0.0752, thres: 0.5575 => acc: 0.9248, f1: 0.9247\n",
    "loss: 0.095, val_loss: 0.091\n",
    "\n",
    "# dropout =.3 and l2=.1\n",
    "================================[   Epoch 21   ]================================\n",
    "TRAIN: roc_auc: 0.9811, eer: 0.0643, thres: 0.3994 => acc: 0.9357, f1: 0.9358\n",
    "loss: 0.083, val_loss: 0.083\n",
    "\n",
    "VALID: roc_auc: 0.9772, eer: 0.0716, thres: 0.4914 => acc: 0.9284, f1: 0.9283\n",
    "loss: 0.083, val_loss: 0.083\n",
    "Epoch 23/30\n",
    "\n",
    "## l2=0.1 filter_order 3\n",
    "================================[   Epoch 14   ]================================\n",
    "TRAIN: roc_auc: 0.9766, eer: 0.0738, thres: 0.3707 => acc: 0.9262, f1: 0.9263\n",
    "loss: 0.092, val_loss: 0.082\n",
    "\n",
    "VALID: roc_auc: 0.9774, eer: 0.0675, thres: 0.4929 => acc: 0.9326, f1: 0.9325\n",
    "loss: 0.092, val_loss: 0.082\n",
    "\n",
    "# # # with butter 15 with negative samples moved drop out after pooling only avg pooling poolsize 2 with temporal attention\n",
    "81/81 [==============================] - 5s 59ms/step - loss: 0.0905 - val_loss: 0.0822\n",
    "================================[   Epoch 6   ]================================\n",
    "TRAIN: roc_auc: 0.9766, eer: 0.0762, thres: 0.3806 => acc: 0.9238, f1: 0.9240\n",
    "loss: 0.091, val_loss: 0.082\n",
    "\n",
    "VALID: roc_auc: 0.9793, eer: 0.0716, thres: 0.5249 => acc: 0.9284, f1: 0.9283\n",
    "loss: 0.091, val_loss: 0.082\n",
    "Epoch 8/30\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling only avg pooling poolsize 3\n",
    "===============================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9796, eer: 0.0678, thres: 0.3878 => acc: 0.9322, f1: 0.9324\n",
    "loss: 0.085, val_loss: 0.079\n",
    "\n",
    "VALID: roc_auc: 0.9801, eer: 0.0716, thres: 0.4686 => acc: 0.9284, f1: 0.9283\n",
    "loss: 0.085, val_loss: 0.079\n",
    "\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling only no pooling\n",
    "81/81 [==============================] - 3s 40ms/step - loss: 0.0794 - val_loss: 0.0810\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9853, eer: 0.0537, thres: 0.3974 => acc: 0.9463, f1: 0.9464\n",
    "loss: 0.079, val_loss: 0.081\n",
    "\n",
    "VALID: roc_auc: 0.9807, eer: 0.0670, thres: 0.5010 => acc: 0.9331, f1: 0.9330\n",
    "loss: 0.079, val_loss: 0.081\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling only avg + max pool\n",
    "================================[   Epoch 8   ]================================\n",
    "TRAIN: roc_auc: 0.9890, eer: 0.0480, thres: 0.3800 => acc: 0.9521, f1: 0.9522\n",
    "loss: 0.078, val_loss: 0.096\n",
    "\n",
    "VALID: roc_auc: 0.9696, eer: 0.0814, thres: 0.5141 => acc: 0.9186, f1: 0.9185\n",
    "loss: 0.078, val_loss: 0.096\n",
    "Epoch 10/30\n",
    "81/81 [==================\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling only avg + min pool\n",
    "================================[   Epoch 5   ]================================\n",
    "TRAIN: roc_auc: 0.9864, eer: 0.0532, thres: 0.3316 => acc: 0.9469, f1: 0.9470\n",
    "loss: 0.087, val_loss: 0.098\n",
    "\n",
    "VALID: roc_auc: 0.9668, eer: 0.1006, thres: 0.5468 => acc: 0.8993, f1: 0.8992\n",
    "loss: 0.087, val_loss: 0.098\n",
    "Epoch 7/30\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling only min pool\n",
    "81/81 [==============================] - 3s 39ms/step - loss: 0.0753 - val_loss: 0.0868\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9887, eer: 0.0485, thres: 0.3601 => acc: 0.9516, f1: 0.9517\n",
    "loss: 0.075, val_loss: 0.087\n",
    "\n",
    "VALID: roc_auc: 0.9785, eer: 0.0773, thres: 0.5312 => acc: 0.9227, f1: 0.9226\n",
    "loss: 0.075, val_loss: 0.087\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling only avg pool\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9829, eer: 0.0623, thres: 0.3981 => acc: 0.9377, f1: 0.9379\n",
    "loss: 0.083, val_loss: 0.076\n",
    "\n",
    "VALID: roc_auc: 0.9807, eer: 0.0634, thres: 0.4825 => acc: 0.9365, f1: 0.9364\n",
    "loss: 0.083, val_loss: 0.076\n",
    "Epoch 13/30\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling only max pool\n",
    "================================[   Epoch 7   ]================================\n",
    "TRAIN: roc_auc: 0.9892, eer: 0.0488, thres: 0.3304 => acc: 0.9513, f1: 0.9514\n",
    "loss: 0.081, val_loss: 0.096\n",
    "\n",
    "VALID: roc_auc: 0.9685, eer: 0.0898, thres: 0.4805 => acc: 0.9102, f1: 0.9101\n",
    "loss: 0.081, val_loss: 0.096\n",
    "Epoch 9/30\n",
    "\n",
    "# # with butter 15 with negative samples moved drop out after pooling\n",
    "================================[   Epoch 8   ]================================\n",
    "TRAIN: roc_auc: 0.9879, eer: 0.0555, thres: 0.3586 => acc: 0.9445, f1: 0.9447\n",
    "loss: 0.076, val_loss: 0.105\n",
    "\n",
    "VALID: roc_auc: 0.9609, eer: 0.1021, thres: 0.5146 => acc: 0.8980, f1: 0.8979\n",
    "loss: 0.076, val_loss: 0.105\n",
    "Epoch 10/30\n",
    "\n",
    "# with butter 15 with negative samples\n",
    "81/81 [==============================] - 4s 54ms/step - loss: 0.0597 - val_loss: 0.1127\n",
    "================================[   Epoch 6   ]================================\n",
    "TRAIN: roc_auc: 0.9749, eer: 0.0812, thres: 0.2448 => acc: 0.9188, f1: 0.9190\n",
    "loss: 0.060, val_loss: 0.113\n",
    "\n",
    "VALID: roc_auc: 0.9718, eer: 0.0776, thres: 0.3526 => acc: 0.9223, f1: 0.9223\n",
    "loss: 0.060, val_loss: 0.113\n",
    "Epoch 8/30\n",
    "\n",
    "# with butter 20 with negative samples\n",
    "================================[   Epoch 6   ]================================\n",
    "TRAIN: roc_auc: 0.9787, eer: 0.0738, thres: 0.2351 => acc: 0.9262, f1: 0.9263\n",
    "loss: 0.060, val_loss: 0.123\n",
    "\n",
    "VALID: roc_auc: 0.9671, eer: 0.0844, thres: 0.3256 => acc: 0.9156, f1: 0.9155\n",
    "loss: 0.060, val_loss: 0.123\n",
    "Epoch 8/30\n",
    "\n",
    "# with butter 30 with negative samples\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9792, eer: 0.0749, thres: 0.2328 => acc: 0.9251, f1: 0.9253\n",
    "loss: 0.051, val_loss: 0.141\n",
    "\n",
    "VALID: roc_auc: 0.9393, eer: 0.1247, thres: 0.2841 => acc: 0.8754, f1: 0.8752\n",
    "loss: 0.051, val_loss: 0.141\n",
    "\n",
    "# with butter 40 with negative samples\n",
    "================================[   Epoch 17   ]================================\n",
    "TRAIN: roc_auc: 0.9783, eer: 0.0710, thres: 0.2214 => acc: 0.9290, f1: 0.9292\n",
    "loss: 0.043, val_loss: 0.142\n",
    "\n",
    "VALID: roc_auc: 0.9454, eer: 0.1180, thres: 0.2726 => acc: 0.8820, f1: 0.8819\n",
    "loss: 0.043, val_loss: 0.142\n",
    "\n",
    "# with butter 49 with negative samples\n",
    "29: 0.16780084371566772\n",
    "\n",
    "\n",
    "# with butter 20 with negative samples\n",
    "================================[   Epoch 11   ]================================\n",
    "TRAIN: roc_auc: 0.9768, eer: 0.0783, thres: 0.2187 => acc: 0.9217, f1: 0.9219\n",
    "loss: 0.052, val_loss: 0.144\n",
    "\n",
    "VALID: roc_auc: 0.9476, eer: 0.1148, thres: 0.2673 => acc: 0.8852, f1: 0.8850\n",
    "loss: 0.052, val_loss: 0.144\n",
    "\n",
    "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
    "Epoch 13/30\n",
    "81/81 [==============================] - 4s 53ms/step - loss: 0.0471 - val_loss: 0.1549\n",
    "================================[   Epoch 12   ]================================\n",
    "\n",
    "# without butter with negative samples\n",
    "================================[   Epoch 13   ]================================\n",
    "TRAIN: roc_auc: 0.9732, eer: 0.0836, thres: 0.2184 => acc: 0.9164, f1: 0.9166\n",
    "loss: 0.046, val_loss: 0.163\n",
    "\n",
    "VALID: roc_auc: 0.9386, eer: 0.1329, thres: 0.2511 => acc: 0.8670, f1: 0.8668\n",
    "loss: 0.046, val_loss: 0.163\n",
    "Epoch 15/30\n",
    " 9/81 [==>...........................] - ETA: 3s - loss: 0.0469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a99a1-9c5b-4cf7-9e3b-5c51557f510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b23aff-c731-49f0-8419-f72e253332ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27b355-ca0a-44e6-9487-e2a4fe6af396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run with hyperparams you found and compare against default\n",
    "# in the next run, switch from val_loss to eer_val\n",
    "remove butter, i dont need we need it\n",
    "maybe increase the cuttoff for loading dataframse to 5 magnitude\n",
    "# run on gyr, accel alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d5f18-86eb-4fe7-86b5-54d8a1ff3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5abc7d-bada-4112-82ff-88e8aedb631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "results_dict[str(window_size)].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3e236-6316-49bd-b223-b2ef9cf2e435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lr_pool = np.logspace(-5, -2, num=10)\n",
    "# lr_pool=[1e-5]#, 2e-5]\n",
    "# lr_epoch_log_dict={}\n",
    "# ReduceLROnPlateau_err_mode={}\n",
    "# ReduceLROnPlateau_args={'mointored_metric': \"val_loss\", \"factor\": 0.2, \"patience\": 0, \"verbose\": 1, \"min_lr\": 1e-8}\n",
    "# ReduceLROnPlateau_args=ReduceLROnPlateau_args\n",
    "# for lr in lr_pool:\n",
    "#     np.random.seed(SEED)\n",
    "#     tf.random.set_seed(SEED)\n",
    "#     arg_dict['optimizer_lr'] = lr\n",
    "#     print(lr)\n",
    "#     print(arg_dict)\n",
    "#     loss_record_dict = {'loss': [], 'val_loss': []}\n",
    "#     metric_record_dict = {}\n",
    "#     model = create_model_func(arg_dict)\n",
    "\n",
    "#     # Train\n",
    "#     history = model.fit(\n",
    "#         x=X_train,\n",
    "#         y=y_train,\n",
    "#         batch_size=arg_dict[\"batch_size\"],\n",
    "#         epochs=200,\n",
    "#         verbose=1,\n",
    "#         validation_data=(X_valid, y_valid),\n",
    "#         shuffle=True,\n",
    "#         callbacks=[MetricsCallback((X_valid, y_valid, X_train, y_train), epoch_evaluate_freq=1, \n",
    "#                                    loss_record_dict=loss_record_dict, metric_record_dict=metric_record_dict, \n",
    "#                                    save_plots=True, print_interm_epochs=True, early_stoping=False,\n",
    "#                                   ReduceLROnPlateau_args=ReduceLROnPlateau_args, lr_epoch_log_dict=lr_epoch_log_dict)]#, reduce_lr],\n",
    "#     )\n",
    "#     print(loss_record_dict)\n",
    "#     print(\"Training History:\")\n",
    "#     loss_fig = utils_plot_training_loss(loss_record_dict)\n",
    "    \n",
    "# min_val = min(metric_record_dict['eer_val'][\"Valid\"])\n",
    "# min_val_index=metric_record_dict['eer_val'][\"Valid\"].index(min_val)\n",
    "# print(metric_record_dict['eer_val'][\"Valid\"])\n",
    "# min_val_index\n",
    "\n",
    "# optimal_lr_epoch_dict={}\n",
    "# for i in range(min_val_index+1):\n",
    "#     optimal_lr_epoch_dict[i] = lr_epoch_log_dict[i]\n",
    "    \n",
    "# optimal_lr_epoch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07607dff-e682-4c75-9151-7ab6d063a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4814207-6f7c-4a76-8596-dcb7b740d462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SCNN_1_5_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2],\n",
    "    \"filters_streams\": [[256, 32, 128, 32, 64]],\n",
    "    \"kernels_streams\": [[7, 3, 5, 3, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3, 3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\", \"l2\", \"l1\", \"l2\", \"l1\"]],\n",
    "    \"strides_streams\": [[1, 1, 1, 1, 1]],\n",
    "    \"paddings_streams\": [[\"causal\", \"causal\", \"causal\", \"causal\", \"causal\"]],\n",
    "    \"dropouts_streams\": [[0.5, 0.4, 0.3, 0.4, 0.5]],\n",
    "    \"activations_streams\": [['relu', 'relu', 'relu', 'relu', 'relu']],\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.2], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "SCNN_simple_1_5_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2],\n",
    "    \"filters_streams\": [[64, 16, 32, 8, 16]],\n",
    "    \"kernels_streams\": [[7, 3, 5, 3, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3, 3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\", \"l2\", \"l1\", \"l2\", \"l1\"]],\n",
    "    \"strides_streams\": [[1, 1, 1, 1, 1]],\n",
    "    \"paddings_streams\": [[\"causal\", \"causal\", \"causal\", \"causal\", \"causal\"]],\n",
    "    \"dropouts_streams\": [[0.1, 0.1, 0.1, 0.1, 0.1]],\n",
    "    \"activations_streams\": [['relu', 'relu', 'relu', 'relu', 'relu']],\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.2], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "SCNN_3_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[64], [64], [64]], #6**3\n",
    "    \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\"], #8**3\n",
    "                             [\"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3], [3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\"],[\"l2\"], [\"l1\"]],\n",
    "    \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.2], [.2], [.2]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "}\n",
    "\n",
    "SCNN_4_1234_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[16], [16, 32], [16, 32, 64], [16, 32, 64, 128]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3], [9, 7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], #8**3\n",
    "                             [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"],\n",
    "                            [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3], [3, 3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\"], [\"l2\",\"l1\"], [\"l1\",\"l2\", \"l1\"], [\"l2\", \"l1\", \"l2\", \"l1\"]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1], [1, 1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"causal\"], [\"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\"], [\"causal\", \"causal\", \"causal\", \"causal\"]], #2*3\n",
    "    \"dropouts_streams\": [[.2], [.2, .3], [.2, .3, .4], [.2, .3, .4, .5]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "SCNN_3_123_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "    \"filters_streams\": [[64], [128, 64], [256, 128, 64]], #6**3\n",
    "    \"kernels_streams\": [[3], [5, 3], [7, 5, 3]], #4*3\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], #8**3\n",
    "                             [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3], [3, 3], [3, 3, 3]], #3**3\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\"], [\"l2\",\"l1\"], [\"l1\",\"l2\", \"l1\"]],\n",
    "    \"strides_streams\": [[1], [1, 1], [1, 1, 1]], #4**3\n",
    "    \"paddings_streams\": [[\"same\"], [\"same\", \"same\"], [\"same\", \"same\", \"same\"]], #2*3\n",
    "    \"dropouts_streams\": [[.4], [.3, .4], [.2, .3, .4]], #5**3\n",
    "    \"activations_streams\": [['relu'], ['relu', 'relu'], ['relu', 'relu', 'relu']], # 8**3\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "SCNN_1_3_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2],\n",
    "    \"filters_streams\": [[256, 128, 64]],\n",
    "    \"kernels_streams\": [[7, 5, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\", \"l1\"]],\n",
    "    \"strides_streams\": [[1, 1, 1]],\n",
    "    \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "    \"dropouts_streams\": [[0.3, 0.4, 0.5]],\n",
    "    \"activations_streams\": [['relu', 'relu', 'relu']],\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\":[3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.2], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "SCNN_1_2_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2],\n",
    "    \"filters_streams\": [[64, 32]],\n",
    "    \"kernels_streams\": [[5, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\"]],\n",
    "    \"strides_streams\": [[1, 1]],\n",
    "    \"paddings_streams\": [[\"same\", \"same\"]],\n",
    "    \"dropouts_streams\": [[0.2, 0.3]],\n",
    "    \"activations_streams\": [['relu', 'relu']],\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\": [3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.2], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "SCNN_1_1_conv_1_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2],\n",
    "    \"filters_streams\": [[64]],\n",
    "    \"kernels_streams\": [[3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3]],\n",
    "    \"strides_streams\": [[1]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\"]],\n",
    "    \"paddings_streams\": [[\"same\"]],\n",
    "    \"dropouts_streams\": [[0.2]],\n",
    "    \"activations_streams\": [['relu']],\n",
    "    \n",
    "    \"dense_layers\": [84],\n",
    "    \"dense_kernel_Max_Norm_constraints\": [3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.2], \n",
    "    \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "}\n",
    "\n",
    "SCNN_1_2_conv_2_dense_arg_dict_default = {\n",
    "    \"input_dropout_streams\": [0.2],\n",
    "    \"filters_streams\": [[128, 64]],\n",
    "    \"kernels_streams\": [[5, 3]],\n",
    "    \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "    \"kernels_Max_Norm_constraint_streams\": [[3, 3]],\n",
    "    \"conv_kernel_regularizer_streams\": [[\"l1\",\"l2\"]],\n",
    "    \"strides_streams\": [[1, 1]],\n",
    "    \"paddings_streams\": [[\"same\", \"same\"]],\n",
    "    \"dropouts_streams\": [[0.2, 0.3]],\n",
    "    \"activations_streams\": [['relu', 'relu']],\n",
    "    \n",
    "    \"dense_layers\": [32, 84],\n",
    "    \"dense_kernel_Max_Norm_constraints\": [3, 3],\n",
    "    \"dense_kernel_regularizer\":[\"l1\", \"l2\"],\n",
    "    \"dense_kernel_inits\": [\"glorot_uniform\", \"glorot_uniform\"],\n",
    "    \"dense_dropouts\": [0.2, 0.2], \n",
    "    \"dense_activations\": ['relu', \"sigmoid\"],\n",
    "    \n",
    "    \"loss_func_name\": \"k_contrastive_loss\",\n",
    "    \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_lr\": 1e-2,\n",
    "    \"optimizer_decay\": None,\n",
    "    \n",
    "    \"batch_size\": 512,\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# single_head_8layercnn_2layerdense_SCNN_arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2],\n",
    "#     \"filters_streams\": [[32, 32, 64, 64, 128, 128, 256, 256]],\n",
    "#     \"kernels_streams\": [[3, 3, 5, 5, 7, 7, 9, 9]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_Max_Norm_constraint_streams\": [[3, 3, 3, 3, 3, 3, 3, 3]],\n",
    "#     \"strides_streams\": [[15, 1, 1, 1, 1, 1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.2, 0.2, 0.3, 0.3, 0.4, 0.4, 0.5, 0.5]],\n",
    "#     \"activations_streams\": [['swish', 'swish', 'swish', 'swish', 'swish', 'swish', 'swish', 'swish']],\n",
    "    \n",
    "#     \"dense_layers\": [128, 256],\n",
    "#     \"dense_kernel_Max_Norm_constraints\": [3, 3],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\", \"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.2, 0.2], \n",
    "#     \"dense_activations\": ['swish', \"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func_name\": \"k_contrastive_loss\",\n",
    "#     \"contrastive_loss_margin\": 1.0,\n",
    "    \n",
    "#     \"optimizer_name\": \"Adam\",\n",
    "#     \"optimizer_lr\": 3e-4,\n",
    "#     \"optimizer_decay\": None,\n",
    "    \n",
    "#     \"batch_size\": 32,\n",
    "    \n",
    "    \n",
    "#     \"Training_samples\": str(np.unique(y_train, return_counts=True)),\n",
    "#     \"Validation_samples\": str(np.unique(y_valid, return_counts=True)),\n",
    "\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0],\n",
    "#     \"filters_streams\": [[32, 32, 32]],\n",
    "#     \"kernels_streams\": [[3, 3, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3), MaxNorm(3), MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.1, 0.1, 0]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [128],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0],\n",
    "#     \"filters_streams\": [[32, 32]],\n",
    "#     \"kernels_streams\": [[3, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3), MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[0.1, 0]],\n",
    "#     \"activations_streams\": [['relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [32],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0],\n",
    "#     \"filters_streams\": [[32]],\n",
    "#     \"kernels_streams\": [[3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1]],\n",
    "#     \"paddings_streams\": [[\"same\"]],\n",
    "#     \"dropouts_streams\": [[0.1]],\n",
    "#     \"activations_streams\": [['relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0],\n",
    "#     \"filters_streams\": [[32, 32, 32], [32, 32, 32]],\n",
    "#     \"kernels_streams\": [[5, 5, 5], [3, 3, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3), MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3), MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1, 1, 1], [1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\"], [\"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[.1, .1, .1], [0.1, .1, .1]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu'], ['relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [32],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0],\n",
    "#     \"filters_streams\": [[32, 32, 32], [32, 32, 32], [32, 32, 32]],\n",
    "#     \"kernels_streams\": [[7, 7, 7], [5, 5, 5], [3, 3, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"], \n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3), MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3), MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\"], [\"same\", \"same\", \"same\"], [\"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[.1, .1, .1], [.1, .1, .1], [0.1, .1, .1]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [32],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0],\n",
    "#     \"filters_streams\": [[32, 32], [32, 32], [32, 32]],\n",
    "#     \"kernels_streams\": [[7, 7], [5, 5], [3, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\"], \n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1, 1], [1, 1], [1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\"], [\"same\", \"same\"], [\"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[.1, .1], [.1, .1], [0.1, .1]],\n",
    "#     \"activations_streams\": [['relu', 'relu'], ['relu', 'relu'], ['relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [32],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0],\n",
    "#     \"filters_streams\": [[32], [32], [32]],\n",
    "#     \"kernels_streams\": [[7], [5], [3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\"], \n",
    "#                              [\"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3)], [MaxNorm(3)], [MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1], [1], [1]],\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]],\n",
    "#     \"dropouts_streams\": [[.1], [.1], [0.1]],\n",
    "#     \"activations_streams\": [['relu'], ['relu'], ['relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0],\n",
    "#     \"filters_streams\": [[32], [32], [32]],\n",
    "#     \"kernels_streams\": [[7], [5], [3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\"], \n",
    "#                              [\"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[\"MaxNorm(3)\"], [\"MaxNorm(3)\"], [\"MaxNorm(3)\"]],\n",
    "#     \"strides_streams\": [[1], [1], [1]],\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]],\n",
    "#     \"dropouts_streams\": [[.1], [.1], [0.1]],\n",
    "#     \"activations_streams\": [['relu'], ['relu'], ['relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_constraints\":[\"MaxNorm(3)\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": \"k_contrastive_loss\",\n",
    "#     \"optimizer\": \"Adam\",\n",
    "# }\n",
    "\n",
    "\n",
    "# arg_dict = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\"], #8**3\n",
    "#                              [\"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[\"MaxNorm(3)\"], [\"MaxNorm(3)\"], [\"MaxNorm(3)\"]], #3**3\n",
    "#     \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.1], [.1], [.1]], #5**3\n",
    "#     \"activations_streams\": [['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_constraints\":[\"MaxNorm(3)\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": \"k_contrastive_loss\",\n",
    "#     \"optimizer\": \"Adam\",\n",
    "# }\n",
    "\n",
    "\n",
    "# arg_dict = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\"], #8**3\n",
    "#                              [\"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[\"MaxNorm(3)\"], [\"MaxNorm(3)\"], [\"MaxNorm(3)\"]], #3**3\n",
    "#     \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.1], [.1], [.1]], #5**3\n",
    "#     \"activations_streams\": [['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_constraints\":[\"MaxNorm(3)\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": \"k_contrastive_loss\",\n",
    "#     \"optimizer\": \"Adam\",\n",
    "# }\n",
    "\n",
    "# arg_dict = {\n",
    "#     \"input_dropout_streams\": [.2, .2, .2], #5**3\n",
    "#     \"filters_streams\": [[32], [32], [32]], #6**3\n",
    "#     \"kernels_streams\": [[7], [5], [3]], #4*3\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\"], #8**3\n",
    "#                              [\"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[\"MaxNorm(3)\"], [\"MaxNorm(3)\"], [\"MaxNorm(3)\"]], #3**3\n",
    "#     \"strides_streams\": [[1], [1], [1]], #4**3\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]], #2*3\n",
    "#     \"dropouts_streams\": [[.1], [.1], [.1]], #5**3\n",
    "#     \"activations_streams\": [['relu'], ['relu'], ['relu']], # 8**3\n",
    "    \n",
    "#     \"dense_layers\": [84],\n",
    "#     \"dense_kernel_constraints\":[\"MaxNorm(3)\"],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0], \n",
    "#     \"dense_activations\": [\"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": \"k_contrastive_loss\",\n",
    "#     \"optimizer\": \"Adam\",\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0, 0, 0],\n",
    "#     \"filters_streams\": [[32, 32, 32], [32, 32, 32], [32, 32, 32]],\n",
    "#     \"kernels_streams\": [[7, 7, 7], [5, 5, 5], [3, 3, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"], \n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3), MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3), MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\"], [\"same\", \"same\", \"same\"], [\"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[.1, .1, .1], [.1, .1, .1], [0.1, .1, .1]],\n",
    "#     \"activations_streams\": [['relu', 'relu', 'relu'], ['relu', 'relu', 'relu'], ['relu', 'relu', 'relu']],\n",
    "    \n",
    "#     \"dense_layers\": [],\n",
    "#     \"dense_kernel_constraints\":[],\n",
    "#     \"dense_kernel_inits\": [],\n",
    "#     \"dense_dropouts\": [], \n",
    "#     \"dense_activations\": [],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2, 0.2, 0.2],\n",
    "#     \"filters_streams\": [[32], [32], [32]],\n",
    "#     \"kernels_streams\": [[7], [5], [3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\"], [\"glorot_uniform\"], \n",
    "#                              [\"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3)], [MaxNorm(3)], [MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1], [1], [1]],\n",
    "#     \"paddings_streams\": [[\"same\"], [\"same\"], [\"same\"]],\n",
    "#     \"dropouts_streams\": [[.1], [.1], [0.1]],\n",
    "#     \"activations_streams\": [['relu'], ['relu'], ['relu']],\n",
    "    \n",
    "#     \"dense_layers\": [84, 84],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3), MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\", \"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.1, 0.1], \n",
    "#     \"dense_activations\": ['relu', \"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n",
    "\n",
    "# arg_dict_default = {\n",
    "#     \"input_dropout_streams\": [0.2, 0.2, 0.2],\n",
    "#     \"filters_streams\": [[10, 20, 30], [10, 20, 30], [10, 20, 30]],\n",
    "#     \"kernels_streams\": [[8, 5, 3], [5, 5, 3], [3, 3, 3]],\n",
    "#     \"kernels_init_streams\": [[\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"], [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"], \n",
    "#                              [\"glorot_uniform\", \"glorot_uniform\", \"glorot_uniform\"]],\n",
    "#     \"kernels_constraint_streams\": [[MaxNorm(3), MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3), MaxNorm(3)], [MaxNorm(3), MaxNorm(3), MaxNorm(3)]],\n",
    "#     \"strides_streams\": [[1, 1, 1], [1, 1, 1], [1, 1, 1]],\n",
    "#     \"paddings_streams\": [[\"same\", \"same\", \"same\"], [\"same\", \"same\", \"same\"], [\"same\", \"same\", \"same\"]],\n",
    "#     \"dropouts_streams\": [[.2, .3, .4], [.2, .3, .4], [0.2, .3, .4]],\n",
    "#     \"activations_streams\": [['tanh', 'tanh', 'tanh'], ['tanh', 'tanh', 'tanh'], ['tanh', 'tanh', 'tanh']],\n",
    "    \n",
    "#     \"dense_layers\": [32, 64],\n",
    "#     \"dense_kernel_constraints\":[MaxNorm(3), MaxNorm(3)],\n",
    "#     \"dense_kernel_inits\": [\"glorot_uniform\", \"glorot_uniform\"],\n",
    "#     \"dense_dropouts\": [0.4, 0.5], \n",
    "#     \"dense_activations\": ['tanh', \"sigmoid\"],\n",
    "    \n",
    "#     \"loss_func\": k_contrastive_loss,\n",
    "#     \"optimizer\": optimizer,\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab7f60-fe83-42c7-a3cb-5d84564894da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    #     ffted_dfList_exp1 = get_ffted_dfList(dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    #     ffted_dfList_exp2 = get_ffted_dfList(dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    #     ffted_dfList_exp1_user_47 = get_ffted_dfList(dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    #     ffted_dfList_exp2_user_47 = get_ffted_dfList(dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    #     EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "    #     EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "\n",
    "    #     EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "    #     EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    #     # preparing train data\n",
    "    #     X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=get_raw_windows(EMAed_dfList_exp1, EMAed_dfList_exp2, window_size, step_width=P.nn_step_width, user_idx_set=train_set, scaler=P.scaler, \n",
    "    #                                                                                         num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "    #                                                                                         EMA_per_win_span=P.EMA_per_win_span, \n",
    "    #                                                                                         SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "    #                                                                                         Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "    #                                                                                         verbose=0)\n",
    "\n",
    "    #     X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47=get_raw_windows_user_47(EMAed_dfList_exp1_user_47, EMAed_dfList_exp2_user_47, \n",
    "    #                                                                                                                         window_size, step_width=P.nn_step_width, scaler=P.scaler, \n",
    "    #                                                                                                                         num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "    #                                                                                                                         EMA_per_win_span=P.EMA_per_win_span, \n",
    "    #                                                                                                                         SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "    #                                                                                                                         Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "    #                                                                                                                         verbose=0)\n",
    "\n",
    "    #     X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=append_user_47_to_data(X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict, P.user_ids, \n",
    "    #                                                                                                X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47, \n",
    "    #                                                                                                verbose=0)\n",
    "\n",
    "        # preparing train data\n",
    "    #     X_train_exp1_dict, X_train_exp2_dict, \\\n",
    "    #     fitted_scaler_train_exp2_dict, fitted_min_max_scaler_train_exp2_dict=get_raw_windows_NN(\\\n",
    "    #                                                                                             dfList_exp1=raw_dfList_exp1, \n",
    "    #                                                                                             dfList_exp2=raw_dfList_exp2, \n",
    "    #                                                                                             window_size=window_size, \n",
    "    #                                                                                             step_width=P.nn_step_width, \n",
    "    #                                                                                             user_idx_set=train_set, \n",
    "    #                                                                                             scaler=P.scaler, \n",
    "    #                                                                                             min_max_scaler=True,\n",
    "    #                                                                                             num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "    #                                                                                             EMA_per_win_span=P.EMA_per_win_span, \n",
    "    #                                                                                             SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "    #                                                                                             Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "    #                                                                                             verbose=0)\n",
    "\n",
    "    #     X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, \\\n",
    "    #     fitted_scaler_train_exp2_dict_user_47, \\\n",
    "    #     fitted_min_max_scaler_train_exp2_dict_user_47=get_raw_windows_user_47_NN(\\\n",
    "    #                                                                              dfList_exp1_user_47=raw_dfList_exp1_user_47, \n",
    "    #                                                                              dfList_exp2_user_47=raw_dfList_exp2_user_47, \n",
    "    #                                                                              window_size=window_size, \n",
    "    #                                                                              step_width=P.nn_step_width, \n",
    "    #                                                                              scaler=P.scaler, \n",
    "    #                                                                              min_max_scaler=True,\n",
    "    #                                                                              num_sample_points_per_exp=P.num_sample_points_per_exp, \n",
    "    #                                                                              EMA_per_win_span=P.EMA_per_win_span, \n",
    "    #                                                                              SMA_per_win_winsize=P.SMA_per_win_winsize,\n",
    "    #                                                                              Butter_per_win_argdict=P.Butter_per_win_argdict, \n",
    "    #                                                                              verbose=0)\n",
    "\n",
    "    #     X_train_exp1_dict, X_train_exp2_dict, \\\n",
    "    #     fitted_scaler_train_exp2_dict, \\\n",
    "    #     fitted_min_max_scaler_train_exp2_dict=append_user_47_to_data_NN(\\\n",
    "    #                                                               X_exp1_dict=X_train_exp1_dict, \n",
    "    #                                                               X_exp2_dict=X_train_exp2_dict, \n",
    "    #                                                               fitted_scaler_exp2_dict=fitted_scaler_train_exp2_dict, \n",
    "    #                                                               all_user_set=P.user_ids, \n",
    "    #                                                               X_exp1_dict_user_47=X_train_exp1_dict_user_47, \n",
    "    #                                                               X_exp2_dict_user_47=X_train_exp2_dict_user_47, \n",
    "    #                                                               fitted_scaler_exp2_dict_user_47=fitted_scaler_train_exp2_dict_user_47, \n",
    "    #                                                               fitted_min_max_scaler_exp2_dict=fitted_min_max_scaler_train_exp2_dict, \n",
    "    #                                                               fitted_min_max_scaler_exp2_dict_user_47=fitted_min_max_scaler_train_exp2_dict_user_47,\n",
    "    #                                                               verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d790497-a662-40c9-be91-bd7d41e83fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da83c43-f47c-4b60-870e-0dd6c7d88f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32477f-a8da-4dd6-9d89-bc7fe96c1140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
