{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "EXP_PATH_NAME=\"SCNN-kNN\"\n",
    "RIVAL_PATH_NAME=\"WACA-kNN\"\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "Numpy Seed was set to: 567\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "import os\n",
    "\n",
    "import gc\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "import time\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "%run ./Classification_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"Numpy Seed was set to: {SEED}\")\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__dir__()\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "        \n",
    "    user_ids: list\n",
    "    num_sample_points_per_exp: int\n",
    "    exp_begin_cutoff_idx: int\n",
    "    exp_end_cutoff_idx: int\n",
    "        \n",
    "    \n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    window_size: int  # After resampling\n",
    "    ocsvm_step_width: int  # After resampling\n",
    "    scaler: str  # StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_kernel: str # ocsvm kernel\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects=29,\n",
    "    max_test_subjects=10,\n",
    "    user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49],\n",
    "    num_sample_points_per_exp=21000,\n",
    "    exp_begin_cutoff_idx=500,\n",
    "    exp_end_cutoff_idx=-500,\n",
    "    seconds_per_subject_train=210,\n",
    "    seconds_per_subject_test=210,    \n",
    "    window_size=250,\n",
    "    ocsvm_step_width=250,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_kernel=\"rbf\",\n",
    "    ocsvm_nu=None,\n",
    "    ocsvm_gamma=None,\n",
    "    feature_cols=[\n",
    "        \"x_a\",\n",
    "        \"y_a\",\n",
    "        \"z_a\",\n",
    "        \"x_g\",\n",
    "        \"y_g\",\n",
    "        \"z_g\",\n",
    "    ],\n",
    "    exclude_subjects=[],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.037,\n",
    "    ocsvm_gamma= 0.001,\n",
    ")\n",
    "# NORMALIZER_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_NORMALIZER_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-NORMALIZER-OCSVM\",\n",
    "    scaler=\"Normalizer\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.074,\n",
    "    ocsvm_gamma= 0.029,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,50, 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM\n",
    "# P = VALID_NORMALIZER_OCSVM\n",
    "N_NEIGHBORS_PARAMS = np.arange(1,20) \n",
    "P.p=2\n",
    "# n_neighbors_params = np.arange(1, 50, 5) \n",
    "\n",
    "P.scaler_clip=False\n",
    "P.is_NN=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>VALID-ROBUST-OCSVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_subjects</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_test_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_ids</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sample_points_per_exp</th>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_begin_cutoff_idx</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_end_cutoff_idx</th>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_train</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_test</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_step_width</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_scope</th>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_global</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_kernel</th>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_nu</th>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_gamma</th>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_cols</th>\n",
       "      <td>[x_a, y_a, z_a, x_g, y_g, z_g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclude_subjects</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Value\n",
       "name                                                      VALID-ROBUST-OCSVM\n",
       "frequency                                                                100\n",
       "max_subjects                                                              29\n",
       "max_test_subjects                                                         10\n",
       "user_ids                   [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...\n",
       "num_sample_points_per_exp                                              21000\n",
       "exp_begin_cutoff_idx                                                     500\n",
       "exp_end_cutoff_idx                                                      -500\n",
       "seconds_per_subject_train                                                210\n",
       "seconds_per_subject_test                                                 210\n",
       "window_size                                                              250\n",
       "ocsvm_step_width                                                         250\n",
       "scaler                                                          RobustScaler\n",
       "scaler_scope                                                         subject\n",
       "scaler_global                                                          False\n",
       "ocsvm_kernel                                                             rbf\n",
       "ocsvm_nu                                                               0.037\n",
       "ocsvm_gamma                                                            0.001\n",
       "feature_cols                                  [x_a, y_a, z_a, x_g, y_g, z_g]\n",
       "exclude_subjects                                                          []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(utils_eer, greater_is_better=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_eer_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n",
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n",
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n",
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n",
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n",
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n",
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n",
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n",
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n",
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n",
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n",
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n",
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n",
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n",
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n",
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n",
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n",
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n",
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n",
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n",
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n",
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n",
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n",
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n",
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n",
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n",
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n",
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n",
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n"
     ]
    }
   ],
   "source": [
    "#include 47 later\n",
    "# user_ids = [9]\n",
    "df_exps_dict = load_data_frames(P.user_ids, P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, P.num_sample_points_per_exp)\n",
    "raw_dfList_exp1, raw_dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n",
      "47) accel_count: 17718, gyro_count: 18353\n"
     ]
    }
   ],
   "source": [
    "num_sample_points_per_exp_user_47 = 18000\n",
    "df_exps_dict_user_47 = load_data_frames([47], P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "raw_dfList_exp2_user_47 = dfList_exp2_user_47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "exp_deep_archi_extractors_dict=get_exp_deep_feature_extractors_dict(exp_num=EXP_NUM_0)\n",
    "# exp_deep_archi_extractors_dict=get_exp_deep_feature_extractors_dict(EXP_NUM_0, model_architectures= [list(TRAINING_CONFIG_DICT['1500'].keys())[0]])\n",
    "P.p=2 #\n",
    "\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = None\n",
    "\n",
    "preprocessing_method=None\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "for scnn_archi_name, exp_deep_feature_extractors_dict in exp_deep_archi_extractors_dict.items():\n",
    "\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{RIVAL_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    # P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    # print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "    test_dict_key=scnn_archi_name\n",
    "    EER_df_test_dict[test_dict_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST,\n",
    "                                                                                test_set=test_set, exp_config=P, \n",
    "                                                                                extract_features_func_dict=exp_deep_feature_extractors_dict, \n",
    "                                                                                overlap=OVERLAP, best_param_df=rival_test_hyperparameters_df)\n",
    "    with open(test_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"test_dict_key: {test_dict_key}\\n\")\n",
    "        f.write(EER_df_test_dict[test_dict_key].to_string())\n",
    "        \n",
    "    \n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"scnn_archi_name\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Butterworth frequency Cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for cut_off_freq in tqdm(list(range(48, 50))):\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": ffted_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                    n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for cut_off_freq in tqdm(list(range(48, 50))):\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                    n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "\n",
    "\n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n",
      "cut_off_freq: 33\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 04:59:24.177018: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 05:01:16.684908: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MakeSCNNExpDicOwner Time:  2.123615157790482\n",
      "MakeSCNNXExpDicUnknown Time:  262.7918708398938\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [07:57<31:50, 477.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.7500167973339558\n",
      "MakeSCNNXExpDicUnknown Time:  147.84856798127294\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:29<17:49, 356.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.5223274556919932\n",
      "MakeSCNNXExpDicUnknown Time:  82.9784836024046\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [15:15<08:59, 269.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.4242823775857687\n",
      "MakeSCNNXExpDicUnknown Time:  62.2270540446043\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [16:46<03:19, 199.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.5062655992805958\n",
      "MakeSCNNXExpDicUnknown Time:  53.55752743314952\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [18:05<00:00, 217.06s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  0.9943220047280192\n",
      "MakeSCNNXExpDicUnknown Time:  63.80654580891132\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:44<06:58, 104.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  1.241743516176939\n",
      "MakeSCNNXExpDicUnknown Time:  45.88241796847433\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:54<04:12, 84.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  1.0895503535866737\n",
      "MakeSCNNXExpDicUnknown Time:  29.47416974324733\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [03:39<02:12, 66.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  0.9881301131099463\n",
      "MakeSCNNXExpDicUnknown Time:  21.814191109500825\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [04:11<00:52, 52.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  1.0175032150000334\n",
      "MakeSCNNXExpDicUnknown Time:  19.200509505346417\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:38<00:00, 55.63s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  4.870510470122099\n",
      "MakeSCNNXExpDicUnknown Time:  428.84808765910566\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [11:51<47:25, 711.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  4.792969892732799\n",
      "MakeSCNNXExpDicUnknown Time:  263.34131877403706\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [19:20<27:52, 557.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  3.971597717143595\n",
      "MakeSCNNXExpDicUnknown Time:  129.51878725923598\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [24:16<14:35, 437.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  4.132049847394228\n",
      "MakeSCNNXExpDicUnknown Time:  87.17781422752887\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [26:43<05:22, 322.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  2.502830123528838\n",
      "MakeSCNNXExpDicUnknown Time:  100.62641231250018\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [29:08<00:00, 349.66s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  1.6021603690460324\n",
      "MakeSCNNXExpDicUnknown Time:  102.61811952386051\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:39<10:38, 159.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  1.4776329845190048\n",
      "MakeSCNNXExpDicUnknown Time:  54.60215181577951\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [04:07<05:52, 117.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  1.4250497026368976\n",
      "MakeSCNNXExpDicUnknown Time:  35.28329959977418\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [05:03<02:58, 89.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  0.9787841895595193\n",
      "MakeSCNNXExpDicUnknown Time:  20.91852432861924\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [05:34<01:06, 66.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  0.9672643356025219\n",
      "MakeSCNNXExpDicUnknown Time:  18.615027411840856\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:00<00:00, 72.08s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  3.6696703527122736\n",
      "MakeSCNNXExpDicUnknown Time:  303.2154254177585\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [09:26<37:47, 567.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  4.468364437110722\n",
      "MakeSCNNXExpDicUnknown Time:  238.23007825296372\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [16:10<23:33, 471.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  3.5061821518465877\n",
      "MakeSCNNXExpDicUnknown Time:  133.50795263051987\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [20:29<12:27, 373.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  3.1017285622656345\n",
      "MakeSCNNXExpDicUnknown Time:  100.92329528555274\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [22:51<04:42, 282.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  2.4015790689736605\n",
      "MakeSCNNXExpDicUnknown Time:  116.20508683938533\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [25:28<00:00, 305.69s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  1.6809095572680235\n",
      "MakeSCNNXExpDicUnknown Time:  107.40811271965504\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:46<11:05, 166.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  1.4424332827329636\n",
      "MakeSCNNXExpDicUnknown Time:  49.93043551873416\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [04:12<05:56, 118.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  1.1804498042911291\n",
      "MakeSCNNXExpDicUnknown Time:  40.414878541603684\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [05:08<03:01, 90.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  1.0798452226445079\n",
      "MakeSCNNXExpDicUnknown Time:  26.201409270055592\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [05:49<01:10, 70.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  1.3651459543034434\n",
      "MakeSCNNXExpDicUnknown Time:  19.43711633514613\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:18<00:00, 75.74s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  3.106049131602049\n",
      "MakeSCNNXExpDicUnknown Time:  313.1325587499887\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [09:09<36:38, 549.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  2.1709690894931555\n",
      "MakeSCNNXExpDicUnknown Time:  140.0600311215967\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [13:33<19:04, 381.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.6659295596182346\n",
      "MakeSCNNXExpDicUnknown Time:  116.82615866046399\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [17:22<10:24, 312.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  2.5901043098419905\n",
      "MakeSCNNXExpDicUnknown Time:  70.21822785027325\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [19:09<03:51, 231.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.433676317334175\n",
      "MakeSCNNXExpDicUnknown Time:  51.511640830896795\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [20:25<00:00, 245.08s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  2.20554758887738\n",
      "MakeSCNNXExpDicUnknown Time:  127.58660187385976\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:56<11:45, 176.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  1.5430516982451081\n",
      "MakeSCNNXExpDicUnknown Time:  53.231799161061645\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [04:15<05:57, 119.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  1.203529947437346\n",
      "MakeSCNNXExpDicUnknown Time:  36.179613936692476\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [05:07<02:57, 88.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  1.6501152692362666\n",
      "MakeSCNNXExpDicUnknown Time:  34.40963509771973\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [05:57<01:13, 73.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.99999994 1.         0.99999994 0.9999999  0.99999994]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  1.0683482605963945\n",
      "MakeSCNNXExpDicUnknown Time:  25.923886441625655\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:34<00:00, 78.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('SCNN_3_1_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62  0.105671                9  0.705887\n",
      "0         250        125  0.075649                9  0.777221\n",
      "0         500        250  0.062316               15  0.838656\n",
      "0         750        375  0.039495                6  0.882495\n",
      "0        1000        500  0.021816                8  0.933126, ('SCNN_3_2_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62    0.1076                4   0.67484\n",
      "0         250        125    0.0999                9  0.712728\n",
      "0         500        250  0.058768                4  0.811263\n",
      "0         750        375  0.035859                8  0.861377\n",
      "0        1000        500  0.020054                3  0.920721, ('SCNN_1_3_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62  0.116881               14  0.699765\n",
      "0         250        125  0.076048                3  0.766851\n",
      "0         500        250  0.056292                8  0.828154\n",
      "0         750        375  0.041414                6  0.864607\n",
      "0        1000        500  0.045257                8   0.89481, ('SCNN_3_123_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62  0.098764               16   0.73292\n",
      "0         250        125  0.068397                7  0.817693\n",
      "0         500        250  0.052477                6  0.839031\n",
      "0         750        375  0.038283               12  0.897772\n",
      "0        1000        500  0.040515               15  0.880007}\n",
      "train_set: {0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 29}\n",
      "test_set: {1, 3, 5, 6, 16, 19, 22, 24, 25, 28}\n",
      "cut_off_freq: 33\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "train_set: {0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 29}\n",
      "test_set: {1, 3, 5, 6, 16, 19, 22, 24, 25, 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  4.995454707182944\n",
      "MakeSCNNXExpDicUnknown Time:  383.1073866132647\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [11:13<44:54, 673.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  3.018433352932334\n",
      "MakeSCNNXExpDicUnknown Time:  188.4940056214109\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [16:57<23:59, 479.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  1.4262744653970003\n",
      "MakeSCNNXExpDicUnknown Time:  93.67047208826989\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [19:53<11:21, 340.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  2.097153889015317\n",
      "MakeSCNNXExpDicUnknown Time:  100.11817555502057\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [22:26<04:26, 266.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  4.308660222217441\n",
      "MakeSCNNXExpDicUnknown Time:  146.3826099699363\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [26:02<00:00, 312.58s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  2.2854397306218743\n",
      "MakeSCNNXExpDicUnknown Time:  92.32952125649899\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:51<11:25, 171.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.2433681720867753\n",
      "MakeSCNNXExpDicUnknown Time:  50.56646528095007\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [04:11<05:52, 117.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  0.7893825210630894\n",
      "MakeSCNNXExpDicUnknown Time:  24.109971208497882\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [04:49<02:42, 81.16s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.0991517463698983\n",
      "MakeSCNNXExpDicUnknown Time:  22.50533641409129\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [05:22<01:02, 62.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.3859066804870963\n",
      "MakeSCNNXExpDicUnknown Time:  25.813060364685953\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:58<00:00, 71.64s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  5.2004086542874575\n",
      "MakeSCNNXExpDicUnknown Time:  417.2080084551126\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [12:31<50:05, 751.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  3.192438779398799\n",
      "MakeSCNNXExpDicUnknown Time:  209.1775892795995\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [18:31<26:03, 521.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  2.5306788133457303\n",
      "MakeSCNNXExpDicUnknown Time:  117.06515802815557\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [22:11<12:47, 383.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  2.1989224180579185\n",
      "MakeSCNNXExpDicUnknown Time:  61.851390447467566\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [23:47<04:30, 270.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  2.2662181770429015\n",
      "MakeSCNNXExpDicUnknown Time:  77.5281966086477\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [25:39<00:00, 307.80s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.790098387748003\n",
      "MakeSCNNXExpDicUnknown Time:  88.13986561726779\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:23<09:34, 143.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.3699548644945025\n",
      "MakeSCNNXExpDicUnknown Time:  57.726609006524086\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [03:50<05:30, 110.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.2122831773012877\n",
      "MakeSCNNXExpDicUnknown Time:  51.180544768460095\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [05:05<03:08, 94.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.5849143462255597\n",
      "MakeSCNNXExpDicUnknown Time:  48.821241334080696\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [06:09<01:22, 82.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.8293753266334534\n",
      "MakeSCNNXExpDicUnknown Time:  28.468396150507033\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:53<00:00, 82.80s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  5.174014645628631\n",
      "MakeSCNNXExpDicUnknown Time:  415.14749759156257\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [12:41<50:47, 761.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  3.0745681542903185\n",
      "MakeSCNNXExpDicUnknown Time:  248.93238372728229\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [19:32<27:45, 555.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  2.5222927294671535\n",
      "MakeSCNNXExpDicUnknown Time:  137.29201706964523\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [23:38<13:48, 414.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  2.257192734628916\n",
      "MakeSCNNXExpDicUnknown Time:  78.25906998291612\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [25:38<04:57, 297.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  1.6062083011493087\n",
      "MakeSCNNXExpDicUnknown Time:  54.34805762115866\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [26:57<00:00, 323.46s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.1166224824264646\n",
      "MakeSCNNXExpDicUnknown Time:  67.84529844019562\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:52<07:28, 112.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  0.8839456709101796\n",
      "MakeSCNNXExpDicUnknown Time:  37.30956700909883\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:51<04:02, 80.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  0.8521000547334552\n",
      "MakeSCNNXExpDicUnknown Time:  21.073209797032177\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [03:23<01:57, 58.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  0.8701410572975874\n",
      "MakeSCNNXExpDicUnknown Time:  16.50875235069543\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:48<00:45, 45.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  0.678335390985012\n",
      "MakeSCNNXExpDicUnknown Time:  15.088011290878057\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [04:08<00:00, 49.79s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  3.286451422609389\n",
      "MakeSCNNXExpDicUnknown Time:  310.9966344675049\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [09:25<37:41, 565.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  3.0020730225369334\n",
      "MakeSCNNXExpDicUnknown Time:  235.18458635918796\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [16:12<23:36, 472.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  2.6715666176751256\n",
      "MakeSCNNXExpDicUnknown Time:  132.88172959163785\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [20:59<12:55, 387.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  3.293300161138177\n",
      "MakeSCNNXExpDicUnknown Time:  101.4282046072185\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [23:29<04:53, 293.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  2.961143545806408\n",
      "MakeSCNNXExpDicUnknown Time:  83.48727686982602\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [25:31<00:00, 306.22s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.6654984951019287\n",
      "MakeSCNNXExpDicUnknown Time:  89.0278377244249\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:38<10:35, 158.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.4033637773245573\n",
      "MakeSCNNXExpDicUnknown Time:  50.128100044094026\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [03:56<05:33, 111.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.1666013831272721\n",
      "MakeSCNNXExpDicUnknown Time:  29.208436159417033\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [04:41<02:41, 80.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.0907040685415268\n",
      "MakeSCNNXExpDicUnknown Time:  22.812265077605844\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [05:15<01:02, 62.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "MakeSCNNExpDicOwner Time:  1.146687532775104\n",
      "MakeSCNNXExpDicUnknown Time:  20.71159950364381\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:44<00:00, 68.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('SCNN_3_1_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62  0.149654               15  0.598566\n",
      "0         250        125  0.104424                5  0.717621\n",
      "0         500        250  0.065529               17  0.760493\n",
      "0         750        375  0.104444               10  0.737395\n",
      "0        1000        500  0.035637               10  0.896198, ('SCNN_3_2_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62  0.153577               11  0.591997\n",
      "0         250        125  0.183633               17  0.554883\n",
      "0         500        250  0.112651                5  0.663689\n",
      "0         750        375  0.106061               10   0.72582\n",
      "0        1000        500  0.071951               10  0.786964, ('SCNN_1_3_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62  0.216733               18  0.479438\n",
      "0         250        125  0.173819               19  0.545355\n",
      "0         500        250  0.091232               10  0.701679\n",
      "0         750        375  0.144444                8  0.641818\n",
      "0        1000        500  0.106233                4  0.698554, ('SCNN_3_123_conv_1_dense_arg_dict_default', 33):   window_size step_width  Mean_EER best_n_neighbors Gini_coef\n",
      "0         125         62  0.150132                8  0.576151\n",
      "0         250        125  0.105689               10  0.683255\n",
      "0         500        250  0.063387                6  0.789264\n",
      "0         750        375  0.044444                8  0.858384\n",
      "0        1000        500  0.095799                5  0.760349}\n",
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n",
      "cut_off_freq: 33\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv2\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  3.2718985695391893\n",
      "MakeSCNNXExpDicUnknown Time:  354.6104431990534\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [10:06<40:24, 606.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  2.7774807382375\n",
      "MakeSCNNXExpDicUnknown Time:  262.34331580158323\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [17:05<24:48, 496.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  2.1574374036863446\n",
      "MakeSCNNXExpDicUnknown Time:  119.78952060360461\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [20:31<12:07, 363.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  2.0214347979053855\n",
      "MakeSCNNXExpDicUnknown Time:  106.55233939643949\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [22:52<04:35, 275.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  1.462035865522921\n",
      "MakeSCNNXExpDicUnknown Time:  47.62481752876192\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [24:04<00:00, 288.84s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.479000880382955\n",
      "MakeSCNNXExpDicUnknown Time:  68.34415547735989\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:57<07:48, 117.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.4345481060445309\n",
      "MakeSCNNXExpDicUnknown Time:  62.787508551962674\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [03:31<05:10, 103.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.0906780483201146\n",
      "MakeSCNNXExpDicUnknown Time:  30.493768429383636\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [04:17<02:34, 77.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.1152894487604499\n",
      "MakeSCNNXExpDicUnknown Time:  28.094337347894907\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [04:56<01:02, 62.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.3999845394864678\n",
      "MakeSCNNXExpDicUnknown Time:  34.69318082649261\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:45<00:00, 69.05s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  4.003402583301067\n",
      "MakeSCNNXExpDicUnknown Time:  398.39078466035426\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [12:08<48:32, 728.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeSCNNExpDicOwner Time:  5.0078676249831915\n",
      "MakeSCNNXExpDicUnknown Time:  278.8945409236476\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [20:08<29:07, 582.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeSCNNExpDicOwner Time:  2.7128392960876226\n",
      "MakeSCNNXExpDicUnknown Time:  180.5050987135619\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [25:49<15:44, 472.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeSCNNExpDicOwner Time:  4.093404549174011\n",
      "MakeSCNNXExpDicUnknown Time:  178.96910119149834\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [29:53<06:21, 381.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeSCNNExpDicOwner Time:  2.5093410024419427\n",
      "MakeSCNNXExpDicUnknown Time:  85.38773930910975\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [32:01<00:00, 384.37s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.803142949938774\n",
      "MakeSCNNXExpDicUnknown Time:  135.71149451751262\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [04:03<16:13, 243.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  2.5148285012692213\n",
      "MakeSCNNXExpDicUnknown Time:  86.01538177300245\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [06:36<09:30, 190.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.4129909202456474\n",
      "MakeSCNNXExpDicUnknown Time:  38.79065477196127\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [07:35<04:21, 130.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  3.08715564198792\n",
      "MakeSCNNXExpDicUnknown Time:  46.39274671673775\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [08:38<01:43, 103.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         1.0000002  0.99999994 1.         0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  0.99999994 1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999999  1.0000001  0.9999999  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001 0.9999998 0.9999998 1.0000001 1.        0.9999998]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999998  1.         0.9999998  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.9999999  0.99999994 1.         0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         0.99999994 1.0000002  0.9999998  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.0000001  0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.99999994 1.0000001  0.9999999  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         1.0000001  1.         0.9999999 ]\n",
      "MakeSCNNExpDicOwner Time:  1.1308230282738805\n",
      "MakeSCNNXExpDicUnknown Time:  23.89310673158616\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:13<00:00, 110.72s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "NN preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.99999994 0.99999994 1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.        1.0000001 0.9999998 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 0.99999994 1.         0.99999994 0.9999999 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.0000001  1.0000002  0.99999994 0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 0.9999999 1.        1.0000001 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 1.0000001  1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 1.         0.9999999  0.9999999  1.         1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  1.         0.9999998  1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000001  0.99999994 0.99999994 1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.99999994 0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.        1.0000001 0.9999999 0.9999999 1.       ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         1.         1.         1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999  0.9999998  1.         1.         0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.9999999  1.0000001  0.99999994 1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.99999994 0.9999998  1.         0.9999999  0.99999994 1.0000001 ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[0.9999999 1.        1.0000001 1.        1.        0.9999999]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         0.99999994 1.         0.9999998  1.         0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.0000002  1.0000001  1.0000002  1.         0.9999998  0.99999994]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.         1.         1.         1.0000001  0.99999994 1.        ]\n",
      "[-1. -1. -1. -1. -1. -1.]\n",
      "[1.        1.0000001 1.        1.        1.        1.0000001]\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeSCNNExpDicOwner Time:  3.1137734558433294\n",
      "MakeSCNNXExpDicUnknown Time:  378.09086183365434\n",
      "Done extracting features\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "clf_type=\"standalone\"\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    \n",
    "    train_set, test_set=THREE_FOLD_CV[cv_fold_idx]\n",
    "    print(f\"train_set: {train_set}\")\n",
    "    print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    #--------------butter33----------------------\n",
    "    P.cut_off_freq=33\n",
    "\n",
    "    P.Butter_per_win_argdict={\n",
    "        \"filter_order\": P.filter_order,\n",
    "        \"cut_off_freq\": P.cut_off_freq,\n",
    "        \"sampling_freq\": P.sampling_freq,\n",
    "        \"filtfilt\": P.filtfilt,\n",
    "        }   \n",
    "\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "    #--------------butter33----------------------\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "        \n",
    "\n",
    "    exp_deep_archi_extractors_dict=get_exp_deep_feature_extractors_dict(exp_num=EXP_NUM_1_2, \n",
    "                                                                        model_architectures=list(TRAINING_CONFIG_CV_DICT[\"Butter\"][cv_fold_idx]['1000'].keys()), \n",
    "                                                                        exp_path_name=EXP_PATH_NAME,\n",
    "                                                                        window_size_lst=WINDOW_SIZE_LST_NN,\n",
    "                                                                        variant_suffix=f\"Butter33-cv{cv_fold_idx}\")\n",
    "        \n",
    "\n",
    "    key_column= [\"cut_off_freq\"]\n",
    "    # -----CV_FOLD-------\n",
    "    # for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_kNN_NN(\\\n",
    "                            cv_fold_idx=cv_fold_idx, \n",
    "                            cv_sets=THREE_FOLD_CV, \n",
    "                            dfList_dict=dfList_dict, \n",
    "                            window_size_lst=WINDOW_SIZE_LST_NN, \n",
    "                            exp_config=P, \n",
    "                            exp_deep_archi_extractors_dict=exp_deep_archi_extractors_dict, \n",
    "                            overlap=OVERLAP, \n",
    "                            n_neighbors_params=N_NEIGHBORS_PARAMS, \n",
    "                            train_file_name=train_file_name, \n",
    "                            test_file_name=test_file_name, \n",
    "                            preprocessing_params=P.cut_off_freq,\n",
    "                            key_column=key_column,\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    del exp_deep_archi_extractors_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Butterworth frequency Cut-off + EMA span\n",
    "## 2.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {choice_num}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_span_pairs[-2:]):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, span = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.span=span\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"span: {P.span}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                              extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                              n_neighbors_params=n_neighbors_params)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "clf_type=\"standalone\"\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    \n",
    "    train_set, test_set=THREE_FOLD_CV[cv_fold_idx]\n",
    "    print(f\"train_set: {train_set}\")\n",
    "    print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    #--------------butter33-EMA20----------------------\n",
    "\n",
    "    P.cut_off_freq=33\n",
    "    P.span=20\n",
    "\n",
    "    P.Butter_per_win_argdict={\n",
    "        \"filter_order\": P.filter_order,\n",
    "        \"cut_off_freq\": P.cut_off_freq,\n",
    "        \"sampling_freq\": P.sampling_freq,\n",
    "        \"filtfilt\": P.filtfilt,\n",
    "        }   \n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    #--------------butter33-EMA20----------------------\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    exp_deep_archi_extractors_dict=get_exp_deep_feature_extractors_dict(exp_num=EXP_NUM_2_2, \n",
    "                                                                        model_architectures=list(TRAINING_CONFIG_CV_DICT[\"Butter-EMA\"][cv_fold_idx]['1000'].keys()), \n",
    "                                                                        exp_path_name=EXP_PATH_NAME,\n",
    "                                                                        window_size_lst=WINDOW_SIZE_LST_NN,\n",
    "                                                                        variant_suffix=f\"Butter33-EMA20-cv{cv_fold_idx}\")\n",
    "        \n",
    "\n",
    "    key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "    # -----CV_FOLD-------\n",
    "    # for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_kNN_NN(\\\n",
    "                            cv_fold_idx=cv_fold_idx, \n",
    "                            cv_sets=THREE_FOLD_CV, \n",
    "                            dfList_dict=dfList_dict, \n",
    "                            window_size_lst=WINDOW_SIZE_LST_NN, \n",
    "                            exp_config=P, \n",
    "                            exp_deep_archi_extractors_dict=exp_deep_archi_extractors_dict, \n",
    "                            overlap=OVERLAP, \n",
    "                            n_neighbors_params=N_NEIGHBORS_PARAMS, \n",
    "                            train_file_name=train_file_name, \n",
    "                            test_file_name=test_file_name, \n",
    "                            preprocessing_params=(P.cut_off_freq, P.EMA_per_win_span),\n",
    "                            key_column=key_column,\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    del exp_deep_archi_extractors_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {choice_num}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_span_pairs[-2:]):\n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, span = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=cut_off_freq\n",
    "    \n",
    "    \n",
    "    P.span=span\n",
    "    P.EMA_per_win_span=span\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"span: {P.span}\")\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                              extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                              n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EMA span\n",
    "## 3.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for span in tqdm(list(range(48, 50))):\n",
    "    P.span=span\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                            extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                            n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for span in tqdm(list(range(48, 50))):\n",
    "    P.span=span\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                            extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                            n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SMA winsize\n",
    "## 4.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for winsize in tqdm(list(range(48, 50))):\n",
    "    P.winsize=winsize\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                               extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                               n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for winsize in tqdm(list(range(48, 50))):\n",
    "    P.winsize=winsize\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                               extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                               n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Butterworth frequency Cut-off + SMA winsize\n",
    "## 5.1 Naive Approach\n",
    "### Optimizing and Testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {choice_num}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_winsize_pairs[-2:]):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, winsize = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.winsize=winsize\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                              extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                              n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "clf_type=\"standalone\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    \n",
    "    train_set, test_set=THREE_FOLD_CV[cv_fold_idx]\n",
    "    print(f\"train_set: {train_set}\")\n",
    "    print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    # --------------butter33-SMA20----------------------\n",
    "    P.winsize=20\n",
    "    P.cut_off_freq=33\n",
    "\n",
    "    P.Butter_per_win_argdict={\n",
    "        \"filter_order\": P.filter_order,\n",
    "        \"cut_off_freq\": P.cut_off_freq,\n",
    "        \"sampling_freq\": P.sampling_freq,\n",
    "        \"filtfilt\": P.filtfilt,\n",
    "         }   \n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "    # --------------butter33-SMA20----------------------\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    exp_deep_archi_extractors_dict=get_exp_deep_feature_extractors_dict(exp_num=EXP_NUM_5_2, \n",
    "                                                                        model_architectures=list(TRAINING_CONFIG_CV_DICT[\"Butter-SMA\"][cv_fold_idx]['1000'].keys()), \n",
    "                                                                        exp_path_name=EXP_PATH_NAME,\n",
    "                                                                        window_size_lst=WINDOW_SIZE_LST_NN,\n",
    "                                                                        variant_suffix=f\"Butter33-SMA20-cv{cv_fold_idx}\")\n",
    "        \n",
    "\n",
    "    key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "    # -----CV_FOLD-------\n",
    "    # for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_kNN_NN(\\\n",
    "                            cv_fold_idx=cv_fold_idx, \n",
    "                            cv_sets=THREE_FOLD_CV, \n",
    "                            dfList_dict=dfList_dict, \n",
    "                            window_size_lst=WINDOW_SIZE_LST_NN, \n",
    "                            exp_config=P, \n",
    "                            exp_deep_archi_extractors_dict=exp_deep_archi_extractors_dict, \n",
    "                            overlap=OVERLAP, \n",
    "                            n_neighbors_params=N_NEIGHBORS_PARAMS, \n",
    "                            train_file_name=train_file_name, \n",
    "                            test_file_name=test_file_name, \n",
    "                            preprocessing_params=(P.cut_off_freq, P.SMA_per_win_winsize),\n",
    "                            key_column=key_column,\n",
    "                            )\n",
    "    \n",
    "    \n",
    "    del exp_deep_archi_extractors_dict\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {choice_num}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_winsize_pairs[-2:]):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, winsize = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.winsize=winsize\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "    \n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                              extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                              n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap*=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The effect of Varying Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for overlap in tqdm(list(range(48, 50))):\n",
    "    overlap*=0.01\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "    max_num_windows=max(len(getIndices(sampleSize=max_window_size, step=step_width, numSamplePoints=P.num_sample_points_per_exp)), 100)\n",
    "    n_neighbors_params = np.arange(1, max_num_windows) \n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[overlap] = calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                             extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                             n_neighbors_params=n_neighbors_params)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\overlap: {overlap}\\n\")\n",
    "        f.write(EER_df_train_dict[overlap].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                      best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"overlap\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\"></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>scnn_archi_name</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>SCNN_1_3_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.176223</td>\n",
       "      <td>0.129907</td>\n",
       "      <td>0.101763</td>\n",
       "      <td>0.092357</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.116310</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>SCNN_3_123_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.136433</td>\n",
       "      <td>0.093912</td>\n",
       "      <td>0.064034</td>\n",
       "      <td>0.050741</td>\n",
       "      <td>0.069061</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>0.001142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>SCNN_3_1_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.137817</td>\n",
       "      <td>0.094234</td>\n",
       "      <td>0.067336</td>\n",
       "      <td>0.068519</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.081892</td>\n",
       "      <td>0.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>SCNN_3_2_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.146791</td>\n",
       "      <td>0.139665</td>\n",
       "      <td>0.086635</td>\n",
       "      <td>0.081145</td>\n",
       "      <td>0.062195</td>\n",
       "      <td>0.103286</td>\n",
       "      <td>0.001418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>SCNN_1_3_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.136856</td>\n",
       "      <td>0.091151</td>\n",
       "      <td>0.069656</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.069106</td>\n",
       "      <td>0.088243</td>\n",
       "      <td>0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>SCNN_3_123_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.143395</td>\n",
       "      <td>0.085263</td>\n",
       "      <td>0.062271</td>\n",
       "      <td>0.051380</td>\n",
       "      <td>0.042005</td>\n",
       "      <td>0.076863</td>\n",
       "      <td>0.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>SCNN_3_1_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.142373</td>\n",
       "      <td>0.085673</td>\n",
       "      <td>0.064436</td>\n",
       "      <td>0.045488</td>\n",
       "      <td>0.039070</td>\n",
       "      <td>0.075408</td>\n",
       "      <td>0.001731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>SCNN_3_2_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.137136</td>\n",
       "      <td>0.085230</td>\n",
       "      <td>0.067760</td>\n",
       "      <td>0.054343</td>\n",
       "      <td>0.050316</td>\n",
       "      <td>0.078957</td>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>SCNN_1_3_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.136268</td>\n",
       "      <td>0.093679</td>\n",
       "      <td>0.075324</td>\n",
       "      <td>0.087609</td>\n",
       "      <td>0.047696</td>\n",
       "      <td>0.088115</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>SCNN_3_123_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.146186</td>\n",
       "      <td>0.085141</td>\n",
       "      <td>0.070303</td>\n",
       "      <td>0.057980</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.081922</td>\n",
       "      <td>0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>SCNN_3_1_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.146494</td>\n",
       "      <td>0.085961</td>\n",
       "      <td>0.064949</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.053884</td>\n",
       "      <td>0.080911</td>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>SCNN_3_2_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.137691</td>\n",
       "      <td>0.088756</td>\n",
       "      <td>0.069277</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.050271</td>\n",
       "      <td>0.081866</td>\n",
       "      <td>0.001166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              \\\n",
       "   mean rank                           scnn_archi_name cut_off_freq EMA_span   \n",
       "0         12    SCNN_1_3_conv_1_dense_arg_dict_default           33        -   \n",
       "1          8  SCNN_3_123_conv_1_dense_arg_dict_default           33        -   \n",
       "2          6    SCNN_3_1_conv_1_dense_arg_dict_default           33        -   \n",
       "3         11    SCNN_3_2_conv_1_dense_arg_dict_default           33        -   \n",
       "4         10    SCNN_1_3_conv_1_dense_arg_dict_default           33       20   \n",
       "5          2  SCNN_3_123_conv_1_dense_arg_dict_default           33       20   \n",
       "6          1    SCNN_3_1_conv_1_dense_arg_dict_default           33       20   \n",
       "7          3    SCNN_3_2_conv_1_dense_arg_dict_default           33       20   \n",
       "8          9    SCNN_1_3_conv_1_dense_arg_dict_default           33        -   \n",
       "9          7  SCNN_3_123_conv_1_dense_arg_dict_default           33        -   \n",
       "10         4    SCNN_3_1_conv_1_dense_arg_dict_default           33        -   \n",
       "11         5    SCNN_3_2_conv_1_dense_arg_dict_default           33        -   \n",
       "\n",
       "                     Window Size                                          \\\n",
       "   SMA_winsize  type         125       250       500       750      1000   \n",
       "0            -  Real    0.176223  0.129907  0.101763  0.092357  0.081301   \n",
       "1            -  Real    0.136433  0.093912  0.064034  0.050741  0.069061   \n",
       "2            -  Real    0.137817  0.094234  0.067336  0.068519  0.041554   \n",
       "3            -  Real    0.146791  0.139665  0.086635  0.081145  0.062195   \n",
       "4            -  Real    0.136856  0.091151  0.069656  0.074444  0.069106   \n",
       "5            -  Real    0.143395  0.085263  0.062271  0.051380  0.042005   \n",
       "6            -  Real    0.142373  0.085673  0.064436  0.045488  0.039070   \n",
       "7            -  Real    0.137136  0.085230  0.067760  0.054343  0.050316   \n",
       "8           20  Real    0.136268  0.093679  0.075324  0.087609  0.047696   \n",
       "9           20  Real    0.146186  0.085141  0.070303  0.057980  0.050000   \n",
       "10          20  Real    0.146494  0.085961  0.064949  0.053266  0.053884   \n",
       "11          20  Real    0.137691  0.088756  0.069277  0.063333  0.050271   \n",
       "\n",
       "                        \n",
       "        mean  variance  \n",
       "0   0.116310  0.001446  \n",
       "1   0.082836  0.001142  \n",
       "2   0.081892  0.001324  \n",
       "3   0.103286  0.001418  \n",
       "4   0.088243  0.000818  \n",
       "5   0.076863  0.001644  \n",
       "6   0.075408  0.001731  \n",
       "7   0.078957  0.001244  \n",
       "8   0.088115  0.001037  \n",
       "9   0.081922  0.001467  \n",
       "10  0.080911  0.001519  \n",
       "11  0.081866  0.001166  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=return_and_save_final_result_df_as_json_NN(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST_NN)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\"></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>scnn_archi_name</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>SCNN_1_3_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>SCNN_3_123_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>22.579438</td>\n",
       "      <td>27.708067</td>\n",
       "      <td>37.075203</td>\n",
       "      <td>45.060153</td>\n",
       "      <td>15.055556</td>\n",
       "      <td>28.779977</td>\n",
       "      <td>21.031478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>SCNN_3_1_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>21.793632</td>\n",
       "      <td>27.460521</td>\n",
       "      <td>33.830300</td>\n",
       "      <td>25.811156</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>29.591696</td>\n",
       "      <td>8.427354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>SCNN_3_2_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>16.701487</td>\n",
       "      <td>-7.511737</td>\n",
       "      <td>14.865161</td>\n",
       "      <td>12.139993</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>11.197412</td>\n",
       "      <td>1.959657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>SCNN_1_3_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>22.339331</td>\n",
       "      <td>29.833547</td>\n",
       "      <td>31.550099</td>\n",
       "      <td>19.394823</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.131477</td>\n",
       "      <td>43.413820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>SCNN_3_123_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>18.628582</td>\n",
       "      <td>34.366197</td>\n",
       "      <td>38.807279</td>\n",
       "      <td>44.367481</td>\n",
       "      <td>48.333333</td>\n",
       "      <td>33.915400</td>\n",
       "      <td>-13.636914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>SCNN_3_1_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>19.208582</td>\n",
       "      <td>34.050363</td>\n",
       "      <td>36.680552</td>\n",
       "      <td>50.747357</td>\n",
       "      <td>51.944444</td>\n",
       "      <td>35.166489</td>\n",
       "      <td>-19.709956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>SCNN_3_2_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>22.180299</td>\n",
       "      <td>34.391805</td>\n",
       "      <td>33.413725</td>\n",
       "      <td>41.159315</td>\n",
       "      <td>38.111111</td>\n",
       "      <td>32.115014</td>\n",
       "      <td>13.997045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>SCNN_1_3_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>22.672986</td>\n",
       "      <td>27.887324</td>\n",
       "      <td>25.981144</td>\n",
       "      <td>5.140357</td>\n",
       "      <td>41.333333</td>\n",
       "      <td>24.240981</td>\n",
       "      <td>28.316713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>SCNN_3_123_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>17.044498</td>\n",
       "      <td>34.460094</td>\n",
       "      <td>30.914273</td>\n",
       "      <td>37.222020</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>29.565717</td>\n",
       "      <td>-1.418828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>SCNN_3_1_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>16.869874</td>\n",
       "      <td>33.828425</td>\n",
       "      <td>36.176277</td>\n",
       "      <td>42.325921</td>\n",
       "      <td>33.722222</td>\n",
       "      <td>30.435097</td>\n",
       "      <td>-5.024883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>SCNN_3_2_conv_1_dense_arg_dict_default</td>\n",
       "      <td>33</td>\n",
       "      <td>-</td>\n",
       "      <td>20</td>\n",
       "      <td>Real</td>\n",
       "      <td>21.865353</td>\n",
       "      <td>31.677337</td>\n",
       "      <td>31.922824</td>\n",
       "      <td>31.425447</td>\n",
       "      <td>38.166667</td>\n",
       "      <td>29.614249</td>\n",
       "      <td>19.382218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              \\\n",
       "   mean rank                           scnn_archi_name cut_off_freq EMA_span   \n",
       "0         12    SCNN_1_3_conv_1_dense_arg_dict_default           33        -   \n",
       "1          8  SCNN_3_123_conv_1_dense_arg_dict_default           33        -   \n",
       "2          6    SCNN_3_1_conv_1_dense_arg_dict_default           33        -   \n",
       "3         11    SCNN_3_2_conv_1_dense_arg_dict_default           33        -   \n",
       "4         10    SCNN_1_3_conv_1_dense_arg_dict_default           33       20   \n",
       "5          2  SCNN_3_123_conv_1_dense_arg_dict_default           33       20   \n",
       "6          1    SCNN_3_1_conv_1_dense_arg_dict_default           33       20   \n",
       "7          3    SCNN_3_2_conv_1_dense_arg_dict_default           33       20   \n",
       "8          9    SCNN_1_3_conv_1_dense_arg_dict_default           33        -   \n",
       "9          7  SCNN_3_123_conv_1_dense_arg_dict_default           33        -   \n",
       "10         4    SCNN_3_1_conv_1_dense_arg_dict_default           33        -   \n",
       "11         5    SCNN_3_2_conv_1_dense_arg_dict_default           33        -   \n",
       "\n",
       "                     Window Size                                              \\\n",
       "   SMA_winsize  type         125        250        500        750       1000   \n",
       "0            -  Real    0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1            -  Real   22.579438  27.708067  37.075203  45.060153  15.055556   \n",
       "2            -  Real   21.793632  27.460521  33.830300  25.811156  48.888889   \n",
       "3            -  Real   16.701487  -7.511737  14.865161  12.139993  23.500000   \n",
       "4            -  Real   22.339331  29.833547  31.550099  19.394823  15.000000   \n",
       "5            -  Real   18.628582  34.366197  38.807279  44.367481  48.333333   \n",
       "6            -  Real   19.208582  34.050363  36.680552  50.747357  51.944444   \n",
       "7            -  Real   22.180299  34.391805  33.413725  41.159315  38.111111   \n",
       "8           20  Real   22.672986  27.887324  25.981144   5.140357  41.333333   \n",
       "9           20  Real   17.044498  34.460094  30.914273  37.222020  38.500000   \n",
       "10          20  Real   16.869874  33.828425  36.176277  42.325921  33.722222   \n",
       "11          20  Real   21.865353  31.677337  31.922824  31.425447  38.166667   \n",
       "\n",
       "                          \n",
       "         mean   variance  \n",
       "0    0.000000   0.000000  \n",
       "1   28.779977  21.031478  \n",
       "2   29.591696   8.427354  \n",
       "3   11.197412   1.959657  \n",
       "4   24.131477  43.413820  \n",
       "5   33.915400 -13.636914  \n",
       "6   35.166489 -19.709956  \n",
       "7   32.115014  13.997045  \n",
       "8   24.240981  28.316713  \n",
       "9   29.565717  -1.418828  \n",
       "10  30.435097  -5.024883  \n",
       "11  29.614249  19.382218  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST_NN)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df.style.hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
