{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "d975284c-a069-40d8-9847-9465d0ac4f47",
    "_uuid": "b6bb54c3-ff29-436c-8f5e-b3a13b9f5153",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "TEST_MODE = 0 # Testing macro\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "CORES = -1\n",
    "SEED = 567\n",
    "\n",
    "import os\n",
    "\n",
    "if TEST_MODE:\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "3ae86968-b273-4857-a4fd-537b178d854b",
    "_uuid": "bcec77b5-0738-4d15-8aad-f6b59b3ac023",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.0.1)\n",
      "utility_functions imports setup complete\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "# !pip install python-docx\n",
    "# !pip install antropy\n",
    "\n",
    "MAGENTA = (202/255, 18/255, 125/255)\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy import signal\n",
    "import numpy as np # linear algebraf\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "import math as math\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "import statsmodels.stats.api as sms\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import asdict\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, accuracy_score, make_scorer, auc\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle as sklearn_shuffle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Input,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Lambda,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling1D,\n",
    "    Activation\n",
    ")\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Ftrl, Nadam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import concatenate as keras_concat\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import median_abs_deviation\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_widths\n",
    "from scipy.stats import entropy\n",
    "# from scipy.special import entr\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "get_new_scaler_dict = {\"StandardScaler\": StandardScaler, \"MinMaxScaler\": MinMaxScaler, \"Normalizer\": Normalizer, \n",
    "                       \"MaxAbsScaler\": MaxAbsScaler, \"RobustScaler\": RobustScaler, \"PowerTransformer\": PowerTransformer}\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc\n",
    "import time\n",
    "import json\n",
    "# import docx\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,8), 'figure.dpi': 180, \"legend.fontsize\": 26, \"axes.labelsize\": 26, #\"xtick.fontsize\": 26, \"ytick.fontsize\": 20, \n",
    "            \"xtick.labelsize\": 20, \"ytick.labelsize\": 20})\n",
    "\n",
    "err_distro_rc={'figure.figsize':(20,10), 'figure.dpi': 180, \"legend.fontsize\": 30, \"axes.labelsize\": 30, #\"xtick.fontsize\": 26, \"ytick.fontsize\": 20, \n",
    "            \"xtick.labelsize\": 25, \"ytick.labelsize\": 25}\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "print(\"utility_functions imports setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,8), 'figure.dpi': 180, \"legend.fontsize\": 9, \"axes.labelsize\": 11, #\"xtick.fontsize\": 26, \"ytick.fontsize\": 20, \n",
    "            \"xtick.labelsize\": 11, \"ytick.labelsize\": 11})\n",
    "# sns.set(rc={'figure.figsize':(12,8), 'figure.dpi': 180, \"legend.fontsize\":11, \"axes.labelsize\": 11, #\"xtick.fontsize\": 26, \"ytick.fontsize\": 20, \n",
    "#             \"xtick.labelsize\": 11, \"ytick.labelsize\": 11})\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "sns.set(font=\"sans\")\n",
    "sns.set_palette(\"tab10\")\n",
    "# for plain matplotlib:\n",
    "plt.style.use([\"seaborn-darkgrid\", \"seaborn-paper\"])\n",
    "plt.rc(\"font\", family=\"sans\", size=8)\n",
    "plt.rc(\"axes\", titlesize=6)\n",
    "plt.rc(\"axes\", labelsize=6)\n",
    "plt.rc(\"xtick\", labelsize=6)\n",
    "plt.rc(\"ytick\", labelsize=6)\n",
    "plt.rc(\"xtick.major\", pad=1)\n",
    "plt.rc(\"ytick.major\", pad=3)\n",
    "plt.rc(\"legend\", fontsize=6)\n",
    "plt.rc(\"figure\", titlesize=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err_distro_rc[\"figure.figsize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def k_euclidean_dist(t):\n",
    "    x = t[0]\n",
    "    y = t[1]    \n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=-1, keepdims=True))\n",
    "\n",
    "\n",
    "def k_contrastive_loss(y_true, dist, margin):\n",
    "    \"\"\"Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "    return K.mean(y_true * K.square(dist) + (1 - y_true) * K.square(K.maximum(margin - dist, 0)))\n",
    "\n",
    "def contrastive_loss_test(y_true, dist, margin=1):\n",
    "    \"\"\"Test function above using implementation with numpy instead tensors.\"\"\"\n",
    "    return y_true * np.square(dist) + (1 - y_true) * np.square(np.max(margin - dist, 0))\n",
    "\n",
    "if TEST_MODE:\n",
    "    print(\"Positive: class=1, distance=0,     loss:\", contrastive_loss_test(1, 0))\n",
    "    print(\"Positive: class=1, distance=0.01,  loss:\", contrastive_loss_test(1, 0.01))\n",
    "    print(\"Positive: class=1, distance=0.3,   loss:\", contrastive_loss_test(1, 0.3))\n",
    "    print(\"Positive: class=1, distance=0.5,   loss:\", contrastive_loss_test(1, 0.5))\n",
    "    print(\"Positive: class=1, distance=1,     loss:\", contrastive_loss_test(1, 1))\n",
    "\n",
    "    print(\"Negative: class=0, distance=0,     loss:\", contrastive_loss_test(0, 0))\n",
    "    print(\"Negative: class=0, distance=0.01,  loss:\", contrastive_loss_test(0, 0.01))\n",
    "    print(\"Negative: class=0, distance=0.3,   loss:\", contrastive_loss_test(0, 0.3))\n",
    "    print(\"Negative: class=0, distance=0.5,   loss:\", contrastive_loss_test(0, 0.5))\n",
    "    print(\"Negative: class=0, distance=1,     loss:\", contrastive_loss_test(0, 1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Positive: class=1, distance=0,     loss:\", k_contrastive_loss(tf.constant(1, dtype=tf.float32), tf.constant(0, dtype=tf.float32), 1))\n",
    "    print(\"Positive: class=1, distance=0.01,  loss:\", k_contrastive_loss(tf.constant(1, dtype=tf.float32), tf.constant(0.01, dtype=tf.float32), 1))\n",
    "    print(\"Positive: class=1, distance=0.3,   loss:\", k_contrastive_loss(tf.constant(1, dtype=tf.float32), tf.constant(0.3, dtype=tf.float32), 1))\n",
    "    print(\"Positive: class=1, distance=0.5,   loss:\", k_contrastive_loss(tf.constant(1, dtype=tf.float32), tf.constant(0.5, dtype=tf.float32), 1))\n",
    "    print(\"Positive: class=1, distance=1,     loss:\", k_contrastive_loss(tf.constant(1, dtype=tf.float32), tf.constant(1, dtype=tf.float32), 1))\n",
    "\n",
    "    print(\"Negative: class=0, distance=0,     loss:\", k_contrastive_loss(tf.constant(0, dtype=tf.float32), tf.constant(0, dtype=tf.float32), 1))\n",
    "    print(\"Negative: class=0, distance=0.01,  loss:\", k_contrastive_loss(tf.constant(0, dtype=tf.float32), tf.constant(0.01, dtype=tf.float32), 1))\n",
    "    print(\"Negative: class=0, distance=0.3,   loss:\", k_contrastive_loss(tf.constant(0, dtype=tf.float32), tf.constant(0.3, dtype=tf.float32), 1))\n",
    "    print(\"Negative: class=0, distance=0.5,   loss:\", k_contrastive_loss(tf.constant(0, dtype=tf.float32), tf.constant(0.5, dtype=tf.float32), 1))\n",
    "    print(\"Negative: class=0, distance=1,     loss:\", k_contrastive_loss(tf.constant(0, dtype=tf.float32), tf.constant(1, dtype=tf.float32), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimizer(name, lr=None, decay=None):\n",
    "    if name == \"SGD\":\n",
    "        lr = lr if lr != None else 0.01\n",
    "        decay = decay if decay != None else 0\n",
    "        optimizer = SGD(learning_rate=lr, decay=decay)\n",
    "    elif name == \"Adam\":\n",
    "        lr = lr if lr != None else 0.001\n",
    "        decay = decay if decay != None else 0\n",
    "        optimizer = Adam(learning_rate=lr, decay=decay)\n",
    "    elif name == \"RMSprop\":\n",
    "        lr = lr if lr != None else 0.001\n",
    "        optimizer = RMSprop(learning_rate=lr)\n",
    "    elif name == \"Adadelta\":\n",
    "        lr = lr if lr != None else 0.001\n",
    "        optimizer = Adadelta(learning_rate=lr)\n",
    "    elif name == \"Adagrad\":\n",
    "        lr = lr if lr != None else 0.001\n",
    "        optimizer = Adagrad(learning_rate=lr)\n",
    "    elif name == \"Adamax\":\n",
    "        lr = lr if lr != None else 0.001\n",
    "        optimizer = Adamax(learning_rate=lr)\n",
    "    elif name == \"Ftrl\":\n",
    "        lr = lr if lr != None else 0.001\n",
    "        optimizer = Ftrl(learning_rate=lr)\n",
    "    elif name == \"Nadam\":\n",
    "        lr = lr if lr != None else 0.001\n",
    "        optimizer = Nadam(learning_rate=lr)\n",
    "    else:\n",
    "        print(name)\n",
    "        raise BaseException(\"Error: Not a valid model name: 1d or 2d.\")\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def get_loss_func(arg_dict):\n",
    "    name = arg_dict[\"loss_func_name\"]\n",
    "    if name == \"k_contrastive_loss\":\n",
    "        loss_func = lambda y_true, dist: k_contrastive_loss(y_true, dist, arg_dict[\"contrastive_loss_margin\"])\n",
    "    else:\n",
    "        print(name)\n",
    "        raise BaseException(\"Error: Not a valid loss func name\")\n",
    "    return loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # cite: Siamese Model with 2D Filters, as derived from Centeno et al. (2018)\n",
    "# # the thesis I found\n",
    "# def build_model_2d(input_shape, filters):\n",
    "#     \"\"\"\n",
    "#         Siamese CNN architecture with 3D input and 2D filters\n",
    "#     \"\"\"\n",
    "#     # Define the tensors for the two input images\n",
    "#     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "#     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "#     # Convolutional Neural Network\n",
    "#     inputs = Input(input_shape, name=\"input\")\n",
    "#     x = Conv2D(filters[0], (7, 7), padding=\"same\", activation=\"tanh\", name=\"conv1\")(inputs)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp1\")(x)\n",
    "#     x = Conv2D(filters[1], (5, 5), padding=\"same\", activation=\"tanh\", name=\"conv2\")(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp2\")(x)\n",
    "#     x = Conv2D(filters[2], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv3\")(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp3\")(x)\n",
    "#     x = Conv2D(filters[3], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv4\")(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp4\")(x)\n",
    "#     x = Flatten(name=\"flat\")(x)\n",
    "    \n",
    "#     # Basemodel instance\n",
    "#     basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "#     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "#     encoded_l = basemodel(left_inputs)\n",
    "#     encoded_r = basemodel(right_inputs)\n",
    "\n",
    "#     # Add a customized layer to compute the distance between the encodings\n",
    "#     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "#     # Combine into one net\n",
    "#     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "#     # return the model\n",
    "#     return siamese_net, basemodel\n",
    "\n",
    "\n",
    "# def get_model(name, window_size, feature_cols, filters):\n",
    "#     print(f\"Using Model variant {name}...\")\n",
    "#     if name == \"1d\":\n",
    "#         model, basemodel = build_model_1d((window_size, len(feature_cols)), filters)\n",
    "#     elif name == \"2d\":\n",
    "#         model, basemodel = build_model_2d((window_size, len(feature_cols), 1), filters)\n",
    "#     elif name == \"fcn\":\n",
    "#         model, basemodel = build_model_fcn((window_size, len(feature_cols)), filters)\n",
    "#     else:\n",
    "#         raise BaseException(\"Error: Not a valid model name: {1d, 2d, fcn}\")\n",
    "\n",
    "#     return model, basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def generate_index_pairs_multi_input(index_arr_1, index_arr_2):\n",
    "#     '''\n",
    "#     return an array of indices for negative/positive pairs. It is assumed that every \n",
    "#     index of pair corresponds to different sessions.\n",
    "#     '''\n",
    "#     mesh = np.array(np.meshgrid(index_arr_1, index_arr_2))\n",
    "#     negative_index_pairs = mesh.T.reshape(-1, 2)\n",
    "    \n",
    "#     return negative_index_pairs\n",
    "\n",
    "# def generate_pairs_multi_input(X_exp2_dic, X_exp1_dic, user_id_list, fitted_raw_scaler_dict=None, num_pair_limit = 50000):\n",
    "#     '''\n",
    "#     return positive and negative pairs\n",
    "#     '''\n",
    "#     num_users = len(user_id_list)\n",
    "#     # print(num_users)\n",
    "# #     X_neg[np.random.choice(X_neg.shape[0], size=X_pos.shape[0], replace=False), :]\n",
    "#     negative_pairs_dic = {}\n",
    "#     positive_pairs_dic = {}\n",
    "    \n",
    "#     total_samples_per_user = len(X_exp2_dic[list(X_exp2_dic.keys())[0]])\n",
    "#     # print(total_samples_per_user)\n",
    "#     multi_input_anchor_index_array = getIndices(sampleSize=3, step=5, numSamplePoints=total_samples_per_user)\n",
    "    \n",
    "#     print(multi_input_anchor_index_array)\n",
    "#     anchor_index_arr=range(multi_input_anchor_index_array.shape[0])\n",
    "#     new_user_index_arr=range(total_samples_per_user)\n",
    "    \n",
    "#     positive_pairs_indices = generate_index_pairs_multi_input(anchor_index_arr, new_user_index_arr)\n",
    "#     negative_pairs_indices = generate_index_pairs_multi_input(anchor_index_arr, new_user_index_arr)\n",
    "    \n",
    "#     # negative_pairs_indices = negative_pairs_indices[np.random.choice(negative_pairs_indices.shape[0], size=positive_pairs_indices.shape[0], replace=False)]\n",
    "#     # negative_pairs_indices = np.sort(negative_pairs_indices)\n",
    "#     # print(negative_pairs_indices)\n",
    "#     positive_left = positive_pairs_indices[:, 0]\n",
    "#     positive_right = positive_pairs_indices[:, 1]\n",
    "    \n",
    "#     negative_left = negative_pairs_indices[:, 0]\n",
    "#     negative_right = negative_pairs_indices[:, 1]\n",
    "#     # fitted_scaler_SNN_exp2_train_dic\n",
    "#     # print(positive_pairs_indices.shape)\n",
    "#     # print(negative_pairs_indices.shape)\n",
    "    \n",
    "#     total_num_pairs = (positive_pairs_indices.shape[0]+negative_pairs_indices.shape[0]) * num_users \n",
    "#     if num_pair_limit < total_num_pairs: \n",
    "#         limit_ratio = num_pair_limit/total_num_pairs\n",
    "#     else:\n",
    "#         limit_ratio=1\n",
    "            \n",
    "    \n",
    "#     # neg_fraction =  ((total_samples_per_user-1) / (total_samples_per_user * (num_users-1)))  # works accurate\n",
    "#     neg_fraction =  1 / (num_users-1)  # works accurate\n",
    "#     # neg_fraction =  (total_samples_per_user-1) / (total_samples_per_user * (num_users)) # works accurate\n",
    "#     for owner_key in tqdm(user_id_list):\n",
    "#         # debugging was: X_exp2_dic is not an array, but needs to be an array if we want integer indexing. This can be changed in utility_functions; however, need to modify other code. \n",
    "#         # print(type(positive_left))\n",
    "#         # print(len(X_exp2_dic[owner_key]))\n",
    "#         # print(np.array(X_exp2_dic[owner_key])[positive_left])\n",
    "#         np.random.seed(SEED + owner_key)\n",
    "#         # transform_user_windows(X_exp_unknown_df_dict[unknown_user], fitted_raw_scaler_dict[owner_key])\n",
    "#         u1_array = np.array(X_exp2_dic[owner_key])\n",
    "#         u2_array = np.array(transform_user_windows(X_exp1_dic[owner_key], fitted_raw_scaler_dict[owner_key]))\n",
    "        \n",
    "#         # print(multi_input_anchor_index_array.shape)\n",
    "#         # print(u1_array.shape)\n",
    "#         # print(positive_pairs_indices)\n",
    "#         # print(total_samples_per_user)\n",
    "#         # print(positive_right.shape)\n",
    "#         # print(negative_right.shape)\n",
    "#         # quick fix for user 47\n",
    "#         if owner_key == 29:\n",
    "            \n",
    "#             u1_array = np.concatenate([u1_array, u1_array[np.random.choice(u1_array.shape[0], size=total_samples_per_user-u1_array.shape[0], replace=False)]], axis=0)#55-47\n",
    "#             u2_array = np.concatenate([u2_array, u2_array[np.random.choice(u2_array.shape[0], size=total_samples_per_user-u2_array.shape[0], replace=False)]], axis=0)\n",
    "          \n",
    "#         u1_array = u1_array[multi_input_anchor_index_array, :]\n",
    "#         # print(u1_array.shape)\n",
    "#         # print(u1_array.shape)\n",
    "#         # print(u2_array.shape)\n",
    "#         # try:\n",
    "#         # print(f\"owner_key: {owner_key}, u1_array.shape: {u1_array.shape}, u2_array.shape: {u2_array.shape}\")\n",
    "#         positive_pairs_dic[owner_key] = np.array(list(zip(u1_array[positive_left], u2_array[positive_right])))\n",
    "#         # except:\n",
    "#         #     print(owner_key)\n",
    "#         # print(f\"positive_pairs per user: {positive_pairs_dic[owner_key].shape[0]}\")\n",
    "#         new_pos_size = int(np.round(limit_ratio * positive_pairs_dic[owner_key].shape[0]))\n",
    "#         positive_pairs_dic[owner_key] = positive_pairs_dic[owner_key][np.random.choice(\n",
    "#                     positive_pairs_dic[owner_key].shape[0], size=new_pos_size, replace=False), :]\n",
    "        \n",
    "\n",
    "#         for u2_key in user_id_list:\n",
    "#             # 47 55\n",
    "#             np.random.seed(SEED + u2_key)\n",
    "#             # should i eliminate less informative pairs like (w_n, w_m) vs (w_m, w_n)?\n",
    "#             if u2_key != owner_key:\n",
    "#                 u2_array = np.array(transform_user_windows(X_exp1_dic[u2_key], fitted_raw_scaler_dict[owner_key]))\n",
    "                \n",
    "#                 # quick fix for user 47\n",
    "#                 if u2_key == 29:\n",
    "#                     u2_array = np.concatenate([u2_array, u2_array[np.random.choice(u2_array.shape[0], size=total_samples_per_user-u2_array.shape[0], replace=False)]], axis=0)#55-47,\n",
    "                \n",
    "                \n",
    "#                 # print(u1_array.shape)\n",
    "#                 # print(u2_array.shape)\n",
    "#                 # print(f\"u2_key {u2_key}, u1_array.shape: {u1_array.shape}, u2_array.shape: {u2_array.shape}\")\n",
    "#                 negative_pairs_dic[(owner_key, u2_key)] = np.array(list(zip(u1_array[negative_left], u2_array[negative_right])))\n",
    "#                 # print(f\"neg_pairs per user: {negative_pairs_dic[(owner_key, u2_key)].shape[0]}\")\n",
    "                \n",
    "#                 new_neg_size = int(np.round(negative_pairs_dic[(owner_key, u2_key)].shape[0] * neg_fraction * limit_ratio))\n",
    "#                 negative_pairs_dic[(owner_key, u2_key)] = negative_pairs_dic[(owner_key, u2_key)][np.random.choice(\n",
    "#                     negative_pairs_dic[(owner_key, u2_key)].shape[0], size=new_neg_size, replace=False), :]\n",
    "#     # print(new_pos_size)\n",
    "#     # print(new_neg_size)\n",
    "#     return {\"positive_pairs_dic\": positive_pairs_dic, \"negative_pairs_dic\": negative_pairs_dic}\n",
    "\n",
    "# def prep_X_y_pair_multi_input(X_exp2_dic, X_exp1_dic, user_id_list, fitted_raw_scaler_dict=None, num_pair_limit = 50000):\n",
    "    \n",
    "#     X_dic = generate_pairs_multi_input(X_exp2_dic, X_exp1_dic, user_id_list, fitted_raw_scaler_dict=fitted_raw_scaler_dict, num_pair_limit=num_pair_limit)\n",
    "#     # print(X_dic['negative_pairs_dic'].keys())\n",
    "#     pos_X, neg_X = get_pos_array(X_dic['positive_pairs_dic']), get_neg_array(X_dic['negative_pairs_dic'])\n",
    "    \n",
    "#     pos_y = np.repeat(1., pos_X.shape[0]).reshape((pos_X.shape[0], 1))\n",
    "#     neg_y = np.repeat(0., neg_X.shape[0]).reshape((neg_X.shape[0], 1))\n",
    "    \n",
    "#     print(np.stack(pos_X[:, 0]).shape)\n",
    "#     print(pos_X[:, 1][0].shape)\n",
    "#     pos_X_left = np.stack(pos_X[:, 0])\n",
    "#     pos_X_right = np.stack(pos_X[:, 1])\n",
    "#     print(pos_X_left.shape)\n",
    "#     print(pos_X_right.shape)\n",
    "    \n",
    "#     neg_X_left = np.stack(neg_X[:, 0])\n",
    "#     neg_X_right = np.stack(neg_X[:, 1])\n",
    "    \n",
    "#     X_left = np.concatenate([pos_X_left, neg_X_left]).astype(\"float32\")\n",
    "#     X_right = np.concatenate([pos_X_right, neg_X_right]).astype(\"float32\")\n",
    "#     y = np.concatenate([pos_y, neg_y]).astype(\"float32\")\n",
    "\n",
    "#     np.random.seed(SEED)\n",
    "#     X_left, X_right, y = sklearn_shuffle(X_left, X_right, y, random_state=SEED)\n",
    "    \n",
    "#     X = [X_left, X_right]\n",
    "    \n",
    "#     return X, y\n",
    "\n",
    "\n",
    "# def create_multi_input_model_fcn(anchor_shape, input_shape, arg_dict, do_plot=True):\n",
    "#     '''\n",
    "#     input_dropout_streams = arg_dict[\"input_dropout_streams\"]\n",
    "#     filters_streams = arg_dict[\"filters_streams\"]\n",
    "#     kernels_streams = arg_dict[\"kernels_streams\"]\n",
    "#     kernels_init_streams = arg_dict[\"kernels_init_streams\"] \n",
    "#     kernels_constraint_streams = arg_dict[\"kernels_constraint_streams\"] \n",
    "#     strides_streams = arg_dict[\"strides_streams\"] \n",
    "#     paddings_streams = arg_dict[\"paddings_streams\"] \n",
    "#     activations_streams = arg_dict[\"activations_streams\"]\n",
    "#     dropouts_streams = arg_dict[\"dropouts_streams\"] \n",
    "    \n",
    "#     dense_layers = arg_dict[\"dense_layers\"] \n",
    "#     dense_kernel_constraints = arg_dict[\"dense_kernel_constraints\"]\n",
    "#     dense_kernel_inits = arg_dict[\"dense_kernel_inits\"] \n",
    "#     dense_dropouts = arg_dict[\"dense_dropouts\"] \n",
    "#     dense_activations = arg_dict[\"dense_activations\"] \n",
    "    \n",
    "#     loss_func = arg_dict[\"loss_func\"] \n",
    "#     optimizer = arg_dict[\"optimizer\"] \n",
    "    \n",
    "#     # Define the tensors for the two input images\n",
    "#     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "#     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "    \n",
    "#     '''\n",
    "#     # conv\n",
    "#     input_dropout_streams = arg_dict[\"input_dropout_streams\"]\n",
    "#     filters_streams = arg_dict[\"filters_streams\"]\n",
    "#     kernels_streams = arg_dict[\"kernels_streams\"]\n",
    "#     kernels_init_streams = arg_dict[\"kernels_init_streams\"] \n",
    "#     kernels_Max_Norm_constraint_streams = arg_dict[\"kernels_Max_Norm_constraint_streams\"] \n",
    "#     strides_streams = arg_dict[\"strides_streams\"] \n",
    "#     paddings_streams = arg_dict[\"paddings_streams\"] \n",
    "#     activations_streams = arg_dict[\"activations_streams\"]\n",
    "#     dropouts_streams = arg_dict[\"dropouts_streams\"]\n",
    "#     conv_kernel_regularizer_streams = arg_dict[\"conv_kernel_regularizer_streams\"]\n",
    "    \n",
    "#     # dense\n",
    "#     dense_layers = arg_dict[\"dense_layers\"] \n",
    "#     dense_kernel_Max_Norm_constraints = arg_dict[\"dense_kernel_Max_Norm_constraints\"]\n",
    "#     dense_kernel_inits = arg_dict[\"dense_kernel_inits\"] \n",
    "#     dense_dropouts = arg_dict[\"dense_dropouts\"] \n",
    "#     dense_activations = arg_dict[\"dense_activations\"] \n",
    "#     dense_kernel_regularizer = arg_dict[\"dense_kernel_regularizer\"]\n",
    "    \n",
    "#     # loss_func = get_loss_func(arg_dict[\"loss_func_name\"], arg_dict[\"loss_func_args\"]) improve in future\n",
    "#     loss_func = get_loss_func(arg_dict)\n",
    "#     optimizer = get_optimizer(arg_dict[\"optimizer_name\"] , lr=arg_dict[\"optimizer_lr\"], decay=arg_dict[\"optimizer_decay\"])\n",
    "    \n",
    "#     # Define the tensors for the two input images\n",
    "#     left_inputs = Input(anchor_shape, name=\"left_inputs\")\n",
    "#     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "    \n",
    "#     # print(tf.squeeze(tf.slice(left_inputs, [0, 1, 0, 0], [-1, 1, -1, -1]), axis=1))\n",
    "#     # Convolutional Neural Network\n",
    "#     inputs_dict = {}\n",
    "#     for head_idx in range(len(filters_streams)):\n",
    "#         inputs_dict[head_idx] = Input(input_shape, name=f\"inputs_{head_idx}\")\n",
    "\n",
    "    \n",
    "#     flat_output_dict = {}\n",
    "#     for head in inputs_dict:\n",
    "#         x= inputs_dict[head]\n",
    "\n",
    "#         x = Dropout(input_dropout_streams[head], seed=SEED, name=f\"stream_{head}_input_drop\")(x)\n",
    "#         for idx in range(len(filters_streams[head])):\n",
    "#             x = Conv1D(filters=filters_streams[head][idx], kernel_size=kernels_streams[head][idx], kernel_initializer=kernels_init_streams[head][idx], \n",
    "#                        kernel_constraint=MaxNorm(kernels_Max_Norm_constraint_streams[head][idx]), strides=strides_streams[head][idx], activation=None, \n",
    "#                        padding=paddings_streams[head][idx], kernel_regularizer=conv_kernel_regularizer_streams[head][idx], name=f\"stream_{head}_conv_{idx+1}\")(x)\n",
    "#             x = BatchNormalization()(x)\n",
    "#             x = Activation(activations_streams[head][idx])(x)\n",
    "#             x = Dropout(dropouts_streams[head][idx], seed=SEED, name=f\"stream_{head}_drop_{idx+1}\")(x)\n",
    "\n",
    "#         x = GlobalAveragePooling1D()(x)\n",
    "        \n",
    "#         flat_output_dict[head] = x\n",
    "    \n",
    "#     # merge\n",
    "#     merged = keras_concat([flat_output_dict[head_idx] for head_idx in range(len(flat_output_dict))])\n",
    "\n",
    "#     x = merged\n",
    "    \n",
    "#     for dense_idx in range(len(dense_layers)):\n",
    "#         x = Dropout(dense_dropouts[dense_idx], name=f\"dense_{dense_idx+1}_dropout\")(x)\n",
    "#         x = Dense(dense_layers[dense_idx], kernel_constraint=MaxNorm(dense_kernel_Max_Norm_constraints[dense_idx]), kernel_initializer=dense_kernel_inits[dense_idx], \n",
    "#                   kernel_regularizer=dense_kernel_regularizer[dense_idx], name=f\"dense_{dense_idx+1}\")(x) # excluded activation=dense_activations[dense_idx]\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = Activation(dense_activations[dense_idx], name=f\"dense_activation_{dense_idx+1}\" )(x)\n",
    "    \n",
    "#     # Basemodel instance\n",
    "#     basemodel = Model(inputs=[inputs_dict[idx] for idx in range(len(inputs_dict))], outputs=x, name=\"basemodel\")\n",
    "\n",
    "#     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "#     print(left_inputs.shape)\n",
    "#     # basemodel_left_inputs_lst=[tf.squeeze(tf.slice(left_inputs, [0, i, 0, 0], [-1, 1, -1, -1]), axis=1) for i in range(len(inputs_dict))]\n",
    "#     # basemodel_left_inputs_lst = Lambda(lambda x: tf.squeeze(tf.split(x, num_or_size_splits=len(inputs_dict), axis=1)))(left_inputs)\n",
    "#     basemodel_left_inputs_lst=[left_inputs[:, i, :, :] for i in range(len(inputs_dict))]\n",
    "\n",
    "#     basemodel_right_inputs_lst=[right_inputs for i in range(len(inputs_dict))]\n",
    "    \n",
    "#     print(basemodel_left_inputs_lst)\n",
    "#     print(basemodel_right_inputs_lst)\n",
    "\n",
    "#     encoded_l = basemodel(basemodel_left_inputs_lst)\n",
    "#     encoded_r = basemodel(basemodel_right_inputs_lst)\n",
    "\n",
    "#     # Add a customized layer to compute the distance between the encodings\n",
    "#     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "#     # Combine into one net\n",
    "#     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "#     if do_plot: \n",
    "#         plot_model(siamese_net, show_shapes=True, to_file='multichannel.png')\n",
    "#         plot_model(basemodel, show_shapes=True, to_file='basemodel.png')\n",
    "        \n",
    "#     siamese_net.compile(loss=loss_func, optimizer=optimizer)\n",
    "    \n",
    "#     # return the model\n",
    "#     return siamese_net\n",
    "\n",
    "# def get_create_model_func_multi_input(name, window_size, feature_cols, num_input):\n",
    "#     print(f\"Using Model variant {name}...\")\n",
    "#     if name == \"multi_input\":\n",
    "#          return lambda arg_dict: create_multi_input_model_fcn((num_input, window_size, len(feature_cols)), (window_size, len(feature_cols)), arg_dict)\n",
    "        \n",
    "#     else:\n",
    "#         raise BaseException(\"Error: Not a valid model name: {1d, 2d, fcn}\")\n",
    "        \n",
    "        \n",
    "# class MetricsCallback_multi_input(Callback):\n",
    "#     \"\"\"\n",
    "#     Custom Keras Callback function.\n",
    "    \n",
    "#     Used to predict and plot distances for positive and negative pairs\n",
    "#     after each n-th epoch, along with some 'classification' metrics. \n",
    "#     'Classification' here means to ability to distinguish between positive \n",
    "#     and negative pairs using a threshold for the distance.\n",
    "    \n",
    "#     Arguments:\n",
    "#         payload {tuple}           -- Datasets used for evaluation: (X_valid, y_valid, X_train, y_train)\n",
    "#         epoch_evaluate_freq {int} -- Frequency for evaluation. After every n-th epoch, \n",
    "#                                      the results are evaluated and printed\n",
    "#         save_plots {boolean}      -- Do you want to save plots as PDF? Path is configured via global\n",
    "#                                      parameter REPORT_PATH.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, payload, epoch_evaluate_freq=1, loss_record_dict={}, metric_record_dict={}, save_plots=False, \n",
    "#                  plot_pca=False, print_interm_epochs=True, early_stoping=False, ReduceLROnPlateau_args=None, optimal_lr_epoch_dict=None, lr_epoch_log_dict={}):\n",
    "#         # super(MetricsCallback, self).__init__()\n",
    "        \n",
    "#         self.lr_epoch_log_dict=lr_epoch_log_dict\n",
    "        \n",
    "#         self.optimal_lr_epoch_dict=optimal_lr_epoch_dict\n",
    "            \n",
    "        \n",
    "#         self.ReduceLROnPlateau_args=ReduceLROnPlateau_args\n",
    "#         self.valid_metrics={\"roc_val\", \"eer_val\", \"thres\", \"acc_val\", \"f1_val\"}\n",
    "#         if self.ReduceLROnPlateau_args != None:\n",
    "#             ReduceLROnPlateau_mode={\"val_loss\": \"min\", \"roc_val\": \"max\", \"eer_val\": \"min\", \"thres\": \"min\", \"acc_val\": \"max\", \"f1_val\": \"max\"}\n",
    "#             self.reduce_lr = MyReduceLROnPlateau(monitor=ReduceLROnPlateau_args['mointored_metric'], factor=ReduceLROnPlateau_args[\"factor\"], \n",
    "#                                                patience=ReduceLROnPlateau_args[\"patience\"], verbose=ReduceLROnPlateau_args[\"verbose\"], \n",
    "#                                                min_lr=ReduceLROnPlateau_args[\"min_lr\"], mode=ReduceLROnPlateau_mode[ReduceLROnPlateau_args['mointored_metric']])\n",
    "\n",
    "#         self.X_valid, self.y_valid, self.X_train, self.y_train = payload\n",
    "#         self.save_plots = save_plots\n",
    "#         self.epoch_evaluate_freq = epoch_evaluate_freq\n",
    "#         self.loss_record_dict = loss_record_dict\n",
    "#         self.metric_record_dict = metric_record_dict\n",
    "#         self.epoch = []\n",
    "#         self.history = {}\n",
    "#         self.plot_pca = plot_pca\n",
    "#         self.print_interm_epochs = print_interm_epochs\n",
    "#         self.early_stoping = early_stoping\n",
    "        \n",
    "#         self.metric_record_dict['roc_val'] = {\"Train\": [], \"Valid\": []}\n",
    "#         self.metric_record_dict['eer_val'] = {\"Train\": [], \"Valid\": []}\n",
    "#         self.metric_record_dict['thres'] = {\"Train\": [], \"Valid\": []}\n",
    "#         self.metric_record_dict['acc_val'] = {\"Train\": [], \"Valid\": []}\n",
    "#         self.metric_record_dict['f1_val'] = {\"Train\": [], \"Valid\": []}\n",
    "        \n",
    "#         # Do we have train and valid set?\n",
    "#         self.sets = []\n",
    "#         if self.X_train:\n",
    "#             self.sets.append([self.X_train, self.y_train, \"Train\"])\n",
    "#         if self.X_valid:\n",
    "#             self.sets.append([self.X_valid, self.y_valid, \"Valid\"])\n",
    "\n",
    "#     def on_train_begin(self, logs={}):\n",
    "\n",
    "#         print(32 * \"=\" + f\"[ Initial State ]\" + 32 * \"=\", end=\"\")\n",
    "#         for X, y, desc in self.sets:\n",
    "#             self.evaluate(X, y, logs, desc, -1)\n",
    "            \n",
    "        \n",
    "\n",
    "#         if self.plot_pca:\n",
    "#             deep_feature_model = Model(\n",
    "#                 inputs=self.model.layers[0].get_input_at(0),  # get_layer(\"left_inputs\").input,\n",
    "#                 outputs=self.model.get_layer(\"basemodel\").get_output_at(0),\n",
    "#                 )\n",
    "#             deep_feature_model.summary()\n",
    "#             deep_features_test = None\n",
    "#             for X, y, subj in samples_test:  \n",
    "                \n",
    "#                 # if 2d, maybe need to import P\n",
    "#                 # if P.model_variant == \"2d\":\n",
    "#                 #     X = X.reshape((*X.shape, 1))\n",
    "#                 pred = deep_feature_model.predict(X)\n",
    "#                 df_features = pd.DataFrame(pred)\n",
    "#                 df_features[\"subject\"] = subj\n",
    "#                 deep_features_test = pd.concat([deep_features_test, df_features])\n",
    "            \n",
    "#             plot_pca(deep_features_test)\n",
    "            \n",
    "\n",
    "#     def on_train_end(self, logs={}):\n",
    "#         print(32 * \"=\" + f\"[ Final State ]\" + 32 * \"=\", end=\"\")\n",
    "#         for X, y, desc in self.sets:\n",
    "#             self.evaluate(X, y, logs, desc, -1)\n",
    "            \n",
    "#     def on_epoch_begin(self, epoch, logs={}, verbose=0):\n",
    "        \n",
    "#         optimizer = self.model.optimizer\n",
    "#         if self.optimal_lr_epoch_dict != None:\n",
    "\n",
    "#             K.set_value(optimizer.lr, self.optimal_lr_epoch_dict[epoch])\n",
    "#             if verbose:\n",
    "#                 print(f\"Learning rate changed to {self.optimal_lr_epoch_dict[epoch]} for epoch {epoch}\")\n",
    "            \n",
    "#         else:\n",
    "#             self.lr_epoch_log_dict[epoch]=K.get_value(optimizer.lr)\n",
    "#             if verbose:\n",
    "#                 print(f\"Logged learning rate of {self.lr_epoch_log_dict[epoch]} for epoch {epoch}\") \n",
    "            \n",
    "            \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         if self.print_interm_epochs:\n",
    "#             print(32 * \"=\" + f\"[   Epoch {epoch}   ]\" + 32 * \"=\", end=\"\")\n",
    "#             if epoch % self.epoch_evaluate_freq == 0:  # Evaluate only every n-th epoch\n",
    "#                 for X, y, desc in self.sets:\n",
    "#                     self.evaluate(X, y, logs, desc, epoch)\n",
    "#             else:\n",
    "#                 print(f\"\\n{ ', '.join([k + ': ' + f'{v:.3f}' for k,v in logs.items()]) }\")\n",
    "            \n",
    "\n",
    "#         logs = logs or {}\n",
    "#         self.epoch.append(epoch)\n",
    "#         for k, v in logs.items():\n",
    "#             self.history.setdefault(k, []).append(v)\n",
    "    \n",
    "        \n",
    "#         if 'val_loss' in logs:\n",
    "#             if self.early_stoping and len(self.loss_record_dict['val_loss'])>1 and self.loss_record_dict['val_loss'][-1] < logs['val_loss']:\n",
    "#                 self.model.stop_training = True\n",
    "                \n",
    "#             else:\n",
    "#                 self.loss_record_dict['val_loss'].append(logs['val_loss'])\n",
    "\n",
    "#                 self.loss_record_dict['loss'].append(logs['loss'])\n",
    "\n",
    "#                 for X, y, desc in self.sets:\n",
    "#                     self.evaluate(X, y, logs, desc, epoch, print_metric=False, save_metric_record_dict=True)\n",
    "            \n",
    "#             # print(logs)\n",
    "#             if self.ReduceLROnPlateau_args != None:\n",
    "#                 if self.ReduceLROnPlateau_args['mointored_metric'] == \"val_loss\":\n",
    "#                     self.reduce_lr.on_epoch_end(epoch, self.model, logs)\n",
    "\n",
    "#                 elif self.ReduceLROnPlateau_args['mointored_metric'] in self.valid_metrics:\n",
    "#                     mointored_metric_dict={self.ReduceLROnPlateau_args['mointored_metric']: self.metric_record_dict[self.ReduceLROnPlateau_args['mointored_metric']][\"Valid\"][-1]}\n",
    "#                     self.reduce_lr.on_epoch_end(epoch, self.model, mointored_metric_dict)\n",
    "\n",
    "#                 else:\n",
    "#                     raise Exception(\"invalid mointored metric\")\n",
    "            \n",
    "                    \n",
    "#         else:\n",
    "#             self.loss_record_dict['loss'].append(logs['loss'])\n",
    "\n",
    "#             for X, y, desc in self.sets:\n",
    "#                 self.evaluate(X, y, logs, desc, epoch, print_metric=False, save_metric_record_dict=True)\n",
    "                \n",
    "        \n",
    "\n",
    "            \n",
    "#     def evaluate(self, X, y, logs, desc, epoch, print_metric=True, save_metric_record_dict=False):\n",
    "#         print(X[0].shape)\n",
    "#         print(X[1].shape)\n",
    "\n",
    "#         print(len(X))\n",
    "#         print(self.model.layers)\n",
    "#         print(self.model.summary())\n",
    "# #         anchor_model = Model(\n",
    "# #                 inputs=self.model.get_layer(\"basemodel\").get_input_at(0),  # get_layer(\"left_inputs\").input,\n",
    "# #                 outputs=self.model.get_layer(\"basemodel\").get_output_at(0),\n",
    "# #             )\n",
    "        \n",
    "#         # test_model = Model(\n",
    "#         #         inputs=self.model.get_layer(\"right_inputs\").get_input_at(0),  # get_layer(\"left_inputs\").input,\n",
    "#         #         outputs=self.model.get_layer(\"basemodel\").get_output_at(0),\n",
    "#         #     )\n",
    "#         # test_model.predict(X[1])\n",
    "#         # Predict\n",
    "#         y_score = self.model.predict(X)\n",
    "#         y_score_neg = y_score * -1  # lower distance means closer to positive class\n",
    "\n",
    "#         # Calc Metrics\n",
    "#         roc_val = metrics.roc_auc_score(y, y_score_neg)\n",
    "#         eer_val, thres = utils_eer(y, y_score_neg, True)\n",
    "#         y_pred = np.where(y_score_neg > thres, 1, 0)\n",
    "#         acc_val = metrics.accuracy_score(y, y_pred)\n",
    "#         f1_val = metrics.f1_score(y, y_pred)\n",
    "        \n",
    "#         if print_metric:\n",
    "#             print(\n",
    "#                 f\"\\n{desc.upper()}: roc_auc: {roc_val:.4f}, \"\n",
    "#                 + f\"eer: {eer_val:.4f}, thres: {thres*-1:.4f} => \"\n",
    "#                 + f\"acc: {acc_val:.4f}, f1: {f1_val:.4f}\\n\"\n",
    "#                 + f\"{ ', '.join([k + ': ' + f'{v:.3f}' for k,v in logs.items()]) }\"\n",
    "#             )\n",
    "\n",
    "#         if save_metric_record_dict:\n",
    "#             self.metric_record_dict['roc_val'][desc].append(roc_val)\n",
    "#             self.metric_record_dict['eer_val'][desc].append(eer_val)\n",
    "#             self.metric_record_dict['thres'][desc].append(float(thres))\n",
    "#             self.metric_record_dict['acc_val'][desc].append(acc_val)\n",
    "#             self.metric_record_dict['f1_val'][desc].append(f1_val)\n",
    "        \n",
    "#         # Plot distances\n",
    "#         mask = np.where(y == 1, True, False)\n",
    "#         dist_positive = y_score[mask]\n",
    "#         dist_negative = y_score[~mask]\n",
    "        \n",
    "        \n",
    "#         if self.plot_pca:\n",
    "#             # Extract one of the child networks\n",
    "#             deep_feature_model = Model(\n",
    "#                 inputs=self.model.layers[0].get_input_at(0),  # get_layer(\"left_inputs\").input,\n",
    "#                 outputs=self.model.get_layer(\"basemodel\").get_output_at(0),\n",
    "#             )\n",
    "#             deep_feature_model.summary()\n",
    "#             deep_features_test = None\n",
    "#             for X, y, subj in samples_test:  \n",
    "#                 # if 2d, maybe need to import P\n",
    "#                 # if P.model_variant == \"2d\":\n",
    "#                 #     X = X.reshape((*X.shape, 1))\n",
    "#                 pred = deep_feature_model.predict(X)\n",
    "#                 df_features = pd.DataFrame(pred)\n",
    "#                 df_features[\"subject\"] = subj\n",
    "#                 deep_features_test = pd.concat([deep_features_test, df_features])\n",
    "\n",
    "#             plot_pca(deep_features_test)\n",
    "        \n",
    "#         #plt = utils_plot_distance_hist(\n",
    "#         #    dist_positive, dist_negative, thres * -1, desc=desc, fig_size=(12, 2), margin=P.margin\n",
    "#         #)\n",
    "\n",
    "# #         if self.save_plots:\n",
    "# #             utils_save_plot(\n",
    "# #                 plt,\n",
    "# #                 REPORT_PATH\n",
    "# #                 / f\"buech2019-siamese-{P.name.lower()}-epoch-{epoch+1}-{desc.lower()}.pdf\",\n",
    "# #             )\n",
    "\n",
    "#         # plt.show()\n",
    "    \n",
    "    \n",
    "#         #|, basemodel\n",
    "# # generate_index_pairs(50)\n",
    "# # anchor_indices = getIndices(sampleSize=10, step=5, numSamplePoints=136)\n",
    "# # len(pos_idices) * 136 * 20\n",
    "# # anchor_indices\n",
    "# # 17000/125\n",
    "# # generate_index_pairs_multi_input(range(2), range(10))\n",
    "\n",
    "#         # # a.append(df_array[windows[i], :]) #CNN\n",
    "#         # a.append(df.iloc[windows[i], :]) #waca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese Model with FCN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_multi_headed_model_fcn(input_shape, arg_dict, do_plot=True):\n",
    "    '''\n",
    "    input_dropout_streams = arg_dict[\"input_dropout_streams\"]\n",
    "    filters_streams = arg_dict[\"filters_streams\"]\n",
    "    kernels_streams = arg_dict[\"kernels_streams\"]\n",
    "    kernels_init_streams = arg_dict[\"kernels_init_streams\"] \n",
    "    kernels_constraint_streams = arg_dict[\"kernels_constraint_streams\"] \n",
    "    strides_streams = arg_dict[\"strides_streams\"] \n",
    "    paddings_streams = arg_dict[\"paddings_streams\"] \n",
    "    activations_streams = arg_dict[\"activations_streams\"]\n",
    "    dropouts_streams = arg_dict[\"dropouts_streams\"] \n",
    "    \n",
    "    dense_layers = arg_dict[\"dense_layers\"] \n",
    "    dense_kernel_constraints = arg_dict[\"dense_kernel_constraints\"]\n",
    "    dense_kernel_inits = arg_dict[\"dense_kernel_inits\"] \n",
    "    dense_dropouts = arg_dict[\"dense_dropouts\"] \n",
    "    dense_activations = arg_dict[\"dense_activations\"] \n",
    "    \n",
    "    loss_func = arg_dict[\"loss_func\"] \n",
    "    optimizer = arg_dict[\"optimizer\"] \n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "    right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "    \n",
    "    '''\n",
    "    # conv\n",
    "    input_dropout_streams = arg_dict[\"input_dropout_streams\"]\n",
    "    filters_streams = arg_dict[\"filters_streams\"]\n",
    "    kernels_streams = arg_dict[\"kernels_streams\"]\n",
    "    kernels_init_streams = arg_dict[\"kernels_init_streams\"] \n",
    "    kernels_Max_Norm_constraint_streams = arg_dict[\"kernels_Max_Norm_constraint_streams\"] \n",
    "    strides_streams = arg_dict[\"strides_streams\"] \n",
    "    paddings_streams = arg_dict[\"paddings_streams\"] \n",
    "    activations_streams = arg_dict[\"activations_streams\"]\n",
    "    dropouts_streams = arg_dict[\"dropouts_streams\"]\n",
    "    conv_kernel_regularizer_streams = arg_dict[\"conv_kernel_regularizer_streams\"]\n",
    "    \n",
    "    # dense\n",
    "    dense_layers = arg_dict[\"dense_layers\"] \n",
    "    dense_kernel_Max_Norm_constraints = arg_dict[\"dense_kernel_Max_Norm_constraints\"]\n",
    "    dense_kernel_inits = arg_dict[\"dense_kernel_inits\"] \n",
    "    dense_dropouts = arg_dict[\"dense_dropouts\"] \n",
    "    dense_activations = arg_dict[\"dense_activations\"] \n",
    "    dense_kernel_regularizer = arg_dict[\"dense_kernel_regularizer\"]\n",
    "    \n",
    "    # loss_func = get_loss_func(arg_dict[\"loss_func_name\"], arg_dict[\"loss_func_args\"]) improve in future\n",
    "    loss_func = get_loss_func(arg_dict)\n",
    "    optimizer = get_optimizer(arg_dict[\"optimizer_name\"] , lr=arg_dict[\"optimizer_lr\"], decay=arg_dict[\"optimizer_decay\"])\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "    right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "    \n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    inputs_dict = {}\n",
    "    for head_idx in range(len(filters_streams)):\n",
    "        inputs_dict[head_idx] = Input(input_shape, name=f\"inputs_{head_idx}\")\n",
    "\n",
    "    \n",
    "    flat_output_dict = {}\n",
    "    for head in inputs_dict:\n",
    "        x= inputs_dict[head]\n",
    "\n",
    "        x = Dropout(input_dropout_streams[head], seed=SEED, name=f\"stream_{head}_input_drop\")(x)\n",
    "        for idx in range(len(filters_streams[head])):\n",
    "            x = Conv1D(filters=filters_streams[head][idx], kernel_size=kernels_streams[head][idx], kernel_initializer=kernels_init_streams[head][idx], \n",
    "                       kernel_constraint=MaxNorm(kernels_Max_Norm_constraint_streams[head][idx]), strides=strides_streams[head][idx], activation=None, \n",
    "                       padding=paddings_streams[head][idx], kernel_regularizer=conv_kernel_regularizer_streams[head][idx], name=f\"stream_{head}_conv_{idx+1}\")(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(activations_streams[head][idx])(x)\n",
    "            x = Dropout(dropouts_streams[head][idx], seed=SEED, name=f\"stream_{head}_drop_{idx+1}\")(x)\n",
    "\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        \n",
    "        flat_output_dict[head] = x\n",
    "    \n",
    "    # merge\n",
    "    merged = keras_concat([flat_output_dict[head_idx] for head_idx in range(len(flat_output_dict))])\n",
    "\n",
    "    x = merged\n",
    "    \n",
    "    for dense_idx in range(len(dense_layers)):\n",
    "        x = Dropout(dense_dropouts[dense_idx], name=f\"dense_{dense_idx+1}_dropout\")(x)\n",
    "        x = Dense(dense_layers[dense_idx], kernel_constraint=MaxNorm(dense_kernel_Max_Norm_constraints[dense_idx]), kernel_initializer=dense_kernel_inits[dense_idx], \n",
    "                  kernel_regularizer=dense_kernel_regularizer[dense_idx], name=f\"dense_{dense_idx+1}\")(x) # excluded activation=dense_activations[dense_idx]\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(dense_activations[dense_idx], name=f\"dense_activation_{dense_idx+1}\" )(x)\n",
    "    \n",
    "    # Basemodel instance\n",
    "    basemodel = Model(inputs=[inputs_dict[idx] for idx in range(len(inputs_dict))], outputs=x, name=\"basemodel\")\n",
    "\n",
    "    # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "    encoded_l = basemodel([left_inputs for i in range(len(inputs_dict))])\n",
    "    encoded_r = basemodel([right_inputs for i in range(len(inputs_dict))])\n",
    "\n",
    "    # Add a customized layer to compute the distance between the encodings\n",
    "    distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "    # Combine into one net\n",
    "    siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "    if do_plot: \n",
    "        plot_model(siamese_net, show_shapes=True, to_file='multichannel.png')\n",
    "        plot_model(basemodel, show_shapes=True, to_file='basemodel.png')\n",
    "        \n",
    "    siamese_net.compile(loss=loss_func, optimizer=optimizer)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net#|, basemodel\n",
    "\n",
    "# def get_model(name, window_size, feature_cols, filters):\n",
    "#     print(f\"Using Model variant {name}...\")\n",
    "#     if name == \"1d\":\n",
    "#         model, basemodel = build_model_1d((window_size, len(feature_cols)), filters)\n",
    "#     elif name == \"2d\":\n",
    "#         model, basemodel = build_model_2d((window_size, len(feature_cols), 1), filters)\n",
    "#     elif name == \"fcn\":\n",
    "#         model, basemodel = build_model_fcn((window_size, len(feature_cols)), filters)\n",
    "#     else:\n",
    "#         raise BaseException(\"Error: Not a valid model name: {1d, 2d, fcn}\")\n",
    "\n",
    "#     return model, basemodel\n",
    "# temp_model, temp_basemodel = get_model(P.model_variant, P.window_size, P.feature_cols, P.filters)\n",
    "\n",
    "# temp_basemodel.summary()\n",
    "# temp_model.summary()\n",
    "\n",
    "def get_create_model_func(name, window_size, feature_cols):\n",
    "    print(f\"Using Model variant {name}...\")\n",
    "    if name == \"1d\":\n",
    "        return lambda filters, kernels, strides, dropouts, activations, dense, loss_func, optimizer: build_model_1d((window_size, len(feature_cols)),\n",
    "                                                                                                               filters, kernels, strides, \n",
    "                                                                                                                    dropouts, activations, dense, \n",
    "                                                                                                                    loss_func, optimizer)\n",
    "    elif name == \"2d\":\n",
    "        return lambda filters, kernels, strides, dropouts, activations, dense, loss_func, optimizer: build_model_2d((window_size, len(feature_cols)),\n",
    "                                                                                                               filters, kernels, strides, \n",
    "                                                                                                                    dropouts, activations, dense, \n",
    "                                                                                                                    loss_func, optimizer)\n",
    "    elif name == \"fcn\":\n",
    "        return lambda filters, kernels, strides, dropouts, activations, dense, loss_func, optimizer: create_model_fcn((window_size, len(feature_cols)),\n",
    "                                                                                                               filters, kernels, strides, \n",
    "                                                                                                                      dropouts, activations, dense, \n",
    "                                                                                                                      loss_func, optimizer)\n",
    "    elif name == \"multi_head_fcn\":\n",
    "         return lambda arg_dict: create_multi_headed_model_fcn((window_size, len(feature_cols)), arg_dict)\n",
    "        \n",
    "    else:\n",
    "        raise BaseException(\"Error: Not a valid model name: {1d, 2d, fcn}\")\n",
    "        \n",
    "        \n",
    "def generate_index_pairs(diagonal_size):\n",
    "    '''\n",
    "    return an array of indices for negative/positive pairs. It is assumed that every \n",
    "    index of pair corresponds to different sessions.\n",
    "    '''\n",
    "    indices = list(range(diagonal_size))\n",
    "    mesh = np.array(np.meshgrid(indices, indices))\n",
    "    negative_index_pairs = mesh.T.reshape(-1, 2)\n",
    "    \n",
    "    return negative_index_pairs\n",
    "\n",
    "\n",
    "def generate_pairs(X_exp2_dic, X_exp1_dic, user_id_list, fitted_raw_scaler_dict=None, num_pair_limit = 50000):\n",
    "    '''\n",
    "    return positive and negative pairs\n",
    "    '''\n",
    "    num_users = len(user_id_list)\n",
    "    # print(num_users)\n",
    "#     X_neg[np.random.choice(X_neg.shape[0], size=X_pos.shape[0], replace=False), :]\n",
    "    negative_pairs_dic = {}\n",
    "    positive_pairs_dic = {}\n",
    "    \n",
    "    total_samples_per_user = len(X_exp2_dic[list(X_exp2_dic.keys())[0]])\n",
    "    # print(total_samples_per_user)\n",
    "    positive_pairs_indices = generate_index_pairs(total_samples_per_user)\n",
    "    negative_pairs_indices = generate_index_pairs(total_samples_per_user)\n",
    "    \n",
    "    # negative_pairs_indices = negative_pairs_indices[np.random.choice(negative_pairs_indices.shape[0], size=positive_pairs_indices.shape[0], replace=False)]\n",
    "    # negative_pairs_indices = np.sort(negative_pairs_indices)\n",
    "    # print(negative_pairs_indices)\n",
    "    positive_left = positive_pairs_indices[:, 0]\n",
    "    positive_right = positive_pairs_indices[:, 1]\n",
    "    \n",
    "    negative_left = negative_pairs_indices[:, 0]\n",
    "    negative_right = negative_pairs_indices[:, 1]\n",
    "    # fitted_scaler_SNN_exp2_train_dic\n",
    "    # print(positive_pairs_indices.shape)\n",
    "    # print(negative_pairs_indices.shape)\n",
    "    \n",
    "    total_num_pairs = (positive_pairs_indices.shape[0]+negative_pairs_indices.shape[0]) * num_users \n",
    "    if num_pair_limit < total_num_pairs: \n",
    "        limit_ratio = num_pair_limit/total_num_pairs\n",
    "    else:\n",
    "        limit_ratio=1\n",
    "            \n",
    "    \n",
    "    # neg_fraction =  ((total_samples_per_user-1) / (total_samples_per_user * (num_users-1)))  # works accurate\n",
    "    neg_fraction =  1 / (num_users-1)  # works accurate\n",
    "    # neg_fraction =  (total_samples_per_user-1) / (total_samples_per_user * (num_users)) # works accurate\n",
    "    for owner_key in tqdm(user_id_list):\n",
    "        # debugging was: X_exp2_dic is not an array, but needs to be an array if we want integer indexing. This can be changed in utility_functions; however, need to modify other code. \n",
    "        # print(type(positive_left))\n",
    "        # print(len(X_exp2_dic[owner_key]))\n",
    "        # print(np.array(X_exp2_dic[owner_key])[positive_left])\n",
    "        np.random.seed(SEED + owner_key)\n",
    "        # transform_user_windows(X_exp_unknown_df_dict[unknown_user], fitted_raw_scaler_dict[owner_key])\n",
    "        u1_array = np.array(X_exp2_dic[owner_key])\n",
    "        u2_array = np.array(transform_user_windows(X_exp1_dic[owner_key], fitted_raw_scaler_dict[owner_key]))\n",
    "        \n",
    "        # print(total_samples_per_user)\n",
    "        # print(positive_right.shape)\n",
    "        # print(negative_right.shape)\n",
    "        \n",
    "        # quick fix no longer needed as this is done in get_raw_windows_user_47()\n",
    "        # quick fix for user 47\n",
    "#         if owner_key == 29:\n",
    "            \n",
    "#             u1_array = np.concatenate([u1_array, u1_array[np.random.choice(u1_array.shape[0], size=total_samples_per_user-u1_array.shape[0], replace=False)]], axis=0)#55-47\n",
    "#             u2_array = np.concatenate([u2_array, u2_array[np.random.choice(u2_array.shape[0], size=total_samples_per_user-u2_array.shape[0], replace=False)]], axis=0)\n",
    "                \n",
    "        # print(u1_array.shape)\n",
    "        # print(u2_array.shape)\n",
    "        # try:\n",
    "        # print(f\"owner_key: {owner_key}, u1_array.shape: {u1_array.shape}, u2_array.shape: {u2_array.shape}\")\n",
    "        positive_pairs_dic[owner_key] = np.array(list(zip(u1_array[positive_left], u2_array[positive_right])))\n",
    "        # except:\n",
    "        #     print(owner_key)\n",
    "        # print(f\"positive_pairs per user: {positive_pairs_dic[owner_key].shape[0]}\")\n",
    "        new_pos_size = int(np.round(limit_ratio * positive_pairs_dic[owner_key].shape[0]))\n",
    "        positive_pairs_dic[owner_key] = positive_pairs_dic[owner_key][np.random.choice(\n",
    "                    positive_pairs_dic[owner_key].shape[0], size=new_pos_size, replace=False), :]\n",
    "        \n",
    "\n",
    "        for u2_key in user_id_list:\n",
    "            # 47 55\n",
    "            np.random.seed(SEED + u2_key)\n",
    "            # should i eliminate less informative pairs like (w_n, w_m) vs (w_m, w_n)?\n",
    "            if u2_key != owner_key:\n",
    "                u2_array = np.array(transform_user_windows(X_exp1_dic[u2_key], fitted_raw_scaler_dict[owner_key]))\n",
    "                \n",
    "                # quick fix no longer needed as this is done in get_raw_windows_user_47()\n",
    "                # quick fix for user 47\n",
    "                # if u2_key == 29:\n",
    "                #     u2_array = np.concatenate([u2_array, u2_array[np.random.choice(u2_array.shape[0], size=total_samples_per_user-u2_array.shape[0], replace=False)]], axis=0)#55-47,\n",
    "                \n",
    "                \n",
    "                # print(u1_array.shape)\n",
    "                # print(u2_array.shape)\n",
    "                # print(f\"u2_key {u2_key}, u1_array.shape: {u1_array.shape}, u2_array.shape: {u2_array.shape}\")\n",
    "                negative_pairs_dic[(owner_key, u2_key)] = np.array(list(zip(u1_array[negative_left], u2_array[negative_right])))\n",
    "                # print(f\"neg_pairs per user: {negative_pairs_dic[(owner_key, u2_key)].shape[0]}\")\n",
    "                \n",
    "                new_neg_size = int(np.round(negative_pairs_dic[(owner_key, u2_key)].shape[0] * neg_fraction * limit_ratio))\n",
    "                negative_pairs_dic[(owner_key, u2_key)] = negative_pairs_dic[(owner_key, u2_key)][np.random.choice(\n",
    "                    negative_pairs_dic[(owner_key, u2_key)].shape[0], size=new_neg_size, replace=False), :]\n",
    "                \n",
    "    # print(new_pos_size)\n",
    "    # print(new_neg_size)\n",
    "    return {\"positive_pairs_dic\": positive_pairs_dic, \"negative_pairs_dic\": negative_pairs_dic}\n",
    "\n",
    "\n",
    "def get_pos_array(X_dic):\n",
    "    \n",
    "    return np.concatenate([X_dic[key] for key in X_dic])\n",
    "\n",
    "def get_neg_array(X_dic):\n",
    "    \n",
    "    return np.concatenate([X_dic[key] for key in X_dic])\n",
    "\n",
    "# sklearn.utils.shuffle(*arrays, random_state=None, n_samples=None)\n",
    "def prep_X_y_pair(X_exp2_dic, X_exp1_dic, user_id_list, fitted_raw_scaler_dict=None, num_pair_limit = 50000):\n",
    "    \n",
    "    X_dic = generate_pairs(X_exp2_dic, X_exp1_dic, user_id_list, fitted_raw_scaler_dict=fitted_raw_scaler_dict, num_pair_limit=num_pair_limit)\n",
    "    # print(X_dic['negative_pairs_dic'].keys())\n",
    "    pos_X, neg_X = get_pos_array(X_dic['positive_pairs_dic']), get_neg_array(X_dic['negative_pairs_dic'])\n",
    "    \n",
    "    pos_y = np.repeat(1., pos_X.shape[0]).reshape((pos_X.shape[0], 1))\n",
    "    neg_y = np.repeat(0., neg_X.shape[0]).reshape((neg_X.shape[0], 1))\n",
    "    \n",
    "    pos_X_left = pos_X[:, 0, :, :]\n",
    "    pos_X_right = pos_X[:, 1, :, :]\n",
    "    \n",
    "    neg_X_left = neg_X[:, 0, :, :]\n",
    "    neg_X_right = neg_X[:, 1, :, :]\n",
    "    \n",
    "    X_left = np.concatenate([pos_X_left, neg_X_left]).astype(\"float32\")\n",
    "    X_right = np.concatenate([pos_X_right, neg_X_right]).astype(\"float32\")\n",
    "    y = np.concatenate([pos_y, neg_y]).astype(\"float32\")\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "    X_left, X_right, y = sklearn_shuffle(X_left, X_right, y, random_state=SEED)\n",
    "    \n",
    "    X = [X_left, X_right]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# coppied and modified to get optimizer: https://github.com/keras-team/keras/blob/v2.11.0/keras/callbacks.py#L2905-L3042\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "class MyReduceLROnPlateau(Callback):\n",
    "    \"\"\"Reduce learning rate when a metric has stopped improving.\n",
    "    Models often benefit from reducing the learning rate by a factor\n",
    "    of 2-10 once learning stagnates. This callback monitors a\n",
    "    quantity and if no improvement is seen for a 'patience' number\n",
    "    of epochs, the learning rate is reduced.\n",
    "    Example:\n",
    "    ```python\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                  patience=5, min_lr=0.001)\n",
    "    model.fit(X_train, Y_train, callbacks=[reduce_lr])\n",
    "    ```\n",
    "    Args:\n",
    "        monitor: quantity to be monitored.\n",
    "        factor: factor by which the learning rate will be reduced.\n",
    "          `new_lr = lr * factor`.\n",
    "        patience: number of epochs with no improvement after which learning rate\n",
    "          will be reduced.\n",
    "        verbose: int. 0: quiet, 1: update messages.\n",
    "        mode: one of `{'auto', 'min', 'max'}`. In `'min'` mode,\n",
    "          the learning rate will be reduced when the\n",
    "          quantity monitored has stopped decreasing; in `'max'` mode it will be\n",
    "          reduced when the quantity monitored has stopped increasing; in\n",
    "          `'auto'` mode, the direction is automatically inferred from the name\n",
    "          of the monitored quantity.\n",
    "        min_delta: threshold for measuring the new optimum, to only focus on\n",
    "          significant changes.\n",
    "        cooldown: number of epochs to wait before resuming normal operation\n",
    "          after lr has been reduced.\n",
    "        min_lr: lower bound on the learning rate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        min_delta=1e-4,\n",
    "        cooldown=0,\n",
    "        min_lr=0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.monitor = monitor\n",
    "        if factor >= 1.0:\n",
    "            raise ValueError(\n",
    "                \"ReduceLROnPlateau does not support \"\n",
    "                f\"a factor >= 1.0. Got {factor}\"\n",
    "            )\n",
    "        if \"epsilon\" in kwargs:\n",
    "            min_delta = kwargs.pop(\"epsilon\")\n",
    "            logging.warning(\n",
    "                \"`epsilon` argument is deprecated and \"\n",
    "                \"will be removed, use `min_delta` instead.\"\n",
    "            )\n",
    "        self.factor = factor\n",
    "        self.min_lr = min_lr\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.cooldown = cooldown\n",
    "        self.cooldown_counter = 0  # Cooldown counter.\n",
    "        self.wait = 0\n",
    "        self.best = 0\n",
    "        self.mode = mode\n",
    "        self.monitor_op = None\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self):\n",
    "        \"\"\"Resets wait counter and cooldown counter.\"\"\"\n",
    "        if self.mode not in [\"auto\", \"min\", \"max\"]:\n",
    "            logging.warning(\n",
    "                \"Learning rate reduction mode %s is unknown, \"\n",
    "                \"fallback to auto mode.\",\n",
    "                self.mode,\n",
    "            )\n",
    "            self.mode = \"auto\"\n",
    "        if self.mode == \"min\" or (\n",
    "            self.mode == \"auto\" and \"acc\" not in self.monitor\n",
    "        ):\n",
    "            self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n",
    "            self.best = np.Inf\n",
    "        else:\n",
    "            self.monitor_op = lambda a, b: np.greater(a, b + self.min_delta)\n",
    "            self.best = -np.Inf\n",
    "        self.cooldown_counter = 0\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self._reset()\n",
    "\n",
    "    def on_epoch_end(self, epoch, model, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs[\"lr\"] = K.get_value(model.optimizer.lr)\n",
    "        # print(logs)\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            logging.warning(\n",
    "                \"Learning rate reduction is conditioned on metric `%s` \"\n",
    "                \"which is not available. Available metrics are: %s\",\n",
    "                self.monitor,\n",
    "                \",\".join(list(logs.keys())),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            if self.in_cooldown():\n",
    "                self.cooldown_counter -= 1\n",
    "                self.wait = 0\n",
    "\n",
    "            if self.monitor_op(current, self.best):\n",
    "                self.best = current\n",
    "                self.wait = 0\n",
    "            elif not self.in_cooldown():\n",
    "                self.wait += 1\n",
    "                if self.wait >= self.patience:\n",
    "                    old_lr = K.get_value(model.optimizer.lr)\n",
    "                    if old_lr > np.float32(self.min_lr):\n",
    "                        new_lr = old_lr * self.factor\n",
    "                        new_lr = max(new_lr, self.min_lr)\n",
    "                        K.set_value(model.optimizer.lr, new_lr)\n",
    "                        if self.verbose > 0:\n",
    "                            print(\n",
    "                                f\"\\nEpoch {epoch +1}: \"\n",
    "                                \"ReduceLROnPlateau reducing \"\n",
    "                                f\"learning rate to {new_lr}.\"\n",
    "                            )\n",
    "                        self.cooldown_counter = self.cooldown\n",
    "                        self.wait = 0\n",
    "\n",
    "    def in_cooldown(self):\n",
    "        return self.cooldown_counter > 0\n",
    "\n",
    "    \n",
    "    \n",
    "class MetricsCallback(Callback):\n",
    "    \"\"\"\n",
    "    Custom Keras Callback function.\n",
    "    \n",
    "    Used to predict and plot distances for positive and negative pairs\n",
    "    after each n-th epoch, along with some 'classification' metrics. \n",
    "    'Classification' here means to ability to distinguish between positive \n",
    "    and negative pairs using a threshold for the distance.\n",
    "    \n",
    "    Arguments:\n",
    "        payload {tuple}           -- Datasets used for evaluation: (X_valid, y_valid, X_train, y_train)\n",
    "        epoch_evaluate_freq {int} -- Frequency for evaluation. After every n-th epoch, \n",
    "                                     the results are evaluated and printed\n",
    "        save_plots {boolean}      -- Do you want to save plots as PDF? Path is configured via global\n",
    "                                     parameter REPORT_PATH.\n",
    "    \"\"\"\n",
    "    def __init__(self, payload, epoch_evaluate_freq=1, loss_record_dict={}, metric_record_dict={}, save_plots=False, \n",
    "                 plot_pca=False, print_interm_epochs=True, early_stoping=False, ReduceLROnPlateau_args=None, optimal_lr_epoch_dict=None, lr_epoch_log_dict={}):\n",
    "        # super(MetricsCallback, self).__init__()\n",
    "        \n",
    "        self.lr_epoch_log_dict=lr_epoch_log_dict\n",
    "        \n",
    "        self.optimal_lr_epoch_dict=optimal_lr_epoch_dict\n",
    "            \n",
    "        \n",
    "        self.ReduceLROnPlateau_args=ReduceLROnPlateau_args\n",
    "        self.valid_metrics={\"roc_val\", \"eer_val\", \"thres\", \"acc_val\", \"f1_val\"}\n",
    "        if self.ReduceLROnPlateau_args != None:\n",
    "            ReduceLROnPlateau_mode={\"val_loss\": \"min\", \"roc_val\": \"max\", \"eer_val\": \"min\", \"thres\": \"min\", \"acc_val\": \"max\", \"f1_val\": \"max\"}\n",
    "            self.reduce_lr = MyReduceLROnPlateau(monitor=ReduceLROnPlateau_args['mointored_metric'], factor=ReduceLROnPlateau_args[\"factor\"], \n",
    "                                               patience=ReduceLROnPlateau_args[\"patience\"], verbose=ReduceLROnPlateau_args[\"verbose\"], \n",
    "                                               min_lr=ReduceLROnPlateau_args[\"min_lr\"], mode=ReduceLROnPlateau_mode[ReduceLROnPlateau_args['mointored_metric']])\n",
    "\n",
    "        self.X_valid, self.y_valid, self.X_train, self.y_train = payload\n",
    "        self.save_plots = save_plots\n",
    "        self.epoch_evaluate_freq = epoch_evaluate_freq\n",
    "        self.loss_record_dict = loss_record_dict\n",
    "        self.metric_record_dict = metric_record_dict\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "        self.plot_pca = plot_pca\n",
    "        self.print_interm_epochs = print_interm_epochs\n",
    "        self.early_stoping = early_stoping\n",
    "        \n",
    "        self.metric_record_dict['roc_val'] = {\"Train\": [], \"Valid\": []}\n",
    "        self.metric_record_dict['eer_val'] = {\"Train\": [], \"Valid\": []}\n",
    "        self.metric_record_dict['thres'] = {\"Train\": [], \"Valid\": []}\n",
    "        self.metric_record_dict['acc_val'] = {\"Train\": [], \"Valid\": []}\n",
    "        self.metric_record_dict['f1_val'] = {\"Train\": [], \"Valid\": []}\n",
    "        \n",
    "        # Do we have train and valid set?\n",
    "        self.sets = []\n",
    "        if self.X_train:\n",
    "            self.sets.append([self.X_train, self.y_train, \"Train\"])\n",
    "        if self.X_valid:\n",
    "            self.sets.append([self.X_valid, self.y_valid, \"Valid\"])\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "\n",
    "        print(32 * \"=\" + f\"[ Initial State ]\" + 32 * \"=\", end=\"\")\n",
    "        for X, y, desc in self.sets:\n",
    "            self.evaluate(X, y, logs, desc, -1)\n",
    "            \n",
    "        \n",
    "\n",
    "        if self.plot_pca:\n",
    "            deep_feature_model = Model(\n",
    "                inputs=self.model.layers[0].get_input_at(0),  # get_layer(\"left_inputs\").input,\n",
    "                outputs=self.model.get_layer(\"basemodel\").get_output_at(0),\n",
    "                )\n",
    "            deep_feature_model.summary()\n",
    "            deep_features_test = None\n",
    "            for X, y, subj in samples_test:  \n",
    "                \n",
    "                # if 2d, maybe need to import P\n",
    "                # if P.model_variant == \"2d\":\n",
    "                #     X = X.reshape((*X.shape, 1))\n",
    "                pred = deep_feature_model.predict(X)\n",
    "                df_features = pd.DataFrame(pred)\n",
    "                df_features[\"subject\"] = subj\n",
    "                deep_features_test = pd.concat([deep_features_test, df_features])\n",
    "            \n",
    "            plot_pca(deep_features_test)\n",
    "            \n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        print(32 * \"=\" + f\"[ Final State ]\" + 32 * \"=\", end=\"\")\n",
    "        for X, y, desc in self.sets:\n",
    "            self.evaluate(X, y, logs, desc, -1)\n",
    "            \n",
    "    def on_epoch_begin(self, epoch, logs={}, verbose=0):\n",
    "        \n",
    "        optimizer = self.model.optimizer\n",
    "        if self.optimal_lr_epoch_dict != None:\n",
    "\n",
    "            K.set_value(optimizer.lr, self.optimal_lr_epoch_dict[epoch])\n",
    "            if verbose:\n",
    "                print(f\"Learning rate changed to {self.optimal_lr_epoch_dict[epoch]} for epoch {epoch}\")\n",
    "            \n",
    "        else:\n",
    "            self.lr_epoch_log_dict[epoch]=K.get_value(optimizer.lr)\n",
    "            if verbose:\n",
    "                print(f\"Logged learning rate of {self.lr_epoch_log_dict[epoch]} for epoch {epoch}\") \n",
    "            \n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if self.print_interm_epochs:\n",
    "            print(32 * \"=\" + f\"[   Epoch {epoch}   ]\" + 32 * \"=\", end=\"\")\n",
    "            if epoch % self.epoch_evaluate_freq == 0:  # Evaluate only every n-th epoch\n",
    "                for X, y, desc in self.sets:\n",
    "                    self.evaluate(X, y, logs, desc, epoch)\n",
    "            else:\n",
    "                print(f\"\\n{ ', '.join([k + ': ' + f'{v:.3f}' for k,v in logs.items()]) }\")\n",
    "            \n",
    "\n",
    "        logs = logs or {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "    \n",
    "        \n",
    "        if 'val_loss' in logs:\n",
    "            if self.early_stoping and len(self.loss_record_dict['val_loss'])>1 and self.loss_record_dict['val_loss'][-1] < logs['val_loss']:\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "            else:\n",
    "                self.loss_record_dict['val_loss'].append(logs['val_loss'])\n",
    "\n",
    "                self.loss_record_dict['loss'].append(logs['loss'])\n",
    "\n",
    "                for X, y, desc in self.sets:\n",
    "                    self.evaluate(X, y, logs, desc, epoch, print_metric=False, save_metric_record_dict=True)\n",
    "            \n",
    "            # print(logs)\n",
    "            if self.ReduceLROnPlateau_args != None:\n",
    "                if self.ReduceLROnPlateau_args['mointored_metric'] == \"val_loss\":\n",
    "                    self.reduce_lr.on_epoch_end(epoch, self.model, logs)\n",
    "\n",
    "                elif self.ReduceLROnPlateau_args['mointored_metric'] in self.valid_metrics:\n",
    "                    mointored_metric_dict={self.ReduceLROnPlateau_args['mointored_metric']: self.metric_record_dict[self.ReduceLROnPlateau_args['mointored_metric']][\"Valid\"][-1]}\n",
    "                    self.reduce_lr.on_epoch_end(epoch, self.model, mointored_metric_dict)\n",
    "\n",
    "                else:\n",
    "                    raise Exception(\"invalid mointored metric\")\n",
    "            \n",
    "                    \n",
    "        else:\n",
    "            self.loss_record_dict['loss'].append(logs['loss'])\n",
    "\n",
    "            for X, y, desc in self.sets:\n",
    "                self.evaluate(X, y, logs, desc, epoch, print_metric=False, save_metric_record_dict=True)\n",
    "                \n",
    "        \n",
    "\n",
    "            \n",
    "    def evaluate(self, X, y, logs, desc, epoch, print_metric=True, save_metric_record_dict=False):\n",
    "        # Predict\n",
    "        y_score = self.model.predict(X)\n",
    "        y_score_neg = y_score * -1  # lower distance means closer to positive class\n",
    "\n",
    "        # Calc Metrics\n",
    "        roc_val = metrics.roc_auc_score(y, y_score_neg)\n",
    "        eer_val, thres = utils_eer(y, y_score_neg, True)\n",
    "        y_pred = np.where(y_score_neg > thres, 1, 0)\n",
    "        acc_val = metrics.accuracy_score(y, y_pred)\n",
    "        f1_val = metrics.f1_score(y, y_pred)\n",
    "        \n",
    "        if print_metric:\n",
    "            print(\n",
    "                f\"\\n{desc.upper()}: roc_auc: {roc_val:.4f}, \"\n",
    "                + f\"eer: {eer_val:.4f}, thres: {thres*-1:.4f} => \"\n",
    "                + f\"acc: {acc_val:.4f}, f1: {f1_val:.4f}\\n\"\n",
    "                + f\"{ ', '.join([k + ': ' + f'{v:.3f}' for k,v in logs.items()]) }\"\n",
    "            )\n",
    "\n",
    "        if save_metric_record_dict:\n",
    "            self.metric_record_dict['roc_val'][desc].append(roc_val)\n",
    "            self.metric_record_dict['eer_val'][desc].append(eer_val)\n",
    "            self.metric_record_dict['thres'][desc].append(float(thres))\n",
    "            self.metric_record_dict['acc_val'][desc].append(acc_val)\n",
    "            self.metric_record_dict['f1_val'][desc].append(f1_val)\n",
    "        \n",
    "        # Plot distances\n",
    "        mask = np.where(y == 1, True, False)\n",
    "        dist_positive = y_score[mask]\n",
    "        dist_negative = y_score[~mask]\n",
    "        \n",
    "        \n",
    "        if self.plot_pca:\n",
    "            # Extract one of the child networks\n",
    "            deep_feature_model = Model(\n",
    "                inputs=self.model.layers[0].get_input_at(0),  # get_layer(\"left_inputs\").input,\n",
    "                outputs=self.model.get_layer(\"basemodel\").get_output_at(0),\n",
    "            )\n",
    "            deep_feature_model.summary()\n",
    "            deep_features_test = None\n",
    "            for X, y, subj in samples_test:  \n",
    "                # if 2d, maybe need to import P\n",
    "                # if P.model_variant == \"2d\":\n",
    "                #     X = X.reshape((*X.shape, 1))\n",
    "                pred = deep_feature_model.predict(X)\n",
    "                df_features = pd.DataFrame(pred)\n",
    "                df_features[\"subject\"] = subj\n",
    "                deep_features_test = pd.concat([deep_features_test, df_features])\n",
    "\n",
    "            plot_pca(deep_features_test)\n",
    "        \n",
    "        #plt = utils_plot_distance_hist(\n",
    "        #    dist_positive, dist_negative, thres * -1, desc=desc, fig_size=(12, 2), margin=P.margin\n",
    "        #)\n",
    "\n",
    "#         if self.save_plots:\n",
    "#             utils_save_plot(\n",
    "#                 plt,\n",
    "#                 REPORT_PATH\n",
    "#                 / f\"buech2019-siamese-{P.name.lower()}-epoch-{epoch+1}-{desc.lower()}.pdf\",\n",
    "#             )\n",
    "\n",
    "        # plt.show()\n",
    "    \n",
    "def tune_stream(data_dict, arg_dict, stream_key, pool_dict, pool_key, create_model_func, tuning_metric, tuning_metric_val_dict, verbose=0):\n",
    "    '''\n",
    "    return the best value found after one round of hyper paramteer tuning of a stream\n",
    "    \n",
    "    arg_dict is the dict of arguments needed for training\n",
    "    stream key is the dict key that specifies the stream from the arg_dict we want to tune\n",
    "    pool dict is the dict containing possible values for all hyperparameters of arg_dict\n",
    "    pool_key is a key for pool dict that specifies the stream key value type so we can choose appropriate \n",
    "    values to tune\n",
    "    create_model_func is the function that that takes an arg_dic tand turnes it into an architectuer.\n",
    "    '''\n",
    "    best_params_lst=[]\n",
    "    for stream_idx in range(len(arg_dict[stream_key])):\n",
    "        for idx in range(len(arg_dict[stream_key][stream_idx])):\n",
    "            result=find_param_ranking(data_dict, arg_dict=arg_dict, dict_key=stream_key, \n",
    "                                      pool_dict=pool_dict, pool_key=pool_key, \n",
    "                                      create_model_func=create_model_func, \n",
    "                                      tuning_metric=tuning_metric, idx=idx, \n",
    "                                      stream_idx=stream_idx, verbose=verbose)\n",
    "            arg_dict = result[\"improved_arg_dict\"]\n",
    "            best_params_lst.append(result[\"best_params\"])\n",
    "    \n",
    "    tuning_metric_val_dict[stream_key]=best_params_lst\n",
    "    return arg_dict, tuning_metric_val_dict\n",
    "\n",
    "def tune_param(data_dict, arg_dict, param_key, pool_dict, pool_key, create_model_func, tuning_metric, tuning_metric_val_dict, verbose=0):\n",
    "    \"\"\"\n",
    "    return the best value found after one round of hyper parameter tuning of a param\n",
    "    \n",
    "    arg_dict is the dict of arguments needed for training\n",
    "    param_key is the dict key that specifies the param from the arg_dict we want to tune\n",
    "    pool dict is the dict containing possible values for all hyperparameters of arg_dict\n",
    "    pool_key is a key for pool dict that specifies the param_key value type so we can choose appropriate \n",
    "    values to tune\n",
    "    create_model_func is the function that that takes an arg_dic tand turnes it into an architectuer.\n",
    "    \"\"\"\n",
    "    best_params_lst=[]\n",
    "    for idx in range(len(arg_dict[param_key])):\n",
    "        result=find_param_ranking(data_dict, arg_dict=arg_dict, dict_key=param_key, \n",
    "                                  pool_dict=pool_dict, pool_key=pool_key, \n",
    "                                  create_model_func=create_model_func, \n",
    "                                  tuning_metric=tuning_metric, idx=idx, \n",
    "                                  stream_idx=None, verbose=verbose)\n",
    "        \n",
    "        arg_dict = result[\"improved_arg_dict\"]\n",
    "        best_params_lst.append(result[\"best_params\"])\n",
    "        \n",
    "    tuning_metric_val_dict[param_key]=best_params_lst\n",
    "    return arg_dict, tuning_metric_val_dict\n",
    "\n",
    "def tune_dense_activations(data_dict, arg_dict, pool_dict, pool_key, create_model_func, tuning_metric, tuning_metric_val_dict, verbose=0):\n",
    "    \"\"\"\n",
    "    return the best value found after one round of hyper parameter tuning of a param\n",
    "    \n",
    "    arg_dict is the dict of arguments needed for training\n",
    "    pool dict is the dict containing possible values for all hyperparameters of arg_dict\n",
    "    pool_key is a key for pool dict that specifies the dense_activations value type so we can choose appropriate \n",
    "    values to tune\n",
    "    create_model_func is the function that that takes an arg_dic tand turnes it into an architectuer.\n",
    "    \"\"\"\n",
    "    best_params_lst=[]\n",
    "    for idx in range(len(arg_dict[\"dense_activations\"]) - 1): # do not tune the final sigmoid\n",
    "        result=find_param_ranking(data_dict, arg_dict=arg_dict, dict_key=\"dense_activations\", \n",
    "                                  pool_dict=pool_dict, pool_key=pool_key, \n",
    "                                  create_model_func=create_model_func, \n",
    "                                  tuning_metric=tuning_metric, idx=idx, \n",
    "                                  stream_idx=None, verbose=verbose)\n",
    "        \n",
    "        arg_dict = result[\"improved_arg_dict\"]\n",
    "        best_params_lst.append(result[\"best_params\"])\n",
    "        \n",
    "    tuning_metric_val_dict['dense_activations']=best_params_lst\n",
    "    return arg_dict, tuning_metric_val_dict\n",
    "\n",
    "def tune_training_params(data_dict, arg_dict, param_key, pool_dict, pool_key, create_model_func, tuning_metric, tuning_metric_val_dict, verbose=0):\n",
    "    \"\"\"\n",
    "    return the best value found after one round of hyper parameter tuning of a training param\n",
    "    training params are as follows: \n",
    "    batch_size, loss function, loss function args, optimizer function, optimizer function args\n",
    "    \n",
    "    arg_dict is the dict of arguments needed for training\n",
    "    param_key is the dict key that specifies the param from the arg_dict we want to tune\n",
    "    pool dict is the dict containing possible values for all hyperparameters of arg_dict\n",
    "    pool_key is a key for pool dict that specifies the param_key value type so we can choose appropriate \n",
    "    values to tune\n",
    "    create_model_func is the function that that takes an arg_dic tand turnes it into an architectuer.\n",
    "    \"\"\"\n",
    "    best_params_lst=[]\n",
    "    result=find_param_ranking(data_dict, arg_dict=arg_dict, dict_key=param_key, \n",
    "                              pool_dict=pool_dict, pool_key=pool_key, \n",
    "                              create_model_func=create_model_func, \n",
    "                              tuning_metric=tuning_metric, idx=None, \n",
    "                              stream_idx=None, verbose=verbose)\n",
    "\n",
    "    arg_dict = result[\"improved_arg_dict\"]\n",
    "    best_params_lst.append(result[\"best_params\"])\n",
    "    \n",
    "    tuning_metric_val_dict[param_key]=best_params_lst\n",
    "    return arg_dict, tuning_metric_val_dict\n",
    "\n",
    "def find_param_ranking(data_dict, arg_dict, dict_key, pool_dict, pool_key, create_model_func, tuning_metric, idx=None, stream_idx=None, verbose=0, early_stoping=False):\n",
    "\n",
    "    X_valid, y_valid, X_train, y_train = data_dict[\"X_valid\"], data_dict[\"y_valid\"], data_dict[\"X_train\"], data_dict[\"y_train\"]\n",
    "    param_metric_performance_dict = {}\n",
    "    \n",
    "    pool=pool_dict[pool_key]\n",
    "    for pool_param in pool:\n",
    "        # keep the initial state fixed\n",
    "        tf.random.set_seed(SEED)\n",
    "        \n",
    "        new_arg_dict = arg_dict.copy()\n",
    "        if stream_idx != None:\n",
    "            new_arg_dict[dict_key][stream_idx][idx] = pool_param\n",
    "        elif idx != None:\n",
    "            new_arg_dict[dict_key][idx] = pool_param\n",
    "        else:\n",
    "            new_arg_dict[dict_key] = pool_param\n",
    "            \n",
    "        # P.margin = new_arg_dict[\"contrastive_loss_margin\"] obsolete\n",
    "        print(new_arg_dict)\n",
    "        loss_record_dict = {'loss': [], 'val_loss': []}\n",
    "        metric_record_dict = {}\n",
    "        model = create_model_func(new_arg_dict)\n",
    "        \n",
    "        ReduceLROnPlateau_err_mode={}\n",
    "        ReduceLROnPlateau_args={'mointored_metric': tuning_metric, \"factor\": 0.2, \"patience\": 2, \"verbose\": 1, \"min_lr\": 1e-6}\n",
    "\n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train,\n",
    "            batch_size=new_arg_dict[\"batch_size\"],\n",
    "            epochs=30,\n",
    "            verbose=verbose,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            callbacks=[MetricsCallback((X_valid, y_valid, X_train, y_train), epoch_evaluate_freq=5, \n",
    "                                       loss_record_dict=loss_record_dict, metric_record_dict=metric_record_dict, \n",
    "                                       save_plots=True, print_interm_epochs=False, early_stoping=early_stoping,\n",
    "                                      ReduceLROnPlateau_args=ReduceLROnPlateau_args)],\n",
    "        )\n",
    "        print(loss_record_dict)\n",
    "        print(\"Training History:\")\n",
    "        # loss_fig = utils_plot_training_loss(loss_record_dict)\n",
    "        if early_stoping:\n",
    "            param_metric_performance_dict[pool_param]={\n",
    "                'val_loss': loss_record_dict['val_loss'][-1], \n",
    "                'roc_val': metric_record_dict['roc_val']['Valid'][-1], \n",
    "                'eer_val': metric_record_dict['eer_val']['Valid'][-1], \n",
    "                'thres': metric_record_dict['thres']['Valid'][-1], \n",
    "                'acc_val': metric_record_dict['acc_val']['Valid'][-1], \n",
    "                'f1_val': metric_record_dict['f1_val']['Valid'][-1],\n",
    "                }\n",
    "            \n",
    "        else: \n",
    "            param_metric_performance_dict[pool_param]={\n",
    "                'val_loss': min(loss_record_dict['val_loss']), \n",
    "                'roc_val': max(metric_record_dict['roc_val']['Valid']), \n",
    "                'eer_val': min(metric_record_dict['eer_val']['Valid']), \n",
    "                'thres': min(metric_record_dict['thres']['Valid']), \n",
    "                'acc_val': max(metric_record_dict['acc_val']['Valid']), \n",
    "                'f1_val': max(metric_record_dict['f1_val']['Valid']),\n",
    "                }\n",
    "    \n",
    "    print(param_metric_performance_dict)\n",
    "    best_params = get_best_parameters(param_metric_performance_dict)\n",
    "    print((\"{}\\n\"*len(best_params)).format(*best_params.items()))\n",
    "    improved_arg_dict = arg_dict.copy()\n",
    "    \n",
    "    if stream_idx != None:\n",
    "        improved_arg_dict[dict_key][stream_idx][idx] = best_params['best_'+tuning_metric][\"param\"]\n",
    "    elif idx != None:\n",
    "        improved_arg_dict[dict_key][idx] = best_params['best_'+tuning_metric][\"param\"]\n",
    "    else:\n",
    "        improved_arg_dict[dict_key] = best_params['best_'+tuning_metric][\"param\"]\n",
    "    \n",
    "    return {\"improved_arg_dict\": improved_arg_dict, \"best_params\": best_params} #, param_ranking # not sure if returning this is useful for now\n",
    "\n",
    "# def log_metrics_tuning(arg_dict, best_params_dict):\n",
    "#     \"\"\"\n",
    "#     log best params through tuning in arg_dict\n",
    "#     \"\"\"\n",
    "#     best_params = {\n",
    "#     'best_val_loss': {\"param\": best_val_loss[0], \"value\": best_val_loss[1]['val_loss']}, \n",
    "#     'best_roc_val': {\"param\": best_roc_val[0], \"value\": best_roc_val[1]['roc_val']},\n",
    "#     'best_eer_val': {\"param\": best_eer_val[0], \"value\": best_eer_val[1]['eer_val']},\n",
    "#     'best_thres': {\"param\": best_thres[0], \"value\": best_thres[1]['thres']},\n",
    "#     'best_acc_val': {\"param\": best_acc_val[0], \"value\": best_acc_val[1]['acc_val']},\n",
    "#     'best_f1_val': {\"param\": best_f1_val[0], \"value\": best_f1_val[1]['f1_val']},\n",
    "#     }\n",
    "def get_best_parameters(param_metric_performance_dict):\n",
    "    '''\n",
    "    calculate and return best valiation parameters given the param_metric_dict.\n",
    "    param_metric_dict is the dicitonary containing the parameters with their correspongin performance\n",
    "    '''\n",
    "    lst = list(param_metric_performance_dict.items())\n",
    "    # sort all in descending order, first element is max and last element is min\n",
    "    # best_val_loss = sorted(lst, key = lambda x: x[1]['val_loss'], reverse=True)[-1] # min\n",
    "    # best_roc_val = sorted(lst, key = lambda x: x[1]['roc_val'], reverse=True)[0] # max\n",
    "    # best_eer_val = sorted(lst, key = lambda x: x[1]['eer_val'], reverse=True)[-1] # min\n",
    "    # best_thres = sorted(lst, key = lambda x: x[1]['thres'], reverse=True)[-1] # min\n",
    "    # best_acc_val = sorted(lst, key = lambda x: x[1]['acc_val'], reverse=True)[0] # max\n",
    "    # best_f1_val = sorted(lst, key = lambda x: x[1]['f1_val'], reverse=True)[0] # max\n",
    "    \n",
    "    best_val_loss = min(lst, key = lambda x: x[1]['val_loss']) # min\n",
    "    best_roc_val = max(lst, key = lambda x: x[1]['roc_val']) # max\n",
    "    best_eer_val = min(lst, key = lambda x: x[1]['eer_val']) # min\n",
    "    best_thres = min(lst, key = lambda x: x[1]['thres']) # min\n",
    "    best_acc_val = max(lst, key = lambda x: x[1]['acc_val']) # max\n",
    "    best_f1_val = max(lst, key = lambda x: x[1]['f1_val']) # max\n",
    "    \n",
    "    best_params = {\n",
    "        'best_val_loss': {\"param\": best_val_loss[0], \"value\": best_val_loss[1]['val_loss']}, \n",
    "        'best_roc_val': {\"param\": best_roc_val[0], \"value\": best_roc_val[1]['roc_val']},\n",
    "        'best_eer_val': {\"param\": best_eer_val[0], \"value\": best_eer_val[1]['eer_val']},\n",
    "        'best_thres': {\"param\": best_thres[0], \"value\": best_thres[1]['thres']},\n",
    "        'best_acc_val': {\"param\": best_acc_val[0], \"value\": best_acc_val[1]['acc_val']},\n",
    "        'best_f1_val': {\"param\": best_f1_val[0], \"value\": best_f1_val[1]['f1_val']},\n",
    "            }\n",
    "    \n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_module = 0\n",
    "if test_module:\n",
    "    # param_metric_performance_dict={}\n",
    "    param_metric_performance_dict={3: {'val_loss': 1, \n",
    "                                          'roc_val': 2, \n",
    "                                          'eer_val': 3, \n",
    "                                          'thres': 4, \n",
    "                                          'acc_val': 5, \n",
    "                                          'f1_val': 6,\n",
    "                                         },\n",
    "                                  4: {'val_loss': 6, \n",
    "                                          'roc_val': 5, \n",
    "                                          'eer_val': 4, \n",
    "                                          'thres': 3, \n",
    "                                          'acc_val': 2, \n",
    "                                          'f1_val': 1,\n",
    "                                         }\n",
    "                                  }\n",
    "\n",
    "    best_params = get_best_parameters(param_metric_performance_dict)\n",
    "    assert best_params['best_val_loss']['value'] == param_metric_performance_dict[3]['val_loss']\n",
    "    assert best_params['best_roc_val']['value'] == param_metric_performance_dict[4]['roc_val']\n",
    "    assert best_params['best_eer_val']['value'] == param_metric_performance_dict[3]['eer_val']\n",
    "    assert best_params['best_thres']['value'] == param_metric_performance_dict[4]['thres']\n",
    "    assert best_params['best_acc_val']['value'] == param_metric_performance_dict[3]['acc_val']\n",
    "    assert best_params['best_f1_val']['value'] == param_metric_performance_dict[3]['f1_val']\n",
    "\n",
    "    assert best_params['best_val_loss']['param'] == 3\n",
    "    assert best_params['best_roc_val']['param'] == 4\n",
    "    assert best_params['best_eer_val']['param'] == 3\n",
    "    assert best_params['best_thres']['param'] == 4\n",
    "    assert best_params['best_acc_val']['param'] == 3\n",
    "    assert best_params['best_f1_val']['param'] == 3\n",
    "    print(\"no err\")\n",
    "    # # rank_f = lambda \n",
    "    # # use lambda functions to sort and store\n",
    "    # lst = list(param_metric_performance_dict.items())\n",
    "    # print(max(lst, key = lambda x: x[1]['thres']))\n",
    "    # param_metric_performance_dict.items()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_pca_dataframe(Raw_X_exp_test_dic, session_id=None):\n",
    "    \n",
    "    columns=['X', 'subject', 'session', 'win_idx']\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    for subject_id in Raw_X_exp_test_dic:\n",
    "        win_idx = 0\n",
    "        for subject_window in Raw_X_exp_test_dic[subject_id]:\n",
    "            new_row = pd.DataFrame([[subject_window.to_numpy(), subject_id, session_id, win_idx]], columns=columns)\n",
    "            df = pd.concat([df, new_row])\n",
    "            win_idx +=1\n",
    "        \n",
    "            \n",
    "    return df\n",
    "   \n",
    "def prep_X_y_single(df):\n",
    "    X = np.stack(list(df[\"X\"].values))\n",
    "    y = df[\"label\"].values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def transform_to_sample_by_subject(df):\n",
    "    sample_by_subject = []\n",
    "    df[\"label\"] = 1\n",
    "    for subj in df[\"subject\"].unique():\n",
    "        df_subj = df[df[\"subject\"] == subj]\n",
    "        X_sub, y_sub = prep_X_y_single(df_subj)\n",
    "        sample_by_subject.append((X_sub, y_sub, subj))\n",
    "    return sample_by_subject\n",
    "\n",
    "def plot_pca(df):\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    deep_transformed = pca.fit_transform(df.drop(columns=[\"subject\"]).values)\n",
    "\n",
    "    # Create df with data needed for chart only\n",
    "    df_viz = df.copy()\n",
    "    df_viz[\"PCA0\"] = deep_transformed[:, 0]\n",
    "    df_viz[\"PCA1\"] = deep_transformed[:, 1]\n",
    "    df_viz.drop(\n",
    "        columns=[c for c in df_viz.columns if c not in [\"PCA0\", \"PCA1\", \"subject\"]]\n",
    "    )\n",
    "\n",
    "    # Generate color index for every subject\n",
    "    df_viz[\"Subject\"] = pd.Categorical(df_viz[\"subject\"])\n",
    "    df_viz[\"colors\"] = df_viz[\"Subject\"].cat.codes\n",
    "\n",
    "    if len(df_viz[\"Subject\"].unique()) <= 10:\n",
    "        pal = sns.color_palette(\"tab10\")\n",
    "    else:\n",
    "        pal = sns.color_palette(\"tab20\")\n",
    "        \n",
    "    # Actual plot\n",
    "    fig = plt.figure(figsize=(10 / 1.5, 10 / 2), dpi=180)\n",
    "    sns.scatterplot(\n",
    "        x=\"PCA0\",\n",
    "        y=\"PCA1\",\n",
    "        data=df_viz,\n",
    "        hue=\"Subject\",\n",
    "        legend=\"full\",\n",
    "        # palette=pal,\n",
    "        s=5,\n",
    "        linewidth=0,\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0, fontsize=5)\n",
    "    fig.tight_layout()\n",
    "    return plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MakeDeepXExpDic(X_exp1_train_dic, X_exp2_train_dic, fitted_scaler_ocsvm_exp2_train_dic, X_exp1_test_dic, X_exp2_test_dic, fitted_scaler_ocsvm_exp2_test_dic, deep_feature_model):\n",
    "    X_exp_train_dic = MakeDeepXExpDicOwner(X_exp2_train_dic, deep_feature_model, scaler_clip=True, scaler_type=\"MinMaxScaler\")\n",
    "    X_exp_train_dic = MakeDeepXExpDicUnknown(X_exp1_train_dic, deep_feature_model, X_exp_train_dic, fitted_raw_scaler_dict=fitted_scaler_ocsvm_exp2_train_dic)\n",
    "    X_exp_test_dic = MakeDeepXExpDicOwner(X_exp2_test_dic, deep_feature_model, scaler_clip=True, scaler_type=\"MinMaxScaler\")\n",
    "    X_exp_test_dic = MakeDeepXExpDicUnknown(X_exp1_test_dic, deep_feature_model, X_exp_test_dic, fitted_raw_scaler_dict=fitted_scaler_ocsvm_exp2_test_dic)\n",
    "    \n",
    "    return X_exp_train_dic, X_exp_test_dic\n",
    "\n",
    "def MakeWACAXExpDic(X_exp1_train_dic, X_exp2_train_dic, fitted_scaler_ocsvm_exp2_train_dic, X_exp1_test_dic, X_exp2_test_dic, fitted_scaler_ocsvm_exp2_test_dic):\n",
    "    X_exp_train_dic = MakeWACAXExpDicOwner(X_exp2_train_dic, scaler_clip=True, scaler_type=\"MinMaxScaler\")\n",
    "    X_exp_train_dic = MakeWACAXExpDicUnknown(X_exp1_train_dic, X_exp_train_dic, fitted_raw_scaler_dict=fitted_scaler_ocsvm_exp2_train_dic)\n",
    "    X_exp_test_dic = MakeWACAXExpDicOwner(X_exp2_test_dic, scaler_clip=True, scaler_type=\"MinMaxScaler\")\n",
    "    X_exp_test_dic = MakeWACAXExpDicUnknown(X_exp1_test_dic, X_exp_test_dic, fitted_raw_scaler_dict=fitted_scaler_ocsvm_exp2_test_dic)\n",
    "    \n",
    "    return X_exp_train_dic, X_exp_test_dic\n",
    "\n",
    "def combine_X_exp_dicts(deep_X_exp_dic, WACA_X_exp_dic):\n",
    "    \n",
    "    union_dic = {}\n",
    "    for user in deep_X_exp_dic:\n",
    "        union_dic[user] = {\"profile_windows\": np.concatenate([WACA_X_exp_dic[user][\"profile_windows\"], deep_X_exp_dic[user][\"profile_windows\"]], axis=1),\n",
    "                           'unknown_users_dict':{}}\n",
    "        \n",
    "        for unknown_user in deep_X_exp_dic[user]['unknown_users_dict']:\n",
    "            union_dic[user]['unknown_users_dict'][unknown_user] = np.concatenate([WACA_X_exp_dic[user][\"unknown_users_dict\"][unknown_user], \n",
    "                                                                               deep_X_exp_dic[user][\"unknown_users_dict\"][unknown_user]], axis=1)\n",
    "            \n",
    "    return union_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(Raw_X_exp2_train_dic.keys())\n",
    "# user_id_lst = list(Raw_X_exp2_train_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validation_pairs_lst = []\n",
    "# for user1_idx in range(len(user_id_lst)-1):\n",
    "#     validation_pairs_lst.append((user_id_lst[user1_idx], user_id_lst[user1_idx+1]))\n",
    "#     print(validation_pairs_lst)\n",
    "    \n",
    "# for user1, user2 in validation_pairs_lst:\n",
    "#     print(user1, user2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_cv_split(valid_sets_lst[0], user_id_set, Raw_X_exp2_train_dic, Raw_X_exp1_train_dic, fitted_scaler_SNN_exp2_train_dic, num_pair_limit_train_2000, num_pair_limit_valid_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # valid_sets_lst = []\n",
    "# # for user1_idx in range(len(user_id_lst)-2):\n",
    "# #     valid_sets_lst.append((user_id_lst[user1_idx], user_id_lst[user1_idx+1], user_id_lst[user1_idx+2]))\n",
    "    \n",
    "# arr = [2, 3, 5, 7, 11, 13]\n",
    "# def make_valid_sets_lst(user_id_lst, k):\n",
    "#     valid_sets_lst=[]\n",
    "#     for i in range(0, len(user_id_lst)-k+1, k):\n",
    "#         valid_sets_lst.append(set(user_id_lst[i:i+k]))\n",
    "    \n",
    "#     return valid_sets_lst\n",
    "\n",
    "# make_valid_sets_lst(user_id_lst, 4)\n",
    "# valid_sets_lst = make_valid_sets_lst(user_id_lst, 5)\n",
    "# # key = list(valid_sets_lst[1])\n",
    "# # key.sort()\n",
    "# valid_sets_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# user_id_array = list(range(10))\n",
    "# # Get the unique user_ids\n",
    "# unique_users = np.unique(user_id_array)\n",
    "\n",
    "\n",
    "# # Iterate through all possible pairs of users\n",
    "# # for user1, user2 in itertools.combinations(unique_users, 2):\n",
    "# #     # Select samples for the current pair of users\n",
    "# #     user1_samples = (user_id_array == user1)\n",
    "# #     user2_samples = (user_id_array == user2)\n",
    "    \n",
    "# #     print(user1, user2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# import itertools\n",
    "\n",
    "# def generate_cv_split(valid_users_set, user_id_set, Raw_X_exp2_train_dic, Raw_X_exp1_train_dic, fitted_scaler_SNN_exp2_train_dic, num_pair_limit_train_2000, num_pair_limit_valid_2000):\n",
    "#     cv_dict = {}\n",
    "    \n",
    "#     cnn_valid_set = valid_users_set\n",
    "#     cnn_train_set = user_id_set - cnn_valid_set\n",
    "    \n",
    "#     cnn_train_exp2 = {key: Raw_X_exp2_train_dic[key] for key in cnn_train_set}\n",
    "#     cnn_train_exp1 = {key: Raw_X_exp1_train_dic[key] for key in cnn_train_set}\n",
    "#     cnn_valid_exp2 = {key: Raw_X_exp2_train_dic[key] for key in cnn_valid_set}\n",
    "#     cnn_valid_exp1 = {key: Raw_X_exp1_train_dic[key] for key in cnn_valid_set}\n",
    "    \n",
    "#     X_train, y_train = prep_X_y_pair(cnn_train_exp2, cnn_train_exp1, list(cnn_train_exp2.keys()), fitted_scaler_SNN_exp2_train_dic, num_pair_limit=num_pair_limit_train_2000)\n",
    "#     X_valid, y_valid = prep_X_y_pair(cnn_valid_exp2, cnn_valid_exp1, list(cnn_valid_exp2.keys()), fitted_scaler_SNN_exp2_train_dic, num_pair_limit=num_pair_limit_valid_2000)\n",
    "    \n",
    "#     key = list(valid_users_set)\n",
    "#     key.sort()\n",
    "#     key = tuple(key)\n",
    "#     cv_dict[key] = {}\n",
    "#     cv_dict[key][\"train\"] = X_train, y_train\n",
    "#     cv_dict[key][\"valid\"] = X_valid, y_valid\n",
    "    \n",
    "#     return cv_dict\n",
    "\n",
    "\n",
    "# num_pair_limit_train_2000 = 9182\n",
    "# num_pair_limit_valid_2000 = 5310\n",
    "# user_id_lst = list(Raw_X_exp2_train_dic.keys())\n",
    "# user_id_set = set(Raw_X_exp2_train_dic.keys())\n",
    "\n",
    "# valid_sets_lst = make_valid_sets_lst(user_id_lst, 5)\n",
    "\n",
    "# print(valid_sets_lst)\n",
    "# # user_id_array = {1,2,3}\n",
    "# results = Parallel(n_jobs=-1, verbose=100)(delayed(generate_cv_split)(valid_users_set, user_id_set, Raw_X_exp2_train_dic, Raw_X_exp1_train_dic, fitted_scaler_SNN_exp2_train_dic, \n",
    "#                                                    num_pair_limit_train_2000, num_pair_limit_valid_2000) for valid_users_set in valid_sets_lst)\n",
    "\n",
    "\n",
    "# results = {k: v for d in results for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results[(5, 6, 7, 8, 9, 10)]['train'][0][0].shape\n",
    "# results.keys()\n",
    "# len(cnn_valid_exp1[list(cnn_valid_exp1.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def generate_negative_index_pairs(diagonal_size):\n",
    "#     '''\n",
    "#     return an array of indices for negative pairs for user u1 and u2, where u1 != u2\n",
    "#     u1 is the genuine user and u2 is the imposter.\n",
    "#     '''\n",
    "#     indices = list(range(diagonal_size))\n",
    "#     mesh = np.array(np.meshgrid(indices, indices))\n",
    "#     negative_index_pairs = mesh.T.reshape(-1, 2)\n",
    "    \n",
    "#     return negative_index_pairs\n",
    "\n",
    "# def generate_positive_index_pairs(diagonal_size):\n",
    "#     '''\n",
    "#     return an array of tuple indices for the positive pairs.\n",
    "#     '''\n",
    "#     indices = list(range(diagonal_size))\n",
    "#     mesh = np.array(np.meshgrid(indices, indices))\n",
    "#     positive_index_pairs = mesh.T.reshape(-1, 2)\n",
    "#     positive_index_pairs = positive_index_pairs.reshape(diagonal_size, diagonal_size, 2)\n",
    "\n",
    "#     new_array_size = diagonal_size * diagonal_size - diagonal_size\n",
    "\n",
    "#     positive_index_pairs = deleteDiagonal(positive_index_pairs).reshape(new_array_size, 2)\n",
    "#     return positive_index_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lim = 2000\n",
    "# for total_samples_per_user in [27]:\n",
    "#     for num_users in [7, 10, 12, 15, 17, 20]:\n",
    "        \n",
    "        \n",
    "#         print(generate_negative_index_pairs(total_samples_per_user).shape)\n",
    "#         num_pos_per_owner = generate_positive_index_pairs(total_samples_per_user).shape[0]\n",
    "#         total_num_pairs = num_pos_per_owner * num_users * 2\n",
    "#         if lim < total_num_pairs: \n",
    "#             limit_ratio = lim/total_num_pairs\n",
    "#         else:\n",
    "#             limit_ratio=1\n",
    "#         num_pos_per_owner = np.round(limit_ratio * num_pos_per_owner)\n",
    "        \n",
    "#         ratio = ((total_samples_per_user-1) / (total_samples_per_user * (num_users-1)))*limit_ratio\n",
    "#         num_neg_per_owner = int(np.round(generate_negative_index_pairs(total_samples_per_user).shape[0]*ratio*(num_users-1)))\n",
    "#         print(num_pos_per_owner)\n",
    "#         print(num_neg_per_owner)\n",
    "#         print(num_pos_per_owner==num_neg_per_owner)\n",
    "#         print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# def generate_cv_split(user1, user2, user_id_array, Raw_X_exp2_train_dic, Raw_X_exp1_train_dic, fitted_scaler_SNN_exp2_train_dic, num_pair_limit_train_2000, num_pair_limit_valid_2000):\n",
    "#     cv_dict = {}\n",
    "    \n",
    "#     cnn_valid_set = {user1, user2}\n",
    "#     cnn_train_set = user_id_array - cnn_valid_set\n",
    "    \n",
    "#     cnn_train_exp2 = {key: Raw_X_exp2_train_dic[key] for key in cnn_train_set}\n",
    "#     cnn_train_exp1 = {key: Raw_X_exp1_train_dic[key] for key in cnn_train_set}\n",
    "#     cnn_valid_exp2 = {key: Raw_X_exp2_train_dic[key] for key in cnn_valid_set}\n",
    "#     cnn_valid_exp1 = {key: Raw_X_exp1_train_dic[key] for key in cnn_valid_set}\n",
    "    \n",
    "#     X_train, y_train = prep_X_y_pair(cnn_train_exp2, cnn_train_exp1, list(cnn_train_exp2.keys()), fitted_scaler_SNN_exp2_train_dic, num_pair_limit=num_pair_limit_train_2000)\n",
    "#     X_valid, y_valid = prep_X_y_pair(cnn_valid_exp2, cnn_valid_exp1, list(cnn_valid_exp2.keys()), fitted_scaler_SNN_exp2_train_dic, num_pair_limit=num_pair_limit_valid_2000)\n",
    "    \n",
    "#     cv_dict[(user1, user2)] = {}\n",
    "#     cv_dict[(user1, user2)][\"train\"] = X_train, y_train\n",
    "#     cv_dict[(user1, user2)][\"valid\"] = X_valid, y_valid\n",
    "    \n",
    "#     return cv_dict\n",
    "\n",
    "\n",
    "# num_pair_limit_train_2000 = 9182\n",
    "# num_pair_limit_valid_2000 = 5310\n",
    "# user_id_array = set(Raw_X_exp2_train_dic.keys())\n",
    "# # user_id_array = {1,2,3,4,5}\n",
    "# results = Parallel(n_jobs=-1, verbose=100)(delayed(generate_cv_split)(user1, user2, user_id_array, Raw_X_exp2_train_dic, Raw_X_exp1_train_dic, fitted_scaler_SNN_exp2_train_dic, \n",
    "#                                                    num_pair_limit_train_2000, num_pair_limit_valid_2000) for user1, user2 in itertools.combinations(user_id_array, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# user_id_array = set(Raw_X_exp2_train_dic.keys())\n",
    "\n",
    "# num_pair_limit_train_2000 = 9182\n",
    "# num_pair_limit_valid_2000 = 5310\n",
    "\n",
    "# cv_dict = {}\n",
    "# # Iterate through all possible pairs of users\n",
    "# for user1, user2 in tqdm(itertools.combinations(user_id_array, 2)):\n",
    "#     cnn_valid_set = {user1, user2}\n",
    "#     cnn_train_set = user_id_array - cnn_valid_set\n",
    "    \n",
    "#     cnn_train_exp2 = {key: Raw_X_exp2_train_dic[key] for key in cnn_train_set}\n",
    "#     cnn_train_exp1 = {key: Raw_X_exp1_train_dic[key] for key in cnn_train_set}\n",
    "#     cnn_valid_exp2 = {key: Raw_X_exp2_train_dic[key] for key in cnn_valid_set}\n",
    "#     cnn_valid_exp1 = {key: Raw_X_exp1_train_dic[key] for key in cnn_valid_set}\n",
    "    \n",
    "#     X_train, y_train = prep_X_y_pair(cnn_train_exp2, cnn_train_exp1, list(cnn_train_exp2.keys()), fitted_scaler_SNN_exp2_train_dic, num_pair_limit=num_pair_limit_train_2000)\n",
    "#     X_valid, y_valid = prep_X_y_pair(cnn_valid_exp2, cnn_valid_exp1, list(cnn_valid_exp2.keys()), fitted_scaler_SNN_exp2_train_dic, num_pair_limit=num_pair_limit_valid_2000)\n",
    "    \n",
    "#     cv_dict[(user1, user2)] = {}\n",
    "#     cv_dict[(user1, user2)][\"train\"] = X_train, y_train\n",
    "#     cv_dict[(user1, user2)][\"valid\"] = X_valid, y_valid\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def deleteDiagonal(array):\n",
    "#     depth = array.shape[-1]\n",
    "#     m = array.shape[1]\n",
    "#     strided = np.lib.stride_tricks.as_strided\n",
    "#     s0,s1,s2 = array.strides\n",
    "#     return strided(array.ravel()[depth:], shape=(m-1, m, depth), strides=(s0+s1,s1, s2)).reshape(m, m-1, depth)\n",
    "# print(mesh.shape)\n",
    "# deleteDiagonal(mesh).reshape(12,2)\n",
    "\n",
    "# def build_model_fcn(input_shape, filters):\n",
    "#     # Define the tensors for the two input images\n",
    "#     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "#     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "#     # Convolutional Neural Network\n",
    "#     inputs = Input(input_shape, name=\"input\")\n",
    "#     x = Conv1D(filters=filters[0], kernel_size=8, strides=1, activation=None, padding=\"same\", name=\"conv1\")(inputs)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation(\"relu\")(x)\n",
    "#     x = Dropout(0.1, name=\"drop1\")(x)\n",
    "#     x = Conv1D(filters=filters[1], kernel_size=5, strides=1, activation=None, padding=\"same\", name=\"conv2\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation(\"relu\")(x)\n",
    "#     x = Dropout(0.1, name=\"drop2\")(x)\n",
    "#     x = Conv1D(filters=filters[2], kernel_size=3, strides=1, activation=None, padding=\"same\", name=\"conv3\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation(\"relu\")(x)\n",
    "#     x = GlobalAveragePooling1D()(x)\n",
    "#     # x = Dense(32, activation=\"sigmoid\", name=\"dense\")(x) # <--- !!!!!!!!!!!!\n",
    "# #     x = Dense(64, activation=\"sigmoid\", name=\"dense\")(x) # <--- !!!!!!!!!!!!\n",
    "#     x = Dense(78, activation=\"sigmoid\", name=\"dense\")(x)\n",
    "\n",
    "#     # Basemodel instance\n",
    "#     basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "#     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "#     encoded_l = basemodel(left_inputs)\n",
    "#     encoded_r = basemodel(right_inputs)\n",
    "\n",
    "#     # Add a customized layer to compute the distance between the encodings\n",
    "#     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "#     # Combine into one net\n",
    "#     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "#     # return the model\n",
    "#     return siamese_net, basemodel\n",
    "\n",
    "# def create_model_fcn(input_shape, filters, kernels, kernel_initializers, strides, dropouts, activations, dense_kernels, dense_kernel_initializers, loss_func, optimizer):\n",
    "#     '''\n",
    "#     it is assumed that len(dropouts)=len(filters)-1\n",
    "#     '''\n",
    "#     # Define the tensors for the two input images\n",
    "#     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "#     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "#     # Convolutional Neural Network\n",
    "#     inputs = Input(input_shape, name=\"input\")\n",
    "    \n",
    "    \n",
    "# #     ------\n",
    "#     x=inputs\n",
    "#     for idx in range(len(dropouts)):\n",
    "#         x = Conv1D(filters=filters[idx], kernel_size=kernels[idx], kernel_initializer=kernel_initializers[idx], kernel_constraint=MaxNorm(3), strides=strides[idx], \n",
    "#                    activation=None, padding=\"same\", name=f\"conv{idx+1}\")(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = Activation(activations[idx])(x)\n",
    "#         x = Dropout(dropouts[idx], name=f\"drop{idx+1}\")(x)\n",
    "    \n",
    "#     x = Conv1D(filters=filters[idx+1], kernel_size=kernels[idx+1], kernel_initializer=kernel_initializers[idx+1], kernel_constraint=MaxNorm(3), strides=strides[idx+1], \n",
    "#                activation=None, padding=\"same\", name=f\"conv{idx+2}\")(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation(activations[idx+1])(x)\n",
    "#     x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "\n",
    "#     x = Dense(dense, kernel_constraint=MaxNorm(3), activation=\"relu\", name=\"dense1\")(x)\n",
    "#     x = Dense(dense, kernel_constraint=MaxNorm(3), activation=\"sigmoid\", name=\"dense\")(x)\n",
    "\n",
    "#     # Basemodel instance\n",
    "#     basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "#     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "#     encoded_l = basemodel(left_inputs)\n",
    "#     encoded_r = basemodel(right_inputs)\n",
    "\n",
    "#     # Add a customized layer to compute the distance between the encodings\n",
    "#     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "#     # Combine into one net\n",
    "#     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "    \n",
    "#     siamese_net.compile(loss=loss_func, optimizer=optimizer)\n",
    "    \n",
    "#     # return the model\n",
    "#     return siamese_net#|, basemodel\n",
    "\n",
    "# # # cite: Siamese Model with 2D Filters, as derived from Centeno et al. (2018)\n",
    "# # # the thesis I found\n",
    "# # def build_model_2d(input_shape, filters):\n",
    "# #     \"\"\"\n",
    "# #         Siamese CNN architecture with 3D input and 2D filters\n",
    "# #     \"\"\"\n",
    "# #     # Define the tensors for the two input images\n",
    "# #     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "# #     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "# #     # Convolutional Neural Network\n",
    "# #     inputs = Input(input_shape, name=\"input\")\n",
    "# #     x = Conv2D(filters[0], (7, 7), padding=\"same\", activation=\"tanh\", name=\"conv1\")(inputs)\n",
    "# #     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp1\")(x)\n",
    "# #     x = Conv2D(filters[1], (5, 5), padding=\"same\", activation=\"tanh\", name=\"conv2\")(x)\n",
    "# #     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp2\")(x)\n",
    "# #     x = Conv2D(filters[2], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv3\")(x)\n",
    "# #     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp3\")(x)\n",
    "# #     x = Conv2D(filters[3], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv4\")(x)\n",
    "# #     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp4\")(x)\n",
    "# #     x = Flatten(name=\"flat\")(x)\n",
    "    \n",
    "# #     # Basemodel instance\n",
    "# #     basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "# #     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "# #     encoded_l = basemodel(left_inputs)\n",
    "# #     encoded_r = basemodel(right_inputs)\n",
    "\n",
    "# #     # Add a customized layer to compute the distance between the encodings\n",
    "# #     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "# #     # Combine into one net\n",
    "# #     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "# #     # return the model\n",
    "# #     return siamese_net, basemodel\n",
    "\n",
    "# # cite: Siamese Model with 2D Filters, as derived from Centeno et al. (2018)\n",
    "# # the thesis I found\n",
    "# def create_model_2d(input_shape, filters):\n",
    "#     \"\"\"\n",
    "#         Siamese CNN architecture with 3D input and 2D filters\n",
    "#     \"\"\"\n",
    "#     # Define the tensors for the two input images\n",
    "#     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "#     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "#     # Convolutional Neural Network\n",
    "#     inputs = Input(input_shape, name=\"input\")\n",
    "#     x = Conv2D(filters[0], (7, 7), padding=\"same\", activation=\"tanh\", name=\"conv1\")(inputs)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp1\")(x)\n",
    "#     x = Conv2D(filters[1], (5, 5), padding=\"same\", activation=\"tanh\", name=\"conv2\")(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp2\")(x)\n",
    "#     x = Conv2D(filters[2], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv3\")(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp3\")(x)\n",
    "#     x = Conv2D(filters[3], (3, 3), padding=\"same\", activation=\"tanh\", name=\"conv4\")(x)\n",
    "#     x = MaxPooling2D(pool_size=(2, 2), padding=\"same\", name=\"mp4\")(x)\n",
    "#     x = Flatten(name=\"flat\")(x)\n",
    "    \n",
    "#     # Basemodel instance\n",
    "#     basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "#     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "#     encoded_l = basemodel(left_inputs)\n",
    "#     encoded_r = basemodel(right_inputs)\n",
    "\n",
    "#     # Add a customized layer to compute the distance between the encodings\n",
    "#     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "#     # Combine into one net\n",
    "#     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "#     # return the model\n",
    "#     return siamese_net, basemodel\n",
    "\n",
    "# # def build_model_1d(input_shape, filters):\n",
    "# #     \"\"\"\n",
    "# #         Model architecture\n",
    "# #     \"\"\"\n",
    "# #     # Define the tensors for the two input images\n",
    "# #     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "# #     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "# #     # Convolutional Neural Network\n",
    "# #     inputs = Input(input_shape, name=\"input\")\n",
    "# #     x = Conv1D(filters[0], 7, activation=\"elu\", padding=\"same\", name=\"conv1\")(inputs)\n",
    "# #     x = MaxPooling1D(pool_size=2, name=\"mp1\")(x)\n",
    "# #     x = Conv1D(filters[1], 5, activation=\"elu\", padding=\"same\", name=\"conv2\")(x)\n",
    "# #     x = MaxPooling1D(pool_size=2, name=\"mp2\")(x)\n",
    "# #     x = Conv1D(filters[2], 3, activation=\"elu\", padding=\"same\", name=\"conv3\")(x)\n",
    "# #     x = MaxPooling1D(pool_size=2, name=\"mp3\")(x)\n",
    "# #     x = Conv1D(filters[3], 3, activation=\"elu\", padding=\"same\", name=\"conv4\")(x)\n",
    "# #     x = MaxPooling1D(pool_size=2, name=\"mp5\")(x)\n",
    "# #     x = Flatten(name=\"flat\")(x)\n",
    "\n",
    "# #     # Generate the encodings (feature vectors) for the two images\n",
    "# #     basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "# #     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "# #     encoded_l = basemodel(left_inputs)\n",
    "# #     encoded_r = basemodel(right_inputs)\n",
    "\n",
    "# #     # Add a customized layer to compute the absolute difference between the encodings\n",
    "# #     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "# #     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "# #     # return the model\n",
    "# #     return siamese_net, basemodel\n",
    "\n",
    "\n",
    "# def create_model_1d(input_shape, filters):\n",
    "#     \"\"\"\n",
    "#         Model architecture\n",
    "#     \"\"\"\n",
    "#     # Define the tensors for the two input images\n",
    "#     left_inputs = Input(input_shape, name=\"left_inputs\")\n",
    "#     right_inputs = Input(input_shape, name=\"right_inputs\")\n",
    "\n",
    "#     # Convolutional Neural Network\n",
    "#     inputs = Input(input_shape, name=\"input\")\n",
    "#     x = Conv1D(filters[0], 7, activation=\"elu\", padding=\"same\", name=\"conv1\")(inputs)\n",
    "#     x = MaxPooling1D(pool_size=2, name=\"mp1\")(x)\n",
    "#     x = Conv1D(filters[1], 5, activation=\"elu\", padding=\"same\", name=\"conv2\")(x)\n",
    "#     x = MaxPooling1D(pool_size=2, name=\"mp2\")(x)\n",
    "#     x = Conv1D(filters[2], 3, activation=\"elu\", padding=\"same\", name=\"conv3\")(x)\n",
    "#     x = MaxPooling1D(pool_size=2, name=\"mp3\")(x)\n",
    "#     x = Conv1D(filters[3], 3, activation=\"elu\", padding=\"same\", name=\"conv4\")(x)\n",
    "#     x = MaxPooling1D(pool_size=2, name=\"mp5\")(x)\n",
    "#     x = Flatten(name=\"flat\")(x)\n",
    "\n",
    "#     # Generate the encodings (feature vectors) for the two images\n",
    "#     basemodel = Model(inputs, x, name=\"basemodel\")\n",
    "\n",
    "#     # using same instance of \"basemodel\" to share weights between left/right networks\n",
    "#     encoded_l = basemodel(left_inputs)\n",
    "#     encoded_r = basemodel(right_inputs)\n",
    "\n",
    "#     # Add a customized layer to compute the absolute difference between the encodings\n",
    "#     distance_layer = Lambda(k_euclidean_dist, name=\"distance\")([encoded_l, encoded_r])\n",
    "\n",
    "#     siamese_net = Model(inputs=[left_inputs, right_inputs], outputs=distance_layer)\n",
    "\n",
    "#     # return the model\n",
    "#     return siamese_net, basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_windows_3(dfList_exp1, dfList_exp2, window_size, step_width, user_idx_set, scaler, num_sample_points_per_exp, EMA_per_win_span=None, SMA_per_win_winsize=None, verbose=1):\n",
    "\n",
    "    # preparing data\n",
    "    exp1_df_user_set_dict, exp2_df_user_set_dict = {user_key: dfList_exp1[user_key] for user_key in user_idx_set}, {user_key: dfList_exp2[user_key] for user_key in user_idx_set}\n",
    "    print(f\"len(exp1_df_user_set_dict): {len(exp1_df_user_set_dict)}\")\n",
    "    print(f\"len(exp2_df_user_set_dict): {len(exp2_df_user_set_dict)}\")\n",
    "    \n",
    "    exp1_data_prep_dict = MakeRawXExpDict(users_exp_df_dict=exp1_df_user_set_dict, window_size=window_size, step=step_width, numSamplePoints=num_sample_points_per_exp, \n",
    "                                          scaler=None, exp_num=1, EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "    \n",
    "    exp2_data_prep_dict = MakeRawXExpDict(users_exp_df_dict=exp2_df_user_set_dict, window_size=window_size, step=step_width, numSamplePoints=num_sample_points_per_exp, \n",
    "                                          scaler=scaler, exp_num=2, EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "\n",
    "    fitted_scaler_exp2_dict = exp2_data_prep_dict[\"fitted_scaler_exp_dic\"]\n",
    "    X_exp1_dict, X_exp2_dict = exp1_data_prep_dict[\"raw_X_exp_dict\"], exp2_data_prep_dict[\"raw_X_exp_dict\"]\n",
    "\n",
    "    if verbose: print(f\"Done getting raw wondows for window_size: {window_size}\")\n",
    "    return X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict\n",
    "\n",
    "\n",
    "def get_raw_windows_2(dfList_exp1, dfList_exp2, window_size, step_width, user_set, scaler, num_sample_points_per_exp, EMA_per_win_span=None, SMA_per_win_winsize=None):\n",
    "\n",
    "    # preparing data\n",
    "    exp1_df_user_set_dict, exp2_df_user_set_dict = {user_key: dfList_exp1[user_key] for user_key in user_set}, {user_key: dfList_exp2[user_key] for user_key in user_set}\n",
    "    # dfList_exp1_user_set, dfList_exp2_user_set = [dfList_exp1[i] for i in user_set], [dfList_exp2[i] for i in user_set]\n",
    "    print(f\"len(exp1_df_user_set_dict): {len(exp1_df_user_set_dict)}\")\n",
    "    print(f\"len(exp2_df_user_set_dict): {len(exp2_df_user_set_dict)}\")\n",
    "    \n",
    "    exp1_data_prep_dict = MakeRawXExpDict(users_exp_df_dict=exp1_df_user_set_dict, window_size=window_size, step=step_width, numSamplePoints=num_sample_points_per_exp, \n",
    "                                          scaler=None, exp_num=1, EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "    \n",
    "    exp2_data_prep_dict = MakeRawXExpDict(users_exp_df_dict=exp2_df_user_set_dict, window_size=window_size, step=step_width, numSamplePoints=num_sample_points_per_exp, \n",
    "                                          scaler=scaler, exp_num=2, EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "\n",
    "    fitted_scaler_exp2_dict = exp2_data_prep_dict[\"fitted_scaler_exp_dic\"]\n",
    "    X_exp1_dict, X_exp2_dict = exp1_data_prep_dict[\"raw_X_exp_dict\"], exp2_data_prep_dict[\"raw_X_exp_dict\"]\n",
    "\n",
    "\n",
    "    #----\n",
    "    return X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict\n",
    "\n",
    "\n",
    "#     df_exps_dict_user_47 = load_data_frames([47], exp_begin_cutoff_idx, exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "#     dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "#     raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "#     raw_dfList_exp2_user_47 = dfList_exp2_user_47\n",
    "    \n",
    "def get_raw_windows_user_47(dfList_exp1_user_47, dfList_exp2_user_47, window_size, step_width, scaler, num_sample_points_per_exp, \n",
    "                                                     EMA_per_win_span=None, SMA_per_win_winsize=None):\n",
    "\n",
    "\n",
    "    exp1_df_dict_user_47, exp2_df_dict_user_47 = {47: dfList_exp1_user_47[0]}, {47: dfList_exp2_user_47[0]}\n",
    "    \n",
    "    \n",
    "    # Loading exp1 data:\n",
    "    # 47) accel_count: 22777, gyro_count: 22226\n",
    "    exp1_data_prep_dict_user_47 = MakeRawXExpDict(users_exp_df_dict=exp1_df_dict_user_47, window_size=window_size, step=step_width, \n",
    "                                                  numSamplePoints=num_sample_points_per_exp, scaler=None, exp_num=1, #+4000\n",
    "                                                  EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "    \n",
    "    # Loading exp2 data:\n",
    "    # 47) accel_count: 17718, gyro_count: 18353\n",
    "    exp2_data_prep_dict_user_47 = MakeRawXExpDict(users_exp_df_dict=exp2_df_dict_user_47, window_size=window_size, step=step_width, \n",
    "                                                  numSamplePoints=18000, scaler=scaler, exp_num=2, # has to be manually chosen\n",
    "                                                  EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "    \n",
    "    \n",
    "    fitted_scaler_exp2_dict_user_47 = exp2_data_prep_dict_user_47[\"fitted_scaler_exp_dic\"]\n",
    "    X_exp1_dict_user_47, X_exp2_dict_user_47 = exp1_data_prep_dict_user_47[\"raw_X_exp_dict\"], exp2_data_prep_dict_user_47[\"raw_X_exp_dict\"]\n",
    "    \n",
    "    # ---- adjusting the len_exp2_user_47\n",
    "    total_samples_per_user=len(X_exp1_dict_user_47[47])\n",
    "    print(f\"len(X_exp1_dict_user_47[47]): {len(X_exp1_dict_user_47[47])}\")\n",
    "    \n",
    "    len_exp2_user_47 = len(X_exp2_dict_user_47[47])\n",
    "    print(f\"len_exp2_user_47: {len_exp2_user_47}\")\n",
    "    np.random.seed(SEED+len_exp2_user_47)\n",
    "    X_exp2_dict_user_47[47] = X_exp2_dict_user_47[47] + [X_exp2_dict_user_47[47][idx] for idx in np.random.choice(len_exp2_user_47,\n",
    "                                                                                                      size=total_samples_per_user-len_exp2_user_47,\n",
    "                                                                                                      replace=False)]\n",
    "    # ----\n",
    "    \n",
    "    return X_exp1_dict_user_47, X_exp2_dict_user_47, fitted_scaler_exp2_dict_user_47\n",
    "\n",
    "\n",
    "\n",
    "def append_user_47_to_data(X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict, all_user_set, X_exp1_dict_user_47, X_exp2_dict_user_47, fitted_scaler_exp2_dict_user_47, verbose=0):\n",
    "    user_47_idx = len(all_user_set)\n",
    "    \n",
    "    if user_47_idx not in all_user_set:\n",
    "        all_user_set.append(user_47_idx)\n",
    "        \n",
    "    user_47_key = user_47_idx\n",
    "    X_exp1_dict[user_47_key] = X_exp1_dict_user_47[47]\n",
    "    X_exp2_dict[user_47_key] = X_exp2_dict_user_47[47]\n",
    "    fitted_scaler_exp2_dict[user_47_key] = fitted_scaler_exp2_dict_user_47[47]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"user_47_idx: {user_47_idx}\")\n",
    "        print(f\"np.unique(all_user_set): {np.unique(all_user_set)}\")\n",
    "\n",
    "        print(f\"X_exp1_dict.keys(): {X_exp1_dict.keys()}\")\n",
    "        print(f\"X_exp2_dict.keys(): {X_exp2_dict.keys()}\")\n",
    "        print(f\"fitted_scaler_exp2_dict.keys(): {fitted_scaler_exp2_dict.keys()}\")\n",
    "        \n",
    "    return X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used in all files, check where and how its used\n",
    "def plot_EER_distro(EER_distro_df, discription, save_file_name=None):\n",
    "    y_col = \"EER\"\n",
    "    figsize=(30, 6)\n",
    "    fontsize=11\n",
    "    n_subject = len(EER_distro_df.columns)\n",
    "    mean_col = EER_distro_df[y_col].mean()\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=180)\n",
    "    ax = sns.boxplot(x=\"owner\", y=y_col, data=EER_distro_df)#, **utils_boxplot_style)\n",
    "    ax.set_ylim((0, 1))\n",
    "    sns.swarmplot(x=\"owner\", y=y_col, data=EER_distro_df, color=\".25\")\n",
    "\n",
    "    plt.plot(\n",
    "        [-0.6, figsize[0] + 0.6],\n",
    "        [mean_col, mean_col],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1,\n",
    "        color=MAGENTA,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.text(n_subject + 0.6, mean_col, f\"mean\", fontsize=fontsize, color=MAGENTA)\n",
    "    plt.text(\n",
    "        n_subject + 0.6, mean_col - 0.04, f\"{mean_col:.3f}\", fontsize=fontsize, color=MAGENTA\n",
    "    )\n",
    "    plt.xticks(rotation=45)\n",
    "    fig.tight_layout()\n",
    "    plt.title(discription)\n",
    "    \n",
    "    plt.savefig(f'{save_file_name}.png', bbox_inches='tight')\n",
    "    print(f\"Overall mean: {mean_col:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_2(X_exp1_dic, X_exp2_dic, fitted_scaler_classifier_exp2_dic, verbose=1):\n",
    "    X_exp_dic = MakeWACAXExpDicOwner(X_exp2_dic, scaler_clip=True, scaler_type=\"MinMaxScaler\")\n",
    "    X_exp_dic = MakeWACAXExpDicUnknown(X_exp1_dic, X_exp_dic, fitted_raw_scaler_dict=fitted_scaler_classifier_exp2_dic)\n",
    "    \n",
    "    if verbose: print(\"Done extracting features\")\n",
    "    return X_exp_dic\n",
    "\n",
    "def extract_deep_features_2(X_exp1_dic, X_exp2_dic, fitted_scaler_classifier_exp2_dic, deep_feature_model, verbose=1):\n",
    "    X_exp_dic = MakeDeepXExpDicOwner(X_exp2_dic, deep_feature_model, scaler_clip=True, scaler_type=\"MinMaxScaler\")\n",
    "    X_exp_dic = MakeDeepXExpDicUnknown(X_exp1_dic, deep_feature_model, X_exp_dic, fitted_raw_scaler_dict=fitted_scaler_classifier_exp2_dic)\n",
    "    \n",
    "    if verbose: print(\"Done extracting features\")\n",
    "    return X_exp_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_EER_distro_df(X_exp_dic, n_neighbors=1, algorithm='brute', verbose=0):\n",
    "    columns = ['owner', \"adv_user_id\", \"EER\"]\n",
    "    EER_distro_df = pd.DataFrame(columns = columns)\n",
    "    for owner in X_exp_dic.keys():\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=algorithm).fit(X_exp_dic[owner][\"profile_windows\"])\n",
    "        \n",
    "        # n_neighbors=n_neighbors+1 since for the owner the first neighbor is the point itself and we drop that\n",
    "        dist_profile_windows, profile_windows_dist_indices = nbrs.kneighbors(X_exp_dic[owner][\"profile_windows\"], n_neighbors=n_neighbors+1)\n",
    "        dist_profile_windows, profile_windows_dist_indices = dist_profile_windows[:, 1:], profile_windows_dist_indices[:, 1:]\n",
    "        dist_profile_windows = dist_profile_windows.mean(axis=1).reshape(dist_profile_windows.shape[0], 1)\n",
    "        scaler = MinMaxScaler(clip=True).fit(dist_profile_windows)\n",
    "    \n",
    "\n",
    "        distFRR, FRR_indices = nbrs.kneighbors(X_exp_dic[owner][\"unknown_users_dict\"][owner], n_neighbors=n_neighbors)\n",
    "        distFRR = distFRR.mean(axis=1).reshape(distFRR.shape[0], 1)\n",
    "        for adv_user_id in X_exp_dic.keys():\n",
    "\n",
    "            if adv_user_id != owner:\n",
    "                # print(f\"adv_user_id: {adv_user_id}, owner: {owner}\")\n",
    "                distFAR, FAR_indices = nbrs.kneighbors(X_exp_dic[owner][\"unknown_users_dict\"][adv_user_id], n_neighbors=n_neighbors)\n",
    "                # print(distFAR)\n",
    "                \n",
    "                \n",
    "                # should axis be 1?\n",
    "                # can i do this with profile data?\n",
    "                distFAR = distFAR.mean(axis=1).reshape(distFAR.shape[0], 1)\n",
    "                # print(distFAR)\n",
    "\n",
    "                \n",
    "                # this seem to assume acess to unknown data, i think we should fit the scaler to profile instead with clip option ON\n",
    "                # all_dist = np.concatenate([distFAR, distFRR])\n",
    "                #print(all_dist.shape)\n",
    "                # this seem to assume acess to unkown data, i think we should fit the scaler to profile instead with clip option ON\n",
    "                # scaler = MinMaxScaler().fit(all_dist)\n",
    "                \n",
    "                scaled_distFRR, scaled_distFAR = scaler.transform(distFRR), scaler.transform(distFAR)\n",
    "\n",
    "\n",
    "                y_true = [1]*distFRR.shape[0] + [-1]*distFAR.shape[0]\n",
    "                y_pred = 1-np.concatenate([scaled_distFRR, scaled_distFAR]).ravel() \n",
    "\n",
    "                temp_eer, tres = utils_eer(y_true, y_pred, return_threshold=True)\n",
    "\n",
    "                if verbose: print(f\"EER: {temp_eer:.9f}, owner_id: {owner}, adv_user_id: {adv_user_id}, Threshold: {tres:.9f}\")\n",
    "\n",
    "                new_row = pd.DataFrame([[owner, adv_user_id, temp_eer]], columns=columns)\n",
    "                EER_distro_df = pd.concat([EER_distro_df, new_row])\n",
    "                \n",
    "                \n",
    "    \n",
    "    return EER_distro_df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_EER_different_window_sizes_optimize_num_neighbors(exp1_df_dict, exp2_df_dict, window_size_lst, train_set, overlap=.5, n_neighbors_params=[1]):\n",
    "    EER_distro_df_dict = {}\n",
    "    scaler_clip = True\n",
    "    columns = ['window_size', \"step_width\", \"scaler_clip\", \"Mean_EER\", \"best_n_neighbors\"]\n",
    "    Mean_EER_df = pd.DataFrame(columns = columns)\n",
    "    for window_size in tqdm(window_size_lst):\n",
    "        print(window_size)\n",
    "        # blockPrint()\n",
    "        step_width = int(window_size * (1-overlap))\n",
    "        X_exp1_train_dic, X_exp2_train_dic, fitted_scaler_ocsvm_exp2_train_dic = get_raw_windows_2(exp1_df_dict, exp2_df_dict, window_size, step_width, user_set=train_set)\n",
    "        X_exp_train_dic = extract_features_2(X_exp1_train_dic, X_exp2_train_dic, fitted_scaler_ocsvm_exp2_train_dic)\n",
    "\n",
    "\n",
    "        mean_eer_dict = {}\n",
    "        for n_neighbors in n_neighbors_params:\n",
    "            EER_distro_df = make_EER_distro_df(X_exp_train_dic, n_neighbors=n_neighbors)\n",
    "            EER_distro_df_dict[f\"window_size: {window_size}, step_width: {step_width}, scaler_clip: {scaler_clip}\"] = EER_distro_df\n",
    "\n",
    "            y_col = \"EER\"\n",
    "            mean_col = EER_distro_df[y_col].mean()\n",
    "            # print(EER_distro_df)\n",
    "            mean_eer_dict[n_neighbors] = mean_col\n",
    "            \n",
    "        # print(mean_eer_dict)\n",
    "        best_n_neighbors = min(mean_eer_dict, key=mean_eer_dict.get)\n",
    "        Mean_EER = mean_eer_dict[best_n_neighbors]\n",
    "\n",
    "        new_row = pd.DataFrame([[window_size, step_width, scaler_clip, Mean_EER, best_n_neighbors]], columns=columns)\n",
    "        Mean_EER_df = pd.concat([Mean_EER_df, new_row])\n",
    "        # enablePrint()\n",
    "    return Mean_EER_df\n",
    "\n",
    "\n",
    "def calculate_EER_different_window_sizes_test(exp1_df_dict, exp2_df_dict, window_size_lst, test_set, overlap=.5, best_param_dict={}):\n",
    "    EER_distro_df_dict = {}\n",
    "    scaler_clip = True\n",
    "    columns = ['window_size', \"step_width\", \"scaler_clip\", \"Mean_EER\"]\n",
    "    Mean_EER_df = pd.DataFrame(columns = columns)\n",
    "    for window_size in tqdm(window_size_lst):\n",
    "        print(window_size)\n",
    "        # blockPrint()\n",
    "        step_width = int(window_size * (1-overlap))\n",
    "        X_exp1_test_dic, X_exp2_test_dic, fitted_scaler_ocsvm_exp2_test_dic = get_raw_windows_2(exp1_df_dict, exp2_df_dict, window_size, step_width, user_set=test_set)\n",
    "        X_exp_test_dic = extract_features_2(X_exp1_test_dic, X_exp2_test_dic, fitted_scaler_ocsvm_exp2_test_dic)\n",
    "\n",
    "        \n",
    "        best_n_neighbors = int(best_param_dict[best_param_dict.window_size==window_size].best_n_neighbors)\n",
    "        EER_distro_df = make_EER_distro_df(X_exp_test_dic, n_neighbors=best_n_neighbors)\n",
    "        EER_distro_df_dict[f\"window_size: {window_size}, step_width: {step_width}, scaler_clip: {scaler_clip}\"] = EER_distro_df\n",
    "\n",
    "        y_col = \"EER\"\n",
    "        mean_col = EER_distro_df[y_col].mean()\n",
    "        Mean_EER = mean_col\n",
    "\n",
    "        new_row = pd.DataFrame([[window_size, step_width, scaler_clip, Mean_EER]], columns=columns)\n",
    "        Mean_EER_df = pd.concat([Mean_EER_df, new_row])\n",
    "        # enablePrint()\n",
    "    return Mean_EER_df, EER_distro_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_butter(df, filter_order=10, cut_off_freq=10, sampling_freq=100, plot=False, filtfilt=1):\n",
    "    N = np.array(df).shape[0]\n",
    "    # sample spacing\n",
    "    T = 1.0 / sampling_freq\n",
    "\n",
    "    sos = signal.butter(filter_order, cut_off_freq, 'lowpass', fs=sampling_freq, output='sos')\n",
    "    # sig = np.array(df)\n",
    "    sig = df.to_numpy()\n",
    "    \n",
    "    if filtfilt:\n",
    "        # this one eliminates the delay \n",
    "        y = signal.sosfiltfilt(sos, sig) #filtered time domain signal\n",
    "    else:\n",
    "        y = signal.sosfilt(sos, sig) #filtered time domain signal\n",
    "\n",
    "\n",
    "    yf = fft(y)\n",
    "    xf = fftfreq(N, T)[:N//2]\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    \n",
    "    return y\n",
    "\n",
    "def get_ffted_dfList(dfList_exp, filter_order=10, cut_off_freq=10, sampling_freq=100, filtfilt=1):\n",
    "    \n",
    "    ffted_dfList_exp = []\n",
    "    for df in dfList_exp:\n",
    "        ffted_df = df.copy()\n",
    "        ffted_df['x_a'] = apply_butter(ffted_df['x_a'], filter_order=filter_order, cut_off_freq=cut_off_freq, sampling_freq=sampling_freq, filtfilt=filtfilt).astype(\"float32\")\n",
    "        ffted_df['y_a'] = apply_butter(ffted_df['y_a'], filter_order=filter_order, cut_off_freq=cut_off_freq, sampling_freq=sampling_freq, filtfilt=filtfilt).astype(\"float32\")\n",
    "        ffted_df['z_a'] = apply_butter(ffted_df['z_a'], filter_order=filter_order, cut_off_freq=cut_off_freq, sampling_freq=sampling_freq, filtfilt=filtfilt).astype(\"float32\")\n",
    "        \n",
    "        ffted_df['x_g'] = apply_butter(ffted_df['x_g'], filter_order=filter_order, cut_off_freq=cut_off_freq, sampling_freq=sampling_freq, filtfilt=filtfilt).astype(\"float32\")\n",
    "        ffted_df['y_g'] = apply_butter(ffted_df['y_g'], filter_order=filter_order, cut_off_freq=cut_off_freq, sampling_freq=sampling_freq, filtfilt=filtfilt).astype(\"float32\")\n",
    "        ffted_df['z_g'] = apply_butter(ffted_df['z_g'], filter_order=filter_order, cut_off_freq=cut_off_freq, sampling_freq=sampling_freq, filtfilt=filtfilt).astype(\"float32\")\n",
    "        \n",
    "        ffted_dfList_exp.append(ffted_df)\n",
    "        \n",
    "    return ffted_dfList_exp\n",
    "\n",
    "def get_EMAed_dfList(dfList_exp, span=None):\n",
    "    \n",
    "    EMAed_dfList_exp = []\n",
    "    for df in dfList_exp:\n",
    "        EMAed_df = df.copy()\n",
    "        EMAed_df['x_a'] = EMAed_df['x_a'].ewm(span=span,adjust=False).mean().astype(\"float32\")\n",
    "        EMAed_df['y_a'] = EMAed_df['y_a'].ewm(span=span,adjust=False).mean().astype(\"float32\")\n",
    "        EMAed_df['z_a'] = EMAed_df['z_a'].ewm(span=span,adjust=False).mean().astype(\"float32\")\n",
    "        \n",
    "        EMAed_df['x_g'] = EMAed_df['x_g'].ewm(span=span,adjust=False).mean().astype(\"float32\")\n",
    "        EMAed_df['y_g'] = EMAed_df['y_g'].ewm(span=span,adjust=False).mean().astype(\"float32\")\n",
    "        EMAed_df['z_g'] = EMAed_df['z_g'].ewm(span=span,adjust=False).mean().astype(\"float32\")\n",
    "        \n",
    "        EMAed_dfList_exp.append(EMAed_df)\n",
    "        \n",
    "    return EMAed_dfList_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "d7a8c48d-ce60-4891-a613-8cac6bcad885",
    "_uuid": "74529ec9-2ddf-43e8-8ef3-d2bba209f31b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matchAccelGyroData(accel, gyro):\n",
    "    # Match the numbers by merge_asof to the higher length vector\n",
    "    accel_count = accel.count().time_stamp\n",
    "    gyro_count = gyro.count().time_stamp\n",
    "    names =['sensor_id', 'time_stamp', 'x', 'y', 'z']\n",
    "    if accel_count > gyro_count:\n",
    "        df = pd.merge_asof(accel, gyro, on=\"time_stamp\", direction='nearest')\n",
    "        df = df.sort_values(by=['time_stamp'])\n",
    "        df = df.dropna()\n",
    "        accel = df[[\"sensor_id_x\", \"time_stamp\", \"x_x\", \"y_x\", \"z_x\"]]\n",
    "        gyro = df[[\"sensor_id_y\", \"time_stamp\", \"x_y\", \"y_y\", \"z_y\"]]\n",
    "    else:\n",
    "        df = pd.merge_asof(gyro, accel, on=\"time_stamp\", direction='nearest')\n",
    "        df = df.sort_values(by=['time_stamp'])\n",
    "        df = df.dropna()\n",
    "        gyro = df[[\"sensor_id_x\", \"time_stamp\", \"x_x\", \"y_x\", \"z_x\"]]\n",
    "        accel = df[[\"sensor_id_y\", \"time_stamp\", \"x_y\", \"y_y\", \"z_y\"]]\n",
    "\n",
    "    accel.columns = names\n",
    "    gyro.columns = names\n",
    "    \n",
    "    return {'accel': accel, 'gyro': gyro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "d8b4d9b0-695e-4551-be65-38a6f1817241",
    "_uuid": "fb41768e-82f1-4fb4-ba68-e1dd6cfcfba3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDataStats1(i, print_accel_gyro_array_size=1, print_na_df_array_size=0, begin_idx=500, end_idx=-500):\n",
    "    \n",
    "    #load the data\n",
    "    names =['sensor_id', 'time_stamp', 'x', 'y', 'z']\n",
    "#     if i!=8:\n",
    "#         data = pd.read_csv('../input/wearable-assisted-ca/user{}_1.csv'.format(i), error_bad_lines = False, header=None, usecols = range(len(names)))\n",
    "#     else:\n",
    "    \n",
    "    data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
    "    data.columns = names\n",
    "    data = data[(data.sensor_id == '10') | (data.sensor_id =='4')]\n",
    "    data.head(10)\n",
    "\n",
    "\n",
    "    types_dict = {'sensor_id': 'int32', 'time_stamp': 'float32', 'x': 'float32', 'y': 'float32', 'z': 'float32'}\n",
    "    for col, col_type in types_dict.items():\n",
    "        data[col] = data[col].astype(col_type)\n",
    "\n",
    "    # find how many NAN values in the data\n",
    "    data.isna().sum()\n",
    "\n",
    "    # since only 7 NAN is a very small amount, drop them\n",
    "    df = data.dropna()\n",
    "\n",
    "    # get rid of begin and end noise\n",
    "    #sort df and filter\n",
    "    df = df.sort_values(by=['time_stamp'])\n",
    "    df = df[begin_idx:end_idx]\n",
    "    \n",
    "    # cleaning extreme outliers\n",
    "    df = df[(df.x < 5) & ( -5 < df.x) & (df.y < 5) & ( -5 < df.y) & (df.z < 5) & ( -5 < df.z) ]\n",
    "\n",
    "    # Extract Accelerometer values and sort\n",
    "    accel = df[df.sensor_id == 10]\n",
    "    accel = accel.sort_values(by=['time_stamp'])\n",
    "\n",
    "    # Extract gyro values and sort\n",
    "    gyro = df[df.sensor_id == 4]\n",
    "    gyro = gyro.sort_values(by=['time_stamp'])\n",
    "    \n",
    "    if print_accel_gyro_array_size:\n",
    "        print(\"{}) accel_count: {}, gyro_count: {}\".format(i, accel.count().time_stamp, gyro.count().time_stamp))\n",
    "    \n",
    "    result = matchAccelGyroData(accel, gyro)\n",
    "    accel, gyro = result['accel'], result['gyro']\n",
    "    \n",
    "#     accel['x_a'] = accel['x'].ewm(span=40,adjust=False).mean()\n",
    "#     accel['y_a'] = accel['y'].ewm(span=40,adjust=False).mean()\n",
    "#     accel['z_a'] = accel['z'].ewm(span=40,adjust=False).mean()\n",
    "\n",
    "#     gyro['x_g'] = gyro['x'].ewm(span=40,adjust=False).mean()\n",
    "#     gyro['y_g'] = gyro['y'].ewm(span=40,adjust=False).mean()\n",
    "#     gyro['z_g'] = gyro['z'].ewm(span=40,adjust=False).mean()\n",
    "    \n",
    "    accel['x_a'] = accel['x']\n",
    "    accel['y_a'] = accel['y']\n",
    "    accel['z_a'] = accel['z']\n",
    "\n",
    "    gyro['x_g'] = gyro['x']\n",
    "    gyro['y_g'] = gyro['y']\n",
    "    gyro['z_g'] = gyro['z']\n",
    "    \n",
    "    left = accel[[\"time_stamp\", \"x_a\", \"y_a\", \"z_a\"]]\n",
    "    right = gyro[[\"time_stamp\", \"x_g\", \"y_g\", \"z_g\"]].set_index('time_stamp')\n",
    "    df = left.join(right, on='time_stamp')\n",
    "\n",
    "    if print_na_df_array_size:\n",
    "        print(\"{}) na_count: {}, df count: {}\".format(i, df.isna().sum().sum(), df.count().time_stamp))\n",
    "    \n",
    "    return {\"accel\":accel.count().time_stamp, \"gyro\": gyro.count().time_stamp, \"df\": df, \"userIdx\": i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "81b39c51-3e35-4210-a3ae-618543e164df",
    "_uuid": "287b6e21-fe46-4032-8e82-2ed1837e9f44",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDataStats2(i, print_accel_gyro_array_size=1, print_na_df_array_size=0, begin_idx=500, end_idx=-500):\n",
    "    \n",
    "    #load the data\n",
    "    names =['sensor_id', 'time_stamp', 'x', 'y', 'z']\n",
    "#     if i!=8:\n",
    "#         data = pd.read_csv('../input/wearable-assisted-ca/user{}_1.csv'.format(i), error_bad_lines = False, header=None, usecols = range(len(names)))\n",
    "#     else:\n",
    "    \n",
    "    data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
    "    data.columns = names\n",
    "    data = data[(data.sensor_id == '10') | (data.sensor_id =='4')]\n",
    "    data.head(10)\n",
    "\n",
    "\n",
    "    types_dict = {'sensor_id': 'int32', 'time_stamp': 'float32', 'x': 'float32', 'y': 'float32', 'z': 'float32'}\n",
    "    for col, col_type in types_dict.items():\n",
    "        data[col] = data[col].astype(col_type)\n",
    "\n",
    "    # find how many NAN values in the data\n",
    "    data.isna().sum()\n",
    "\n",
    "    # since only 7 NAN is a very small amount, drop them\n",
    "    df = data.dropna()\n",
    "\n",
    "    # get rid of begin and end noise\n",
    "    #sort df and filter\n",
    "    df = df.sort_values(by=['time_stamp'])\n",
    "    df = df[begin_idx:end_idx]\n",
    "    \n",
    "    # cleaning extreme outliers\n",
    "    df = df[(df.x < 5) & ( -5 < df.x) & (df.y < 5) & ( -5 < df.y) & (df.z < 5) & ( -5 < df.z) ]\n",
    "\n",
    "    # Extract Accelerometer values and sort\n",
    "    accel = df[df.sensor_id == 10]\n",
    "    accel = accel.sort_values(by=['time_stamp'])\n",
    "\n",
    "    # Extract gyro values and sort\n",
    "    gyro = df[df.sensor_id == 4]\n",
    "    gyro = gyro.sort_values(by=['time_stamp'])\n",
    "    \n",
    "    if print_accel_gyro_array_size:\n",
    "        print(\"{}) accel_count: {}, gyro_count: {}\".format(i, accel.count().time_stamp, gyro.count().time_stamp))\n",
    "    \n",
    "    result = matchAccelGyroData(accel, gyro)\n",
    "    accel, gyro = result['accel'], result['gyro']\n",
    "    \n",
    "#     accel['x_a'] = accel['x'].ewm(span=40,adjust=False).mean()\n",
    "#     accel['y_a'] = accel['y'].ewm(span=40,adjust=False).mean()\n",
    "#     accel['z_a'] = accel['z'].ewm(span=40,adjust=False).mean()\n",
    "\n",
    "#     gyro['x_g'] = gyro['x'].ewm(span=40,adjust=False).mean()\n",
    "#     gyro['y_g'] = gyro['y'].ewm(span=40,adjust=False).mean()\n",
    "#     gyro['z_g'] = gyro['z'].ewm(span=40,adjust=False).mean()\n",
    "\n",
    "    accel['x_a'] = accel['x']\n",
    "    accel['y_a'] = accel['y']\n",
    "    accel['z_a'] = accel['z']\n",
    "\n",
    "    gyro['x_g'] = gyro['x']\n",
    "    gyro['y_g'] = gyro['y']\n",
    "    gyro['z_g'] = gyro['z']\n",
    "    \n",
    "    left = accel[[\"time_stamp\", \"x_a\", \"y_a\", \"z_a\"]]\n",
    "    right = gyro[[\"time_stamp\", \"x_g\", \"y_g\", \"z_g\"]].set_index('time_stamp')\n",
    "    df = left.join(right, on='time_stamp')\n",
    "\n",
    "    if print_na_df_array_size:\n",
    "        print(\"{}) na_count: {}, df count: {}\".format(i, df.isna().sum().sum(), df.count().time_stamp))\n",
    "    \n",
    "    return {\"accel\":accel.count().time_stamp, \"gyro\": gyro.count().time_stamp, \"df\": df, \"userIdx\": i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "852f6592-f958-4c9b-b8f4-73946030cfef",
    "_uuid": "52758db0-8d25-455e-91ec-b1bd76be8f7b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_rate = 10 #Hz\n",
    "# #3352843.3\n",
    "# x = np.array([318.45,302.78,316.47,334.14,333.41,326.15,320.07,318.68,314.12,308.64,\n",
    "#               300.15,304.33,318.42,322.72,329.56,339.18,338.03,343.27,351.44,353.23,\n",
    "#               352.35,352.88,353.43,352.14,351.28,352.82,353.36,353.35,353.19,353.82])\n",
    "\n",
    "# mn=np.mean(x)\n",
    "# print(f' mean = {mn:.3f} unit')\n",
    "# print(f' sum x[i]**2  : {np.sum(x**2) :.1f} unit^2 ')\n",
    "\n",
    "\n",
    "# print(f' n *sum X[k]**2   : {spectral_energy(x) :.1f} unit^2 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "4054a4f7-9d44-4c4d-865d-b30fc17e48db",
    "_uuid": "e31d6f97-ed7c-4146-bec0-ba773f823c37",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def spectral_energy(x):\n",
    "    '''\n",
    "    spectral_energy according to Parseval's theorem\n",
    "    '''\n",
    "    # should i keep using rfft or just fft\n",
    "    return (1/len(x)) * np.sum(np.abs(np.fft.rfft(x))**2)\n",
    "\n",
    "def window_entropy(x, n_bins=13):\n",
    "    \n",
    "    heights, bins = np.histogram(x, bins=n_bins)\n",
    "    heights = heights/sum(heights)\n",
    "    window_entropy=entropy(heights, base=2, axis=0)\n",
    "    \n",
    "    return window_entropy\n",
    "\n",
    "def average_absolute_difference_peaks(peaks, window_size):\n",
    "    \n",
    "    if len(peaks) == 0:\n",
    "        return window_size\n",
    "    elif len(peaks) == 1:\n",
    "        return window_size\n",
    "    \n",
    "    n = len(peaks) * (len(peaks)-1)\n",
    "    \n",
    "    return np.abs(peaks[:, None] - peaks[None, :]).ravel().sum()/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "77192541-b078-4a38-9a98-29b1868f61b2",
    "_uuid": "d0eaad53-bd24-45f3-8261-1e1f4a244ce5",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def signal_to_encoding(signal_df, freq=100):\n",
    "    dic = {}\n",
    "\n",
    "#     print(\"mean calculation started\")\n",
    "    dic['mean_x_a'] = np.mean(signal_df['x_a'])\n",
    "    dic['mean_y_a'] = np.mean(signal_df['y_a'])\n",
    "    dic['mean_z_a'] = np.mean(signal_df['z_a'])\n",
    "    dic['mean_x_g'] = np.mean(signal_df['x_g'])\n",
    "    dic['mean_y_g'] = np.mean(signal_df['y_g'])\n",
    "    dic['mean_z_g'] = np.mean(signal_df['z_g'])\n",
    "#     print(\"mean calculation ended\")\n",
    "    \n",
    "#     print(\"median calculation started\")\n",
    "    dic['median_x_a'] = np.median(signal_df['x_a'])\n",
    "    dic['median_y_a'] = np.median(signal_df['y_a'])\n",
    "    dic['median_z_a'] = np.median(signal_df['z_a'])\n",
    "    dic['median_x_g'] = np.median(signal_df['x_g'])\n",
    "    dic['median_y_g'] = np.median(signal_df['y_g'])\n",
    "    dic['median_z_g'] = np.median(signal_df['z_g'])\n",
    "#     print(\"median calculation ended\")\n",
    "    \n",
    "#     print(\"var calculation started\")\n",
    "    dic['var_x_a'] = np.var(signal_df['x_a'])\n",
    "    dic['var_y_a'] = np.var(signal_df['y_a'])\n",
    "    dic['var_z_a'] = np.var(signal_df['z_a'])\n",
    "    dic['var_x_g'] = np.var(signal_df['x_g'])\n",
    "    dic['var_y_g'] = np.var(signal_df['y_g'])\n",
    "    dic['var_z_g'] = np.var(signal_df['z_g'])\n",
    "#     print(\"var calculation ended\")\n",
    "\n",
    "#     print(\"avg absolute difference of peaks calculation started\")\n",
    "    peaks_x_a, _ = find_peaks(signal_df['x_a'], height=None)\n",
    "    peaks_y_a, _ = find_peaks(signal_df['y_a'], height=None)\n",
    "    peaks_z_a, _ = find_peaks(signal_df['z_a'], height=None)\n",
    "    peaks_x_g, _ = find_peaks(signal_df['x_g'], height=None)\n",
    "    peaks_y_g, _ = find_peaks(signal_df['y_g'], height=None)\n",
    "    peaks_z_g, _ = find_peaks(signal_df['z_g'], height=None)\n",
    "    \n",
    "    window_size=len(signal_df['x_a'])\n",
    "    dic['aadp_x_a'] = average_absolute_difference_peaks(peaks=peaks_x_a, window_size=window_size)\n",
    "    dic['aadp_y_a'] = average_absolute_difference_peaks(peaks=peaks_y_a, window_size=window_size)\n",
    "    dic['aadp_z_a'] = average_absolute_difference_peaks(peaks=peaks_z_a, window_size=window_size)\n",
    "    dic['aadp_x_g'] = average_absolute_difference_peaks(peaks=peaks_x_g, window_size=window_size)\n",
    "    dic['aadp_y_g'] = average_absolute_difference_peaks(peaks=peaks_y_g, window_size=window_size)\n",
    "    dic['aadp_z_g'] = average_absolute_difference_peaks(peaks=peaks_z_g, window_size=window_size)\n",
    "    \n",
    "#     print(type(peak_widths(peaks_x_a, signal_df['x_a'], rel_height=0.5)[0]))\n",
    "    # dic['aadp_x_a'] = np.mean(peak_widths(signal_df['x_a'], peaks_x_a, rel_height=0.5)[0])\n",
    "    # dic['aadp_y_a'] = np.mean(peak_widths(signal_df['y_a'], peaks_y_a, rel_height=0.5)[0])\n",
    "    # dic['aadp_z_a'] = np.mean(peak_widths(signal_df['z_a'], peaks_z_a, rel_height=0.5)[0])\n",
    "    # dic['aadp_x_g'] = np.mean(peak_widths(signal_df['x_g'], peaks_x_g, rel_height=0.5)[0])\n",
    "    # dic['aadp_y_g'] = np.mean(peak_widths(signal_df['y_g'], peaks_y_g, rel_height=0.5)[0])\n",
    "    # dic['aadp_z_g'] = np.mean(peak_widths(signal_df['z_g'], peaks_z_g, rel_height=0.5)[0])\n",
    "#     print(\"avg absolute difference of peaks calculation ended\")\n",
    "    \n",
    "#     print(\"range calculation started\")\n",
    "    dic['ptp_x_a'] = np.ptp(signal_df['x_a'])\n",
    "    dic['ptp_y_a'] = np.ptp(signal_df['y_a'])\n",
    "    dic['ptp_z_a'] = np.ptp(signal_df['z_a'])\n",
    "    dic['ptp_x_g'] = np.ptp(signal_df['x_g'])\n",
    "    dic['ptp_y_g'] = np.ptp(signal_df['y_g'])\n",
    "    dic['ptp_z_g'] = np.ptp(signal_df['z_g'])\n",
    "#     print(\"range calculation ended\")\n",
    "    \n",
    "#     print(\"mode calculation started\")\n",
    "    dic['mode_x_a'] = mode(signal_df['x_a'])[0][0]\n",
    "    dic['mode_y_a'] = mode(signal_df['y_a'])[0][0]\n",
    "    dic['mode_z_a'] = mode(signal_df['z_a'])[0][0]\n",
    "    dic['mode_x_g'] = mode(signal_df['x_g'])[0][0]\n",
    "    dic['mode_y_g'] = mode(signal_df['y_g'])[0][0]\n",
    "    dic['mode_z_g'] = mode(signal_df['z_g'])[0][0]\n",
    "#     print(\"mode calculation ended\")\n",
    "    \n",
    "#     print(\"cov calculation started\")\n",
    "# seem to require 2 axes according to waca pattent\n",
    "    # dic['cov_x_a'] = np.cov(signal_df['x_a']) * 1\n",
    "    # dic['cov_y_a'] = np.cov(signal_df['y_a']) * 1\n",
    "    # dic['cov_z_a'] = np.cov(signal_df['z_a']) * 1\n",
    "    # dic['cov_x_g'] = np.cov(signal_df['x_g']) * 1\n",
    "    # dic['cov_y_g'] = np.cov(signal_df['y_g']) * 1\n",
    "    # dic['cov_z_g'] = np.cov(signal_df['z_g']) * 1\n",
    "    dic['cov_xy_a'] = np.cov(signal_df['x_a'], signal_df['y_a'])[0][1]\n",
    "    dic['cov_yz_a'] = np.cov(signal_df['y_a'], signal_df['z_a'])[0][1]\n",
    "    dic['cov_xz_a'] = np.cov(signal_df['x_a'], signal_df['z_a'])[0][1]\n",
    "    dic['cov_xy_g'] = np.cov(signal_df['x_g'], signal_df['y_g'])[0][1]\n",
    "    dic['cov_yz_g'] = np.cov(signal_df['y_g'], signal_df['z_g'])[0][1]\n",
    "    dic['cov_xz_g'] = np.cov(signal_df['x_g'], signal_df['z_g'])[0][1]\n",
    "    \n",
    "#     print(\"cov calculation ended\")\n",
    "    \n",
    "#     print(\"mean absolute deviation calculation started\")\n",
    "    dic['mad_x_a'] = median_abs_deviation(signal_df['x_a'])\n",
    "    dic['mad_y_a'] = median_abs_deviation(signal_df['y_a'])\n",
    "    dic['mad_z_a'] = median_abs_deviation(signal_df['z_a'])\n",
    "    dic['mad_x_g'] = median_abs_deviation(signal_df['x_g'])\n",
    "    dic['mad_y_g'] = median_abs_deviation(signal_df['y_g'])\n",
    "    dic['mad_z_g'] = median_abs_deviation(signal_df['z_g'])\n",
    "#     print(\"mean absolute deviation calculation ended\")\n",
    "    \n",
    "#     print(\"inter-quartile range calculation started\")\n",
    "    dic['iqr_x_a'] = iqr(signal_df['x_a'])\n",
    "    dic['iqr_y_a'] = iqr(signal_df['y_a'])\n",
    "    dic['iqr_z_a'] = iqr(signal_df['z_a'])\n",
    "    dic['iqr_x_g'] = iqr(signal_df['x_g'])\n",
    "    dic['iqr_y_g'] = iqr(signal_df['y_g'])\n",
    "    dic['iqr_z_g'] = iqr(signal_df['z_g'])\n",
    "#     print(\"inter-quartile range calculation ended\")\n",
    "    \n",
    "#     print(\"correlation calculation started\")\n",
    "    dic['correlate_xy_a'] = np.corrcoef(signal_df['x_a'], signal_df['y_a'])[0][1]\n",
    "    dic['correlate_yz_a'] = np.corrcoef(signal_df['y_a'], signal_df['z_a'])[0][1]\n",
    "    dic['correlate_xz_a'] = np.corrcoef(signal_df['x_a'], signal_df['z_a'])[0][1]\n",
    "    dic['correlate_xy_g'] = np.corrcoef(signal_df['x_g'], signal_df['y_g'])[0][1]\n",
    "    dic['correlate_yz_g'] = np.corrcoef(signal_df['y_g'], signal_df['z_g'])[0][1]\n",
    "    dic['correlate_xz_g'] = np.corrcoef(signal_df['x_g'], signal_df['z_g'])[0][1]\n",
    "#     print(\"correlation calculation ended\")\n",
    "    \n",
    "#     print(\"skew calculation started\")\n",
    "    dic['skew_x_a'] = skew(signal_df['x_a'])\n",
    "    dic['skew_y_a'] = skew(signal_df['y_a'])\n",
    "    dic['skew_z_a'] = skew(signal_df['z_a'])\n",
    "    dic['skew_x_g'] = skew(signal_df['x_g'])\n",
    "    dic['skew_y_g'] = skew(signal_df['y_g'])\n",
    "    dic['skew_z_g'] = skew(signal_df['z_g'])\n",
    "#     print(\"skew calculation ended\")\n",
    "    \n",
    "#     print(\"kurtosis calculation started\")\n",
    "    dic['kurtosis_x_a'] = kurtosis(signal_df['x_a'])\n",
    "    dic['kurtosis_y_a'] = kurtosis(signal_df['y_a'])\n",
    "    dic['kurtosis_z_a'] = kurtosis(signal_df['z_a'])\n",
    "    dic['kurtosis_x_g'] = kurtosis(signal_df['x_g'])\n",
    "    dic['kurtosis_y_g'] = kurtosis(signal_df['y_g'])\n",
    "    dic['kurtosis_z_g'] = kurtosis(signal_df['z_g'])\n",
    "#     print(\"kurtosis calculation ended\")\n",
    "    \n",
    "    \n",
    "#     print(\"spectral energy calculation started\")\n",
    "    dic['spectral_energy_x_a'] = spectral_energy(signal_df['x_a'])\n",
    "    dic['spectral_energy_y_a'] = spectral_energy(signal_df['y_a'])\n",
    "    dic['spectral_energy_z_a'] = spectral_energy(signal_df['z_a'])\n",
    "    dic['spectral_energy_x_g'] = spectral_energy(signal_df['x_g'])\n",
    "    dic['spectral_energy_y_g'] = spectral_energy(signal_df['y_g'])\n",
    "    dic['spectral_energy_z_g'] = spectral_energy(signal_df['z_g'])\n",
    "#     print(\"spectral energy calculation ended\")\n",
    "\n",
    "    # print(\"entropy calculation started\")\n",
    "\n",
    "    dic['entropy_x_a'] = window_entropy(signal_df['x_a'])\n",
    "    dic['entropy_y_a'] = window_entropy(signal_df['y_a'])\n",
    "    dic['entropy_z_a'] = window_entropy(signal_df['z_a'])\n",
    "    dic['entropy_x_g'] = window_entropy(signal_df['x_g'])\n",
    "    dic['entropy_y_g'] = window_entropy(signal_df['y_g'])\n",
    "    dic['entropy_z_g'] = window_entropy(signal_df['z_g'])\n",
    "    \n",
    "    # print(\"entropy calculation started\")\n",
    "\n",
    "\n",
    "    # print(\"spectral entropy calculation started\")\n",
    "    # method = 'fft'\n",
    "    # normalize = False\n",
    "    # sf=freq\n",
    "#     print(signal_df['x_a'])\n",
    "#     print(signal_df['x_a'].shape)\n",
    "    # axis = -1\n",
    "    # dic['spectral_entropy_x_a'] = ant.spectral_entropy(signal_df['x_a'], sf=sf, method=method, normalize=normalize, axis=axis)\n",
    "    # dic['spectral_entropy_y_a'] = ant.spectral_entropy(signal_df['y_a'], sf=sf, method=method, normalize=normalize, axis=axis)\n",
    "    # dic['spectral_entropy_z_a'] = ant.spectral_entropy(signal_df['z_a'], sf=sf, method=method, normalize=normalize, axis=axis)\n",
    "    # dic['spectral_entropy_x_g'] = ant.spectral_entropy(signal_df['x_g'], sf=sf, method=method, normalize=normalize, axis=axis)\n",
    "    # dic['spectral_entropy_y_g'] = ant.spectral_entropy(signal_df['y_g'], sf=sf, method=method, normalize=normalize, axis=axis)\n",
    "    # dic['spectral_entropy_z_g'] = ant.spectral_entropy(signal_df['z_g'], sf=sf, method=method, normalize=normalize, axis=axis)\n",
    "    \n",
    "    # print(dic['spectral_entropy_x_a'],\n",
    "    #           dic['spectral_entropy_y_a'],\n",
    "    #           dic['spectral_entropy_z_a'],\n",
    "    #           dic['spectral_entropy_x_g'],\n",
    "    #           dic['spectral_entropy_y_g'],\n",
    "    #           dic['spectral_entropy_z_g'])\n",
    "    # print(\"spectral entropy calculation ended\")\n",
    "\n",
    "\n",
    "#     print(\"entropy calculation started\")\n",
    "    \n",
    "#     cols = signal_df[[\"x_a\", \"y_a\", \"z_a\", \"x_g\", \"y_g\", \"z_g\"]]\n",
    "#     cols = normalize(cols, norm='l2', axis = 0)\n",
    "#     print(cols.sum(axis = 0))\n",
    "#     cols = StandardScaler().fit_transform(cols)\n",
    "#     p = cols/cols.sum(axis=0)\n",
    "#     print(p.sum(axis=0))\n",
    "#     print(p.shape)\n",
    "#     print(cols.sum(axis=0))\n",
    "#     entropy = entr(p).sum(axis=0)\n",
    "#     print(entropy.shape)\n",
    "#     dic['entropy_x_a'] = entropy[0]\n",
    "#     dic['entropy_y_a'] = entropy[1]\n",
    "#     dic['entropy_z_a'] = entropy[2]\n",
    "#     dic['entropy_x_g'] = entropy[3]\n",
    "#     dic['entropy_y_g'] = entropy[4]\n",
    "#     dic['entropy_z_g'] = entropy[5]\n",
    "#     print(\"entropy calculation ended\")\n",
    "    \n",
    "    vector = [dic['mean_x_a'], \n",
    "              dic['mean_y_a'],\n",
    "              dic['mean_z_a'],\n",
    "              dic['mean_x_g'],\n",
    "              dic['mean_y_g'],\n",
    "              dic['mean_z_g'],\n",
    "              \n",
    "              dic['median_x_a'],\n",
    "              dic['median_y_a'],\n",
    "              dic['median_z_a'],\n",
    "              dic['median_x_g'],\n",
    "              dic['median_y_g'],\n",
    "              dic['median_z_g'],\n",
    "              \n",
    "              dic['var_x_a'],\n",
    "              dic['var_y_a'],\n",
    "              dic['var_z_a'],\n",
    "              dic['var_x_g'],\n",
    "              dic['var_y_g'],\n",
    "              dic['var_z_g'],\n",
    "              \n",
    "              dic['aadp_x_a'],\n",
    "              dic['aadp_y_a'],\n",
    "              dic['aadp_z_a'],\n",
    "              dic['aadp_x_g'],\n",
    "              dic['aadp_y_g'],\n",
    "              dic['aadp_z_g'],\n",
    "              \n",
    "              dic['ptp_x_a'],\n",
    "              dic['ptp_y_a'],\n",
    "              dic['ptp_z_a'],\n",
    "              dic['ptp_x_g'],\n",
    "              dic['ptp_y_g'],\n",
    "              dic['ptp_z_g'],\n",
    "              \n",
    "              dic['mode_x_a'],\n",
    "              dic['mode_y_a'],\n",
    "              dic['mode_z_a'],\n",
    "              dic['mode_x_g'],\n",
    "              dic['mode_y_g'],\n",
    "              dic['mode_z_g'],\n",
    "              \n",
    "              dic['cov_xy_a'],\n",
    "              dic['cov_yz_a'],\n",
    "              dic['cov_xz_a'],\n",
    "              dic['cov_xy_g'],\n",
    "              dic['cov_yz_g'],\n",
    "              dic['cov_xz_g'],\n",
    "              \n",
    "              dic['mad_x_a'],\n",
    "              dic['mad_y_a'],\n",
    "              dic['mad_z_a'],\n",
    "              dic['mad_x_g'],\n",
    "              dic['mad_y_g'],\n",
    "              dic['mad_z_g'],\n",
    "              \n",
    "              dic['iqr_x_a'],\n",
    "              dic['iqr_y_a'],\n",
    "              dic['iqr_z_a'],\n",
    "              dic['iqr_x_g'],\n",
    "              dic['iqr_y_g'],\n",
    "              dic['iqr_z_g'],\n",
    "              \n",
    "              dic['correlate_xy_a'],\n",
    "              dic['correlate_yz_a'],\n",
    "              dic['correlate_xz_a'],\n",
    "              dic['correlate_xy_g'],\n",
    "              dic['correlate_yz_g'],\n",
    "              dic['correlate_xz_g'],\n",
    "              \n",
    "              dic['skew_x_a'],\n",
    "              dic['skew_y_a'],\n",
    "              dic['skew_z_a'],\n",
    "              dic['skew_x_g'],\n",
    "              dic['skew_y_g'],\n",
    "              dic['skew_z_g'],\n",
    "              \n",
    "              dic['kurtosis_x_a'],\n",
    "              dic['kurtosis_y_a'],\n",
    "              dic['kurtosis_z_a'],\n",
    "              dic['kurtosis_x_g'],\n",
    "              dic['kurtosis_y_g'],\n",
    "              dic['kurtosis_z_g'],\n",
    "              \n",
    "              dic['spectral_energy_x_a'],\n",
    "              dic['spectral_energy_y_a'],\n",
    "              dic['spectral_energy_z_a'],\n",
    "              dic['spectral_energy_x_g'],\n",
    "              dic['spectral_energy_y_g'],\n",
    "              dic['spectral_energy_z_g'],\n",
    "              \n",
    "              dic['entropy_x_a'],\n",
    "              dic['entropy_y_a'],\n",
    "              dic['entropy_z_a'],\n",
    "              dic['entropy_x_g'],\n",
    "              dic['entropy_y_g'],\n",
    "              dic['entropy_z_g']\n",
    "              \n",
    "#               dic['spectral_entropy_x_a'],\n",
    "#               dic['spectral_entropy_y_a'],\n",
    "#               dic['spectral_entropy_z_a'],\n",
    "#               dic['spectral_entropy_x_g'],\n",
    "#               dic['spectral_entropy_y_g'],\n",
    "#               dic['spectral_entropy_z_g']\n",
    "             ]\n",
    "    \n",
    "    \n",
    "    return dic, np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "405969a0-3049-4c9a-a3b1-fd5f15905170",
    "_uuid": "86a331fc-b630-4411-ab56-0375c262e607",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rolling_window(a, window, stride):\n",
    "    shape = a.shape[:-1] + (int((a.shape[-1] - window)/stride + 1), window)\n",
    "    strides = (stride*a.strides[-1],) + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "\n",
    "def getIndices(sampleSize=1000, step=1000, numSamplePoints=24000):\n",
    "    indices = np.arange(0, numSamplePoints, 1)\n",
    "    indices = rolling_window(indices, sampleSize, step)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "\n",
    "def getEncodingArray(df, windows):\n",
    "    a = []\n",
    "    for i in range(len(windows)):\n",
    "        # replaced loc with iloc per documentation\n",
    "#         a.append(signal_to_encoding(df.loc[windows[i], :])[1])\n",
    "        a.append(signal_to_encoding(df.iloc[windows[i], :])[1])\n",
    "        \n",
    "    return np.array(a)\n",
    "\n",
    "\n",
    "def deleteDiagonal(array):\n",
    "    depth = array.shape[-1]\n",
    "    m = array.shape[1]\n",
    "    strided = np.lib.stride_tricks.as_strided\n",
    "    s0,s1,s2 = array.strides\n",
    "    return strided(array.ravel()[depth:], shape=(m-1, m, depth), strides=(s0+s1,s1, s2)).reshape(m, m-1, depth)\n",
    "\n",
    "\n",
    "def MinMaxTransformation(windows_features_array):\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(windows_features_array)\n",
    "#     scaled_array = scaler.transform(windows_features_array)\n",
    "    \n",
    "    return scaler\n",
    "    \n",
    "    \n",
    "def getDistFRR1(dfList, window_size = 1000, step = 1000, numSamplePoints= 18000):\n",
    "    \n",
    "    windows = getIndices(sampleSize=window_size, step=step, numSamplePoints= numSamplePoints)\n",
    "\n",
    "    norm_dist = []\n",
    "    norm_distro_dict = {}\n",
    "    counter = 1\n",
    "    for m in range(len(dfList)):\n",
    "        \n",
    "        \n",
    "        encoding_array = getEncodingArray(dfList[m], windows)\n",
    "#         print(dfList[m].columns)\n",
    "#         print(encoding_array.shape)\n",
    "\n",
    "#         print(np.sum(encoding_array, axis = 1))\n",
    "\n",
    "        # Doesn't make sense to normalize this here\n",
    "#         scaler = MinMaxTransformation(encoding_array)\n",
    "#         encoding_array = scaler.transform(encoding_array)\n",
    "#         print(encoding_array.shape)\n",
    "        # Should this be put between braces before indexing??? No\n",
    "        encoding_array = encoding_array / np.linalg.norm(encoding_array, axis = 1)[:, None]\n",
    "#         print(np.linalg.norm(encoding_array, axis=1)[:, None].shape)\n",
    "#         print(encoding_array.shape)\n",
    "#         print(np.linalg.norm(encoding_array, axis=1))\n",
    "        # Is dist_array distance calculation done correctly??? It seems it does not square\n",
    "        # It appears so dist = numpy.linalg.norm(a-b)\n",
    "        # https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy\n",
    "        dist_array = (encoding_array[None, :] - encoding_array[:, None])\n",
    "\n",
    "        dist_array = deleteDiagonal(dist_array)\n",
    "\n",
    "        dist_array = np.linalg.norm(dist_array, axis = 2)\n",
    "        \n",
    "        norm_dist.append(dist_array)\n",
    "        \n",
    "        # for err dist\n",
    "        norm_distro_dict[m] = np.array(dist_array).ravel()\n",
    "        \n",
    "        counter += 1\n",
    "    \n",
    "    return {\"dist_array\": np.array(norm_dist).ravel(), \"dist_dict\": norm_distro_dict}\n",
    "\n",
    "\n",
    "def getDistFRRFinal(dfList_exp1, dfList_exp2, window_size = 1000, step = 1000, numSamplePoints= 18000):\n",
    "    '''\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "    if len(dfList_exp1) != len(dfList_exp2): \n",
    "        raise Exception(\"dfLists are not of the same size.\")\n",
    "        \n",
    "    windows = getIndices(sampleSize=window_size, step=step, numSamplePoints= numSamplePoints)\n",
    "\n",
    "    norm_dist = []\n",
    "    norm_distro_dict = {}\n",
    "    voting_dist_dict = {}\n",
    "    counter = 1\n",
    "    for m in range(len(dfList_exp1)):\n",
    "        \n",
    "        \n",
    "        encoding_array_exp1 = getEncodingArray(dfList_exp1[m], windows)\n",
    "        encoding_array_exp2 = getEncodingArray(dfList_exp2[m], windows)\n",
    "        \n",
    "        # Doesn't make sense to normalize this here\n",
    "        scaler = MinMaxTransformation(encoding_array_exp1)\n",
    "        encoding_array_exp1 = scaler.transform(encoding_array_exp1)\n",
    "#         encoding_array_exp2 = scaler.transform(encoding_array_exp2)\n",
    "        \n",
    "#         # approach 2: Not intuitive as you dont have access to all of user2s stream of 4 min, only windowsizes at a time\n",
    "#         scaler = MinMaxTransformation(encoding_array_exp2)\n",
    "\n",
    "        encoding_array_exp2 = scaler.transform(encoding_array_exp2)\n",
    "        \n",
    "#         print(dfList[m].columns)\n",
    "#         print(encoding_array.shape)\n",
    "\n",
    "#         print(np.sum(encoding_array, axis = 1))\n",
    "#         print((encoding_array_exp1 / np.linalg.norm(encoding_array_exp1, axis = 1)[:, None]).shape)\n",
    "#         print(encoding_array_exp1.shape)\n",
    "#         print(encoding_array.shape)\n",
    "        # Should this be put between braces before indexing??? No\n",
    "        encoding_array_exp1 = encoding_array_exp1 / np.linalg.norm(encoding_array_exp1, axis = 1)[:, None]\n",
    "        encoding_array_exp2 = encoding_array_exp2 / np.linalg.norm(encoding_array_exp2, axis = 1)[:, None]\n",
    "#         print(np.linalg.norm(encoding_array, axis=1)[:, None].shape)\n",
    "#         print(encoding_array.shape)\n",
    "#         print(np.linalg.norm(encoding_array, axis=1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # Is dist_array distance calculation done correctly??? It seems it does not square\n",
    "        # It appears so dist = numpy.linalg.norm(a-b)\n",
    "        # https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy\n",
    "        dist_array = (encoding_array_exp1[None, :] - encoding_array_exp2[:, None])\n",
    "#         print(dist_array.shape)\n",
    "        \n",
    "        dist_array = np.linalg.norm(dist_array, axis = 2)\n",
    "        \n",
    "        norm_dist.append(dist_array)\n",
    "        \n",
    "#         print(dist_array.shape)\n",
    "        # for err dist\n",
    "        norm_distro_dict[m] = np.array(dist_array).ravel()\n",
    "        \n",
    "        # for voting dist\n",
    "        voting_dist_dict[m] = dist_array[None, :]\n",
    "        \n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "#         print(voting_dist_dict[0].shape)\n",
    "    \n",
    "    return {\"dist_array\": np.array(norm_dist).ravel(), \"dist_dict\": norm_distro_dict, \"voting_dist_dict\": voting_dist_dict}\n",
    "\n",
    "\n",
    "def getDistFARFinal(dfList, window_size = 1000, step = 1000, numSamplePoints= 18000):\n",
    "    \n",
    "    windows = getIndices(sampleSize=window_size, step=step, numSamplePoints= numSamplePoints)\n",
    "\n",
    "    norm_dist = []\n",
    "    norm_distro_dict = {}\n",
    "    voting_dist_dict = {}\n",
    "    counter = 1\n",
    "    \n",
    "    encoding_array_dic = {}\n",
    "    for i in range(len(dfList)):\n",
    "        encoding_array_dic[i] = getEncodingArray(dfList[i], windows)\n",
    "        # Should this be put between braces before indexing???\n",
    "#         # Should this be done here? Not here this only makes the result vector small and should be at the end\n",
    "#         encoding_array_dic[i] = encoding_array_dic[i] / np.linalg.norm(encoding_array_dic[i], axis = 1)[:, None]\n",
    "        \n",
    "    for m in range(len(dfList)):\n",
    "        \n",
    "        cum_distro_array = []\n",
    "        encoding_array_m = encoding_array_dic[m]\n",
    "        \n",
    "        # Should I scale the new vector with the transform of the user profile?\n",
    "        scaler = MinMaxTransformation(encoding_array_m)\n",
    "        encoding_array_m = scaler.transform(encoding_array_m)\n",
    "        \n",
    "        encoding_array_m = encoding_array_m / np.linalg.norm(encoding_array_m, axis = 1)[:, None]\n",
    "        \n",
    "        for k in range(len(dfList)):\n",
    "            \n",
    "            if m != k:\n",
    "                \n",
    "                encoding_array_k = encoding_array_dic[k]\n",
    "                \n",
    "#                 # approach 2\n",
    "#                 scaler = MinMaxTransformation(encoding_array_k)\n",
    "                \n",
    "                # Scale array_k with array_m transform\n",
    "                encoding_array_k = scaler.transform(encoding_array_k)\n",
    "                \n",
    "                encoding_array_k = encoding_array_k / np.linalg.norm(encoding_array_k, axis = 1)[:, None]\n",
    "                \n",
    "                # Is dist_array distance calculation done correctly??? It seems it does not square. No, resolved\n",
    "                # It appears so dist = numpy.linalg.norm(a-b)\n",
    "                # https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy\n",
    "                dist_array = (encoding_array_m[None, :] - encoding_array_k[:, None])\n",
    "                \n",
    "                # print and check dimensions\n",
    "                \n",
    "                dist_array = np.linalg.norm(dist_array, axis = 2)\n",
    "\n",
    "                norm_dist.append(dist_array)\n",
    "                \n",
    "                # for err dist\n",
    "                cum_distro_array.append(dist_array)\n",
    "                \n",
    "\n",
    "        \n",
    "        norm_distro_dict[m] = np.array(cum_distro_array).ravel()\n",
    "        \n",
    "        # for voting dist\n",
    "        voting_dist_dict[m] = np.array(cum_distro_array)\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "#         print(voting_dist_dict[0].shape)\n",
    "    \n",
    "    return {\"dist_array\": np.array(norm_dist).ravel(), \"dist_dict\": norm_distro_dict, \"voting_dist_dict\": voting_dist_dict}\n",
    "\n",
    "\n",
    "def decision_confidence(dist_array, dist_threshold):\n",
    "    '''\n",
    "    input: dist_array: (N, # unknown_user windows, # genuine_user windows)\n",
    "    output: (N, de/auth decision percentage)\n",
    "    '''\n",
    "    vals = np.where(dist_array < dist_threshold, 1, 0)\n",
    "    windows_decision_confidence = np.mean(vals, axis = 2)\n",
    "\n",
    "    return windows_decision_confidence\n",
    "\n",
    "\n",
    "def decision_module(dist_array, dist_threshold, acceptance_threshold):\n",
    "    '''\n",
    "    input: dist_array: (N, # unknown_user windows, # genuine_user windows)\n",
    "    output: (N, de/auth boolean decision)\n",
    "    '''\n",
    "    \n",
    "    windows_decision_confidence = decision_confidence(dist_array, dist_threshold = dist_threshold)\n",
    "    windows_final_decision = np.where(windows_decision_confidence >= acceptance_threshold, 1, 0)\n",
    "    \n",
    "    return windows_final_decision\n",
    "    \n",
    "def FRR_vote_based(dist_array, dist_threshold = None, acceptance_threshold = None):\n",
    "    '''\n",
    "    input: dist_array: (N, # unknown_user windows, # genuine_user windows)\n",
    "    output: vote based FRR\n",
    "    '''\n",
    "    \n",
    "    #good note but not applicable here np.where((a==0)|(a==1), a^1, a)\n",
    "\n",
    "    windows_final_decision = decision_module(dist_array, dist_threshold, acceptance_threshold)\n",
    "    vals = windows_final_decision^1\n",
    "    \n",
    "    return np.mean(vals)\n",
    "\n",
    "\n",
    "def FAR_vote_based(dist_array, dist_threshold = None, acceptance_threshold = None):\n",
    "    '''\n",
    "    input: dist_array: (M*N, # unknown_user windows, # genuine_user windows)\n",
    "    output: vote based FAR\n",
    "    '''\n",
    "    windows_final_decision = decision_module(dist_array, dist_threshold, acceptance_threshold)\n",
    "    vals = windows_final_decision\n",
    "    \n",
    "    return np.mean(vals)\n",
    "\n",
    "\n",
    "def FRR(dist, threshold):\n",
    "    \n",
    "    vals = np.where(dist < threshold, 0, 1)\n",
    "    \n",
    "    return np.mean(vals)\n",
    "\n",
    "\n",
    "def FAR(dist, threshold):\n",
    "    \n",
    "    vals = np.where(dist < threshold, 1, 0)\n",
    "    \n",
    "    return np.mean(vals)\n",
    "\n",
    "\n",
    "def DistroFRR(dist_dict, threshold):\n",
    "    \n",
    "    distro = []\n",
    "    for i in range(len(dist_dict)):\n",
    "        vals = np.where(dist_dict[i] < threshold, 0, 1)\n",
    "        distro.append(sum(vals))\n",
    "        \n",
    "    return distro\n",
    "\n",
    "\n",
    "def DistroFAR(dist_dict, threshold):\n",
    "    \n",
    "    distro = []\n",
    "    for i in range(len(dist_dict)):\n",
    "        vals = np.where(dist_dict[i] < threshold, 1, 0)\n",
    "        distro.append(sum(vals))\n",
    "        \n",
    "    return distro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "22910d65-b4d1-4e4a-84d3-a25c50e209d4",
    "_uuid": "84284a3d-28ba-4306-b7a6-5f75fc60d6ef",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# np.where(np.array([.5, 1]) < .6, 1, 0)\n",
    "# a = np.array(range(5, 11))\n",
    "# b = np.array(range(2, 6))\n",
    "\n",
    "# res = a[None, :] - b[:, None]\n",
    "# # print(res)\n",
    "# a = res % 2\n",
    "# print(a)\n",
    "# a^1\n",
    "# b = np.array([a, a-9])\n",
    "# print(b)\n",
    "# np.concatenate(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "f65d8fe7-ec15-4c54-bf10-60be43248f67",
    "_uuid": "44582f38-8dfe-4b42-bb60-0b9fb69c7d03",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# d = {}\n",
    "# d[0] = np.array([[[1,2]]])\n",
    "# d[1] = np.array([[[2,3]]])\n",
    "# a = np.array(list(d.values()))\n",
    "# print(a.shape)\n",
    "# a = np.concatenate(a)\n",
    "# print(a.shape)\n",
    "# a = np.concatenate(a)\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "0fb342ee-f860-4038-8e5d-e5f15e05a0b7",
    "_uuid": "789c9f3b-abe9-4d26-b9ce-1e2ef446819c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getEER(distFRR, distFAR, thresholdList=None):\n",
    "    \n",
    "    if thresholdList is None:\n",
    "        thresholdList = np.arange(0, 3, 0.001)\n",
    "    \n",
    "    farList = []\n",
    "    frrList = []\n",
    "    \n",
    "    eer = []\n",
    "    for t in thresholdList:\n",
    "        far = FAR(distFAR, threshold = t)\n",
    "        frr = FRR(distFRR, threshold = t)\n",
    "        farList.append(far)\n",
    "        frrList.append(frr)\n",
    "        eer.append(abs(far-frr))\n",
    "        \n",
    "    eer = np.array(eer)\n",
    "    eer[eer==0] = 99999\n",
    "    print(farList[np.argmin(eer)])\n",
    "    print(frrList[np.argmin(eer)])\n",
    "\n",
    "#     print(\"EER: {}\".format((frrList[np.argmin(eer)] + farList[np.argmin(eer)])/2))\n",
    "    return {\"EER\": (frrList[np.argmin(eer)] + farList[np.argmin(eer)])/2, \"farList\": farList, \"frrList\": frrList, \"EER_threshold\": thresholdList[np.argmin(eer)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "f960835d-39be-43fa-8133-1ad0afd703b3",
    "_uuid": "0fe92d18-0abf-49c8-bee3-45757483d7f0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getEERVoteBased(dist_array_FRR, dist_array_FAR, thresholdList=None):\n",
    "    \n",
    "    if thresholdList is None:\n",
    "        thresholdList = np.arange(0, 3, 0.001)\n",
    "    \n",
    "    farList = []\n",
    "    frrList = []\n",
    "    \n",
    "    eer = []\n",
    "    acceptance_threshold = .6\n",
    "    \n",
    "    for t in thresholdList:\n",
    "        far = FAR_vote_based(dist_array_FAR, dist_threshold = t, acceptance_threshold = acceptance_threshold)\n",
    "        frr = FRR_vote_based(dist_array_FRR, dist_threshold = t, acceptance_threshold = acceptance_threshold)\n",
    "        farList.append(far)\n",
    "        frrList.append(frr)\n",
    "        eer.append(abs(far-frr))\n",
    "        \n",
    "    eer = np.array(eer)\n",
    "    eer[eer==0] = 99999\n",
    "    print(farList[np.argmin(eer)])\n",
    "    print(frrList[np.argmin(eer)])\n",
    "\n",
    "#     print(\"EER: {}\".format((frrList[np.argmin(eer)] + farList[np.argmin(eer)])/2))\n",
    "    return {\"EER\": (frrList[np.argmin(eer)] + farList[np.argmin(eer)])/2, \"farList\": farList, \"frrList\": frrList, \"EER_threshold\": thresholdList[np.argmin(eer)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "c3d38626-be37-4339-9588-cbb6f973631f",
    "_uuid": "61a4c410-4d16-4105-b115-77a477c1a094",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getEERWindowsDict(dfList_exp1, start_window_size=250, end_window_size=3000, increment_step=250, numSamplePoints=22001, isEqualSampleSize = False, fixedSampleStep=3000, thresholdList=None, dfList_exp2=None):\n",
    "    \n",
    "    window_EER_dict = {}\n",
    "    window_EER_threshold_dict = {}\n",
    "    window_farList_dict = {}\n",
    "    window_frrList_dict = {}\n",
    "    window_farDistro_dict = {}\n",
    "    window_frrDistro_dict = {}\n",
    "    \n",
    "    lst = np.arange(start_window_size, end_window_size + 1, increment_step)\n",
    "    \n",
    "    for w in lst:\n",
    "        if isEqualSampleSize:\n",
    "            sampleStep = fixedSampleStep\n",
    "        else:\n",
    "            sampleStep = w\n",
    "        \n",
    "        if dfList_exp2 is None:\n",
    "            print(\"dfList_exp2 is None\")\n",
    "            distFRRDATA = getDistFRR1(dfList_exp1, window_size = w, step = sampleStep, numSamplePoints= numSamplePoints)\n",
    "        else:\n",
    "            print(\"dfList_exp2 is Not None\")\n",
    "            distFRRDATA = getDistFRRFinal(dfList_exp1, dfList_exp2, window_size = w, step = sampleStep, numSamplePoints= numSamplePoints)\n",
    "            \n",
    "        distFARDATA = getDistFARFinal(dfList_exp1, window_size = w, step = sampleStep, numSamplePoints= numSamplePoints)\n",
    "        \n",
    "#         print('--- start of voting based')\n",
    "#         print(distFRRDATA[\"voting_dist_dict\"][0].shape)\n",
    "#         print(distFARDATA[\"voting_dist_dict\"][0].shape)\n",
    "#         print(np.concatenate(list(distFRRDATA[\"voting_dist_dict\"].values())).shape)\n",
    "#         print(np.concatenate(list(distFARDATA[\"voting_dist_dict\"].values())).shape)\n",
    "        \n",
    "        \n",
    "#         voting_dist_FRR = np.concatenate(list(distFRRDATA[\"voting_dist_dict\"].values()))\n",
    "#         voting_dist_FAR = np.concatenate(list(distFARDATA[\"voting_dist_dict\"].values()))\n",
    "#         voting_EER_data = getEERVoteBased(voting_dist_FRR, voting_dist_FAR, thresholdList=thresholdList)\n",
    "        \n",
    "#         print(\"numParticipants: {}, windowSize: {}, isEqualSampleSize: {}, EER: {}\".format(len(dfList_exp1), w, isEqualSampleSize, voting_EER_data[\"EER\"]))\n",
    "        \n",
    "#         print(\"--- end of voting based\")\n",
    "        \n",
    "        distFRR = distFRRDATA[\"dist_array\"]\n",
    "        distFAR = distFARDATA[\"dist_array\"]\n",
    "        EER_data = getEER(distFRR, distFAR, thresholdList=thresholdList)\n",
    "        \n",
    "        window_EER_dict[w] = EER_data[\"EER\"]\n",
    "        window_EER_threshold_dict[w] = EER_data[\"EER_threshold\"]\n",
    "        window_farList_dict[w] = EER_data[\"farList\"]\n",
    "        window_frrList_dict[w] = EER_data[\"frrList\"]\n",
    "        window_farDistro_dict[w] = distFARDATA[\"dist_dict\"]\n",
    "        window_frrDistro_dict[w] = distFRRDATA[\"dist_dict\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"numParticipants: {}, windowSize: {}, isEqualSampleSize: {}, EER: {}\".format(len(dfList_exp1), w, isEqualSampleSize, window_EER_dict[w]))\n",
    "        \n",
    "    return { \"window_EER_dict\": window_EER_dict, \"window_EER_threshold_dict\": window_EER_threshold_dict , \"window_farList_dict\": window_farList_dict, \"window_frrList_dict\": window_frrList_dict, \"window_farDistro_dict\": window_farDistro_dict, \"window_frrDistro_dict\": window_frrDistro_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "c8a14ba8-0697-40f9-86cc-89421fb6a520",
    "_uuid": "a53170a9-9345-41a5-a95d-29ef35396180",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getErrFixedThreshold(distFRR, distFAR, threshold):\n",
    "        \n",
    "    far = FAR(distFAR, threshold = threshold)\n",
    "    frr = FRR(distFRR, threshold = threshold)\n",
    "    \n",
    "\n",
    "    return {\"FAR\": far, \"FRR\": frr, \"threshold\": threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1d0c061-c833-4051-88cd-b03cf6665d3a",
    "_uuid": "e709a3ce-9cac-4c5b-908a-5a9f0eaaf4ac",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# To be done\n",
    "def getErrFixedThresholdWindowsDict(dfList, start_window_size=250, end_window_size=3000, increment_step=250, numSamplePoints=22001, isEqualSampleSize = False, fixedSampleStep=3000):\n",
    "    \n",
    "    window_EER_dict = {}\n",
    "    window_EER_threshold_dict = {}\n",
    "    window_farDistro_dict = {}\n",
    "    window_frrDistro_dict = {}\n",
    "    \n",
    "    lst = np.arange(start_window_size, end_window_size + 1, increment_step)\n",
    "    \n",
    "    for w in lst:\n",
    "        if isEqualSampleSize:\n",
    "            sampleStep = fixedSampleStep\n",
    "        else:\n",
    "            sampleStep = w\n",
    "            \n",
    "        distFRRDATA = getDistFRRFinal(dfList, window_size = w, step = sampleStep, numSamplePoints= numSamplePoints)\n",
    "        distFARDATA = getDistFARFinal(dfList, window_size = w, step = sampleStep, numSamplePoints= numSamplePoints)\n",
    "        \n",
    "        distFRR = distFRRDATA[\"dist_array\"]\n",
    "        distFAR = distFARDATA[\"dist_array\"]\n",
    "        EER_data = getEER(distFRR, distFAR)\n",
    "\n",
    "        \n",
    "        window_EER_dict[w] = EER_data[\"EER\"]\n",
    "        window_EER_threshold_dict[w] = EER_data[\"EER_threshold\"]\n",
    "        window_farDistro_dict[w] = distFARDATA[\"dist_dict\"]\n",
    "        window_frrDistro_dict[w] = distFRRDATA[\"dist_dict\"]\n",
    "        \n",
    "        print(\"numParticipants: {}, windowSize: {}, isEqualSampleSize: {}, EER: {}\".format(len(dfList), w, isEqualSampleSize, window_EER_dict[w]))\n",
    "        \n",
    "    return { \"window_EER_dict\": window_EER_dict, \"window_EER_threshold_dict\": window_EER_threshold_dict , \"window_farList_dict\": window_farList_dict, \"window_frrList_dict\": window_frrList_dict, \"window_farDistro_dict\": window_farDistro_dict, \"window_frrDistro_dict\": window_frrDistro_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_cell_guid": "ae9b2983-8cec-4f02-922a-d7b8c0e36822",
    "_uuid": "6afdfc26-d91b-4d3a-8604-528d56426826",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cite the thesis paper i found\n",
    "def utils_ppp(P):\n",
    "    \"\"\"Pretty print parameters of an experiment.\"\"\"\n",
    "    df = pd.DataFrame([asdict(P)])\n",
    "    df = df.T\n",
    "    df.columns = [\"Value\"]\n",
    "    \n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "ef3ded46-6c27-44c6-8792-7c30cf5c0af3",
    "_uuid": "449eb557-cbf1-416c-b0ec-ddcc4f104119",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source: https://github.com/dynobo/ContinAuth/blob/master/notebooks/utils.ipynb\n",
    "def utils_eer(y_true, y_pred, return_threshold=False):\n",
    "    \"\"\"Calculate the Equal Error Rate.\n",
    "\n",
    "    Based on https://stackoverflow.com/a/49555212, https://yangcha.github.io/EER-ROC/\n",
    "    and https://scikit-learn.org/stable/modules/model_evaluation.html#implementing-your-own-scoring-object\n",
    "\n",
    "    Arguments:\n",
    "        y_true {np.array}  -- Actual labels\n",
    "        y_pred {np.array}  -- Predicted labels or probability\n",
    "        \n",
    "    Returns:\n",
    "        float              -- Equal Error Rate        \n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)  # Calculated threshold, not needed for score\n",
    "    if return_threshold:\n",
    "        return eer, thresh\n",
    "    else:\n",
    "        return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "8e188ef2-60ad-44e7-8c98-77d859e152ec",
    "_uuid": "c755e89d-f293-4da4-a418-85186fcfbe17",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n"
     ]
    }
   ],
   "source": [
    "if TEST_MODE:\n",
    "    temp_eer, tres = utils_eer(\n",
    "        [-1, -1, -1, 1, 1, 1], [0, 0.9, 0.1, 0.74, 0.8, .6], return_threshold=True\n",
    "    )\n",
    "    print(f\"EER: {temp_eer:.3f}, Threshold: {tres:.3f} <-- Arbitrary case\")\n",
    "\n",
    "    temp_eer, tres = utils_eer(\n",
    "        [-1, -1, -1, 1, 1], [0.1, 0.2, 0.3, 1, 0.9], return_threshold=True\n",
    "    )\n",
    "    print(f\"EER: {temp_eer:.3f}, Threshold: {tres:.3f} <-- Best case\")\n",
    "\n",
    "    temp_eer, tres = utils_eer(\n",
    "        [1, 1, 1, -1, -1], [0.1, 0.2, 0.3, 1, 0.9], return_threshold=True\n",
    "    )\n",
    "    print(f\"EER: {temp_eer:.3f}, Threshold: {tres:.3f} <-- Worse case\")\n",
    "    \n",
    "#     new case does it make sense? I don't think so\n",
    "    temp_eer, tres = utils_eer(\n",
    "        [1, 1, 1, -1, -1], [-1, 1, -1, -1, -1], return_threshold=True\n",
    "    )\n",
    "    print(f\"EER: {temp_eer:.3f}, Threshold: {tres:.3f} <-- Worse case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([0.74, 0.8, .6]) > .6).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([0, 0.9, 0.1])<.6).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "304dbab1-3cf2-4166-a521-178f5a3f55fe",
    "_uuid": "1f3464be-7fe5-4d37-bf84-e2f63e99b345",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "utils_eer_scorer = make_scorer(utils_eer, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0092c407-5812-43bd-a3a9-f78bfadff3b7",
    "_uuid": "35621051-b220-428d-b505-85ef106f8ce6"
   },
   "source": [
    "# Split Dataset for Valid/Test  \n",
    "In two splits: one used during hyperparameter optimization, and one used during testing.\n",
    "\n",
    "The split is done along the subjects: All sessions of a single subject will either be in the validation split or in the testing split, never in both.\n",
    "\n",
    "They did a 30 60 split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "92d8caee-6b8e-45c7-b272-010046daec00",
    "_uuid": "0c7969f6-43b9-4d95-9253-76d5d040d30a"
   },
   "source": [
    "# Reshaping Raw Features.\n",
    "We have our own function of windows for this. Do this for both training and testing.\n",
    "\n",
    "# Extracting time and frequency based features.\n",
    "Again, we have a function for this. Do this for both training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11bbc563-4576-4588-a73c-44936653c13b",
    "_uuid": "b9984fbd-a13f-4d5d-ad57-8b0c41aafe1d"
   },
   "source": [
    "# Hyperparameter Optimization \n",
    "\n",
    "I do not find any reaqsonable explaination how to use a cross-validation as we are talking about anomaly detection.\n",
    "\n",
    "I am using the experiment 1 data as train, and experiment 2 data as validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d09c240f-d000-4840-880c-260436115209",
    "_uuid": "aca85e4e-ed2f-4c54-bf0f-2f938ac45a07"
   },
   "source": [
    "# Using SVM in a real-world Scenario with multiple genuine users and intruders\n",
    "Source: https://datascience.stackexchange.com/questions/23623/what-is-the-best-way-to-classify-data-not-belonging-to-set-of-classes\n",
    "\n",
    "Stage 1: \n",
    "    Use one-class SVM to assign those images that do not belong to the set of predefined classes as the 9-th class.\n",
    "\n",
    "Stage 2:\n",
    "    For those images that passes through your filter, let the multi-class SVM assign them to one of the 8 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79b10ce2-42b2-4156-a1df-633bf52c05e6",
    "_uuid": "bf0780fa-46ed-4d13-90ee-3640fe7cc4aa"
   },
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "72d60ae5-be59-4add-868d-4ba29d842b9f",
    "_uuid": "126e56a7-4e62-4f9d-adf7-89308283fccd",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data_frames(user_ids, begin_idx, end_idx, min_len):\n",
    "    '''\n",
    "    input: \n",
    "        user_ids: list of approved user_ids after exploratory data analysis\n",
    "        begin_idx: the index before which data is discarded for user i\n",
    "        end_idx: the index after which data is discarded for user i\n",
    "        min_len: the minimum length that a dataframe has to be after cutting of both endings\n",
    "        \n",
    "    output:\n",
    "        {dfList_exp1, dfList_exp2}: return dfList for exp1 and exp2 of the selected user_ids\n",
    "    '''\n",
    "    print(\"Loading exp1 data:\")\n",
    "    dfList_exp1 = []\n",
    "    for i in user_ids:\n",
    "        dic = getDataStats1(i, begin_idx=begin_idx, end_idx=end_idx)\n",
    "\n",
    "        if(dic['accel']<min_len):\n",
    "            raise Exception(\"The Stream is shorter than {}\".format(min_len))\n",
    "\n",
    "        dfList_exp1 = dfList_exp1 + [dic['df'].reset_index(drop=True)]\n",
    "\n",
    "\n",
    "    print(\"Loading exp2 data:\")\n",
    "    dfList_exp2 = []\n",
    "    for i in user_ids:\n",
    "        dic = getDataStats2(i, begin_idx=begin_idx, end_idx=end_idx)\n",
    "\n",
    "        if(dic['accel']<min_len):\n",
    "            raise Exception(\"The Stream is shorter than {}\".format(min_len))\n",
    "\n",
    "        dfList_exp2 = dfList_exp2 + [dic['df'].reset_index(drop=True)]\n",
    "    #     dfList = dfList + [dic['df']]\n",
    "    \n",
    "    return {\"dfList_exp1\": dfList_exp1, \"dfList_exp2\": dfList_exp2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "adb215c0-9999-4e8f-a64f-1ce0bef9da1a",
    "_uuid": "696cb33f-f151-4447-8e46-7018e15cc5be",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def MakeXExpDic(dfList_exp1, dfList_exp2, window_size = 1000, step = 1000, numSamplePoints= 18000):\n",
    "    '''\n",
    "    return \n",
    "    X_exp1_dic\n",
    "    X_exp2_dic\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "    if len(dfList_exp1) != len(dfList_exp2): \n",
    "        raise Exception(\"dfLists are not of the same size.\")\n",
    "    \n",
    "    windows = getIndices(sampleSize=window_size, step=step, numSamplePoints= numSamplePoints)\n",
    "\n",
    "    X_exp1_dic = {}\n",
    "    X_exp2_dic = {}\n",
    "    for i in range(len(dfList_exp1)):\n",
    "        \n",
    "        \n",
    "        encoding_array_exp1 = getEncodingArray(dfList_exp1[i], windows)\n",
    "        encoding_array_exp2 = getEncodingArray(dfList_exp2[i], windows)\n",
    "        \n",
    "        X_exp1_dic[i] = encoding_array_exp1\n",
    "        X_exp2_dic[i] = encoding_array_exp2\n",
    "        \n",
    "    return {\"X_exp1_dic\": X_exp1_dic, \"X_exp2_dic\": X_exp2_dic}\n",
    "\n",
    "\n",
    "def OneClassSVMSets(k, X_exp1_dic, X_exp2_dic, cv=5):\n",
    "    '''\n",
    "    return the required sets for an OCSVM trained on the user with key. \n",
    "    X_train: X data from X_exp1_dic[k]\n",
    "    X_test_regular: X data from X_exp2_dic[k]\n",
    "    X_test_anomalous: X data from X_exp2_dic[!k]\n",
    "    '''\n",
    "    \n",
    "    if k not in  X_exp1_dic:\n",
    "        raise Exception(\"invalid key for dic\")\n",
    "        \n",
    "    \n",
    "    X_pos = X_exp1_dic[k]\n",
    "#     X_neg = np.concatenate([X_exp1_dic[key] for key in X_exp1_dic.keys() if key != k], axis=0)\n",
    "    X_test_regular = X_exp2_dic[k]\n",
    "    X_test_anomalous = np.concatenate([X_exp2_dic[key] for key in X_exp2_dic.keys() if key != k], axis=0)\n",
    "    \n",
    "    \n",
    "#     n, m = len(Xpos), len(Xneg)\n",
    "    np.random.shuffle(X_neg)\n",
    "    print((X_neg.shape[0], X_pos.shape[0]))\n",
    "    X_neg = X_neg[np.random.choice(X_neg.shape[0], size=X_pos.shape[0], replace=False), :]\n",
    "    print(X_pos.shape, X_neg.shape)\n",
    "    # Creating (train, test) tuples of indices for k-folds cross-validation\n",
    "    # We split the positive class (normal data) as we only want the positive examples in the training set.\n",
    "    \n",
    "    train_splits = KFold(n_splits=cv, shuffle=True).split(X_pos)\n",
    "    anomalous_splits = KFold(n_splits=cv, shuffle=True).split(X_neg)\n",
    "\n",
    "#     print(len(train_splits), len(anomalous_splits))\n",
    "    # Negative examples (abnormal data) are added to the test set (see https://stackoverflow.com/a/58459322/3673842)\n",
    "    y_train = np.concatenate([np.repeat(1.0, len(X_pos)), np.repeat(-1.0, len(X_neg))])\n",
    "    X_train = np.concatenate([X_pos, X_neg], axis=0)\n",
    "    \n",
    "    # https://github.com/steppi/adeft/blob/anomaly_detection/adeft/modeling/find_anomalies.py#L170\n",
    "    cv_splits = ((train, np.concatenate((test, anom_test + X_pos.shape[0]), axis = 0))\n",
    "                  for (train, test), (_, anom_test)\n",
    "                  in zip(train_splits, anomalous_splits))\n",
    "    \n",
    "    return {\"X_train\": X_train, \"y_train\": y_train, \"X_test_regular\": X_test_regular, \"X_test_anomalous\": X_test_anomalous, \"cv_splits\": cv_splits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For CNN file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRawDataChunks(df, windows, scaler=None, user_key=None, exp_num=None, EMA_per_win_span=None, SMA_per_win_winsize=None, verbose=0):\n",
    "    a = []\n",
    "    df = df.drop(columns=[\"time_stamp\"]).copy()\n",
    "    # df_array = df.to_numpy()\n",
    "    \n",
    "    if EMA_per_win_span!=None and SMA_per_win_winsize!=None:\n",
    "        raise Exception(\"cannot apply both EMA_per_win_span and SMA_per_win_winsize at the same time.\")\n",
    "        \n",
    "    if scaler!=None:\n",
    "        if verbose: print(f\"user_key: {user_key}, exp_num: {exp_num}, scaler: {scaler}\")\n",
    "        # print(df_array.shape)\n",
    "        scaler = get_new_scaler_dict[scaler]\n",
    "        # scaler = scaler().fit(df_array)\n",
    "        scaler = scaler().fit(df)\n",
    "        # df_array = scaler.transform(df_array)\n",
    "        df_array = scaler.transform(df)\n",
    "        # scaled_df = pd.DataFrame(data=df_array, columns = df.columns, dtype=df_array.dtype)\n",
    "        scaled_df = pd.DataFrame(data=df_array, columns = df.columns, dtype=df_array.dtype)\n",
    "        df = scaled_df\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(windows)):\n",
    "        # a.append(df_array[windows[i], :]) #CNN\n",
    "        \n",
    "        df_window=df.iloc[windows[i], :]\n",
    "        \n",
    "        # exponential moving average\n",
    "        if EMA_per_win_span!=None:\n",
    "\n",
    "            df_window['x_a'] = df_window['x_a'].ewm(span=EMA_per_win_span,adjust=False).mean()\n",
    "            df_window['y_a'] = df_window['y_a'].ewm(span=EMA_per_win_span,adjust=False).mean()\n",
    "            df_window['z_a'] = df_window['z_a'].ewm(span=EMA_per_win_span,adjust=False).mean()\n",
    "\n",
    "            df_window['x_g'] = df_window['x_g'].ewm(span=EMA_per_win_span,adjust=False).mean()\n",
    "            df_window['y_g'] = df_window['y_g'].ewm(span=EMA_per_win_span,adjust=False).mean()\n",
    "            df_window['z_g'] = df_window['z_g'].ewm(span=EMA_per_win_span,adjust=False).mean()\n",
    "\n",
    "        # simple moving average\n",
    "        elif SMA_per_win_winsize!=None:\n",
    "            \n",
    "            df_window['x_a'] = df_window['x_a'].rolling(window=SMA_per_win_winsize, min_periods=0).mean()\n",
    "            df_window['y_a'] = df_window['y_a'].rolling(window=SMA_per_win_winsize, min_periods=0).mean()\n",
    "            df_window['z_a'] = df_window['z_a'].rolling(window=SMA_per_win_winsize, min_periods=0).mean()\n",
    "\n",
    "            df_window['x_g'] = df_window['x_g'].rolling(window=SMA_per_win_winsize, min_periods=0).mean()\n",
    "            df_window['y_g'] = df_window['y_g'].rolling(window=SMA_per_win_winsize, min_periods=0).mean()\n",
    "            df_window['z_g'] = df_window['z_g'].rolling(window=SMA_per_win_winsize, min_periods=0).mean()\n",
    "\n",
    "    \n",
    "        a.append(df_window) #waca\n",
    "    \n",
    "#     print(len(a))\n",
    "#     print(len(a))\n",
    "#     return np.array([a])\n",
    "    # return np.array(a), scaler #CNN\n",
    "    \n",
    "    return a, scaler #waca\n",
    "\n",
    "\n",
    "def MakeRawXExpDict(users_exp_df_dict, window_size, step, numSamplePoints, scaler, exp_num, EMA_per_win_span=None, SMA_per_win_winsize=None):\n",
    "    '''\n",
    "    return \n",
    "    X_exp_dic\n",
    "    '''\n",
    "    \n",
    "    windows = getIndices(sampleSize=window_size, step=step, numSamplePoints=numSamplePoints)\n",
    "\n",
    "    X_exp_dic = {}\n",
    "    fitted_scaler_exp_dic={}\n",
    "    for user_key in users_exp_df_dict:\n",
    "        \n",
    "        encoding_array_exp, fitted_scaler_exp = getRawDataChunks(users_exp_df_dict[user_key], windows, scaler=scaler, user_key=user_key, exp_num=exp_num,\n",
    "                                                                  EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "        \n",
    "        X_exp_dic[user_key] = encoding_array_exp\n",
    "        \n",
    "        fitted_scaler_exp_dic[user_key]=fitted_scaler_exp\n",
    "        \n",
    "    return {\"raw_X_exp_dict\": X_exp_dic, \"fitted_scaler_exp_dic\": fitted_scaler_exp_dic}\n",
    "\n",
    "\n",
    "\n",
    "def MakeRawXExpDict_old(users_exp1_df_dict, users_exp2_df_dict, window_size = 1000, step = 1000, numSamplePoints= 18000, scale_exp1=False, scale_exp2=True, \n",
    "                   scaler=\"MinMaxScaler\", EMA_per_win_span=None, SMA_per_win_winsize=None):\n",
    "    '''\n",
    "    return \n",
    "    X_exp1_dic\n",
    "    X_exp2_dic\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "\n",
    "    if len(users_exp1_df_dict) != len(users_exp2_df_dict): \n",
    "        raise Exception(\"dfLists are not of the same size.\")\n",
    "    \n",
    "    windows = getIndices(sampleSize=window_size, step=step, numSamplePoints= numSamplePoints)\n",
    "\n",
    "    X_exp1_dic = {}\n",
    "    X_exp2_dic = {}\n",
    "    fitted_scaler_exp1_dic={}\n",
    "    fitted_scaler_exp2_dic={}\n",
    "    \n",
    "    exp1_scaler = scaler\n",
    "    exp2_scaler = scaler\n",
    "    \n",
    "    if scale_exp1!=True:\n",
    "        exp1_scaler=None\n",
    "    if scale_exp2!=True:\n",
    "        exp2_scaler=None\n",
    "    for user_key in users_exp1_df_dict:\n",
    "        \n",
    "        \n",
    "        encoding_array_exp1, fitted_scaler_exp1 = getRawDataChunks(users_exp1_df_dict[user_key], windows, scaler=exp1_scaler, user_key=user_key, exp_num=1,\n",
    "                                                                  EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "        encoding_array_exp2, fitted_scaler_exp2 = getRawDataChunks(users_exp2_df_dict[user_key], windows, scaler=exp2_scaler, user_key=user_key, exp_num=2,\n",
    "                                                                  EMA_per_win_span=EMA_per_win_span, SMA_per_win_winsize=SMA_per_win_winsize)\n",
    "        \n",
    "        X_exp1_dic[user_key] = encoding_array_exp1\n",
    "        X_exp2_dic[user_key] = encoding_array_exp2\n",
    "        \n",
    "        fitted_scaler_exp1_dic[user_key]=fitted_scaler_exp1\n",
    "        fitted_scaler_exp2_dic[user_key]=fitted_scaler_exp2\n",
    "        \n",
    "    return {\"Raw_X_exp1_dic\": X_exp1_dic, \"Raw_X_exp2_dic\": X_exp2_dic, \"fitted_scaler_exp1_dic\": fitted_scaler_exp1_dic, \"fitted_scaler_exp2_dic\": fitted_scaler_exp2_dic}\n",
    "\n",
    "\n",
    "\n",
    "# def MakeDeepXExpDic(dfList_exp, deep_feature_model, fitted_scaler_dic=None):\n",
    "#     '''\n",
    "#     ???\n",
    "#     return \n",
    "#     X_exp_dic\n",
    "#     dfLists are of the same size.\n",
    "#     '''\n",
    "\n",
    "#     X_exp_dic = {}\n",
    "#     for k in dfList_exp.keys():\n",
    "#         if fitted_scaler_dic:\n",
    "#             print(f\"scaling exp1 samples of user: {k}\")\n",
    "#             X_exp_dic[k] = deep_feature_model.predict(transform_user_windows(dfList_exp[k], fitted_scaler_dic[k]))\n",
    "#         else:\n",
    "#             print(f\"not scaling exp2 samples of user: {k}\")\n",
    "#             X_exp_dic[k] = deep_feature_model.predict(dfList_exp[k])\n",
    "        \n",
    "        \n",
    "#     return X_exp_dic\n",
    "\n",
    "\n",
    "\n",
    "def MakeXExpDicOwner(X_exp_reg_df_dict, scaler_clip=True, scaler_type=\"MinMaxScaler\", feature_extractor=None, feature_extractor_transformer=None, verbose=0):\n",
    "    '''k\n",
    "    ???\n",
    "    return \n",
    "    X_exp_dic\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "\n",
    "    X_exp_dic = {}\n",
    "    for owner in X_exp_reg_df_dict.keys():\n",
    "\n",
    "        if verbose: print(f\"raw exp2 samples of owner: {owner} are scaled already so we {feature_extractor.__name__}\")\n",
    "        \n",
    "        X_exp_dic[owner] = {\"profile_windows\": feature_extractor(X_exp_reg_df_dict[owner]), \"unknown_users_dict\": {}, \"fitted_feature_scaler\": None}\n",
    "        \n",
    "#         #------- DEBUG--------\n",
    "#         if owner == 2: \n",
    "#             X_exp_dic['debug']= X_exp_dic[owner], X_exp_reg_df_dict[owner]\n",
    "#             return X_exp_dic\n",
    "        \n",
    "#         #------- DEBUG--------\n",
    "        \n",
    "        # do minmax scaling here\n",
    "        if verbose: print(f\"fit_transform {feature_extractor.__name__} features using scaler of type: {scaler_type}, for profile_windows of owner: {owner}\")\n",
    "        if verbose: print(f\"owner: {owner}, exp_num: {2}, scaler: {scaler_type}, scaler_clip: {scaler_clip}\")\n",
    "        \n",
    "        scaler = get_new_scaler_dict[scaler_type]\n",
    "        scaler = scaler(clip=scaler_clip).fit(X_exp_dic[owner][\"profile_windows\"])\n",
    "        X_exp_dic[owner][\"fitted_feature_scaler\"] = scaler\n",
    "\n",
    "        X_exp_dic[owner][\"profile_windows\"] = feature_extractor_transformer(X_exp_dic[owner][\"profile_windows\"], X_exp_dic[owner][\"fitted_feature_scaler\"])\n",
    "        \n",
    "        \n",
    "    return X_exp_dic\n",
    "    \n",
    "\n",
    "# def extract_features_and_scale_for_parallel_call(X_exp_unknown_df_dict, X_exp_dic, fitted_raw_scaler_dict, feature_extractor, feature_extractor_transformer, unknown_user, owner):\n",
    "#     X_exp_dic[owner][\"unknown_users_dict\"][unknown_user] = feature_extractor(transform_user_windows(X_exp_unknown_df_dict[unknown_user], fitted_raw_scaler_dict[owner]))\n",
    "#     fitted_feature_scaler = X_exp_dic[owner][\"fitted_feature_scaler\"]\n",
    "#     X_exp_dic[owner][\"unknown_users_dict\"][unknown_user] = feature_extractor_transformer(X_exp_dic[owner][\"unknown_users_dict\"][unknown_user], fitted_feature_scaler)\n",
    "#     # return X_exp_dic[owner][\"unknown_users_dict\"][unknown_user]\n",
    "\n",
    "def extract_features_and_scale_for_parallel_call_owner(X_exp_unknown_df_dict, X_exp_dic, fitted_raw_scaler_dict, feature_extractor, feature_extractor_transformer, owner, verbose=0):\n",
    "    if fitted_raw_scaler_dict:\n",
    "        \n",
    "        if verbose: print(f\"scaling exp1 unknown windows for when user: {owner}, is owner\")\n",
    "        \n",
    "        for unknown_user in X_exp_unknown_df_dict.keys():\n",
    "            X_exp_dic[owner][\"unknown_users_dict\"][unknown_user] = feature_extractor(transform_user_windows(X_exp_unknown_df_dict[unknown_user], fitted_raw_scaler_dict[owner]))\n",
    "            fitted_feature_scaler = X_exp_dic[owner][\"fitted_feature_scaler\"]\n",
    "            X_exp_dic[owner][\"unknown_users_dict\"][unknown_user] = feature_extractor_transformer(X_exp_dic[owner][\"unknown_users_dict\"][unknown_user], fitted_feature_scaler)\n",
    "            \n",
    "        if verbose: print(f\"done scaling exp1 unknown windows for when user: {owner}, is owner\")\n",
    "        \n",
    "    return {\"owner\": owner, \"unknown_users_dict\": X_exp_dic[owner][\"unknown_users_dict\"]}\n",
    "    \n",
    "def MakeXExpDicUnknown(X_exp_unknown_df_dict, X_exp_dic, fitted_raw_scaler_dict, feature_extractor=None, feature_extractor_transformer=None):\n",
    "    '''k\n",
    "    ???\n",
    "    return \n",
    "    X_exp_dic\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "\n",
    "    for owner in X_exp_unknown_df_dict.keys():\n",
    "        if fitted_raw_scaler_dict:\n",
    "            print(f\"scaling exp1 unknown windows for when user: {owner}, is owner\")\n",
    "            for unknown_user in X_exp_unknown_df_dict.keys():\n",
    "                X_exp_dic[owner][\"unknown_users_dict\"][unknown_user] = feature_extractor(transform_user_windows(X_exp_unknown_df_dict[unknown_user], fitted_raw_scaler_dict[owner]))\n",
    "                fitted_feature_scaler = X_exp_dic[owner][\"fitted_feature_scaler\"]\n",
    "                X_exp_dic[owner][\"unknown_users_dict\"][unknown_user] = feature_extractor_transformer(X_exp_dic[owner][\"unknown_users_dict\"][unknown_user], fitted_feature_scaler)\n",
    "            \n",
    "            \n",
    "            \n",
    "#     results = Parallel(n_jobs=-1, verbose=100)(delayed(extract_features_and_scale_for_parallel_call_owner)(X_exp_unknown_df_dict, X_exp_dic, fitted_raw_scaler_dict, \n",
    "#                                                                                                                      feature_extractor, feature_extractor_transformer,\n",
    "#                                                                                                                      owner) for owner in X_exp_unknown_df_dict.keys())\n",
    "    \n",
    "#     for item in results:\n",
    "#         owner = item[\"owner\"]\n",
    "#         unknown_users_dict = item[\"unknown_users_dict\"]\n",
    "#         X_exp_dic[owner][\"unknown_users_dict\"] = unknown_users_dict\n",
    "    \n",
    "    return X_exp_dic\n",
    "\n",
    "    # df_reports = Parallel(n_jobs=-1)(delayed(evaluate_owner_IF_train_valid)(owner_idx, X_exp_train_dic, SEED, run, param_dist, CORES=1) for owner_idx in range(len(train_set)))\n",
    "    # # df_reports = Parallel(n_jobs=-1)(delayed(evaluate_owner_IF_train_valid)(owner_idx, X_exp_train_dic, SEED, run, param_dist, CORES=1) for owner_idx in range(len([0])))\n",
    "    # df_results = pd.concat([df_results] + df_reports, sort=False)\n",
    "\n",
    "def MakeDeepXExpDicOwner(X_exp_reg_df_dict, deep_feature_model, scaler_clip=True, scaler_type=\"MinMaxScaler\"):\n",
    "    '''k\n",
    "    ???\n",
    "    return \n",
    "    X_exp_dic\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "    \n",
    "    extract_deep_features = lambda X_exp : ExtractDeepFeatures(X_exp, deep_feature_model)\n",
    "    return MakeXExpDicOwner(X_exp_reg_df_dict, scaler_clip=scaler_clip, scaler_type=\"MinMaxScaler\",\n",
    "                                feature_extractor=extract_deep_features, feature_extractor_transformer=transform_user_WACA_windows)\n",
    "    \n",
    "\n",
    "    \n",
    "def MakeDeepXExpDicUnknown(X_exp_unknown_df_dict, deep_feature_model, X_exp_dic, fitted_raw_scaler_dict):\n",
    "    '''k\n",
    "    ???\n",
    "    return \n",
    "    X_exp_dic\n",
    "    dfLists are of the same size.\n",
    "    '''  \n",
    "    \n",
    "    extract_deep_features = lambda X_exp : ExtractDeepFeatures(X_exp, deep_feature_model)\n",
    "    return MakeXExpDicUnknown(X_exp_unknown_df_dict, X_exp_dic, fitted_raw_scaler_dict, \n",
    "                                  feature_extractor=extract_deep_features, feature_extractor_transformer=transform_user_WACA_windows)\n",
    "\n",
    "\n",
    "\n",
    "def MakeWACAXExpDicOwner(X_exp_reg_df_dict, scaler_clip=True, scaler_type=\"MinMaxScaler\"):\n",
    "    '''k\n",
    "    ???\n",
    "    return \n",
    "    X_exp_dic\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "        \n",
    "    return MakeXExpDicOwner(X_exp_reg_df_dict, scaler_clip=scaler_clip, scaler_type=\"MinMaxScaler\",\n",
    "                                feature_extractor=ExtractWACAFeatures, feature_extractor_transformer=transform_user_WACA_windows)\n",
    "    \n",
    "\n",
    "    \n",
    "def MakeWACAXExpDicUnknown(X_exp_unknown_df_dict, X_exp_dic, fitted_raw_scaler_dict):\n",
    "    '''k\n",
    "    ???\n",
    "    return \n",
    "    X_exp_dic\n",
    "    dfLists are of the same size.\n",
    "    '''  \n",
    "        \n",
    "    return MakeXExpDicUnknown(X_exp_unknown_df_dict, X_exp_dic, fitted_raw_scaler_dict, \n",
    "                                  feature_extractor=ExtractWACAFeatures, feature_extractor_transformer=transform_user_WACA_windows)\n",
    "\n",
    "\n",
    "def ExtractDeepFeatures(X_exp, deep_feature_model):\n",
    "        \n",
    "    # if X_exp and deep_feature_model:\n",
    "    return deep_feature_model.predict(np.array(X_exp))\n",
    "    \n",
    "#     elif deep_feature_model:\n",
    "#         return lambda X_exp : deep_feature_model.predict(np.array(X_exp))\n",
    "    \n",
    "#     else:\n",
    "#         raise Exception(f'arguments: (X_exp, deep_feature_model) are ({X_exp}, {deep_feature_model})')\n",
    "\n",
    "\n",
    "\n",
    "def ExtractWACAFeatures(X_exp):\n",
    "    a = []\n",
    "    \n",
    "    for window in X_exp:\n",
    "        a.append(signal_to_encoding(window)[1])\n",
    "        \n",
    "    return np.array(a)\n",
    "\n",
    "\n",
    "# def MakeScaledXExpDic(df_exp_dict, fitted_scaler_dic):\n",
    "#     '''\n",
    "#     ???\n",
    "#     return \n",
    "#     X_exp_dic\n",
    "#     dfLists are of the same size.\n",
    "#     '''\n",
    "\n",
    "#     X_exp_dic = {}\n",
    "#     for k in df_exp_dict.keys():\n",
    "#         print(f\"scaling exp1 samples of user: {k}\")\n",
    "#         X_exp_dic[k] = transform_user_windows(df_exp_dict[k], fitted_scaler_dic[k])\n",
    "        \n",
    "        \n",
    "#     return X_exp_dic\n",
    "\n",
    "\n",
    "def scale_feature_windows(df_exp_dict, fitted_scaler_dic=None, scaler_type=None, scaler_clip=False):\n",
    "    '''\n",
    "    ???\n",
    "    return \n",
    "    X_exp_dic\n",
    "    dfLists are of the same size.\n",
    "    '''\n",
    "    if fitted_scaler_dic == None:\n",
    "        fitted_scaler_dic={}\n",
    "        \n",
    "    X_exp_dic = {}\n",
    "    for k in df_exp_dict.keys():\n",
    "        if k in fitted_scaler_dic:\n",
    "            print(f\"transform exp1 samples of user: {k}\")\n",
    "        else:\n",
    "            print(f\"fit_transform exp2 samples of user: {k}\")\n",
    "            print(f\"user_idx: {k}, exp_num: {2}, scaler: {scaler_type}, scaler_clip: {scaler_clip}\")\n",
    "            scaler = get_new_scaler_dict[scaler_type]\n",
    "            scaler = scaler(clip=scaler_clip).fit(df_exp_dict[k])\n",
    "            fitted_scaler_dic[k] = scaler\n",
    "\n",
    "#         print(df_exp_dict[k].shape)\n",
    "        X_exp_dic[k] = transform_user_WACA_windows(df_exp_dict[k], fitted_scaler_dic[k])\n",
    "        \n",
    "        \n",
    "    return {\"X_exp_dic\": X_exp_dic, \"fitted_scaler_dic\": fitted_scaler_dic}\n",
    "\n",
    "\n",
    "def transform_user_WACA_windows(X_exp, fitted_scaler):\n",
    "    \n",
    "    \n",
    "    transformed_X_exp = []\n",
    "    \n",
    "#     print(X_exp[0].shape)\n",
    "    for window in X_exp:\n",
    "        if len(window.shape) == 1:\n",
    "            window = window.reshape(1, -1)\n",
    "        scaled_array = fitted_scaler.transform(window)\n",
    "        transformed_X_exp.append(scaled_array.reshape(-1))\n",
    "        \n",
    "    return np.array(transformed_X_exp)\n",
    "\n",
    "\n",
    "def transform_user_windows(X_exp, fitted_scaler):\n",
    "    \n",
    "    \n",
    "    transformed_X_exp = []\n",
    "    \n",
    "#     print(X_exp[0].shape)\n",
    "    for window in X_exp:\n",
    "        scaled_array = fitted_scaler.transform(window)\n",
    "        scaled_window_df = pd.DataFrame(data=scaled_array, columns = window.columns, dtype=scaled_array.dtype)\n",
    "        transformed_X_exp.append(scaled_window_df)\n",
    "        \n",
    "    return transformed_X_exp\n",
    "\n",
    "\n",
    "def extract_deep_feature_extactor(model):\n",
    "    \"\"\"\n",
    "    extracts and returns the a subnetwork of a two branch siamese network.\n",
    "    input: siamese model containing sub networks\n",
    "    \"\"\"\n",
    "    \n",
    "    return Model(\n",
    "                inputs=model.layers[0].get_input_at(0),\n",
    "                outputs=model.get_layer(\"basemodel\").get_output_at(0))\n",
    "\n",
    "\n",
    "def custom_save_model(arg_dict, win_size, loss_record_dict, metric_record_dict, deep_feature_model=None, test_res_fig_dic = None, other_dict=None, custom_prefix_dir_name=\"\"):\n",
    "    \"\"\"\n",
    "    save the deep learning feature extractor model, along with dictionary of arguments as a json,\n",
    "    best epoch found, a dictionary containing the accurcy and EER figures, and the window size, and\n",
    "    a dicgionary of validation and training loss values over time that can be later plotted.\n",
    "    inputs: \n",
    "    deep_feature_model: tf model\n",
    "    arg_dict: serializable dictionary\n",
    "    test_res_fig_dic: dict containing keys {\"acc\", \"eer\"}\n",
    "    win_size: int\n",
    "    loss_record_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    dir_name = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    if deep_feature_model:\n",
    "        save_dir = f\"siamese_cnn_results/{win_size}/\"+ custom_prefix_dir_name + \"best_model_\" + dir_name\n",
    "        os.mkdir(save_dir)\n",
    "        deep_feature_model.save(save_dir)\n",
    "    else:\n",
    "        save_dir = f\"siamese_cnn_results/{win_size}/\"+ custom_prefix_dir_name + dir_name\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    \n",
    "    if test_res_fig_dic:\n",
    "        test_res_fig_dic[\"acc\"].savefig(f'{save_dir}/accuracy.svg', bbox_inches='tight')\n",
    "        test_res_fig_dic[\"eer\"].savefig(f'{save_dir}/eer.svg', bbox_inches='tight')\n",
    "    \n",
    "    with open(f\"{save_dir}/arg_dict.json\", 'w') as file:\n",
    "        arg_dict_json = json.dumps(arg_dict)\n",
    "        file.write(arg_dict_json)\n",
    "        \n",
    "    with open(f\"{save_dir}/loss_record.json\", 'w') as file:\n",
    "        loss_record_json = json.dumps(loss_record_dict)\n",
    "        file.write(loss_record_json)\n",
    "        \n",
    "    with open(f\"{save_dir}/metric_record.json\", 'w') as file:\n",
    "        metric_record_json = json.dumps(metric_record_dict)\n",
    "        file.write(metric_record_json)\n",
    "    \n",
    "    if other_dict != None:\n",
    "        with open(f\"{save_dir}/other_dict.json\", 'w') as file:\n",
    "            other_dict_json = json.dumps(other_dict)\n",
    "            file.write(other_dict_json)\n",
    "\n",
    "        \n",
    "    fig_dict = utils_plot_validation_metric(metric_record_dict)\n",
    "    for metric in fig_dict:\n",
    "        fig = fig_dict[metric]\n",
    "        fig.savefig(f'{save_dir}/{metric}_epoch.svg', bbox_inches='tight')\n",
    "    \n",
    "    print(f\"saved model at {save_dir}\")\n",
    "    \n",
    "    \n",
    "def utils_plot_validation_metric(metric_record_dict):\n",
    "    \"\"\"Plot Train/Valid metric during Epochs.\"\"\"\n",
    "    \n",
    "    fig_dict = {}\n",
    "    for metric in metric_record_dict:\n",
    "        fig = plt.figure(figsize=(5.473, 2.7), dpi=180)\n",
    "        plt.plot(metric_record_dict[metric]['Train'], label=\"train\", color=\"tab:blue\")\n",
    "        plt.plot(metric_record_dict[metric]['Valid'], label=\"valid\", color=MAGENTA)\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        fig.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        fig_dict[metric] = fig\n",
    "    \n",
    "    return fig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "6db5413f-6f83-4172-a988-bbd6b2c80ed8",
    "_uuid": "b3e92b0e-b8f0-4521-bb00-99e6b15496d7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, 0, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(5), 5, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils_plot_distance_hist() For CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_plot_distance_hist(dist_positive, dist_negative, thres, desc, fig_size=(12, 4), margin=None):\n",
    "    \"\"\"Plot histogramm of Euclidean Distances for Positive & Negative Pairs.\"\"\"\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Plot Distributions\n",
    "    plt.figure(figsize=fig_size, dpi=180)\n",
    "    bins = np.linspace(\n",
    "        min(dist_positive.min(), dist_negative.min()),\n",
    "        max(dist_positive.max(), dist_negative.max()),\n",
    "        num=21,\n",
    "    )\n",
    "    g1 = sns.distplot(\n",
    "        dist_positive,\n",
    "        label=\"positive pairs\",\n",
    "        bins=bins,\n",
    "        axlabel=False,\n",
    "        hist_kws=dict(edgecolor=\"k\", lw=0.5),\n",
    "        kde_kws=dict(linewidth=0.8),\n",
    "        color=\"tab:blue\",\n",
    "    )\n",
    "    g2 = sns.distplot(\n",
    "        dist_negative,\n",
    "        label=\"negative pairs\",\n",
    "        bins=bins,\n",
    "        hist_kws=dict(edgecolor=\"k\", lw=0.5),\n",
    "        kde_kws=dict(linewidth=0.8),\n",
    "        color=\"tab:gray\",\n",
    "    )\n",
    "\n",
    "    # Plot vertical lines\n",
    "    if thres > 0:\n",
    "        max_y = max(g1.get_ylim()[1], g2.get_ylim()[1])\n",
    "        plt.axvline(x=thres, color=MAGENTA, linestyle=\"--\", lw=0.8, alpha=0.7)\n",
    "        plt.text(\n",
    "            x=thres + 0.001,\n",
    "            y=max_y * 0.65,\n",
    "            s=f\"EER Threshold\\n({thres:.2f})\",\n",
    "            color=MAGENTA,\n",
    "            weight=\"bold\",\n",
    "            fontsize=5,\n",
    "            alpha=1\n",
    "        )\n",
    "        if margin:\n",
    "            plt.axvline(x=margin, color=MAGENTA, linestyle=\"--\", lw=0.8, alpha=0.7)\n",
    "            plt.text(\n",
    "                x=margin + 0.001,\n",
    "                y=max_y * 0.15,\n",
    "                s=f\"Margin\\n({margin})\",\n",
    "                color=MAGENTA,\n",
    "                weight=\"bold\",\n",
    "                fontsize=5,\n",
    "                alpha=1\n",
    "            )\n",
    "\n",
    "    # Legend\n",
    "    plt.legend(\n",
    "        loc=\"upper right\",\n",
    "        title=f\"{desc} Distances\",\n",
    "        title_fontsize=5,\n",
    "        fontsize=6,\n",
    "    )\n",
    "\n",
    "    warnings.filterwarnings(\"default\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TEST_MODE:\n",
    "    dist_pos = np.array([0.0, 0.1, 0.1, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.5, 0.8])\n",
    "    dist_neg = np.array([0.4, 0.5, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7, 0.7, 0.8, 1, 1])\n",
    "    utils_plot_distance_hist(\n",
    "        dist_pos, dist_neg, thres=0.4, desc=\"Pair\", fig_size=(12, 4), margin=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "478e1e7e-68bd-4f32-94a8-e2aa98381323",
    "_uuid": "59ce837f-6626-42f9-bd8c-ac2fdf93c5c2"
   },
   "source": [
    "# utils_create_cv_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "1cfaf4af-a653-485b-be5b-c28d2797798f",
    "_uuid": "38ee9619-b1c4-40d6-9980-1809d1775875",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def utils_create_cv_splits(owner_key, train_dic, valid_test_dic, seed=0):\n",
    "    '''\n",
    "    return the required sets for an OCSVM trained on the user with key. \n",
    "    X_train: X data from train_dic[k], comes from exp2\n",
    "    X_test_regular: X data from valid_test_dic[k], comes from exp1\n",
    "    X_test_anomalous: X data from valid_test_dic[!k], comes from exp1\n",
    "    \n",
    "    Create cross-validation mask with train-valid pairs.\n",
    "    \n",
    "    See e.g. https://stackoverflow.com/a/37591377\n",
    "    \n",
    "    Arguments:\n",
    "        cv_mask {np.ndarray} --\n",
    "        \n",
    "    Return:\n",
    "        {list} -- List of tuple: (<train indices>, <valid indices>)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    if owner_key not in  train_dic:\n",
    "        raise Exception(\"invalid key for dic\")\n",
    "    \n",
    "        \n",
    "    X_pos = train_dic[owner_key].copy()\n",
    "    X_test_regular = valid_test_dic[owner_key].copy()\n",
    "    X_test_anomalous = np.concatenate([valid_test_dic[key] for key in valid_test_dic.keys() if key != owner_key], axis=0).copy()\n",
    "    \n",
    "    train_idx_owner = np.arange(X_pos.shape[0])\n",
    "    valid_idx_owner = np.arange(X_test_regular.shape[0]) + train_idx_owner.shape[0]\n",
    "    \n",
    "    print(f\"owner: {owner_key} train_idx range: {train_idx_owner[0]}, {train_idx_owner[-1]}\")\n",
    "    print(f\"owner: {owner_key} valid_idx range: {valid_idx_owner[0]}, {valid_idx_owner[-1]}\")\n",
    "    np.random.seed(seed + owner_key)\n",
    "    np.random.shuffle(train_idx_owner)\n",
    "    np.random.shuffle(valid_idx_owner)\n",
    "\n",
    "    \n",
    "    cv_splits = []\n",
    "    base_idx = train_idx_owner.shape[0] + valid_idx_owner.shape[0]\n",
    "    for key in valid_test_dic.keys():\n",
    "        \n",
    "        if key != owner_key:\n",
    "            # Impostor validation indices\n",
    "            valid_idx_impostor = np.arange(valid_test_dic[key].shape[0]) + base_idx\n",
    "            print(f\"imposter: {key} valid_idx range: {valid_idx_impostor[0]}, {valid_idx_impostor[-1]}\")\n",
    "\n",
    "            # Balance classes\n",
    "            min_samples = min(valid_idx_owner.shape[0], valid_idx_impostor.shape[0])\n",
    "            np.random.seed(seed + key)\n",
    "            valid_idx_owner_samp = np.random.choice(\n",
    "                valid_idx_owner, size=min_samples, replace=False\n",
    "            )\n",
    "            np.random.seed(seed + key)\n",
    "            valid_idx_impostor_samp = np.random.choice(\n",
    "                valid_idx_impostor, size=min_samples, replace=False\n",
    "            )\n",
    "\n",
    "            # Concat owner & impostor validation indices\n",
    "            valid_idx_both = np.hstack([valid_idx_owner_samp, valid_idx_impostor_samp])\n",
    "\n",
    "            # Add train/valid pair to cv\n",
    "            cv_splits.append((list(train_idx_owner), list(valid_idx_both)))\n",
    "            \n",
    "            base_idx += valid_idx_impostor.shape[0]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_train = np.concatenate([np.repeat(1.0, X_pos.shape[0]), np.repeat(1.0, X_test_regular.shape[0]), np.repeat(-1.0, X_test_anomalous.shape[0])])\n",
    "    X_train = np.concatenate([X_pos, X_test_regular, X_test_anomalous], axis=0)\n",
    "    \n",
    "    \n",
    "    return {\"X_train\": X_train, \"y_train\": y_train, \"X_test_regular\": X_test_regular, \"X_test_anomalous\": X_test_anomalous, \"cv_splits\": cv_splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_cell_guid": "6abc81ef-9648-4c12-95c7-d8af54bd1923",
    "_uuid": "03caeebf-831e-40bd-8724-6eeeb713e63b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# if TEST_MODE:\n",
    "#     # Mask Explained:\n",
    "#     # -2 => Training data (owner)\n",
    "#     # -1 => Validation data (owner)\n",
    "#     # 0+ => Validation impostors\n",
    "#     #              Indices:    0   1   2   3   4   5  6  7  8  9  10 11 12 13 14 15\n",
    "#     dummy_cv_mask = np.array([-2, -2, -1, -1, -1, -1, 0, 0, 0, 1, 1, 1, 2, 2, 2, -2])\n",
    "\n",
    "#     # Generate tuples of training data and validation data, one tuple for each impostor (0, 1, 2).\n",
    "#     # Training data (1st list in tuple) contains only indices of owner training data (-2)\n",
    "#     # Validation data (2nd list in tuple) contains  indices of validation data from owner (-1) and\n",
    "#     # from a single impostor (0+), each 50 %\n",
    "#     splits = utils_create_cv_splits(dummy_cv_mask, seed=123)\n",
    "#     [print(s) for s in splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9f0938b3-dc22-4b9b-9418-3be1a44595e3",
    "_uuid": "04c3c832-4264-44b4-b076-195e0d551630"
   },
   "source": [
    "# utils_cv_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_cv_report(random_search, owner, impostors):\n",
    "    \"\"\"Transform the random_search.cv_results_ into nice formatted dataframe.\"\"\"\n",
    "    # Create report\n",
    "    df_report = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "    # Add owner information\n",
    "    df_report[\"owner\"] = owner\n",
    "\n",
    "    # Drop uninteressting columns\n",
    "    drop_columns = [col for col in df_report.columns if \"_train_\" in col]\n",
    "    drop_columns = drop_columns + [col for col in df_report.columns if col.startswith(\"split\") and (col.endswith(\"recall\") or col.endswith(\"precision\") or col.endswith(\"f1\") or col.endswith(\"roc_auc\"))]\n",
    "    drop_columns = drop_columns + [\"params\"]\n",
    "    df_report = df_report.drop(columns=drop_columns)\n",
    "\n",
    "    # Flip sign of eer (revert flip by sklearn scorer)\n",
    "    eer_columns = [col for col in df_report.columns if col.endswith(\"_eer\")]\n",
    "    df_report[eer_columns] = df_report[eer_columns].abs()\n",
    "    \n",
    "    # Rename split result columns with impostor-ids used in split\n",
    "    rename_cols = {}\n",
    "    for idx, impostor in enumerate(impostors):\n",
    "        print(f\"idx: {idx}, impostor: {impostor}\")\n",
    "        to_rename_cols = [col for col in df_report.columns if col.startswith(f\"split{idx}\")]\n",
    "        for col in to_rename_cols:\n",
    "            rename_cols[col] = str(impostor)+col[len(f\"split{idx}\"):]\n",
    "    df_report = df_report.rename(columns=rename_cols)      \n",
    "\n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODE:\n",
    "    print(\"Performing Dummy RandomSearch...\")\n",
    "    from sklearn import svm, datasets\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "    parameters = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 2, 3, 4, 5, 6, 7, 10]}\n",
    "    svc = svm.SVC(gamma=\"scale\")\n",
    "    clf = RandomizedSearchCV(svc, parameters, cv=3, iid=False)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    print(\"Create report:\")\n",
    "    df_temp = utils_cv_report(clf, \"owner x\", [\"impo_1\", \"impo_2\", \"impo_3\"])\n",
    "    display(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_plot_randomsearch_results(df_results, n_top=1):\n",
    "    # Prepare data for plotting\n",
    "    df_plot = df_results[df_results[\"rank_test_eer\"] <= n_top].rename(\n",
    "        columns={\n",
    "            \"param_model__nu\": r\"$\\nu$\",\n",
    "            \"param_model__gamma\": r\"$\\gamma$\",\n",
    "            \"mean_test_accuracy\": \"Mean Test Acc.\",\n",
    "            \"mean_test_eer\": \"Mean Test EER\",\n",
    "        }\n",
    "    )\n",
    "    df_plot[\"Mean Test EER\"] = df_plot[\"Mean Test EER\"] * -1  # Because fewer is more\n",
    "\n",
    "    median_nu = df_plot[r\"$\\nu$\"].median()\n",
    "    median_gamma = df_plot[r\"$\\gamma$\"].median()\n",
    "\n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(5.473 / 1.3, 2), dpi=180)\n",
    "    g = sns.scatterplot(\n",
    "        x=r\"$\\nu$\",\n",
    "        y=r\"$\\gamma$\",\n",
    "        data=df_plot,\n",
    "        size=\"Mean Test EER\",\n",
    "        sizes=(7, 60),\n",
    "        hue=\"Mean Test EER\",\n",
    "        alpha=1,\n",
    "        #        palette=\"Blues\",\n",
    "        linewidth=0,\n",
    "    )\n",
    "\n",
    "    # Format Legend labels\n",
    "    leg = g.get_legend()\n",
    "    new_handles = [h for h in leg.legendHandles]\n",
    "    new_labels = []\n",
    "    for i, handle in enumerate(leg.legendHandles):\n",
    "        label = handle.get_label()\n",
    "        print(f'{i}, {label}')\n",
    "        if ord(label[0]) == 8722:\n",
    "            label = '-' + label[1:]\n",
    "            \n",
    "        if i != 0:\n",
    "            \n",
    "            try:\n",
    "                new_labels.append(f\"{abs(float(label)):.3f}\")\n",
    "\n",
    "            except ValueError:\n",
    "                new_labels.append(\"\")\n",
    "\n",
    "    # Plot mean values\n",
    "    plt.plot(\n",
    "        [-0.01, 0.31],\n",
    "        [median_gamma, median_gamma],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        alpha=0.7,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        0.23,\n",
    "        median_gamma * 1.7 ** 2,\n",
    "        r\"median($\\gamma$)\",\n",
    "        fontsize=6,\n",
    "        color=\"black\",\n",
    "        alpha=0.9,\n",
    "    )\n",
    "    plt.text(\n",
    "        0.23,\n",
    "        median_gamma * 1.2 ** 2,\n",
    "        f\"{median_gamma:.3f}\",\n",
    "        fontsize=5,\n",
    "        color=\"black\",\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        [median_nu, median_nu],\n",
    "        [0.0001, 1000],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        alpha=0.7,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        median_nu + 0.005, 400, r\"median($\\nu$)\", fontsize=6, color=\"black\", alpha=0.9\n",
    "    )\n",
    "    plt.text(\n",
    "        median_nu + 0.005, 200, f\"{median_nu:.3f}\", fontsize=5, color=\"black\", alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Adjust axes & legend\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylim(0.0001, 1000)\n",
    "    plt.xlim(0, 0.305)\n",
    "#     print(new_handles)\n",
    "    print(new_labels)\n",
    "    plt.legend(\n",
    "        new_handles,\n",
    "        new_labels,\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=2,\n",
    "        borderaxespad=0.0,\n",
    "        title=\"Mean EER per Owner\\n(Validation Results)\",\n",
    "        title_fontsize=5,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return median_nu, median_gamma, fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_plot_2d_hyperparam_selection(h1_name, h1_val, h2_name, h2_val, df_plot):\n",
    "    \n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(5.473 / 1.3, 2), dpi=100)\n",
    "    g = sns.scatterplot(\n",
    "        x=h1_name,\n",
    "        y=h2_name,\n",
    "        data=df_plot,\n",
    "        size=\"Mean Test EER\",\n",
    "        sizes=(7, 60),\n",
    "        hue=\"Mean Test EER\",\n",
    "        alpha=1,\n",
    "        #        palette=\"Blues\",\n",
    "        linewidth=0,\n",
    "    )\n",
    "\n",
    "    # Format Legend labels\n",
    "    leg = g.get_legend()\n",
    "    new_handles = [h for h in leg.legendHandles]\n",
    "    new_labels = []\n",
    "    for i, handle in enumerate(leg.legendHandles):\n",
    "        label = handle.get_label()\n",
    "        print(f'{i}, {label}')\n",
    "        if ord(label[0]) == 8722:\n",
    "            label = '-' + label[1:]\n",
    "            \n",
    "        if i != 0:\n",
    "            \n",
    "            try:\n",
    "                new_labels.append(f\"{abs(float(label)):.3f}\")\n",
    "\n",
    "            except ValueError:\n",
    "                new_labels.append(\"\")\n",
    "\n",
    "    # Plot mean values\n",
    "    plt.plot(\n",
    "        [-0.01, 0.31],\n",
    "        [h2_val, h2_val],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        alpha=0.7,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        0.23,\n",
    "        h2_val * 1.7 ** 2,\n",
    "        f\"median({h2_name})\",\n",
    "        fontsize=6,\n",
    "        color=\"black\",\n",
    "        alpha=0.9,\n",
    "    )\n",
    "    plt.text(\n",
    "        0.23,\n",
    "        h2_val * 1.2 ** 2,\n",
    "        f\"{h2_val:.3f}\",\n",
    "        fontsize=5,\n",
    "        color=\"black\",\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        [h1_val, h1_val],\n",
    "        [0.0001, 1000],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        alpha=0.7,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        h1_val + 0.005, 400, f\"median({h1_name})\", fontsize=6, color=\"black\", alpha=0.9\n",
    "    )\n",
    "    plt.text(\n",
    "        h1_val + 0.005, 200, f\"{h1_val:.3f}\", fontsize=5, color=\"black\", alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Adjust axes & legend\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylim(0.0001, 1000)\n",
    "    plt.xlim(0, 0.305)\n",
    "#     print(new_handles)\n",
    "    print(new_labels)\n",
    "    plt.legend(\n",
    "        new_handles,\n",
    "        new_labels,\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=2,\n",
    "        borderaxespad=0.0,\n",
    "        title=\"Mean EER per Owner\\n(Validation Results)\",\n",
    "        title_fontsize=5,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/11159436/multiple-figures-in-a-single-window\n",
    "def arrange_figures(figures, nrows = 1, ncols=1):\n",
    "    \"\"\"Plot a dictionary of figures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    figures : <title, figure> dictionary\n",
    "    ncols : number of columns of subplots wanted in the display\n",
    "    nrows : number of rows of subplots wanted in the figure\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "    for ind,title in enumerate(figures):\n",
    "        axeslist.ravel()[ind].imshow(figures[title], cmap=plt.gray())\n",
    "        axeslist.ravel()[ind].set_title(title)\n",
    "        axeslist.ravel()[ind].set_axis_off()\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_plot_randomsearch_results_IF(df_results, n_top=1):\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    df_plot = df_results[df_results[\"rank_test_eer\"] <= n_top].rename(\n",
    "        columns={\n",
    "                \"param_model__n_estimators\": \"n_estimators\",\n",
    "                \"param_model__max_samples\": \"max_samples\",\n",
    "                \"param_model__contamination\": \"contamination\",\n",
    "                \"param_model__max_features\": \"max_features\",\n",
    "                \"mean_test_accuracy\": \"Mean Test Acc.\",\n",
    "                \"mean_test_eer\": \"Mean Test EER\",\n",
    "        }\n",
    "    )\n",
    "    df_plot[\"Mean Test EER\"] = df_plot[\"Mean Test EER\"] * -1  # Because fewer is more\n",
    "\n",
    "    print(df_plot.keys())\n",
    "    median_n_estimators = df_plot[\"n_estimators\"].median()\n",
    "    median_max_samples = df_plot[\"max_samples\"].median()\n",
    "    median_contamination = df_plot[\"contamination\"].median()\n",
    "    median_max_features = df_plot[\"max_features\"].median()\n",
    "\n",
    "    figures = []\n",
    "    figures.append(utils_plot_2d_hyperparam_selection(\"n_estimators\", median_n_estimators, \"max_samples\", median_max_samples, df_plot))\n",
    "    figures.append(utils_plot_2d_hyperparam_selection(\"n_estimators\", median_n_estimators, \"contamination\", median_contamination, df_plot))\n",
    "    figures.append(utils_plot_2d_hyperparam_selection(\"n_estimators\", median_n_estimators, \"max_features\", median_max_features, df_plot))\n",
    "    figures.append(utils_plot_2d_hyperparam_selection(\"max_samples\", median_max_samples, \"contamination\", median_contamination, df_plot))\n",
    "    figures.append(utils_plot_2d_hyperparam_selection(\"max_samples\", median_max_samples, \"max_features\", median_max_features, df_plot))\n",
    "    figures.append(utils_plot_2d_hyperparam_selection(\"contamination\", median_contamination, \"max_features\", median_max_features, df_plot))\n",
    "    \n",
    "    # fig = arrange_figures(figures, nrows=3, ncols=2)\n",
    "    \n",
    "\n",
    "    return median_n_estimators, median_max_samples, median_contamination, median_max_features, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "b7fd521d-f17e-4894-84c3-4d3ab3655c44",
    "_uuid": "081f655b-dd63-4dc9-8b08-9cb0f7982129",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def utils_plot_acc_eer_dist(df_plot, y_col):\n",
    "    n_subject = len(df_plot[\"Owner\"].unique()) - 1\n",
    "    mean_col = df_plot[y_col].mean()\n",
    "\n",
    "    fig = plt.figure(figsize=(5.473, 2), dpi=180)\n",
    "    ax = sns.boxplot(x=\"Owner\", y=y_col, data=df_plot, **utils_boxplot_style)\n",
    "    ax.set_ylim((0, 1))\n",
    "\n",
    "    plt.plot(\n",
    "        [-0.6, n_subject + 0.6],\n",
    "        [mean_col, mean_col],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1,\n",
    "        color=MAGENTA,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.text(n_subject + 0.6, mean_col, f\"mean\", fontsize=6, color=MAGENTA)\n",
    "    plt.text(\n",
    "        n_subject + 0.6, mean_col - 0.04, f\"{mean_col:.3f}\", fontsize=4.5, color=MAGENTA\n",
    "    )\n",
    "    plt.xticks(rotation=45)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    print(f\"Overall mean: {mean_col:.4f}\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# X_vals_owner_idx['X_train']\n",
    "def utils_plot_acc_eer_dist_thesis(EER_distro_df, y_col, discription, save_file_name=None, boxplot_color=\"springgreen\"):\n",
    "\n",
    "    sns.set(err_distro_rc)\n",
    "    n_subject = len(EER_distro_df['owner'].unique())+1\n",
    "    mean_col = EER_distro_df[y_col].mean()\n",
    "    fig = plt.figure()\n",
    "    ax = sns.boxplot(x=\"owner\", y=y_col, data=EER_distro_df, color=boxplot_color)#, **utils_boxplot_style)\n",
    "    \n",
    "    # Select which box you want to change    \n",
    "    mybox = ax.patches[4]\n",
    "\n",
    "    ax.set_ylim((0, 1))\n",
    "    # sns.swarmplot(x=\"owner\", y=y_col, data=EER_distro_df, color=\".25\")\n",
    "    \n",
    "\n",
    "    plt.plot(\n",
    "        [-0.5, n_subject -1.5],\n",
    "        [mean_col, mean_col],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        color=MAGENTA,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.text(n_subject/2, mean_col + 0.01, f\"mean\", fontsize=err_distro_rc[\"ytick.labelsize\"], color=MAGENTA)\n",
    "    plt.text(\n",
    "        n_subject/2, mean_col - 0.04, f\"{mean_col:.3f}\", fontsize=err_distro_rc[\"ytick.labelsize\"], color=MAGENTA\n",
    "    )\n",
    "    plt.xticks(rotation=45)\n",
    "    fig.tight_layout()\n",
    "    plt.title(discription)\n",
    "    \n",
    "    ax.set_xlabel(\"owner id\")\n",
    "    ax.set_ylabel(f\"Mean {y_col}\")\n",
    "    \n",
    "    plt.savefig(f'{save_file_name}', bbox_inches='tight')\n",
    "    print(f\"Overall mean: {mean_col:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_cell_guid": "230b6da5-a942-4634-a5cc-6e3a07d81646",
    "_uuid": "df80a643-53d2-4d31-9dc2-437d83a306eb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# if TEST_MODE:\n",
    "#     print(\"Performing Dummy RandomSearch...\")\n",
    "#     from sklearn import svm, datasets\n",
    "#     from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#     iris = datasets.load_iris()\n",
    "#     parameters = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 2, 3, 4, 5, 6, 7, 10]}\n",
    "#     svc = svm.SVC(gamma=\"scale\")\n",
    "#     clf = RandomizedSearchCV(svc, parameters, cv=3, iid=False)\n",
    "#     clf.fit(iris.data, iris.target)\n",
    "#     print(\"Create report:\")\n",
    "#     df_temp = utils_cv_report(clf, \"owner x\", [\"impo_1\", \"impo_2\", \"impo_3\"])\n",
    "#     display(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "61fb5ecc-ec29-4f86-8590-0db7735de365",
    "_uuid": "bd017a22-bbf8-4c0b-890b-07cc71a417ae",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class pca_feature_selector:\n",
    "    def __init__(self, n_components):\n",
    "        self._pca_dict = {}\n",
    "        self.n_components = n_components\n",
    "        \n",
    "    def add_user_pca(self, owner_idx, user_pca):\n",
    "        if owner_idx in self._pca_dict:\n",
    "            raise Exception(f\"owner_idx: {owner_idx} alraedy exists!\")\n",
    "        \n",
    "        self._pca_dict[owner_idx] = user_pca\n",
    "        \n",
    "    def user_feature_ranking(self, owner_idx):\n",
    "        '''\n",
    "        these two are the same \n",
    "        np.matmul(pca.explained_variance_ratio_[np.newaxis], abs_components) == np.dot(pca.explained_variance_ratio_, abs_components)[np.newaxis]\n",
    "        '''\n",
    "        pca = self._pca_dict[owner_idx]\n",
    "        abs_components = np.abs(pca.components_)\n",
    "        feature_importance = np.dot(pca.explained_variance_ratio_, abs_components)[np.newaxis]\n",
    "        top_feature_indices = np.argsort(-1*feature_importance)\n",
    "        \n",
    "        return {\"top_feature_indices\": top_feature_indices, \"feature_importance\": feature_importance}\n",
    "    \n",
    "    def get_comparison_matrix(self):\n",
    "        \n",
    "        feature_importance_matrix = []\n",
    "        top_feature_matrix = []\n",
    "        for owner_idx in self._pca_dict:\n",
    "            user_feature_dict = self.user_feature_ranking(owner_idx) \n",
    "            feature_importance_matrix += [user_feature_dict[\"feature_importance\"]]\n",
    "            top_feature_matrix += [user_feature_dict[\"top_feature_indices\"]]\n",
    "            \n",
    "        self._feature_importance_matrix = np.concatenate(feature_importance_matrix, axis=0)\n",
    "        self._top_feature_matrix = np.concatenate(top_feature_matrix, axis=0)\n",
    "\n",
    "        return {\"feature_importance_matrix\": self._feature_importance_matrix, \"top_feature_matrix\" :self._top_feature_matrix}\n",
    "    \n",
    "    def find_top_n_features(self):\n",
    "        \n",
    "        best_feature_lst = []\n",
    "        for i in range(self.n_components):\n",
    "            best_feature_lst.append(self.find_next_best_feature(best_feature_lst))\n",
    "            \n",
    "        return best_feature_lst\n",
    "        \n",
    "    def find_next_best_feature(self, curr_feature_lst):\n",
    "        \n",
    "        curr_pc_idx = len(curr_feature_lst)\n",
    "        feature_column_count = np.bincount(self._top_feature_matrix[:, curr_pc_idx])\n",
    "        print(f\"top_f_m: {self._top_feature_matrix[:, curr_pc_idx]}\")\n",
    "        print(curr_feature_lst)\n",
    "        \n",
    "        i = 0\n",
    "        #probably need to use a tree type or heap structure\n",
    "        while i < len(feature_column_count):\n",
    "            top_feature_idx = np.argmax(feature_column_count[i:]) + i\n",
    "            if top_feature_idx not in curr_feature_lst:\n",
    "                return top_feature_idx\n",
    "            print('-------')\n",
    "            print(feature_column_count)\n",
    "            print(f\"i: {i}, top_feature_idx: {top_feature_idx}\")\n",
    "\n",
    "            i = top_feature_idx + 1\n",
    "            \n",
    "        raise Exception('could not find best feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_plot_training_loss(history):\n",
    "    \"\"\"Plot Train/Valid Loss during Epochs.\"\"\"\n",
    "    fig = plt.figure(figsize=(5.473, 2.7), dpi=180)\n",
    "    plt.plot(history[\"loss\"], label=\"train\", color=\"tab:blue\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"valid\", color=MAGENTA)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    fig.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    fig.tight_layout()\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODE:\n",
    "    HistoryDummy = type(\"History\", (object,), {})\n",
    "    history = HistoryDummy()\n",
    "    history.history = {}\n",
    "    history.history[\"loss\"] = [0.6, 0.4, 0.3, 0.2, 0.21, 0.15]\n",
    "    history.history[\"val_loss\"] = [0.9, 0.7, 0.5, 0.4, 0.35, 0.3]\n",
    "    utils_plot_training_loss(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "9a6a5c02-ace2-47be-bad3-10b646266720",
    "_uuid": "b03ec3d1-6ac2-4da7-9d90-eadad41f35b7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# randomized_data_idx = list(range(len(r)))\n",
    "# random.shuffle(randomized_data_idx)\n",
    "# split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "# train_set = randomized_data_idx[: split_idx]\n",
    "# test_set = randomized_data_idx[split_idx: ]\n",
    "# print(f\"train_set: {train_set}\\ntest_set: {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "c8931e16-a4e2-42c8-b626-7dfd6e8f2ed4",
    "_uuid": "d73dc5fe-0599-458f-ba69-ee6405152e40",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # preparing train data\n",
    "# # train_set = r\n",
    "# dfList_exp1_train, dfList_exp2_train = [dfList_exp1[i] for i in train_set], [dfList_exp2[i] for i in train_set]\n",
    "# print(f\"len(dfList_exp1_train): {len(dfList_exp1_train)}\")\n",
    "# print(f\"len(dfList_exp2_train): {len(dfList_exp2_train)}\")\n",
    "# XExpTrainDict = MakeXExpDic(dfList_exp1_train, dfList_exp2_train, window_size = 250, step = 251, numSamplePoints= 18000)\n",
    "# X_exp1_train_dic, X_exp2_train_dic = XExpTrainDict[\"X_exp1_dic\"], XExpTrainDict[\"X_exp2_dic\"]\n",
    "\n",
    "# # preparing test data\n",
    "# dfList_exp1_test, dfList_exp2_test = [dfList_exp1[i] for i in test_set], [dfList_exp2[i] for i in test_set]\n",
    "# print(f\"len(dfList_exp1_test): {len(dfList_exp1_test)}\")\n",
    "# print(f\"len(dfList_exp2_test): {len(dfList_exp2_test)}\")\n",
    "# XExpTestDict = MakeXExpDic(dfList_exp1_test, dfList_exp2_test, window_size = 250, step = 251, numSamplePoints= 18000)\n",
    "# X_exp1_test_dic, X_exp2_test_dic = XExpTestDict[\"X_exp1_dic\"], XExpTestDict[\"X_exp2_dic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "92b22de7-7efb-4cce-aa17-a941d9bc262d",
    "_uuid": "7900b26e-3f79-4af8-b0dd-3c66f8193ad6"
   },
   "source": [
    "**use the following to write tests for distro functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_cell_guid": "34212531-d2e8-4ddf-85fb-9735252c8b1b",
    "_uuid": "18ad7845-afb9-46a8-b194-28b36a1acf3e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# source: https://zhiyzuo.github.io/Plot-Lorenz/\n",
    "#  0 representing perfect equality, and 1 absolute inequality.\n",
    "def gini(arr):\n",
    "    ## first sort\n",
    "    sorted_arr = arr.copy()\n",
    "    sorted_arr.sort()\n",
    "    n = arr.size\n",
    "    coef_ = 2. / n\n",
    "    const_ = (n + 1.) / n\n",
    "    weighted_sum = sum([(i+1)*yi for i, yi in enumerate(sorted_arr)])\n",
    "    return coef_*weighted_sum/(sorted_arr.sum()) - const_\n",
    "\n",
    "def lorenz_curve(X):\n",
    "    ## first sort\n",
    "    X = X.copy()\n",
    "    X.sort()\n",
    "    X_lorenz = X.cumsum() / X.sum()\n",
    "    X_lorenz = np.insert(X_lorenz, 0, 0) \n",
    "    X_lorenz[0], X_lorenz[-1]\n",
    "    fig, ax = plt.subplots(figsize=[6,6])\n",
    "    ## scatter plot of Lorenz curve\n",
    "    ax.scatter(np.arange(X_lorenz.size)/(X_lorenz.size-1), X_lorenz, \n",
    "               marker='x', color='darkgreen', s=100)\n",
    "    ## line plot of equality\n",
    "    ax.plot([0,1], [0,1], color='k')\n",
    "    ax.set_xlabel('% of Population')\n",
    "    ax.set_ylabel('% of Errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_cell_guid": "9fcf45a3-f8fc-4df5-8463-ae1ec5a02e70",
    "_uuid": "d9c1d4f4-21a7-40f7-af56-bd0f48ab254e",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# window = 1000\n",
    "# window_farDistro_array = DistroFAR(dic[\"window_farDistro_dict\"][window], threshold = dic[\"window_EER_threshold_dict\"][window])\n",
    "# window_frrDistro_array = DistroFRR(dic[\"window_frrDistro_dict\"][window], threshold = dic[\"window_EER_threshold_dict\"][window])\n",
    "# X = np.array(window_frrDistro_array)\n",
    "# # print(X)\n",
    "# print(gini(X))\n",
    "# lorenz_curve(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "8c1a264f-679a-4cf6-ae79-0750956ba0d7",
    "_uuid": "3598674f-4484-4ffc-a276-045f6fdd71a2",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# X = np.array(window_farDistro_array)\n",
    "# # print(X)\n",
    "# print(gini(X))\n",
    "# lorenz_curve(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_cell_guid": "84cef82a-53b1-46ef-b9ea-53b56e9dd7ae",
    "_uuid": "decd2faf-d977-4db9-a53e-e303a433e7f5",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# keys_list = r\n",
    "# values_list = window_frrDistro_array\n",
    "# #Get pairs of elements\n",
    "\n",
    "\n",
    "# zip_iterator = zip(keys_list, values_list)\n",
    "\n",
    "# Distro_dict = dict(zip_iterator)\n",
    "\n",
    "# Distro_dict = {k: v for k, v in sorted(Distro_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "# fig, ax =plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "# ax.set_title('FRR Distrobution')\n",
    "# print(Distro_dict)\n",
    "# data = {\"User\": list(Distro_dict.keys()), \"False Rejects\": list(Distro_dict.values())}\n",
    "# g = sns.barplot(x=data[\"User\"], y=data[\"False Rejects\"], order=data[\"User\"],ax = ax)\n",
    "# #y=EER_dict.values()\n",
    "\n",
    "# # y_ticks = np.arange(0, .25 + 0.001, .05)\n",
    "\n",
    "# # g.set_yticks(y_ticks)\n",
    "# ax.axhline(np.mean(data[\"False Rejects\"]), ls='--')\n",
    "# ax.set_xlabel('User')\n",
    "# ax.set_ylabel('False Rejects')\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_cell_guid": "aabe956d-b0cc-44b0-a65c-47058842dbd1",
    "_uuid": "b629854f-9aca-444f-9b87-2309ba0a5d44",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# X = np.array(window_farDistro_array)\n",
    "# # print(X)\n",
    "# print(gini(X))\n",
    "# lorenz_curve(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_cell_guid": "5438d555-f070-4019-8536-c063e35b7e94",
    "_uuid": "5a18caf2-bb56-45b4-a085-da83f4b35404",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# auc(frrList, farList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_cell_guid": "e00ca0fd-f3b5-40b4-8e6b-4813887fe906",
    "_uuid": "2ef37b96-5eae-466c-9d73-cf9ee3abb975",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getAUROCDist(window_frrList_dict, window_farList_dict, start_window_size=250, end_window_size=3000, increment_step=250):\n",
    "    \n",
    "    window_AUROC_dict = {}\n",
    "    lst = np.arange(start_window_size, end_window_size + 1, increment_step)\n",
    "    \n",
    "    for w in lst:\n",
    "        \n",
    "        frrList = dic[\"window_frrList_dict\"][w]\n",
    "        farList = dic[\"window_farList_dict\"][w]\n",
    "        window_AUROC_dict[w] = auc(frrList, farList)\n",
    "        \n",
    "    return window_AUROC_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_cell_guid": "09da174d-f14b-4a97-be01-ea606e593339",
    "_uuid": "b2e8ce39-9be1-4e28-8439-2ed3a704d924",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# AUROC_dict = getAUROCDist(dic[\"window_frrList_dict\"], dic[\"window_farList_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_cell_guid": "84bd2da7-ede2-4a35-8495-5bc96140ca01",
    "_uuid": "1bbd0ddf-1782-49f8-94d6-d72dafd3bd1c",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../input/wearable-assisted-ca/user10_1.docx', error_bad_lines = False, header=None, dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_cell_guid": "f3569ab8-ad0e-4ddc-8e5f-231c149e7995",
    "_uuid": "50be2017-9348-4fad-9f17-901e13021645",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# def extractTextFromDocx(path):\n",
    "#     try:\n",
    "#         doc = docx.Document(path)  # Creating word reader object.\n",
    "#         data = \"\"\n",
    "#         fullText = []\n",
    "#         for para in doc.paragraphs:\n",
    "#             fullText.append(para.text)\n",
    "#             data = '\\n'.join(fullText)\n",
    "\n",
    "#     except IOError:\n",
    "#         print('There was an error opening the file!')\n",
    "#         return\n",
    "#     return data\n",
    "\n",
    "# # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-03-18T18:34:19.771958Z\",\"iopub.execute_input\":\"2022-03-18T18:34:19.772266Z\",\"iopub.status.idle\":\"2022-03-18T18:34:19.793851Z\",\"shell.execute_reply.started\":\"2022-03-18T18:34:19.772229Z\",\"shell.execute_reply\":\"2022-03-18T18:34:19.792569Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n",
    "# def numberOfWords(text):\n",
    "#     return len(text.strip().split())\n",
    "\n",
    "# def numberOfChars(text):\n",
    "#     return len(text)\n",
    "\n",
    "# def wordsPerMinute(text, mins):\n",
    "#     return numberOfWords(text)/mins\n",
    "\n",
    "# def charsPerMinute(text, mins):\n",
    "#     return numberOfChars(text)/mins\n",
    "\n",
    "# def classifyTypists(typistsSpeeds):\n",
    "#     '''\n",
    "#         WPM\n",
    "#     Beginner\t0 - 24\n",
    "#     Intermediate\t25 - 30\n",
    "#     Average\t31 - 41\n",
    "#     Pro\t42 - 54\n",
    "#     Typemaster\t55 - 79\n",
    "#     Megaracer\t80+\n",
    "#     '''\n",
    "#     exp2_typingspeeds = [29.96428571, 37.42857143, 44.89285714, 52.35714286, 59.82142857, 67.28571429]\n",
    "#     speedDict = {\"Beginner\": 24, \"Intermediate\": 30, \"Average\": 41, \"Pro\": 54, \"Typemaster\": 79, \"Megaracer\": 1000}\n",
    "    \n",
    "#     keys = list(speedDict.keys())\n",
    "#     for i in range(len(speedDict.keys())):\n",
    "#         speedDict[keys[i]] = exp2_typingspeeds[i]\n",
    "    \n",
    "#     speedStats = {\"Beginner\": 0, \"Intermediate\": 0, \"Average\": 0, \"Pro\": 0, \"Typemaster\": 0, \"Megaracer\": 0}\n",
    "#     typistsIDStats = {\"Beginner\": [], \"Intermediate\": [], \"Average\": [], \"Pro\": [], \"Typemaster\": [], \"Megaracer\": []}\n",
    "    \n",
    "#     for typist, speed in typistsSpeeds.items():\n",
    "#         if speed <= speedDict[\"Beginner\"]:\n",
    "#             speedStats[\"Beginner\"] += 1\n",
    "#             typistsIDStats[\"Beginner\"].append(typist)\n",
    "            \n",
    "#         elif speed <= speedDict[\"Intermediate\"]:\n",
    "#             speedStats[\"Intermediate\"] += 1\n",
    "#             typistsIDStats[\"Intermediate\"].append(typist)\n",
    "            \n",
    "#         elif speed <= speedDict[\"Average\"]:\n",
    "#             speedStats[\"Average\"] += 1\n",
    "#             typistsIDStats[\"Average\"].append(typist)\n",
    "            \n",
    "#         elif speed <= speedDict[\"Pro\"]:\n",
    "#             speedStats[\"Pro\"] += 1\n",
    "#             typistsIDStats[\"Pro\"].append(typist)\n",
    "            \n",
    "#         elif speed <= speedDict[\"Typemaster\"]:\n",
    "#             speedStats[\"Typemaster\"] += 1\n",
    "#             typistsIDStats[\"Typemaster\"].append(typist)\n",
    "            \n",
    "#         else:\n",
    "#             speedStats[\"Megaracer\"] += 1\n",
    "#             typistsIDStats[\"Megaracer\"].append(typist)\n",
    "            \n",
    "#     return {\"speedStats\": speedStats, \"typistsIDStats\": typistsIDStats}\n",
    "\n",
    "# # %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-03-18T18:34:19.795159Z\",\"iopub.execute_input\":\"2022-03-18T18:34:19.795733Z\",\"iopub.status.idle\":\"2022-03-18T18:34:19.814022Z\",\"shell.execute_reply.started\":\"2022-03-18T18:34:19.795693Z\",\"shell.execute_reply\":\"2022-03-18T18:34:19.812934Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n",
    "# r = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
    "# #r = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
    "\n",
    "\n",
    "# def users_typing_speed(user_ids_lst):\n",
    "#     '''\n",
    "#     input: \n",
    "#         user_ids_lst: list of selected user ids\n",
    "#     Return {user_id: typing_speed in words per minute}\n",
    "#     '''\n",
    "#     typistsSpeeds = {}\n",
    "#     for i in user_ids_lst:\n",
    "#         user_text_data = extractTextFromDocx('../input/wearable-assisted-ca/user{0}_{1}.docx'.format(i, 2))\n",
    "\n",
    "#         typistsSpeeds[i] = wordsPerMinute(user_text_data, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_cell_guid": "19063d95-fc9e-4094-8ab7-5999e611c04e",
    "_uuid": "d119855a-a09a-4c7e-b31b-b26a65900d93",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# dic = classifyTypists(typistsSpeeds)\n",
    "# dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1215f780-6abe-4c99-9c42-de10cf6fbd57",
    "_uuid": "50d96fcf-e53b-4424-9b98-f58d5133e2d9"
   },
   "source": [
    "# Divide the users using histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a style I use a lot for boxplots:\n",
    "utils_boxplot_style = dict(\n",
    "    color=\"tab:blue\",\n",
    "    linewidth=0.5,\n",
    "    saturation=1,\n",
    "    width=0.7,\n",
    "    flierprops=dict(\n",
    "        marker=\"o\", markersize=2, markerfacecolor=\"none\", markeredgewidth=0.5\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define a style I use a lot for lineplots:\n",
    "utils_lineplot_style = dict(\n",
    "    color=\"tab:blue\", linewidth=0.5, marker=\"o\", markersize=3, markeredgewidth=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utility functions imported\n"
     ]
    }
   ],
   "source": [
    "print(\"utility functions imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimented with the follwoing LR scheduling functions, but ended up using from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# commented out as it is not in use\n",
    "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# def step_decay(epoch):\n",
    "#     # initial_lr = 0.00001 #used for original size\n",
    "#     # drop = 0.2\n",
    "#     # # if epoch < 3:\n",
    "#     # epochs_drop = 5# used for original size\n",
    "#     # else: \n",
    "#     #     epochs_drop = 5\n",
    "\n",
    "#     # initial_lr = 0.00003\n",
    "#     # drop=1\n",
    "#     # epochs_drop = 5\n",
    "\n",
    "#     # if epoch<10:\n",
    "#     #     lr = initial_lr - (initial_lr*0.1*epoch)\n",
    "#     # elif epoch<20:\n",
    "#     #     lr = initial_lr - (initial_lr*0.01*epoch)\n",
    "#     # elif epoch<30:\n",
    "#     #     lr = initial_lr - (initial_lr*0.001*epoch)\n",
    "#     # else:\n",
    "#     #     lr = initial_lr * drop ** (epoch // epochs_drop)\n",
    "    \n",
    "#     initial_lrate = 0.0001\n",
    "#     k = 0.1\n",
    "#     lrate = initial_lrate * exp(-k*t)\n",
    "#     print(lr)\n",
    "#     return lr\n",
    "\n",
    "\n",
    "# def lr_time_based_decay(epoch):\n",
    "#     initial_learning_rate=0.00005\n",
    "#     decay = initial_learning_rate/epoch\n",
    "#     return lr * 1 / (1 + decay * epoch)\n",
    "    \n",
    "# def lr_exp_decay(epoch, lr=0.001):\n",
    "    \n",
    "#     k = 0.5\n",
    "#     lr = lr * math.exp(-k*epoch)\n",
    "#     print(lr)\n",
    "#     return lr\n",
    "    \n",
    "# def lr_step_based_decay(epoch, lr=.001):\n",
    "#     drop_rate = 0.1\n",
    "#     epochs_drop = 3\n",
    "#     epochs_drop_rate=3\n",
    "\n",
    "#     # lr = lr * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "#     lr = lr * drop_rate ** (int(np.emath.logn(epochs_drop, epoch+1)))\n",
    "#     print(lr)\n",
    "#     return lr\n",
    "\n",
    "# def lr_cyclic_step_based_decay(epoch, lr=0.001):\n",
    "    \n",
    "#     new_epoch = epoch%5\n",
    "#     # initial_learning_rate=0.001 #0.0001, epoch 20 gives 10%\n",
    "#     drop_rate = 0.5\n",
    "#     epochs_drop = 1\n",
    "#     lr = lr * math.pow(drop_rate, math.floor(new_epoch/epochs_drop))\n",
    "#     print(lr)\n",
    "#     return lr\n",
    "\n",
    "# def lr_exp_decay_step_based_decay(epoch, lr=0.001):\n",
    "#     initial_learning_rate=0.001\n",
    "    \n",
    "#     if epoch<3:\n",
    "#         k = 0.3\n",
    "#         lr = initial_learning_rate * math.exp(-k*epoch)\n",
    "    \n",
    "#     else:\n",
    "#         drop_rate = 0.5\n",
    "#         epochs_drop = 1\n",
    "#         lr = lr * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "#     print(lr)\n",
    "#     return lr\n",
    "\n",
    "# def lr_poly_scheduler(epoch, lr=0.001):\n",
    "#     decay_rate = 10\n",
    "#     lr=lr * (1 - epoch/50) ** decay_rate\n",
    "#     print(lr)\n",
    "#     return lr\n",
    "\n",
    "# # define the learning rate scheduler callback\n",
    "\n",
    "# def lr_schedule(epoch):\n",
    "#     if epoch < 3:\n",
    "#         return 0.001\n",
    "#     else:\n",
    "#         return 0.001 - (epoch - 2) * 0.0001\n",
    "    \n",
    "    \n",
    "# # lr_scheduler = lr_exp_decay(lr_exp_decay)\n",
    "\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='eer_val', factor=0.01,\n",
    "#                               patience=0, min_lr=0.000000001, verbose=1)\n",
    "\n",
    "# # lr_schedule = tf.keras.experimental.CosineDecay(0.0001, 10)\n",
    "# # lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "# # lr_schedule(tf.range(30, dtype=tf.float32))\n",
    "\n",
    "# x = np.arange(50)\n",
    "# y = map(lr_exp_decay, x)\n",
    "# sns.lineplot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "len(exp1_df_train_dict): 19\n",
      "len(exp2_df_train_dict): 19\n",
      "len(exp1_df_test_dict): 10\n",
      "len(exp2_df_test_dict): 10\n",
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1305/3451180807.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_1.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n",
      "/tmp/ipykernel_1305/601587177.py:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(f'{os.getcwd()}/WACA_dataset/user{i}_2.csv', error_bad_lines = False, header=None, usecols = range(len(names)), dtype = str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47) accel_count: 17718, gyro_count: 18353\n",
      "29\n",
      "[ 1  3  5  6  7  8 11 13 16 17 19 20 21 22 24 25 26 27 28 29]\n",
      "dict_keys([7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 29])\n",
      "train set: dict_keys([7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6])\n",
      "validation set: dict_keys([25, 16, 1, 17, 27, 5, 29])\n",
      "train set: dict_keys([7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6])\n",
      "validation set: dict_keys([25, 16, 1, 17, 27, 5, 29])\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "user_47_idx: 29\n",
      "np.unique(all_user_set): [ 1  2  3  4  5  6  7  8 19 21 22 26 27 28 29 35 36 37 38 39 40 41 42 43\n",
      " 44 45 46 48 49]\n",
      "X_exp1_dict.keys(): dict_keys([7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 29])\n",
      "X_exp2_dict.keys(): dict_keys([7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 29])\n",
      "fitted_scaler_exp2_dict.keys(): dict_keys([7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 29])\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "verifying user_key: 7\n",
      "verifying user_key: 24\n",
      "verifying user_key: 8\n",
      "verifying user_key: 11\n",
      "verifying user_key: 13\n",
      "verifying user_key: 19\n",
      "verifying user_key: 28\n",
      "verifying user_key: 21\n",
      "verifying user_key: 26\n",
      "verifying user_key: 3\n",
      "verifying user_key: 20\n",
      "verifying user_key: 22\n",
      "verifying user_key: 6\n",
      "verifying user_key: 25\n",
      "verifying user_key: 16\n",
      "verifying user_key: 1\n",
      "verifying user_key: 17\n",
      "verifying user_key: 27\n",
      "verifying user_key: 5\n",
      "verifying user_key: 29\n",
      "no err train dicts\n",
      "verifying user_key: 0\n",
      "verifying user_key: 12\n",
      "verifying user_key: 14\n",
      "verifying user_key: 9\n",
      "verifying user_key: 18\n",
      "verifying user_key: 23\n",
      "verifying user_key: 2\n",
      "verifying user_key: 15\n",
      "verifying user_key: 10\n",
      "verifying user_key: 4\n",
      "no err test dicts\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x792 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This test was passed in earlier versions of the file, since we modifed prep_x_y and get_raw_windows_user_47, the test does not hold, as get_raw_windows_user_47 now takes care of the shorter\n",
    "# stream length of user_47 data\n",
    "if TEST_MODE:\n",
    "    \n",
    "#     user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
    "#     exp_begin_cutoff_idx = 500\n",
    "#     exp_end_cutoff_idx = -500\n",
    "#     num_sample_points_per_exp = 21000\n",
    "#     df_exps_dict = load_data_frames(user_ids, exp_begin_cutoff_idx, exp_end_cutoff_idx, num_sample_points_per_exp)\n",
    "#     dfList_exp1, dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']\n",
    "    \n",
    "#     raw_dfList_exp1 = dfList_exp1\n",
    "#     raw_dfList_exp2 = dfList_exp2\n",
    "\n",
    "    smoothing = \"FFT\"\n",
    "    cut_off_freq=25\n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=cut_off_freq, filter_order=10, filtfilt=1)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=cut_off_freq, filter_order=10, filtfilt=1)\n",
    "    raw_dfList_exp2[0]['x_a'][0:1000].plot()\n",
    "    ffted_dfList_exp2[0]['x_a'][0:1000].plot()\n",
    "    # get_ffted_dfList([raw_dfList_exp2[0][raw_dfList_exp2[0].columns][500:1000]], cut_off_freq=P.cut_off_freq, filter_order=10)[0]['EMA_x_a'].plot()\n",
    "    dfList_exp1 = ffted_dfList_exp1\n",
    "    dfList_exp2 = ffted_dfList_exp2\n",
    "\n",
    "    span=49\n",
    "    # P.smoothing = \"FFT+EMA\"\n",
    "    # # raw_dfList_exp1 = dfList_exp1\n",
    "    # # raw_dfList_exp2 = dfList_exp2\n",
    "    # P.cut_off_freq=42\n",
    "    # ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=10)\n",
    "    # ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=10)\n",
    "    # ffted_dfList_exp2[0]['EMA_x_a'][500:1000].plot()\n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=span)\n",
    "    # EMAed_dfList_exp2[0]['EMA_x_a'][500:1000].plot()\n",
    "    # dfList_exp1 = EMAed_dfList_exp1\n",
    "    # dfList_exp2 = EMAed_dfList_exp2\n",
    "    raw_dfList_exp2[0]['x_a'][500:1000].rolling(window=30, min_periods=0).mean()[:].plot()\n",
    "    raw_dfList_exp2[0]['x_a'][500:1000].ewm(span=30, adjust=False).mean()[:].plot()\n",
    "    \n",
    "    randomized_data_idx = list(range(len(user_ids)))\n",
    "    random.Random(SEED).shuffle(randomized_data_idx)\n",
    "    split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "    train_set = randomized_data_idx[: split_idx]\n",
    "    test_set = randomized_data_idx[split_idx: ]\n",
    "    print(f\"train_set: {train_set}\\ntest_set: {test_set}\")\n",
    "    \n",
    "    # preparing train data\n",
    "    \n",
    "    \n",
    "    window_size = 500\n",
    "    nn_step_width = window_size//2\n",
    "    ocsvm_step_width = window_size//2\n",
    "    scaler = \"RobustScaler\"\n",
    "\n",
    "\n",
    "    # train_set = r\n",
    "    exp1_df_train_dict, exp2_df_train_dict = {user_key: dfList_exp1[user_key] for user_key in train_set}, {user_key: dfList_exp2[user_key] for user_key in train_set}\n",
    "    print(f\"len(exp1_df_train_dict): {len(exp1_df_train_dict)}\")\n",
    "    print(f\"len(exp2_df_train_dict): {len(exp2_df_train_dict)}\")\n",
    "    # Raw_X_Exp_Train_Dict = MakeRawXExpDic(exp1_df_train_dict, exp2_df_train_dict, window_size=P.window_size, step=P.nn_step_width, numSamplePoints=P.num_sample_points_per_exp, \n",
    "    #                                       scale_exp1=True, scale_exp2=True, scaler=P.scaler)\n",
    "    # ---- new, realistic way\n",
    "    Raw_X_Exp_Train_Dict = MakeRawXExpDict_old(exp1_df_train_dict, exp2_df_train_dict, window_size=window_size, step=nn_step_width, numSamplePoints=num_sample_points_per_exp, \n",
    "                                          scale_exp1=False, scale_exp2=True, scaler=scaler)\n",
    "\n",
    "    fitted_scaler_SNN_exp2_train_dic = Raw_X_Exp_Train_Dict[\"fitted_scaler_exp2_dic\"]\n",
    "    # -----new\n",
    "    Raw_X_exp1_train_dic, Raw_X_exp2_train_dic = Raw_X_Exp_Train_Dict[\"Raw_X_exp1_dic\"], Raw_X_Exp_Train_Dict[\"Raw_X_exp2_dic\"]\n",
    "\n",
    "    # preparing test data\n",
    "    exp1_df_test_dict, exp2_df_test_dict = {user_key: dfList_exp1[user_key] for user_key in test_set}, {user_key: dfList_exp2[user_key] for user_key in test_set}\n",
    "    print(f\"len(exp1_df_test_dict): {len(exp1_df_test_dict)}\")\n",
    "    print(f\"len(exp2_df_test_dict): {len(exp2_df_test_dict)}\")\n",
    "    Raw_X_Exp_Test_Dict = MakeRawXExpDict_old(exp1_df_test_dict, exp2_df_test_dict, window_size=window_size, step=ocsvm_step_width, numSamplePoints=num_sample_points_per_exp, \n",
    "                                         scale_exp1=False, scale_exp2=True, scaler=scaler)\n",
    "\n",
    "    fitted_scaler_ocsvm_exp2_dic = Raw_X_Exp_Test_Dict[\"fitted_scaler_exp2_dic\"]\n",
    "    Raw_X_exp1_test_dic, Raw_X_exp2_test_dic = Raw_X_Exp_Test_Dict[\"Raw_X_exp1_dic\"], Raw_X_Exp_Test_Dict[\"Raw_X_exp2_dic\"]\n",
    "\n",
    "\n",
    "\n",
    "    num_sample_points_per_exp_user_47 = 18000\n",
    "    df_exps_dict_user_47 = load_data_frames([47], exp_begin_cutoff_idx, exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "    dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "    raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "    raw_dfList_exp2_user_47 = dfList_exp2_user_47\n",
    "\n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=cut_off_freq, filter_order=10, filtfilt=1)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=cut_off_freq, filter_order=10, filtfilt=1)\n",
    "    ffted_dfList_exp2_user_47[0]['x_a'][500:1000].plot()\n",
    "    dfList_exp1_user_47 = ffted_dfList_exp1_user_47\n",
    "    dfList_exp2_user_47 = ffted_dfList_exp2_user_47\n",
    "    # EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "    # EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    # EMAed_dfList_exp2_user_47[0]['EMA_x_a'][500:1000].plot()\n",
    "    # dfList_exp1_user_47 = EMAed_dfList_exp1_user_47\n",
    "    # dfList_exp2_user_47 = EMAed_dfList_exp2_user_47\n",
    "    exp1_df_dict_user_47, exp2_df_dict_user_47 = {47: dfList_exp1_user_47[0]}, {47: dfList_exp2_user_47[0]}\n",
    "    Raw_X_Exp_Train_Dict_user_47 = MakeRawXExpDict_old(exp1_df_dict_user_47, exp2_df_dict_user_47, window_size=window_size, step=nn_step_width, numSamplePoints=num_sample_points_per_exp_user_47, \n",
    "                                          scale_exp1=False, scale_exp2=True, scaler=scaler)\n",
    "\n",
    "    fitted_scaler_SNN_exp2_train_dic_user_47 = Raw_X_Exp_Train_Dict_user_47[\"fitted_scaler_exp2_dic\"]\n",
    "    # -----new\n",
    "    Raw_X_exp1_train_dic_user_47, Raw_X_exp2_train_dic_user_47 = Raw_X_Exp_Train_Dict_user_47[\"Raw_X_exp1_dic\"], Raw_X_Exp_Train_Dict_user_47[\"Raw_X_exp2_dic\"]\n",
    "\n",
    "\n",
    "\n",
    "    user_47_idx = len(user_ids)\n",
    "    print(user_47_idx)\n",
    "    if user_47_idx not in train_set:\n",
    "        train_set.append(user_47_idx)\n",
    "    print(np.unique(train_set))\n",
    "    user_47_key = user_47_idx\n",
    "    Raw_X_Exp_Train_Dict[\"Raw_X_exp1_dic\"][user_47_key] = Raw_X_Exp_Train_Dict_user_47[\"Raw_X_exp1_dic\"][47]\n",
    "    Raw_X_Exp_Train_Dict[\"Raw_X_exp2_dic\"][user_47_key] = Raw_X_Exp_Train_Dict_user_47[\"Raw_X_exp2_dic\"][47]\n",
    "    Raw_X_Exp_Train_Dict['fitted_scaler_exp1_dic'][user_47_key] = Raw_X_Exp_Train_Dict_user_47['fitted_scaler_exp1_dic'][47]\n",
    "    Raw_X_Exp_Train_Dict['fitted_scaler_exp2_dic'][user_47_key] = Raw_X_Exp_Train_Dict_user_47['fitted_scaler_exp2_dic'][47]\n",
    "\n",
    "    print(Raw_X_Exp_Train_Dict['Raw_X_exp1_dic'].keys())\n",
    "    fitted_scaler_SNN_exp2_train_dic = Raw_X_Exp_Train_Dict[\"fitted_scaler_exp2_dic\"]\n",
    "    # -----new\n",
    "    Raw_X_exp1_train_dic, Raw_X_exp2_train_dic = Raw_X_Exp_Train_Dict[\"Raw_X_exp1_dic\"], Raw_X_Exp_Train_Dict[\"Raw_X_exp2_dic\"]\n",
    "\n",
    "\n",
    "    spliter = 2*len(Raw_X_exp2_train_dic)//3\n",
    "    cnn_train_exp2 = {key: Raw_X_exp2_train_dic[key] for key in list(Raw_X_exp2_train_dic.keys())[:spliter]}\n",
    "    cnn_train_exp1 = {key: Raw_X_exp1_train_dic[key] for key in list(Raw_X_exp1_train_dic.keys())[:spliter]}\n",
    "    cnn_valid_exp2 = {key: Raw_X_exp2_train_dic[key] for key in list(Raw_X_exp2_train_dic.keys())[spliter:]}\n",
    "    cnn_valid_exp1 = {key: Raw_X_exp1_train_dic[key] for key in list(Raw_X_exp1_train_dic.keys())[spliter:]}\n",
    "\n",
    "\n",
    "    print(f\"train set: {cnn_train_exp2.keys()}\\nvalidation set: {cnn_valid_exp2.keys()}\")\n",
    "    print(f\"train set: {cnn_train_exp1.keys()}\\nvalidation set: {cnn_valid_exp1.keys()}\")\n",
    "\n",
    "\n",
    "    X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict=get_raw_windows_3(dfList_exp1, dfList_exp2, window_size, nn_step_width, train_set[:-1], \n",
    "                                                                        scaler, num_sample_points_per_exp, EMA_per_win_span=None, SMA_per_win_winsize=None)\n",
    "\n",
    "    X_exp1_dict_user_47, X_exp2_dict_user_47, fitted_scaler_exp2_dict_user_47=get_raw_windows_user_47(dfList_exp1_user_47, dfList_exp2_user_47, window_size, nn_step_width, \n",
    "                                                                                                      scaler=scaler, num_sample_points_per_exp=18000, \n",
    "                                                                                                      EMA_per_win_span=None, SMA_per_win_winsize=None)\n",
    "\n",
    "    X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict=append_user_47_to_data(X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict, user_ids, X_exp1_dict_user_47, X_exp2_dict_user_47, \n",
    "                                                                             fitted_scaler_exp2_dict_user_47, verbose=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # preparing test data\n",
    "    X_test_exp1_dict, X_test_exp2_dict, fitted_scaler_test_exp2_dict=get_raw_windows_3(dfList_exp1, dfList_exp2, window_size, ocsvm_step_width, test_set, \n",
    "                                                                        scaler, num_sample_points_per_exp, EMA_per_win_span=None, SMA_per_win_winsize=None)\n",
    "\n",
    "    assert fitted_scaler_SNN_exp2_train_dic.keys()==fitted_scaler_exp2_dict.keys()\n",
    "    assert Raw_X_exp2_train_dic.keys()==X_exp1_dict.keys()\n",
    "    assert Raw_X_exp1_train_dic.keys()==X_exp2_dict.keys()\n",
    "    for user_key in Raw_X_exp2_train_dic:\n",
    "        print(f\"verifying user_key: {user_key}\")\n",
    "        for df_idx in range(len(Raw_X_exp2_train_dic[user_key])):\n",
    "            try:\n",
    "                assert_frame_equal(Raw_X_exp1_train_dic[user_key][df_idx], X_exp1_dict[user_key][df_idx])\n",
    "                assert_frame_equal(Raw_X_exp2_train_dic[user_key][df_idx], X_exp2_dict[user_key][df_idx])\n",
    "            except:\n",
    "                print(f\"user_key: {user_key}, df_idx: {df_idx}\")\n",
    "    # assert Raw_X_exp1_train_dic[1]==X_exp2_dict[1]\n",
    "    print(\"no err train dicts\")\n",
    "    \n",
    "    assert fitted_scaler_ocsvm_exp2_dic.keys()==fitted_scaler_test_exp2_dict.keys()\n",
    "    assert Raw_X_exp2_test_dic.keys()==X_test_exp1_dict.keys()\n",
    "    assert Raw_X_exp1_test_dic.keys()==X_test_exp2_dict.keys()\n",
    "    for user_key in Raw_X_exp2_test_dic:\n",
    "        print(f\"verifying user_key: {user_key}\")\n",
    "        for df_idx in range(len(Raw_X_exp2_test_dic[user_key])):\n",
    "            try:\n",
    "                assert_frame_equal(Raw_X_exp1_test_dic[user_key][df_idx], X_test_exp1_dict[user_key][df_idx])\n",
    "                assert_frame_equal(Raw_X_exp2_test_dic[user_key][df_idx], X_test_exp2_dict[user_key][df_idx])\n",
    "            except:\n",
    "                print(f\"user_key: {user_key}, df_idx: {df_idx}\")\n",
    "    # assert Raw_X_exp1_train_dic[1]==X_exp2_dict[1]\n",
    "    print(\"no err test dicts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
