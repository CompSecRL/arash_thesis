{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "EXP_PATH_NAME=\"WACA-IF\"\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "Numpy Seed was set to: 567\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "from sklearn.svm import OneClassSVM\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "%run ./Classification_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "RIVAL_CLASSIFIER_TYPE_LST=[\"OCSVM\", \"kNN\", \"LOF\"]\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"Numpy Seed was set to: {SEED}\")\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__dir__()\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "        \n",
    "    user_ids: list\n",
    "    num_sample_points_per_exp: int\n",
    "    exp_begin_cutoff_idx: int\n",
    "    exp_end_cutoff_idx: int\n",
    "        \n",
    "    \n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    window_size: int  # After resampling\n",
    "    ocsvm_step_width: int  # After resampling\n",
    "    scaler: str  # StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_kernel: str # ocsvm kernel\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects=29,\n",
    "    max_test_subjects=10,\n",
    "    user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49],\n",
    "    num_sample_points_per_exp=21000,\n",
    "    exp_begin_cutoff_idx=500,\n",
    "    exp_end_cutoff_idx=-500,\n",
    "    seconds_per_subject_train=210,\n",
    "    seconds_per_subject_test=210,    \n",
    "    window_size=250,\n",
    "    ocsvm_step_width=250,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_kernel=\"rbf\",\n",
    "    ocsvm_nu=None,\n",
    "    ocsvm_gamma=None,\n",
    "    feature_cols=[\n",
    "        \"x_a\",\n",
    "        \"y_a\",\n",
    "        \"z_a\",\n",
    "        \"x_g\",\n",
    "        \"y_g\",\n",
    "        \"z_g\",\n",
    "    ],\n",
    "    exclude_subjects=[],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM_125 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=125\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "\n",
    "VALID_ROBUST_OCSVM_250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_2000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=2000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "# NORMALIZER_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_NORMALIZER_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-NORMALIZER-OCSVM\",\n",
    "    scaler=\"Normalizer\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.074,\n",
    "    ocsvm_gamma= 0.029,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM_2000\n",
    "P.ocsvm_step_width = int(P.window_size * .5)\n",
    "P.classifier=\"IF\"\n",
    "\n",
    "P.train_cores=1 # 20 cores for every user and 1 core for the nested crossval function\n",
    "P.test_cores=2 # 10 cores for every user and 2 for the nested crossval function\n",
    "\n",
    "P.scaler_clip=False\n",
    "P.is_NN=False\n",
    "\n",
    "# param_dist\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": np.linspace(50, 200, num=10, dtype=np.int64),\n",
    "    'model__max_samples':  np.arange(0.1, 1.1, 0.1),\n",
    "    'model__contamination': np.arange(0.01, 0.11, 0.01),\n",
    "    'model__max_features': np.arange(0.1, 1.1, 0.1),\n",
    "    # 'model__bootstrap': [True, False], \n",
    "    }\n",
    "\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [10],\n",
    "    'model__max_samples':  np.arange(0.1, 1.1, 0.1),\n",
    "    'model__contamination': np.arange(0.01, 0.11, 0.01),\n",
    "    'model__max_features': np.arange(0.1, 1.1, 0.1),\n",
    "    # 'model__bootstrap': [True, False], \n",
    "    }\n",
    "\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [50, 100, 150, 200],\n",
    "    'model__max_samples':  np.arange(0.1, 1.01, 0.1),\n",
    "    'model__contamination': np.linspace(0.0001, 0.1, 50),\n",
    "    'model__max_features': np.arange(0.1, 1.01, 0.1),\n",
    "    'model__warm_start': [False], \n",
    "    }\n",
    "\n",
    "# param_dist = {\n",
    "#     \"model__n_estimators\": [50, 100, 150, 200], #np.linspace(50, 200, num=10, dtype=np.int64),\n",
    "#     'model__max_samples':  [.5,  .1],\n",
    "#     'model__contamination': [0.01],\n",
    "#     'model__max_features': [.5, 1.0],\n",
    "#     'model__warm_start': [True], \n",
    "#     }\n",
    "\n",
    "# param_dist = {\n",
    "#     \"model__n_estimators\": [50, 100], #np.linspace(50, 200, num=10, dtype=np.int64),\n",
    "#     'model__max_samples':  [.1],\n",
    "#     'model__contamination': [0.01],\n",
    "#     'model__max_features': [.5, 1.0],\n",
    "#     'model__warm_start': [True], \n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': [50, 100, 150, 200],\n",
       " 'model__max_samples': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " 'model__contamination': array([0.0001    , 0.00213878, 0.00417755, 0.00621633, 0.0082551 ,\n",
       "        0.01029388, 0.01233265, 0.01437143, 0.0164102 , 0.01844898,\n",
       "        0.02048776, 0.02252653, 0.02456531, 0.02660408, 0.02864286,\n",
       "        0.03068163, 0.03272041, 0.03475918, 0.03679796, 0.03883673,\n",
       "        0.04087551, 0.04291429, 0.04495306, 0.04699184, 0.04903061,\n",
       "        0.05106939, 0.05310816, 0.05514694, 0.05718571, 0.05922449,\n",
       "        0.06126327, 0.06330204, 0.06534082, 0.06737959, 0.06941837,\n",
       "        0.07145714, 0.07349592, 0.07553469, 0.07757347, 0.07961224,\n",
       "        0.08165102, 0.0836898 , 0.08572857, 0.08776735, 0.08980612,\n",
       "        0.0918449 , 0.09388367, 0.09592245, 0.09796122, 0.1       ]),\n",
       " 'model__max_features': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " 'model__warm_start': [False]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>VALID-ROBUST-OCSVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_subjects</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_test_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_ids</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sample_points_per_exp</th>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_begin_cutoff_idx</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_end_cutoff_idx</th>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_train</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_test</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_step_width</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_scope</th>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_global</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_kernel</th>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_nu</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_gamma</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_cols</th>\n",
       "      <td>[x_a, y_a, z_a, x_g, y_g, z_g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclude_subjects</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Value\n",
       "name                                                      VALID-ROBUST-OCSVM\n",
       "frequency                                                                100\n",
       "max_subjects                                                              29\n",
       "max_test_subjects                                                         10\n",
       "user_ids                   [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...\n",
       "num_sample_points_per_exp                                              21000\n",
       "exp_begin_cutoff_idx                                                     500\n",
       "exp_end_cutoff_idx                                                      -500\n",
       "seconds_per_subject_train                                                210\n",
       "seconds_per_subject_test                                                 210\n",
       "window_size                                                             2000\n",
       "ocsvm_step_width                                                        1000\n",
       "scaler                                                          RobustScaler\n",
       "scaler_scope                                                         subject\n",
       "scaler_global                                                          False\n",
       "ocsvm_kernel                                                             rbf\n",
       "ocsvm_nu                                                                None\n",
       "ocsvm_gamma                                                             None\n",
       "feature_cols                                  [x_a, y_a, z_a, x_g, y_g, z_g]\n",
       "exclude_subjects                                                          []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(utils_eer, greater_is_better=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_eer_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n",
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n",
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n",
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n",
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n",
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n",
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n",
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n",
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n",
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n",
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n",
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n",
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n",
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n",
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n",
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n",
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n",
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n",
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n",
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n",
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n",
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n",
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n",
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n",
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n",
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n",
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n",
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n",
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n"
     ]
    }
   ],
   "source": [
    "#include 47 later\n",
    "# user_ids = [9]\n",
    "df_exps_dict = load_data_frames(P.user_ids, P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, P.num_sample_points_per_exp)\n",
    "raw_dfList_exp1, raw_dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n",
      "47) accel_count: 17718, gyro_count: 18353\n"
     ]
    }
   ],
   "source": [
    "num_sample_points_per_exp_user_47 = 18000\n",
    "df_exps_dict_user_47 = load_data_frames([47], P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "raw_dfList_exp2_user_47 = dfList_exp2_user_47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. No Smoothing\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = None\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=None\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": raw_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\"]\n",
    "min_key=DASH_MACRO_NUM\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Butterworth frequency Cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "min_key=P.cut_off_freq\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": ffted_dfList_exp1,\n",
    "            \"dfList_exp2\": ffted_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "    \n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": ffted_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                    param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "min_key=P.cut_off_freq\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": ffted_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "    \n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    \n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "\n",
    "\n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Butterworth frequency Cut-off + EMA span\n",
    "## 2.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "min_key= P.cut_off_freq, P.span\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P.smoothing = \"Butter+EMA\" \n",
    "preprocessing_method=\"Naive\"\n",
    "\n",
    "rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-kNN/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "rival_test_hyperparameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "    key_pair= P.cut_off_freq, P.span, clf_type\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key[:-1]] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key[:-1]].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "P.EMA_per_win_span=P.span\n",
    "\n",
    "min_key= P.cut_off_freq, P.span\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    key_pair= P.cut_off_freq, P.span, clf_type\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key[:-1]] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key[:-1]].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EMA span\n",
    "## 3.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "min_key=P.span\n",
    "print(f\"EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "\n",
    "EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "rival_test_hyperparameters_df\n",
    "print(rival_test_hyperparameters_file_name)\n",
    "print(RIVAL_CLASSIFIER_TYPE_LST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                    param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "    \n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "P.EMA_per_win_span=P.span\n",
    "min_key=P.span\n",
    "print(f\"EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                    param_dist=param_dist) \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SMA winsize\n",
    "## 4.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "min_key=P.winsize\n",
    "print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                       param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.SMA_per_win_winsize=P.winsize\n",
    "min_key=P.winsize\n",
    "print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                       param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Butterworth frequency Cut-off + SMA winsize\n",
    "## 5.1 Naive Approach\n",
    "### Optimizing and Testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "min_key= P.cut_off_freq, P.winsize\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    \n",
    "    key_pair= P.cut_off_freq, P.winsize, clf_type\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key[:-1]] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key[:-1]].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "min_key= P.cut_off_freq, P.winsize\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    \n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "    \n",
    "    key_pair= P.cut_off_freq, P.winsize, clf_type\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "\n",
    "EER_df_test_dict[min_key[:-1]] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key[:-1]].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The effect of Varying Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap: 0.01\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  10.639008737169206\n",
      "MakeWACAXExpDicUnknown Time:  122.17002968676388\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 3849.93it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [19:38<39:17, 1178.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22770.38it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [40:41<20:28, 1228.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16313.90it/s]\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": raw_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "for overlap in tqdm(OVERLAP_EXP_RANGE):\n",
    "\n",
    "    train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap={overlap}_Mean_EER_df_train_dict.txt\"\n",
    "    test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap={overlap}_Mean_EER_df_test_dict.txt\"\n",
    "    \n",
    "    with open(train_file_name, \"w\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    with open(test_file_name, \"w\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "    overlap*=0.01\n",
    "    print(f\"overlap: {overlap}\")\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "\n",
    "\n",
    "    key_column= [\"overlap\"]\n",
    "    #-----CV_FOLD-------\n",
    "    for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "        process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                    cv_fold_idx=cv_fold_idx, \n",
    "                                    cv_sets=THREE_FOLD_CV, \n",
    "                                    dfList_dict=dfList_dict, \n",
    "                                    window_size_lst=WINDOW_SIZE_LST, \n",
    "                                    exp_config=P, \n",
    "                                    extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                    overlap=overlap, \n",
    "                                    param_dist=param_dist, \n",
    "                                    train_file_name=train_file_name, \n",
    "                                    test_file_name=test_file_name, \n",
    "                                    preprocessing_params=overlap, \n",
    "                                    key_column=key_column,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for overlap in tqdm(OVERLAP_EXP_RANGE):\n",
    "    overlap*=0.01\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "    max_num_windows=max(len(getIndices(sampleSize=max_window_size, step=step_width, numSamplePoints=P.num_sample_points_per_exp)), 100)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[overlap] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                     extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                     param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\overlap: {overlap}\\n\")\n",
    "        f.write(EER_df_train_dict[overlap].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"overlap\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 EER per window for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_EXP_RESULTS_PATH\n",
    "EXP_PATH_NAME\n",
    "# WINDOW_SIZE_LST\n",
    "%run ./Classification_utility-functions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip=False-Smoothing=None-Prep=None-EER_df_test_dict_raw_df_cv0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th colspan=\"9\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>1250</th>\n",
       "      <th>1500</th>\n",
       "      <th>1750</th>\n",
       "      <th>2000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.239770</td>\n",
       "      <td>0.190747</td>\n",
       "      <td>0.164511</td>\n",
       "      <td>0.145838</td>\n",
       "      <td>0.144589</td>\n",
       "      <td>0.133275</td>\n",
       "      <td>0.134019</td>\n",
       "      <td>0.135185</td>\n",
       "      <td>0.134352</td>\n",
       "      <td>0.158032</td>\n",
       "      <td>0.001299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.232656</td>\n",
       "      <td>0.183976</td>\n",
       "      <td>0.153271</td>\n",
       "      <td>0.142606</td>\n",
       "      <td>0.143695</td>\n",
       "      <td>0.130185</td>\n",
       "      <td>0.129698</td>\n",
       "      <td>0.128937</td>\n",
       "      <td>0.125278</td>\n",
       "      <td>0.152256</td>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.233231</td>\n",
       "      <td>0.188434</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0.145380</td>\n",
       "      <td>0.140542</td>\n",
       "      <td>0.131343</td>\n",
       "      <td>0.128656</td>\n",
       "      <td>0.124348</td>\n",
       "      <td>0.125796</td>\n",
       "      <td>0.152529</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>37</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.196879</td>\n",
       "      <td>0.167937</td>\n",
       "      <td>0.141428</td>\n",
       "      <td>0.130236</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>0.115694</td>\n",
       "      <td>0.123978</td>\n",
       "      <td>0.122625</td>\n",
       "      <td>0.117111</td>\n",
       "      <td>0.136985</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.245663</td>\n",
       "      <td>0.200741</td>\n",
       "      <td>0.157474</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.137118</td>\n",
       "      <td>0.132222</td>\n",
       "      <td>0.137545</td>\n",
       "      <td>0.128728</td>\n",
       "      <td>0.135426</td>\n",
       "      <td>0.157735</td>\n",
       "      <td>0.001572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>41</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.198859</td>\n",
       "      <td>0.172240</td>\n",
       "      <td>0.150464</td>\n",
       "      <td>0.138936</td>\n",
       "      <td>0.128383</td>\n",
       "      <td>0.123322</td>\n",
       "      <td>0.138409</td>\n",
       "      <td>0.130853</td>\n",
       "      <td>0.128611</td>\n",
       "      <td>0.145564</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.242983</td>\n",
       "      <td>0.193176</td>\n",
       "      <td>0.164583</td>\n",
       "      <td>0.147044</td>\n",
       "      <td>0.144481</td>\n",
       "      <td>0.132477</td>\n",
       "      <td>0.134170</td>\n",
       "      <td>0.135314</td>\n",
       "      <td>0.134556</td>\n",
       "      <td>0.158754</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.192808</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>0.142838</td>\n",
       "      <td>0.134808</td>\n",
       "      <td>0.118753</td>\n",
       "      <td>0.121192</td>\n",
       "      <td>0.125171</td>\n",
       "      <td>0.128889</td>\n",
       "      <td>0.126352</td>\n",
       "      <td>0.139408</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.236955</td>\n",
       "      <td>0.197199</td>\n",
       "      <td>0.154873</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.140551</td>\n",
       "      <td>0.137326</td>\n",
       "      <td>0.130850</td>\n",
       "      <td>0.124364</td>\n",
       "      <td>0.126389</td>\n",
       "      <td>0.154760</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>-</td>\n",
       "      <td>34</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.207071</td>\n",
       "      <td>0.178235</td>\n",
       "      <td>0.148220</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.120116</td>\n",
       "      <td>0.126927</td>\n",
       "      <td>0.123188</td>\n",
       "      <td>0.124519</td>\n",
       "      <td>0.143848</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.237110</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0.153971</td>\n",
       "      <td>0.142498</td>\n",
       "      <td>0.139178</td>\n",
       "      <td>0.137535</td>\n",
       "      <td>0.132716</td>\n",
       "      <td>0.122995</td>\n",
       "      <td>0.128537</td>\n",
       "      <td>0.153484</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Window Size            \\\n",
       "   mean rank cut_off_freq EMA_span SMA_winsize   type         125       250   \n",
       "0         10            -        -           -      -    0.239770  0.190747   \n",
       "1          5           37        -           -  Naive    0.232656  0.183976   \n",
       "2          6           49        -           -   Real    0.233231  0.188434   \n",
       "3          1            -       37           -  Naive    0.196879  0.167937   \n",
       "4          9            -        9           -   Real    0.245663  0.200741   \n",
       "5          4            -        -          41  Naive    0.198859  0.172240   \n",
       "6         11            -        -           1   Real    0.242983  0.193176   \n",
       "7          2           41       48           -  Naive    0.192808  0.163859   \n",
       "8          8           40        3           -   Real    0.236955  0.197199   \n",
       "9          3           43        -          34  Naive    0.207071  0.178235   \n",
       "10         7           26        -           2   Real    0.237110  0.186815   \n",
       "\n",
       "                                                                          \\\n",
       "         500       750      1000      1250      1500      1750      2000   \n",
       "0   0.164511  0.145838  0.144589  0.133275  0.134019  0.135185  0.134352   \n",
       "1   0.153271  0.142606  0.143695  0.130185  0.129698  0.128937  0.125278   \n",
       "2   0.155029  0.145380  0.140542  0.131343  0.128656  0.124348  0.125796   \n",
       "3   0.141428  0.130236  0.116974  0.115694  0.123978  0.122625  0.117111   \n",
       "4   0.157474  0.144700  0.137118  0.132222  0.137545  0.128728  0.135426   \n",
       "5   0.150464  0.138936  0.128383  0.123322  0.138409  0.130853  0.128611   \n",
       "6   0.164583  0.147044  0.144481  0.132477  0.134170  0.135314  0.134556   \n",
       "7   0.142838  0.134808  0.118753  0.121192  0.125171  0.128889  0.126352   \n",
       "8   0.154873  0.144330  0.140551  0.137326  0.130850  0.124364  0.126389   \n",
       "9   0.148220  0.141401  0.124959  0.120116  0.126927  0.123188  0.124519   \n",
       "10  0.153971  0.142498  0.139178  0.137535  0.132716  0.122995  0.128537   \n",
       "\n",
       "                        \n",
       "        mean  variance  \n",
       "0   0.158032  0.001299  \n",
       "1   0.152256  0.001238  \n",
       "2   0.152529  0.001316  \n",
       "3   0.136985  0.000779  \n",
       "4   0.157735  0.001572  \n",
       "5   0.145564  0.000621  \n",
       "6   0.158754  0.001386  \n",
       "7   0.139408  0.000591  \n",
       "8   0.154760  0.001434  \n",
       "9   0.143848  0.000901  \n",
       "10  0.153484  0.001333  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=return_and_save_final_result_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.239770</td>\n",
       "      <td>0.190747</td>\n",
       "      <td>0.164511</td>\n",
       "      <td>0.145838</td>\n",
       "      <td>0.144589</td>\n",
       "      <td>0.177091</td>\n",
       "      <td>0.001577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.232656</td>\n",
       "      <td>0.183976</td>\n",
       "      <td>0.153271</td>\n",
       "      <td>0.142606</td>\n",
       "      <td>0.143695</td>\n",
       "      <td>0.171241</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.233231</td>\n",
       "      <td>0.188434</td>\n",
       "      <td>0.155029</td>\n",
       "      <td>0.145380</td>\n",
       "      <td>0.140542</td>\n",
       "      <td>0.172523</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>37</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.196879</td>\n",
       "      <td>0.167937</td>\n",
       "      <td>0.141428</td>\n",
       "      <td>0.130236</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.245663</td>\n",
       "      <td>0.200741</td>\n",
       "      <td>0.157474</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.137118</td>\n",
       "      <td>0.177139</td>\n",
       "      <td>0.002073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>41</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.198859</td>\n",
       "      <td>0.172240</td>\n",
       "      <td>0.150464</td>\n",
       "      <td>0.138936</td>\n",
       "      <td>0.128383</td>\n",
       "      <td>0.157776</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.242983</td>\n",
       "      <td>0.193176</td>\n",
       "      <td>0.164583</td>\n",
       "      <td>0.147044</td>\n",
       "      <td>0.144481</td>\n",
       "      <td>0.178453</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.192808</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>0.142838</td>\n",
       "      <td>0.134808</td>\n",
       "      <td>0.118753</td>\n",
       "      <td>0.150613</td>\n",
       "      <td>0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.236955</td>\n",
       "      <td>0.197199</td>\n",
       "      <td>0.154873</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.140551</td>\n",
       "      <td>0.174781</td>\n",
       "      <td>0.001716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>-</td>\n",
       "      <td>34</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.207071</td>\n",
       "      <td>0.178235</td>\n",
       "      <td>0.148220</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.159977</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.237110</td>\n",
       "      <td>0.186815</td>\n",
       "      <td>0.153971</td>\n",
       "      <td>0.142498</td>\n",
       "      <td>0.139178</td>\n",
       "      <td>0.171915</td>\n",
       "      <td>0.001683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Window Size            \\\n",
       "   mean rank cut_off_freq EMA_span SMA_winsize   type         125       250   \n",
       "0          9            -        -           -      -    0.239770  0.190747   \n",
       "1          5           37        -           -  Naive    0.232656  0.183976   \n",
       "2          7           49        -           -   Real    0.233231  0.188434   \n",
       "3          2            -       37           -  Naive    0.196879  0.167937   \n",
       "4         10            -        9           -   Real    0.245663  0.200741   \n",
       "5          3            -        -          41  Naive    0.198859  0.172240   \n",
       "6         11            -        -           1   Real    0.242983  0.193176   \n",
       "7          1           41       48           -  Naive    0.192808  0.163859   \n",
       "8          8           40        3           -   Real    0.236955  0.197199   \n",
       "9          4           43        -          34  Naive    0.207071  0.178235   \n",
       "10         6           26        -           2   Real    0.237110  0.186815   \n",
       "\n",
       "                                                      \n",
       "         500       750      1000      mean  variance  \n",
       "0   0.164511  0.145838  0.144589  0.177091  0.001577  \n",
       "1   0.153271  0.142606  0.143695  0.171241  0.001459  \n",
       "2   0.155029  0.145380  0.140542  0.172523  0.001501  \n",
       "3   0.141428  0.130236  0.116974  0.150691  0.001018  \n",
       "4   0.157474  0.144700  0.137118  0.177139  0.002073  \n",
       "5   0.150464  0.138936  0.128383  0.157776  0.000792  \n",
       "6   0.164583  0.147044  0.144481  0.178453  0.001678  \n",
       "7   0.142838  0.134808  0.118753  0.150613  0.000820  \n",
       "8   0.154873  0.144330  0.140551  0.174781  0.001716  \n",
       "9   0.148220  0.141401  0.124959  0.159977  0.001065  \n",
       "10  0.153971  0.142498  0.139178  0.171915  0.001683  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=return_and_save_final_result_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST_NN, save_file_suffix=\"-max1000\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Relative improvment of EER per window for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "df.style.format(STYLER_ERR_FORMAT_DICT).hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df.style.format(STYLER_IMPROVEMENT_FORMAT_DICT).hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Gini coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th colspan=\"9\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>1250</th>\n",
       "      <th>1500</th>\n",
       "      <th>1750</th>\n",
       "      <th>2000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.335525</td>\n",
       "      <td>0.382443</td>\n",
       "      <td>0.422797</td>\n",
       "      <td>0.444283</td>\n",
       "      <td>0.481188</td>\n",
       "      <td>0.491695</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>0.533526</td>\n",
       "      <td>0.454852</td>\n",
       "      <td>0.004147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.334345</td>\n",
       "      <td>0.380367</td>\n",
       "      <td>0.421546</td>\n",
       "      <td>0.453790</td>\n",
       "      <td>0.481866</td>\n",
       "      <td>0.510246</td>\n",
       "      <td>0.543939</td>\n",
       "      <td>0.540802</td>\n",
       "      <td>0.543426</td>\n",
       "      <td>0.467814</td>\n",
       "      <td>0.005829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.329424</td>\n",
       "      <td>0.370514</td>\n",
       "      <td>0.415564</td>\n",
       "      <td>0.441483</td>\n",
       "      <td>0.490492</td>\n",
       "      <td>0.509331</td>\n",
       "      <td>0.527388</td>\n",
       "      <td>0.549604</td>\n",
       "      <td>0.558650</td>\n",
       "      <td>0.465828</td>\n",
       "      <td>0.006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>37</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.411922</td>\n",
       "      <td>0.420017</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.479385</td>\n",
       "      <td>0.517618</td>\n",
       "      <td>0.514364</td>\n",
       "      <td>0.514173</td>\n",
       "      <td>0.500893</td>\n",
       "      <td>0.521120</td>\n",
       "      <td>0.480804</td>\n",
       "      <td>0.001895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.327937</td>\n",
       "      <td>0.354495</td>\n",
       "      <td>0.405440</td>\n",
       "      <td>0.441446</td>\n",
       "      <td>0.463883</td>\n",
       "      <td>0.486247</td>\n",
       "      <td>0.481957</td>\n",
       "      <td>0.487276</td>\n",
       "      <td>0.495751</td>\n",
       "      <td>0.438270</td>\n",
       "      <td>0.003856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>41</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.424465</td>\n",
       "      <td>0.432035</td>\n",
       "      <td>0.453476</td>\n",
       "      <td>0.475676</td>\n",
       "      <td>0.486337</td>\n",
       "      <td>0.506637</td>\n",
       "      <td>0.477826</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.508049</td>\n",
       "      <td>0.474200</td>\n",
       "      <td>0.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.333520</td>\n",
       "      <td>0.375218</td>\n",
       "      <td>0.422969</td>\n",
       "      <td>0.447346</td>\n",
       "      <td>0.481516</td>\n",
       "      <td>0.497658</td>\n",
       "      <td>0.505188</td>\n",
       "      <td>0.496970</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.454903</td>\n",
       "      <td>0.004401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>48</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.420102</td>\n",
       "      <td>0.428429</td>\n",
       "      <td>0.461247</td>\n",
       "      <td>0.467759</td>\n",
       "      <td>0.514398</td>\n",
       "      <td>0.521505</td>\n",
       "      <td>0.528563</td>\n",
       "      <td>0.512201</td>\n",
       "      <td>0.513685</td>\n",
       "      <td>0.485321</td>\n",
       "      <td>0.001741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.336111</td>\n",
       "      <td>0.362273</td>\n",
       "      <td>0.414233</td>\n",
       "      <td>0.442201</td>\n",
       "      <td>0.482965</td>\n",
       "      <td>0.474139</td>\n",
       "      <td>0.508701</td>\n",
       "      <td>0.542696</td>\n",
       "      <td>0.536897</td>\n",
       "      <td>0.455580</td>\n",
       "      <td>0.005373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>-</td>\n",
       "      <td>34</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.413097</td>\n",
       "      <td>0.422727</td>\n",
       "      <td>0.447351</td>\n",
       "      <td>0.461513</td>\n",
       "      <td>0.505626</td>\n",
       "      <td>0.516237</td>\n",
       "      <td>0.504336</td>\n",
       "      <td>0.524641</td>\n",
       "      <td>0.520669</td>\n",
       "      <td>0.479578</td>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.329076</td>\n",
       "      <td>0.372623</td>\n",
       "      <td>0.419319</td>\n",
       "      <td>0.449127</td>\n",
       "      <td>0.472443</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.535070</td>\n",
       "      <td>0.553866</td>\n",
       "      <td>0.459408</td>\n",
       "      <td>0.005622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Window Size            \\\n",
       "   mean rank cut_off_freq EMA_span SMA_winsize   type         125       250   \n",
       "0          2            -        -           -      -    0.335525  0.382443   \n",
       "1          7           37        -           -  Naive    0.334345  0.380367   \n",
       "2          6           49        -           -   Real    0.329424  0.370514   \n",
       "3         10            -       37           -  Naive    0.411922  0.420017   \n",
       "4          1            -        9           -   Real    0.327937  0.354495   \n",
       "5          8            -        -          41  Naive    0.424465  0.432035   \n",
       "6          3            -        -           1   Real    0.333520  0.375218   \n",
       "7         11           41       48           -  Naive    0.420102  0.428429   \n",
       "8          4           40        3           -   Real    0.336111  0.362273   \n",
       "9          9           43        -          34  Naive    0.413097  0.422727   \n",
       "10         5           26        -           2   Real    0.329076  0.372623   \n",
       "\n",
       "                                                                          \\\n",
       "         500       750      1000      1250      1500      1750      2000   \n",
       "0   0.422797  0.444283  0.481188  0.491695  0.505200  0.497006  0.533526   \n",
       "1   0.421546  0.453790  0.481866  0.510246  0.543939  0.540802  0.543426   \n",
       "2   0.415564  0.441483  0.490492  0.509331  0.527388  0.549604  0.558650   \n",
       "3   0.447742  0.479385  0.517618  0.514364  0.514173  0.500893  0.521120   \n",
       "4   0.405440  0.441446  0.463883  0.486247  0.481957  0.487276  0.495751   \n",
       "5   0.453476  0.475676  0.486337  0.506637  0.477826  0.503300  0.508049   \n",
       "6   0.422969  0.447346  0.481516  0.497658  0.505188  0.496970  0.533744   \n",
       "7   0.461247  0.467759  0.514398  0.521505  0.528563  0.512201  0.513685   \n",
       "8   0.414233  0.442201  0.482965  0.474139  0.508701  0.542696  0.536897   \n",
       "9   0.447351  0.461513  0.505626  0.516237  0.504336  0.524641  0.520669   \n",
       "10  0.419319  0.449127  0.472443  0.487950  0.515200  0.535070  0.553866   \n",
       "\n",
       "                        \n",
       "        mean  variance  \n",
       "0   0.454852  0.004147  \n",
       "1   0.467814  0.005829  \n",
       "2   0.465828  0.006592  \n",
       "3   0.480804  0.001895  \n",
       "4   0.438270  0.003856  \n",
       "5   0.474200  0.000986  \n",
       "6   0.454903  0.004401  \n",
       "7   0.485321  0.001741  \n",
       "8   0.455580  0.005373  \n",
       "9   0.479578  0.001921  \n",
       "10  0.459408  0.005622  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_result_df=return_and_save_final_Gini_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "gini_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_and_save_final_relative_gini_result_df_as_json(gini_result_df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, \n",
    "                                                      exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
