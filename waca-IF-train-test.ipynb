{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "EXP_PATH_NAME=\"WACA-IF\"\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "Numpy Seed was set to: 567\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "from sklearn.svm import OneClassSVM\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "%run ./Classification_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "RIVAL_CLASSIFIER_TYPE_LST=[\"OCSVM\", \"kNN\", \"LOF\"]\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"Numpy Seed was set to: {SEED}\")\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__dir__()\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "        \n",
    "    user_ids: list\n",
    "    num_sample_points_per_exp: int\n",
    "    exp_begin_cutoff_idx: int\n",
    "    exp_end_cutoff_idx: int\n",
    "        \n",
    "    \n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    window_size: int  # After resampling\n",
    "    ocsvm_step_width: int  # After resampling\n",
    "    scaler: str  # StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_kernel: str # ocsvm kernel\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects=29,\n",
    "    max_test_subjects=10,\n",
    "    user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49],\n",
    "    num_sample_points_per_exp=21000,\n",
    "    exp_begin_cutoff_idx=500,\n",
    "    exp_end_cutoff_idx=-500,\n",
    "    seconds_per_subject_train=210,\n",
    "    seconds_per_subject_test=210,    \n",
    "    window_size=250,\n",
    "    ocsvm_step_width=250,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_kernel=\"rbf\",\n",
    "    ocsvm_nu=None,\n",
    "    ocsvm_gamma=None,\n",
    "    feature_cols=[\n",
    "        \"x_a\",\n",
    "        \"y_a\",\n",
    "        \"z_a\",\n",
    "        \"x_g\",\n",
    "        \"y_g\",\n",
    "        \"z_g\",\n",
    "    ],\n",
    "    exclude_subjects=[],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM_125 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=125\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "\n",
    "VALID_ROBUST_OCSVM_250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_2000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=2000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "# NORMALIZER_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_NORMALIZER_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-NORMALIZER-OCSVM\",\n",
    "    scaler=\"Normalizer\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.074,\n",
    "    ocsvm_gamma= 0.029,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM_2000\n",
    "P.ocsvm_step_width = int(P.window_size * .5)\n",
    "P.classifier=\"IF\"\n",
    "\n",
    "P.train_cores=1 # 20 cores for every user and 1 core for the nested crossval function\n",
    "P.test_cores=2 # 10 cores for every user and 2 for the nested crossval function\n",
    "\n",
    "# param_dist\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": np.linspace(50, 200, num=10, dtype=np.int64),\n",
    "    'model__max_samples':  np.arange(0.1, 1.1, 0.1),\n",
    "    'model__contamination': np.arange(0.01, 0.11, 0.01),\n",
    "    'model__max_features': np.arange(0.1, 1.1, 0.1),\n",
    "    # 'model__bootstrap': [True, False], \n",
    "    }\n",
    "\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [10],\n",
    "    'model__max_samples':  np.arange(0.1, 1.1, 0.1),\n",
    "    'model__contamination': np.arange(0.01, 0.11, 0.01),\n",
    "    'model__max_features': np.arange(0.1, 1.1, 0.1),\n",
    "    # 'model__bootstrap': [True, False], \n",
    "    }\n",
    "\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [50, 100, 200],\n",
    "    'model__max_samples':  np.arange(0.1, 1.01, 0.1),\n",
    "    'model__contamination': np.linspace(0.0001, 0.1, 50),\n",
    "    'model__max_features': np.arange(0.1, 1.01, 0.1),\n",
    "    'model__warm_start': [True], \n",
    "    }\n",
    "\n",
    "# param_dist = {\n",
    "#     \"model__n_estimators\": [50, 100, 150, 200], #np.linspace(50, 200, num=10, dtype=np.int64),\n",
    "#     'model__max_samples':  [.5,  .1],\n",
    "#     'model__contamination': [0.01],\n",
    "#     'model__max_features': [.5, 1.0],\n",
    "#     'model__warm_start': [True], \n",
    "#     }\n",
    "\n",
    "# param_dist = {\n",
    "#     \"model__n_estimators\": [50, 100], #np.linspace(50, 200, num=10, dtype=np.int64),\n",
    "#     'model__max_samples':  [.1],\n",
    "#     'model__contamination': [0.01],\n",
    "#     'model__max_features': [.5, 1.0],\n",
    "#     'model__warm_start': [True], \n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': [50, 100, 200],\n",
       " 'model__max_samples': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " 'model__contamination': array([0.0001    , 0.00213878, 0.00417755, 0.00621633, 0.0082551 ,\n",
       "        0.01029388, 0.01233265, 0.01437143, 0.0164102 , 0.01844898,\n",
       "        0.02048776, 0.02252653, 0.02456531, 0.02660408, 0.02864286,\n",
       "        0.03068163, 0.03272041, 0.03475918, 0.03679796, 0.03883673,\n",
       "        0.04087551, 0.04291429, 0.04495306, 0.04699184, 0.04903061,\n",
       "        0.05106939, 0.05310816, 0.05514694, 0.05718571, 0.05922449,\n",
       "        0.06126327, 0.06330204, 0.06534082, 0.06737959, 0.06941837,\n",
       "        0.07145714, 0.07349592, 0.07553469, 0.07757347, 0.07961224,\n",
       "        0.08165102, 0.0836898 , 0.08572857, 0.08776735, 0.08980612,\n",
       "        0.0918449 , 0.09388367, 0.09592245, 0.09796122, 0.1       ]),\n",
       " 'model__max_features': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " 'model__warm_start': [True]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>VALID-ROBUST-OCSVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_subjects</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_test_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_ids</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sample_points_per_exp</th>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_begin_cutoff_idx</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_end_cutoff_idx</th>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_train</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_test</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_step_width</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_scope</th>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_global</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_kernel</th>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_nu</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_gamma</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_cols</th>\n",
       "      <td>[x_a, y_a, z_a, x_g, y_g, z_g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclude_subjects</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Value\n",
       "name                                                      VALID-ROBUST-OCSVM\n",
       "frequency                                                                100\n",
       "max_subjects                                                              29\n",
       "max_test_subjects                                                         10\n",
       "user_ids                   [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...\n",
       "num_sample_points_per_exp                                              21000\n",
       "exp_begin_cutoff_idx                                                     500\n",
       "exp_end_cutoff_idx                                                      -500\n",
       "seconds_per_subject_train                                                210\n",
       "seconds_per_subject_test                                                 210\n",
       "window_size                                                             2000\n",
       "ocsvm_step_width                                                        1000\n",
       "scaler                                                          RobustScaler\n",
       "scaler_scope                                                         subject\n",
       "scaler_global                                                          False\n",
       "ocsvm_kernel                                                             rbf\n",
       "ocsvm_nu                                                                None\n",
       "ocsvm_gamma                                                             None\n",
       "feature_cols                                  [x_a, y_a, z_a, x_g, y_g, z_g]\n",
       "exclude_subjects                                                          []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(utils_eer, greater_is_better=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_eer_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n",
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n",
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n",
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n",
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n",
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n",
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n",
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n",
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n",
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n",
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n",
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n",
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n",
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n",
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n",
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n",
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n",
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n",
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n",
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n",
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n",
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n",
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n",
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n",
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n",
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n",
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n",
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n",
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n"
     ]
    }
   ],
   "source": [
    "#include 47 later\n",
    "# user_ids = [9]\n",
    "df_exps_dict = load_data_frames(P.user_ids, P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, P.num_sample_points_per_exp)\n",
    "raw_dfList_exp1, raw_dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "randomized_data_idx = list(range(len(P.user_ids)))\n",
    "random.Random(SEED).shuffle(randomized_data_idx)\n",
    "split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "train_set = randomized_data_idx[: split_idx]\n",
    "test_set = randomized_data_idx[split_idx: ]\n",
    "# train_set = randomized_data_idx\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")\n",
    "# train_set = test_set\n",
    "# test_set = train_set\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n",
      "47) accel_count: 17718, gyro_count: 18353\n"
     ]
    }
   ],
   "source": [
    "num_sample_points_per_exp_user_47 = 18000\n",
    "df_exps_dict_user_47 = load_data_frames([47], P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "raw_dfList_exp2_user_47 = dfList_exp2_user_47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"train_set: {train_set}\")\n",
    "# print(f\"X_exp1_train_dic: {X_exp1_train_dic.keys()}\")\n",
    "# print(f\"X_exp2_train_dic: {X_exp2_train_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"test_set: {test_set}\")\n",
    "# print(f\"X_exp1_test_dic: {X_exp1_test_dic.keys()}\")\n",
    "# print(f\"X_exp2_test_dic: {X_exp2_test_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Butterworth frequency Cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 47]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_off_freq: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  14.4827835210599\n",
      "MakeWACAXExpDicUnknown Time:  95.08045976795256\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13523.47it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [10:46<21:33, 646.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 10601.05it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [22:45<11:29, 689.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12246.14it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [33:22<00:00, 667.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14854.98it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:10<00:43, 10.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15202.26it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:21<00:32, 10.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14722.02it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:33<00:22, 11.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15022.58it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:44<00:11, 11.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 15360.94it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:54<00:00, 10.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [36:09<4:49:13, 2169.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  7.887034908868372\n",
      "MakeWACAXExpDicUnknown Time:  48.53014501417056\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13060.26it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [08:45<17:30, 525.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15117.33it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [18:25<09:17, 557.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14198.73it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [26:44<00:00, 534.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 10884.40it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:12<00:51, 12.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 9071.71it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:24<00:37, 12.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14535.80it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:37<00:24, 12.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15454.33it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:49<00:12, 12.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14947.63it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:01<00:00, 12.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [1:04:52<3:42:26, 1906.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeWACAXExpDicOwner Time:  4.520187194924802\n",
      "MakeWACAXExpDicUnknown Time:  25.11877340869978\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 16834.45it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:23<14:47, 443.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 21862.41it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:39<07:54, 474.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 8987.15it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [22:57<00:00, 459.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15759.17it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:05<00:23,  5.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12287.40it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:10<00:16,  5.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14041.86it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:16<00:10,  5.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15014.51it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:21<00:05,  5.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 10054.67it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [1:28:46<2:49:07, 1691.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeWACAXExpDicOwner Time:  3.9539000308141112\n",
      "MakeWACAXExpDicUnknown Time:  17.32767686713487\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13501.70it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:02<14:04, 422.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11011.56it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:57<07:33, 453.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14084.30it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [21:51<00:00, 437.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 16313.90it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:08<00:34,  8.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16002.69it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:16<00:25,  8.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14177.13it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:25<00:16,  8.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 13245.87it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:33<00:08,  8.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 10925.51it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:41<00:00,  8.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 4/9 [1:51:41<2:10:31, 1566.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeWACAXExpDicOwner Time:  3.1301190350204706\n",
      "MakeWACAXExpDicUnknown Time:  14.299044861923903\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 10270.09it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:51<13:42, 411.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16555.37it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:34<07:21, 441.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 18901.78it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [21:21<00:00, 427.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13955.43it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:08<00:33,  8.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 9729.31it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:16<00:24,  8.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13767.62it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:24<00:15,  7.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14665.40it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:31<00:07,  7.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 19350.88it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:39<00:00,  7.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 5/9 [2:14:01<1:38:58, 1484.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 32\n",
      "len_exp2_user_47: 27\n",
      "MakeWACAXExpDicOwner Time:  2.779260363895446\n",
      "MakeWACAXExpDicUnknown Time:  11.68259002501145\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13428.22it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:45<13:30, 405.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16206.74it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:19<07:13, 433.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 7569.58it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [20:56<00:00, 418.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14873.42it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:31,  7.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 7688.21it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:15<00:23,  7.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12045.67it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:23<00:15,  7.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14588.88it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:31<00:07,  7.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 12893.65it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:38<00:00,  7.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 6/9 [2:35:51<1:11:15, 1425.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 27\n",
      "len_exp2_user_47: 23\n",
      "MakeWACAXExpDicOwner Time:  3.162320881150663\n",
      "MakeWACAXExpDicUnknown Time:  10.502737625967711\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13107.20it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:40<13:20, 400.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14423.33it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [13:56<07:01, 421.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 20717.73it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [20:11<00:00, 403.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15947.92it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:30,  7.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 13152.41it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:14<00:22,  7.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 11799.98it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:22<00:14,  7.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14786.90it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:29<00:07,  7.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14124.61it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:36<00:00,  7.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 7/9 [2:56:54<45:44, 1372.11s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 23\n",
      "len_exp2_user_47: 19\n",
      "MakeWACAXExpDicOwner Time:  2.5562584418803453\n",
      "MakeWACAXExpDicUnknown Time:  9.338910352438688\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15155.57it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:59<11:58, 359.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 13074.51it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [11:46<05:51, 351.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12648.69it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [17:23<00:00, 347.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15735.52it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:30,  7.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 13906.84it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:14<00:22,  7.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14098.50it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:22<00:14,  7.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 13558.44it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:29<00:07,  7.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14596.50it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:36<00:00,  7.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 8/9 [3:15:06<21:22, 1282.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 20\n",
      "len_exp2_user_47: 17\n",
      "MakeWACAXExpDicOwner Time:  2.2013420737348497\n",
      "MakeWACAXExpDicUnknown Time:  8.889498334843665\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 23039.30it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:39<13:18, 399.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12937.40it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:08<07:08, 428.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12518.44it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [20:38<00:00, 412.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18724.57it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:14<00:56, 14.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16640.76it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:28<00:42, 14.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 19013.16it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:41<00:27, 13.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15017.20it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:55<00:13, 13.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 17578.81it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:08<00:00, 13.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 9/9 [3:37:04<00:00, 1447.14s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [3:37:05<7:14:11, 13025.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_off_freq: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  12.788082277402282\n",
      "MakeWACAXExpDicUnknown Time:  92.26151118567213\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15019.89it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [10:23<20:47, 623.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11287.15it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [21:56<11:04, 664.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14371.44it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [32:09<00:00, 643.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15174.76it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:16<01:05, 16.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 9607.84it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:31<00:47, 15.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14813.01it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:48<00:32, 16.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 17626.83it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [01:03<00:15, 15.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 16412.85it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:19<00:00, 15.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [35:16<4:42:13, 2116.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  7.950014244765043\n",
      "MakeWACAXExpDicUnknown Time:  45.45798933599144\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14910.43it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [08:22<16:44, 502.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 28102.54it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [17:45<08:58, 538.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 11733.96it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [25:59<00:00, 519.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17501.79it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:11<00:46, 11.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14242.12it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:22<00:34, 11.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 18583.54it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:33<00:22, 11.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 20779.31it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:45<00:11, 11.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 7536.26it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:56<00:00, 11.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [1:03:07<3:36:19, 1854.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeWACAXExpDicOwner Time:  4.821947382297367\n",
      "MakeWACAXExpDicUnknown Time:  24.814646950922906\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17764.95it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:21<14:43, 441.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11140.25it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:37<07:53, 473.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12381.71it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [22:54<00:00, 458.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15511.48it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:09<00:37,  9.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14415.89it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:18<00:27,  9.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14758.28it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:27<00:18,  9.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 11013.01it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:36<00:09,  9.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 13074.51it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:45<00:00,  9.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [1:27:17<2:46:57, 1669.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeWACAXExpDicOwner Time:  3.5379281849600375\n",
      "MakeWACAXExpDicUnknown Time:  17.01485111285001\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 11244.78it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:59<13:59, 419.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16644.06it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:51<07:30, 450.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12768.05it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [21:46<00:00, 435.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17331.83it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:15<01:02, 15.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 8027.38it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:30<00:45, 15.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 18339.76it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:45<00:30, 15.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15830.55it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [01:00<00:15, 15.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 27280.03it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:15<00:00, 15.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 4/9 [1:50:40<2:10:21, 1564.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeWACAXExpDicOwner Time:  3.191100529395044\n",
      "MakeWACAXExpDicUnknown Time:  14.206605634186417\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 21399.51it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:50<13:40, 410.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12620.14it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:28<07:18, 438.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13277.32it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [21:12<00:00, 424.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15809.66it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:08<00:33,  8.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15842.51it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:16<00:24,  8.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14528.24it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:23<00:15,  7.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 16329.78it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:31<00:07,  7.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14191.52it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:39<00:00,  7.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 5/9 [2:12:49<1:38:38, 1479.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 32\n",
      "len_exp2_user_47: 27\n",
      "MakeWACAXExpDicOwner Time:  2.736522404011339\n",
      "MakeWACAXExpDicUnknown Time:  11.625669909175485\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15551.74it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:42<13:24, 402.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 18678.71it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:13<07:11, 431.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15216.05it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [20:51<00:00, 417.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 16885.28it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:31,  7.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 18716.22it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:15<00:23,  7.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 19052.03it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:23<00:15,  7.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 17542.05it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:30<00:07,  7.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 22635.21it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:38<00:00,  7.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 6/9 [2:34:34<1:11:00, 1420.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 27\n",
      "len_exp2_user_47: 23\n",
      "MakeWACAXExpDicOwner Time:  2.6598458657972515\n",
      "MakeWACAXExpDicUnknown Time:  10.207025946583599\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 9311.36it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:39<13:19, 399.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17527.39it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [14:04<07:06, 426.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 11649.23it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [20:36<00:00, 412.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 16419.28it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:30,  7.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15869.48it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:15<00:22,  7.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12535.28it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:22<00:14,  7.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 8711.82it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:29<00:07,  7.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 15147.36it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:37<00:00,  7.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 7/9 [2:56:01<45:53, 1376.76s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 23\n",
      "len_exp2_user_47: 19\n",
      "MakeWACAXExpDicOwner Time:  2.653576830867678\n",
      "MakeWACAXExpDicUnknown Time:  9.300200960133225\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15103.72it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:35<13:10, 395.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 7473.81it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [13:58<07:03, 423.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 17158.13it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [20:28<00:00, 409.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 12505.38it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:31,  7.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 9740.60it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:15<00:22,  7.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 11937.68it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:22<00:14,  7.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 17512.75it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:29<00:07,  7.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 16464.39it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:36<00:00,  7.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 8/9 [3:17:19<22:25, 1345.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 20\n",
      "len_exp2_user_47: 17\n",
      "MakeWACAXExpDicOwner Time:  2.560922408942133\n",
      "MakeWACAXExpDicUnknown Time:  8.92113559693098\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15508.61it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:32<13:05, 392.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17955.07it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [13:54<07:01, 421.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12301.82it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [20:22<00:00, 407.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14807.78it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:29,  7.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 10721.64it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:15<00:22,  7.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13536.56it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:21<00:14,  7.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14742.72it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:29<00:07,  7.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 12887.71it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:36<00:00,  7.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 9/9 [3:38:29<00:00, 1456.65s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [7:15:37<3:37:56, 13076.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_off_freq: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  13.844133395235986\n",
      "MakeWACAXExpDicUnknown Time:  92.25850717490539\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 12762.22it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [10:22<20:45, 622.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 10796.15it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [21:27<10:47, 647.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13890.72it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [30:56<00:00, 618.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14523.21it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:15<01:00, 15.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 9976.94it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:29<00:44, 14.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 8299.80it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:44<00:29, 14.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14217.98it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:58<00:14, 14.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 12310.84it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:13<00:00, 14.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [33:58<4:31:49, 2038.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  7.819817592855543\n",
      "MakeWACAXExpDicUnknown Time:  40.6218337980099\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13637.80it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:33<13:06, 393.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14072.48it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:07<07:44, 464.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 10873.11it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [23:10<00:00, 463.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18633.07it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:11<00:47, 11.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 10057.08it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:23<00:34, 11.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 17221.53it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:34<00:22, 11.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 10976.98it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:45<00:11, 11.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 10290.25it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:57<00:00, 11.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [58:56<3:20:42, 1720.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeWACAXExpDicOwner Time:  4.4516099649481475\n",
      "MakeWACAXExpDicUnknown Time:  25.269359302241355\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 19368.76it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:11<14:22, 431.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15842.51it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:16<07:42, 462.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14413.42it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [22:25<00:00, 448.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15009.14it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:09<00:39,  9.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12832.50it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:19<00:28,  9.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 18067.22it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:28<00:18,  9.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 13543.12it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:37<00:09,  9.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 15709.00it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [1:22:39<2:38:27, 1584.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeWACAXExpDicOwner Time:  3.5906891161575913\n",
      "MakeWACAXExpDicUnknown Time:  18.114789451938123\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13171.00it/s]\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "    \n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": ffted_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                                    param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 47]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_off_freq: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  12.72940863110125\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "    \n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    \n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                                param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "\n",
    "\n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Butterworth frequency Cut-off + EMA span\n",
    "## 2.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n",
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 47]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "total cut_off_span_pairs: (2401, 2), choice_num: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_off_freq: 24, EMA span: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  12.993648618925363\n",
      "MakeWACAXExpDicUnknown Time:  69.987546721939\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15394.77it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:49<15:38, 469.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12961.38it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:14<07:35, 455.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14388.69it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [23:12<00:00, 464.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 10557.02it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:13<00:53, 13.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 8516.35it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:26<00:39, 13.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15117.33it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:39<00:26, 13.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15252.01it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:52<00:13, 13.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14722.02it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:05<00:00, 13.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [25:42<3:25:43, 1543.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  6.894736903719604\n",
      "MakeWACAXExpDicUnknown Time:  36.0194004913792\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13842.59it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:29<12:58, 389.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14086.66it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [12:42<06:19, 379.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15824.58it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [19:18<00:00, 386.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14813.01it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:27,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14667.96it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:13<00:19,  6.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15543.09it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:19<00:12,  6.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15612.52it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:25<00:06,  6.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 13895.33it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:32<00:00,  6.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [46:17<2:38:52, 1361.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeWACAXExpDicOwner Time:  3.9790216931141913\n",
      "MakeWACAXExpDicUnknown Time:  19.215043989941478\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15274.23it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:49<11:39, 349.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12893.65it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [11:26<05:41, 341.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 9576.04it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [17:22<00:00, 347.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 19517.47it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:29,  7.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17074.31it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:14<00:21,  7.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 10236.25it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:21<00:13,  6.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14453.15it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:28<00:07,  7.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14378.83it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:35<00:00,  7.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [1:04:39<2:04:18, 1243.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeWACAXExpDicOwner Time:  3.1667675408534706\n",
      "MakeWACAXExpDicUnknown Time:  13.573128675110638\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18829.65it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:34<11:09, 334.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15548.86it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:56<05:27, 327.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 7753.59it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:38<00:00, 332.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13497.36it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:27,  6.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14293.08it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:13<00:19,  6.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14186.72it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:19<00:12,  6.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 13353.40it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:26<00:06,  6.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 11655.70it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:32<00:00,  6.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 4/9 [1:22:08<1:37:11, 1166.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeWACAXExpDicOwner Time:  2.783846422098577\n",
      "MakeWACAXExpDicUnknown Time:  10.360258480999619\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 22900.92it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:29<10:58, 329.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 10619.84it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:46<05:21, 321.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 10539.78it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:26<00:00, 328.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13125.66it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:26,  6.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11958.10it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:19,  6.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 11411.52it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:18<00:12,  6.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14987.69it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:24<00:06,  6.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 20722.85it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:31<00:00,  6.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 5/9 [1:39:20<1:14:31, 1117.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 32\n",
      "len_exp2_user_47: 27\n",
      "MakeWACAXExpDicOwner Time:  2.3735593031160533\n",
      "MakeWACAXExpDicUnknown Time:  8.558625368401408\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 20774.17it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:31<11:03, 331.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14971.64it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [11:29<05:47, 347.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 9960.35it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [17:45<00:00, 355.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 12787.51it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:29,  7.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16088.62it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:14<00:21,  7.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14810.40it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:20<00:13,  6.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 18196.55it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:26<00:06,  6.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 18168.96it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:33<00:00,  6.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 6/9 [1:57:50<55:45, 1115.32s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 27\n",
      "len_exp2_user_47: 23\n",
      "MakeWACAXExpDicOwner Time:  2.2838802239857614\n",
      "MakeWACAXExpDicUnknown Time:  8.737952002789825\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 12850.20it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:42<11:24, 342.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 13929.94it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:59<05:27, 327.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 9792.91it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:39<00:00, 333.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14191.52it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:30,  7.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17479.91it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:14<00:22,  7.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 18436.50it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:21<00:14,  7.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 19422.57it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:27<00:06,  6.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 21839.65it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:33<00:00,  6.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 7/9 [2:15:15<36:24, 1092.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 23\n",
      "len_exp2_user_47: 19\n",
      "MakeWACAXExpDicOwner Time:  2.2191082830540836\n",
      "MakeWACAXExpDicUnknown Time:  6.8117343401536345\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 8005.16it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:28<10:56, 328.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14210.75it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [11:04<05:32, 332.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13964.72it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:46<00:00, 335.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18534.26it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:24,  6.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14378.83it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:18,  6.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15158.31it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:17<00:11,  5.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15969.18it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:23<00:05,  5.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 30897.27it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:29<00:00,  5.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 8/9 [2:32:41<17:57, 1077.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 20\n",
      "len_exp2_user_47: 17\n",
      "MakeWACAXExpDicOwner Time:  2.0390960066579282\n",
      "MakeWACAXExpDicUnknown Time:  6.189915192779154\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18192.60it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:29<10:59, 329.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 21161.98it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:50<05:24, 324.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13101.06it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:21<00:00, 327.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17761.19it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:24,  6.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12808.99it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:11<00:17,  5.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15750.30it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:17<00:11,  5.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 22028.91it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:23<00:05,  5.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 8287.50it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:29<00:00,  5.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 9/9 [2:49:40<00:00, 1131.16s/it]\u001b[A\n",
      "  0%|          | 0/3 [2:49:42<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'key_pair' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m EMAed_dfList_exp2_user_47 \u001b[38;5;241m=\u001b[39m get_EMAed_dfList(ffted_dfList_exp2_user_47, span\u001b[38;5;241m=\u001b[39mP\u001b[38;5;241m.\u001b[39mspan)\n\u001b[1;32m     56\u001b[0m dfList_dict\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdfList_exp1\u001b[39m\u001b[38;5;124m\"\u001b[39m: EMAed_dfList_exp1,\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdfList_exp2\u001b[39m\u001b[38;5;124m\"\u001b[39m: EMAed_dfList_exp2,\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdfList_exp1_user_47\u001b[39m\u001b[38;5;124m\"\u001b[39m: EMAed_dfList_exp1_user_47,\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdfList_exp2_user_47\u001b[39m\u001b[38;5;124m\"\u001b[39m: EMAed_dfList_exp2_user_47\n\u001b[1;32m     61\u001b[0m }\n\u001b[0;32m---> 64\u001b[0m EER_df_train_dict[\u001b[43mkey_pair\u001b[49m] \u001b[38;5;241m=\u001b[39m calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst\u001b[38;5;241m=\u001b[39mWINDOW_SIZE_LST, train_set\u001b[38;5;241m=\u001b[39mtrain_set, exp_config\u001b[38;5;241m=\u001b[39mP, \n\u001b[1;32m     65\u001b[0m                                                                                   extract_features_func_dict\u001b[38;5;241m=\u001b[39mEXTRACT_WACA_features_DICT, overlap\u001b[38;5;241m=\u001b[39moverlap, \n\u001b[1;32m     66\u001b[0m                                                                                   param_dist\u001b[38;5;241m=\u001b[39mparam_dist)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(train_file_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     68\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m22\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'key_pair' is not defined"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EMA span\n",
    "## 3.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_experiments_results/WACA-LOF/EMA_Mean_EER_Naive_df_test_dict_raw_df.json\n",
      "['OCSVM', 'kNN', 'LOF']\n"
     ]
    }
   ],
   "source": [
    "rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "rival_test_hyperparameters_df\n",
    "print(rival_test_hyperparameters_file_name)\n",
    "print(RIVAL_CLASSIFIER_TYPE_LST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 47]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA span: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  13.062254984863102\n",
      "MakeWACAXExpDicUnknown Time:  70.15507365902886\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13978.68it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:42<15:25, 462.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15022.58it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:01<07:28, 448.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13899.93it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [22:51<00:00, 457.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17829.13it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:12<00:51, 12.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12447.85it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:25<00:38, 12.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15890.52it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:38<00:25, 12.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14987.69it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:51<00:12, 12.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 15812.64it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:04<00:00, 12.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [25:21<3:22:52, 1521.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  7.1527830311097205\n",
      "MakeWACAXExpDicUnknown Time:  36.04419967997819\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18970.17it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:28<12:56, 388.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11264.41it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [12:35<06:15, 375.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13806.14it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [19:09<00:00, 383.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18082.79it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:28,  7.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 13609.03it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:13<00:20,  6.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12031.85it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:20<00:13,  6.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 17342.58it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:26<00:06,  6.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 13950.79it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:33<00:00,  6.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [45:49<2:37:20, 1348.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeWACAXExpDicOwner Time:  5.009889138862491\n",
      "MakeWACAXExpDicUnknown Time:  19.624387376010418\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13162.73it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:45<11:30, 345.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11971.75it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [11:16<05:37, 337.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13279.42it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [17:07<00:00, 342.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17025.79it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:30,  7.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 10762.90it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:15<00:22,  7.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 17974.30it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:22<00:14,  7.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 10286.46it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:29<00:07,  7.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 12497.93it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:37<00:00,  7.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [1:03:59<2:03:04, 1230.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeWACAXExpDicOwner Time:  3.803320126142353\n",
      "MakeWACAXExpDicUnknown Time:  13.681158740073442\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15996.58it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:30<11:01, 330.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 22339.83it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:49<05:23, 323.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13129.77it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:25<00:00, 328.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17989.72it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:26,  6.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15307.68it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:13<00:19,  6.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14354.22it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:19<00:12,  6.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14513.16it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:25<00:06,  6.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14897.19it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:32<00:00,  6.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 4/9 [1:21:15<1:36:09, 1153.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeWACAXExpDicOwner Time:  3.1264242129400373\n",
      "MakeWACAXExpDicUnknown Time:  10.677245123777539\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 16027.15it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:25<10:50, 325.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 21339.63it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:36<05:16, 317.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 16707.05it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:05<00:00, 321.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17267.62it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:25,  6.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 18303.75it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:18,  6.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14334.60it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:18<00:12,  6.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15750.30it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:24<00:06,  6.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 15839.52it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:30<00:00,  6.17s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 5/9 [1:38:06<1:13:29, 1102.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 32\n",
      "len_exp2_user_47: 27\n",
      "MakeWACAXExpDicOwner Time:  2.549272044096142\n",
      "MakeWACAXExpDicUnknown Time:  8.888312234077603\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 16814.21it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:20<10:40, 320.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17447.19it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:29<05:13, 313.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 19779.79it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:53<00:00, 317.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17780.01it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:25,  6.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16653.98it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:18,  6.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14926.35it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:18<00:12,  6.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 24392.58it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:24<00:06,  6.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 15161.05it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:30<00:00,  6.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 6/9 [1:54:42<53:18, 1066.27s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 27\n",
      "len_exp2_user_47: 23\n",
      "MakeWACAXExpDicOwner Time:  2.617520100902766\n",
      "MakeWACAXExpDicUnknown Time:  8.17238405533135\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 9729.31it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:18<10:36, 318.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11414.63it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:26<05:12, 312.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13189.64it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:49<00:00, 316.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15902.57it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:24,  6.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12122.27it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:18,  6.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 9496.90it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:18<00:11,  6.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14244.54it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:23<00:05,  5.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 12584.17it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:29<00:00,  5.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 7/9 [2:11:13<34:42, 1041.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 23\n",
      "len_exp2_user_47: 19\n",
      "MakeWACAXExpDicOwner Time:  2.3743277583271265\n",
      "MakeWACAXExpDicUnknown Time:  7.408004925120622\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13711.36it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:16<10:33, 316.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17690.02it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:21<05:09, 309.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 8446.04it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:42<00:00, 314.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15095.57it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:24,  6.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15491.43it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:11<00:17,  5.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14807.78it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:17<00:11,  5.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 18534.26it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:23<00:05,  5.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 20495.01it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:29<00:00,  5.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 8/9 [2:27:35<17:02, 1022.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 20\n",
      "len_exp2_user_47: 17\n",
      "MakeWACAXExpDicOwner Time:  2.44208434317261\n",
      "MakeWACAXExpDicUnknown Time:  6.526431104633957\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 24752.46it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:15<10:30, 315.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 11525.98it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:19<05:08, 308.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 17783.78it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:38<00:00, 312.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17652.79it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:10<00:43, 10.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 20851.62it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:21<00:32, 10.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12685.03it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:32<00:21, 10.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 13763.10it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:42<00:10, 10.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 15101.00it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:53<00:00, 10.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 9/9 [2:44:17<00:00, 1095.26s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [2:44:17<5:28:35, 9857.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA span: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  13.154410085175186\n",
      "MakeWACAXExpDicUnknown Time:  70.51950130797923\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14155.60it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:48<15:37, 468.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 10539.78it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:14<07:35, 455.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15318.86it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [23:07<00:00, 462.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 16390.40it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:13<00:53, 13.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 9997.15it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:26<00:39, 13.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14841.84it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:39<00:26, 13.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14473.10it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:52<00:13, 13.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14220.39it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [01:05<00:00, 13.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [25:39<3:25:19, 1539.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  7.380835693329573\n",
      "MakeWACAXExpDicUnknown Time:  36.08114330098033\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18575.31it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:24<12:49, 384.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12274.81it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [12:31<06:14, 374.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13586.99it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [19:05<00:00, 381.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18880.50it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:27,  6.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 23373.11it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:19,  6.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 11642.76it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:19<00:12,  6.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14480.59it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:25<00:06,  6.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14011.37it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:31<00:00,  6.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [46:01<2:37:49, 1352.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeWACAXExpDicOwner Time:  4.32451828988269\n",
      "MakeWACAXExpDicUnknown Time:  19.267858140170574\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17795.10it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:48<11:37, 348.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16269.60it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [11:24<05:40, 340.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14055.98it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [17:20<00:00, 346.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17288.97it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:07<00:29,  7.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14844.47it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:14<00:21,  7.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14657.71it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:21<00:14,  7.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14883.97it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:28<00:07,  7.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14413.42it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:35<00:00,  7.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [1:04:22<2:03:45, 1237.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeWACAXExpDicOwner Time:  3.3790314039215446\n",
      "MakeWACAXExpDicUnknown Time:  13.367395809851587\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 8494.79it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:35<11:11, 335.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14354.22it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:59<05:28, 328.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13247.96it/s]\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                    param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 47]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA span: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  13.175995624158531\n",
      "MakeWACAXExpDicUnknown Time:  87.51563867088407\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15682.57it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:44<15:29, 464.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 13187.56it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:06<07:30, 450.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14074.85it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [22:59<00:00, 459.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17342.58it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:09<00:37,  9.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 21263.90it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:18<00:27,  9.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15827.56it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:27<00:18,  9.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 9579.32it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:37<00:09,  9.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14408.46it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [25:41<3:25:32, 1541.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  6.767945127096027\n",
      "MakeWACAXExpDicUnknown Time:  44.429857335053384\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17772.47it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:23<12:46, 383.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 8745.42it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [12:30<06:14, 374.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12690.78it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [19:01<00:00, 380.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15106.44it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:09<00:38,  9.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12677.36it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:18<00:28,  9.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 23912.79it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:28<00:18,  9.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 16644.06it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:37<00:09,  9.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 17943.55it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.36s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 2/9 [46:28<2:39:39, 1368.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "MakeWACAXExpDicOwner Time:  4.043536094948649\n",
      "MakeWACAXExpDicUnknown Time:  23.766124312765896\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17461.72it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:43<11:27, 343.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17228.61it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [11:14<05:35, 335.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 9593.56it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [17:06<00:00, 342.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18550.66it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:04<00:17,  4.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14478.09it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:08<00:12,  4.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 17063.89it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:12<00:08,  4.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 25930.78it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:17<00:04,  4.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 17385.72it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:21<00:00,  4.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 3/9 [1:04:28<2:03:40, 1236.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "MakeWACAXExpDicOwner Time:  3.301316248252988\n",
      "MakeWACAXExpDicUnknown Time:  16.41517993621528\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 19991.92it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:30<11:00, 330.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 20296.66it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:47<05:22, 322.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 14758.28it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:23<00:00, 327.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14642.36it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:26,  6.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15324.46it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:13<00:19,  6.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 16057.83it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:19<00:12,  6.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 14696.23it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:26<00:06,  6.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 16743.73it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:32<00:00,  6.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 4/9 [1:21:47<1:36:32, 1158.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "MakeWACAXExpDicOwner Time:  2.7105154106393456\n",
      "MakeWACAXExpDicUnknown Time:  12.824486402794719\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 18978.75it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:24<10:49, 324.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15327.26it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:36<05:17, 317.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 13121.55it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [16:05<00:00, 321.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17102.16it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:25,  6.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15372.20it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:18,  6.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15001.09it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:18<00:12,  6.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 8040.46it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:24<00:06,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 16693.75it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:30<00:00,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 5/9 [1:38:41<1:13:46, 1106.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 32\n",
      "len_exp2_user_47: 27\n",
      "MakeWACAXExpDicOwner Time:  2.2318514031358063\n",
      "MakeWACAXExpDicUnknown Time:  10.543259413912892\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 20405.27it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:20<10:41, 320.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 16939.84it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:28<05:13, 313.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15249.24it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:53<00:00, 317.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 8185.60it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:24,  6.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15414.57it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:18,  6.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 15302.09it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:18<00:11,  6.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 13115.40it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:24<00:05,  5.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 17008.53it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:29<00:00,  5.97s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 6/9 [1:55:20<53:29, 1069.82s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 27\n",
      "len_exp2_user_47: 23\n",
      "MakeWACAXExpDicOwner Time:  2.2281984738074243\n",
      "MakeWACAXExpDicUnknown Time:  9.280386331025511\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 19987.15it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:21<10:42, 321.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17203.87it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:27<05:12, 312.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12587.95it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:51<00:00, 317.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15505.74it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:06<00:24,  6.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15987.44it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:12<00:18,  6.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 27776.85it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:17<00:11,  5.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 18855.04it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:23<00:05,  5.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 13772.14it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:29<00:00,  5.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 7/9 [2:11:54<34:49, 1044.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 23\n",
      "len_exp2_user_47: 19\n",
      "MakeWACAXExpDicOwner Time:  1.9670538469217718\n",
      "MakeWACAXExpDicUnknown Time:  8.244210000149906\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 15756.21it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:16<10:32, 316.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15899.56it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:19<05:08, 308.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 12336.19it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:39<00:00, 313.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 19086.71it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:10<00:43, 10.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 14942.30it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:21<00:32, 10.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 17520.07it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:32<00:21, 10.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 19235.51it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:42<00:10, 10.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 17210.93it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:53<00:00, 10.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 8/9 [2:28:38<17:12, 1032.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 20\n",
      "len_exp2_user_47: 17\n",
      "MakeWACAXExpDicOwner Time:  1.9653846421279013\n",
      "MakeWACAXExpDicUnknown Time:  7.237030545715243\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 14403.52it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [05:14<10:29, 314.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 17545.72it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [10:17<05:07, 307.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 18283.80it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [15:37<00:00, 312.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17468.99it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:05<00:23,  5.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 13519.11it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:11<00:17,  5.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 28669.20it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:17<00:11,  5.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 25213.73it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:23<00:05,  5.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 14339.50it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:28<00:00,  5.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 9/9 [2:44:55<00:00, 1099.52s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [2:44:55<5:29:51, 9895.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA span: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "MakeWACAXExpDicOwner Time:  12.653837237041444\n",
      "MakeWACAXExpDicUnknown Time:  89.56300481688231\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17147.60it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [07:45<15:31, 465.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 12580.40it/s]\n",
      "\n",
      "\n",
      " 67%|██████▋   | 2/3 [15:09<07:32, 452.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 18157.16it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 3/3 [23:02<00:00, 460.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 17509.10it/s]\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:09<00:37,  9.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 20345.88it/s]\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:18<00:27,  9.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|██████████| 20/20 [00:00<00:00, 21361.36it/s]\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:27<00:18,  9.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|██████████| 20/20 [00:00<00:00, 15488.57it/s]\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [00:37<00:09,  9.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|██████████| 20/20 [00:00<00:00, 21307.11it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:46<00:00,  9.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 1/9 [25:46<3:26:12, 1546.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "MakeWACAXExpDicOwner Time:  7.051525607705116\n",
      "MakeWACAXExpDicUnknown Time:  44.71043225098401\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|██████████| 20/20 [00:00<00:00, 13595.80it/s]\n",
      "\n",
      "\n",
      " 33%|███▎      | 1/3 [06:23<12:47, 383.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|██████████| 20/20 [00:00<00:00, 15139.16it/s]\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                    param_dist=param_dist) \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SMA winsize\n",
    "## 4.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                       param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                       param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Butterworth frequency Cut-off + SMA winsize\n",
    "## 5.1 Naive Approach\n",
    "### Optimizing and Testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "overlap=0.5\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for clf_type in tqdm(RIVAL_CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    \n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "    \n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The effect of Varying Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for overlap in tqdm(OVERLAP_EXP_RANGE):\n",
    "    overlap*=0.01\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "    max_num_windows=max(len(getIndices(sampleSize=max_window_size, step=step_width, numSamplePoints=P.num_sample_points_per_exp)), 100)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[overlap] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                     extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                     param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\overlap: {overlap}\\n\")\n",
    "        f.write(EER_df_train_dict[overlap].to_string())\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=overlap, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"overlap\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected character found when decoding 'false'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mreturn_and_save_final_result_df_as_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_exp_results_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFINAL_EXP_RESULTS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_path_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEXP_PATH_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size_lst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWINDOW_SIZE_LST\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\n",
      "File \u001b[0;32m/tmp/ipykernel_101/3687518155.py:9\u001b[0m, in \u001b[0;36mreturn_and_save_final_result_df_as_json\u001b[0;34m(final_exp_results_path, exp_path_name, window_size_lst)\u001b[0m\n\u001b[1;32m      5\u001b[0m concate_df_lst\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      8\u001b[0m test_file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_exp_results_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_path_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/None_Mean_EER_None_df_test_dict.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m eer_per_window_size_col_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtest_file_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_eer_per_window_size_col_df.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;66;03m#\"('index', '')\", \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(eer_per_window_size_col_df)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert the string representation of tuples back to tuples\u001b[39;00m\n\u001b[1;32m     12\u001b[0m idx_tuples \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28meval\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m eer_per_window_size_col_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:612\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m json_reader:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:746\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    744\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_object_parser(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:768\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    766\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 768\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:880\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_numpy()\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 880\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_no_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/json/_json.py:1133\u001b[0m, in \u001b[0;36mFrameParser._parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1129\u001b[0m orient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morient\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1133\u001b[0m         \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m     )\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1136\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loads(json, precise_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecise_float)\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1139\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected character found when decoding 'false'"
     ]
    }
   ],
   "source": [
    "\n",
    "df=return_and_save_final_result_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, \n",
    "                                                             window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df.style.hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
