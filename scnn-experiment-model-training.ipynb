{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "Numpy Seed was set to: 567\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# got rid of memory issue bugs with gc.collect()\n",
    "import gc\n",
    "\n",
    "\n",
    "# !pip install --upgrade pip\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "from sklearn.svm import OneClassSVM\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "import ast\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "%run ./Classification_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"Numpy Seed was set to: {SEED}\")\n",
    "\n",
    "# change this constant when testing\n",
    "FINAL_EXP_RESULTS_PATH=\"clip=False_experiments_results\"\n",
    "\n",
    "\n",
    "SAVE_PATH_NAME=\"SCNN_trained_models\"\n",
    "CLASSIFIER_TYPE_LST=[\"OCSVM\", \"kNN\", \"LOF\"]\n",
    "WINDOW_SIZE_LST = [125, 250, 500, 750, 1000]#, 1250, 1500]#[125, 250, 500, 750, 1000, 1250, 1500, 1750, 2000]\n",
    "OVERLAP=0.5\n",
    "\n",
    "# TRAINING_CONFIG_DICT_FILE_NAME=\"model_archi_performance_lr_dict.json\"\n",
    "# TRAINING_CONFIG_DICT_FILE_NAME=\"results_dict_1000-SCNN_3_1_conv_1_dense_arg_dict_default20230702-054339.json\"\n",
    "\n",
    "# TRAINING_CONFIG_DICT_FILE_NAME=\"results_dict_1000-SCNN_3_1_conv_1_dense_arg_dict_default20230708-061921.json\"\n",
    "# TRAINING_CONFIG_DICT_FILE_NAME=\"results_dict_1000-SCNN_3_1_conv_1_dense_arg_dict_default20230714-055018.json\"#margin=.5\n",
    "# TRAINING_CONFIG_DICT_FILE_NAME=\"results_dict_1000-SCNN_3_1_conv_1_dense_arg_dict_default20230714-065735.json\"#margin=.1\n",
    "# TRAINING_CONFIG_DICT_FILE_NAME=\"results_dict_1000-SCNN_3_1_conv_1_dense_arg_dict_default20230714-071551.json\"#margin=.25\n",
    "# TRAINING_CONFIG_DICT_FILE_NAME=\"results_dict_1000-SCNN_3_1_conv_1_dense_arg_dict_default20230714-085935.json\"\n",
    "\n",
    "TRAINING_CONFIG_DICT_FILE_NAME_CV_DICT={\\\n",
    "                                        \"Butter\":\n",
    "                                        {0: \"results_dict_Butter33-cv0-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                         1: \"results_dict_Butter33-cv1-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                         2: \"results_dict_Butter33-cv2-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                        },\n",
    "                                        \"Butter-EMA\":\n",
    "                                        {0: \"results_dict_Butter33-EMA20-cv0-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                         1: \"results_dict_Butter33-EMA20-cv1-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                         2: \"results_dict_Butter33-EMA20-cv2-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                        },\n",
    "                                        \"Butter-SMA\":\n",
    "                                        {0: \"results_dict_Butter33-SMA20-cv0-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                         1: \"results_dict_Butter33-SMA20-cv1-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                         2: \"results_dict_Butter33-SMA20-cv2-1000-SCNN_3_123_conv_1_dense_arg_dict_default_thesis.json\",\n",
    "                                        },\n",
    "                                        \n",
    "}\n",
    "\n",
    "\n",
    "TRAINING_CONFIG_DICT_FOLDER_PATH=\"siamese_cnn_results_final\"\n",
    "# with open(f\"{TRAINING_CONFIG_DICT_FOLDER_PATH}/{TRAINING_CONFIG_DICT_FILE_NAME}\", 'r') as file:\n",
    "#     TRAINING_CONFIG_DICT=json.load(file)\n",
    "    \n",
    "    \n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__dir__()\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "        \n",
    "    user_ids: list\n",
    "    num_sample_points_per_exp: int\n",
    "    exp_begin_cutoff_idx: int\n",
    "    exp_end_cutoff_idx: int\n",
    "        \n",
    "    \n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    window_size: int  # After resampling\n",
    "    ocsvm_step_width: int  # After resampling\n",
    "    scaler: str  # StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_kernel: str # ocsvm kernel\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects=29,\n",
    "    max_test_subjects=10,\n",
    "    user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49],\n",
    "    num_sample_points_per_exp=21000,\n",
    "    exp_begin_cutoff_idx=500,\n",
    "    exp_end_cutoff_idx=-500,\n",
    "    seconds_per_subject_train=210,\n",
    "    seconds_per_subject_test=210,    \n",
    "    window_size=250,\n",
    "    ocsvm_step_width=250,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_kernel=\"rbf\",\n",
    "    ocsvm_nu=None,\n",
    "    ocsvm_gamma=None,\n",
    "    feature_cols=[\n",
    "        \"x_a\",\n",
    "        \"y_a\",\n",
    "        \"z_a\",\n",
    "        \"x_g\",\n",
    "        \"y_g\",\n",
    "        \"z_g\",\n",
    "    ],\n",
    "    exclude_subjects=[],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM_125 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=125\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "\n",
    "VALID_ROBUST_OCSVM_250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_2000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=2000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "# NORMALIZER_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_NORMALIZER_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-NORMALIZER-OCSVM\",\n",
    "    scaler=\"Normalizer\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.074,\n",
    "    ocsvm_gamma= 0.029,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM_2000\n",
    "P.ocsvm_step_width = int(P.window_size * .5)\n",
    "\n",
    "P.model_variant = 'multi_head_fcn'\n",
    "\n",
    "P.filter_order=10\n",
    "P.sampling_freq=100\n",
    "P.filtfilt=1\n",
    "P.cut_off_freq=33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "# preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "# for clf_type in CLASSIFIER_TYPE_LST:\n",
    "#     rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "#     rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "#     print(rival_test_hyperparameters_df[\"cut_off_freq\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>VALID-ROBUST-OCSVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_subjects</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_test_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_ids</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sample_points_per_exp</th>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_begin_cutoff_idx</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_end_cutoff_idx</th>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_train</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_test</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_step_width</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_scope</th>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_global</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_kernel</th>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_nu</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_gamma</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_cols</th>\n",
       "      <td>[x_a, y_a, z_a, x_g, y_g, z_g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclude_subjects</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Value\n",
       "name                                                      VALID-ROBUST-OCSVM\n",
       "frequency                                                                100\n",
       "max_subjects                                                              29\n",
       "max_test_subjects                                                         10\n",
       "user_ids                   [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...\n",
       "num_sample_points_per_exp                                              21000\n",
       "exp_begin_cutoff_idx                                                     500\n",
       "exp_end_cutoff_idx                                                      -500\n",
       "seconds_per_subject_train                                                210\n",
       "seconds_per_subject_test                                                 210\n",
       "window_size                                                             2000\n",
       "ocsvm_step_width                                                        1000\n",
       "scaler                                                          RobustScaler\n",
       "scaler_scope                                                         subject\n",
       "scaler_global                                                          False\n",
       "ocsvm_kernel                                                             rbf\n",
       "ocsvm_nu                                                                None\n",
       "ocsvm_gamma                                                             None\n",
       "feature_cols                                  [x_a, y_a, z_a, x_g, y_g, z_g]\n",
       "exclude_subjects                                                          []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(utils_eer, greater_is_better=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_eer_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n",
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n",
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n",
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n",
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n",
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n",
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n",
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n",
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n",
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n",
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n",
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n",
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n",
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n",
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n",
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n",
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n",
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n",
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n",
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n",
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n",
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n",
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n",
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n",
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n",
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n",
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n",
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n",
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n"
     ]
    }
   ],
   "source": [
    "#include 47 later\n",
    "# user_ids = [9]\n",
    "df_exps_dict = load_data_frames(P.user_ids, P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, P.num_sample_points_per_exp)\n",
    "raw_dfList_exp1, raw_dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "randomized_data_idx = list(range(len(P.user_ids)))\n",
    "random.Random(SEED).shuffle(randomized_data_idx)\n",
    "split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "train_set = randomized_data_idx[: split_idx]\n",
    "test_set = randomized_data_idx[split_idx: ]\n",
    "# train_set = randomized_data_idx\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")\n",
    "# train_set = test_set\n",
    "# test_set = train_set\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n",
      "47) accel_count: 17718, gyro_count: 18353\n"
     ]
    }
   ],
   "source": [
    "num_sample_points_per_exp_user_47 = 18000\n",
    "df_exps_dict_user_47 = load_data_frames([47], P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "raw_dfList_exp2_user_47 = dfList_exp2_user_47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_set: {train_set}\")\n",
    "# print(f\"X_exp1_train_dic: {X_exp1_train_dic.keys()}\")\n",
    "# print(f\"X_exp2_train_dic: {X_exp2_train_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_set: {test_set}\")\n",
    "# print(f\"X_exp1_test_dic: {X_exp1_test_dic.keys()}\")\n",
    "# print(f\"X_exp2_test_dic: {X_exp2_test_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_save_model_exp_notebook(model,\n",
    "                                   model_classifier_type, exp_num, archi_name, winsize, \n",
    "                                   arg_dict, loss_record_dict, metric_record_dict, other_dict=None, save_name_suffix=''):\n",
    "    \"\"\"EXP_PATH_NAME\n",
    "    save the deep learning feature extractor model, along with dictionary of arguments as a json,\n",
    "    best epoch found, a dictionary containing the accurcy and EER figures, and the window size, and\n",
    "    a dicgionary of validation and training loss values over time that can be later plotted.\n",
    "    inputs: \n",
    "    deep_feature_model: tf model\n",
    "    arg_dict: serializable dictionary\n",
    "    test_res_fig_dic: dict containing keys {\"acc\", \"eer\"}\n",
    "    win_size: int\n",
    "    loss_record_dict\n",
    "    \"\"\"\n",
    "        \n",
    "    base_path=f\"{FINAL_EXP_RESULTS_PATH}/{SAVE_PATH_NAME}/{model_classifier_type}/{exp_num}\"\n",
    "    path_to_archi_name=base_path+f\"/{archi_name}\"\n",
    "    final_path=path_to_archi_name+f\"/{winsize}\"\n",
    "    \n",
    "    if not os.path.isdir(base_path):\n",
    "        raise Exception(f\"Base path does not exist: {base_path}\")\n",
    "        \n",
    "    if not os.path.isdir(path_to_archi_name):\n",
    "        os.mkdir(path_to_archi_name)\n",
    "\n",
    "    if not os.path.isdir(final_path):\n",
    "        os.mkdir(final_path)\n",
    "        \n",
    "    model.save(final_path+f\"/{model_classifier_type}-{exp_num}-{archi_name}-{winsize}-model-{save_name_suffix}\")\n",
    "    deep_feature_model = extract_deep_feature_extactor(model)\n",
    "    deep_feature_model.save(final_path+f\"/{model_classifier_type}-{exp_num}-{archi_name}-{winsize}-deep_feature_extractor-{save_name_suffix}\")\n",
    "    \n",
    "    \n",
    "    with open(f\"{final_path}/arg_dict-{save_name_suffix}.json\", 'w') as file:\n",
    "        arg_dict_json = json.dumps(arg_dict)\n",
    "        file.write(arg_dict_json)\n",
    "        \n",
    "    with open(f\"{final_path}/loss_record-{save_name_suffix}.json\", 'w') as file:\n",
    "        loss_record_json = json.dumps(loss_record_dict)\n",
    "        file.write(loss_record_json)\n",
    "        \n",
    "    with open(f\"{final_path}/metric_record-{save_name_suffix}.json\", 'w') as file:\n",
    "        metric_record_json = json.dumps(metric_record_dict)\n",
    "        file.write(metric_record_json)\n",
    "    \n",
    "    if other_dict != None:\n",
    "        with open(f\"{final_path}/other_dict-{save_name_suffix}.json\", 'w') as file:\n",
    "            other_dict_json = json.dumps(other_dict)\n",
    "            file.write(other_dict_json)\n",
    "\n",
    "        \n",
    "    fig_dict = utils_plot_validation_metric(metric_record_dict)\n",
    "    for metric in fig_dict:\n",
    "        fig = fig_dict[metric]\n",
    "        fig.savefig(f'{final_path}/{metric}_epoch-{save_name_suffix}.svg', bbox_inches='tight')\n",
    "    \n",
    "    print(f\"saved model at {final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.logspace(-4, -1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_experiment_params(exp_config=P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_optimal_lr_epoch_dict(loss_record_dict, lr_epoch_log_dict):\n",
    "\n",
    "    min_val = min(loss_record_dict['val_loss'])\n",
    "    min_val_index=loss_record_dict['val_loss'].index(min_val)\n",
    "    print(f\"loss_record_dict: {loss_record_dict['val_loss']}, min_val_index: {min_val_index}\")\n",
    "\n",
    "    optimal_lr_epoch_dict={}\n",
    "    for i in range(min_val_index+1):\n",
    "        optimal_lr_epoch_dict[i] = lr_epoch_log_dict[i]\n",
    "\n",
    "    return optimal_lr_epoch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_with_training_config_dict(dfList_dict, window_size_lst, train_set, exp_config, overlap, training_config_dict, save_info_dict):\n",
    "    \n",
    "    model_classifier_type = save_info_dict[\"model_classifier_type\"]\n",
    "    exp_num = save_info_dict[\"exp_num\"]\n",
    "    cv_fold_idx = save_info_dict[\"cv_fold_idx\"]\n",
    "\n",
    "    for window_size in tqdm(window_size_lst):\n",
    "\n",
    "        np.random.seed(SEED)\n",
    "        tf.random.set_seed(SEED)\n",
    "        print(f\"Seed was set to: {SEED}\")\n",
    "\n",
    "        if str(window_size) in training_config_dict:\n",
    "            winsize_training_config_dict=training_config_dict[str(window_size)]\n",
    "        else:\n",
    "            raise Exception(\"Window size not in training_config_dict\")\n",
    "\n",
    "        exp_config.window_size=window_size\n",
    "        exp_config.nn_step_width = int(exp_config.window_size * overlap)\n",
    "\n",
    "        \n",
    "        dfList_exp1=dfList_dict[\"dfList_exp1\"]\n",
    "        dfList_exp2=dfList_dict[\"dfList_exp2\"]\n",
    "        \n",
    "        if 29 in train_set:\n",
    "            dfList_exp1_user_47=dfList_dict[\"dfList_exp1_user_47\"]\n",
    "            dfList_exp2_user_47=dfList_dict[\"dfList_exp2_user_47\"]\n",
    "\n",
    "\n",
    "        # separate user 47 which has 29 index by default from the other users as 47 has shorter time series\n",
    "        if 29 in train_set:\n",
    "\n",
    "            user_idx_set_without_user_47 = train_set - {29}\n",
    "\n",
    "        else:\n",
    "\n",
    "            user_idx_set_without_user_47 = train_set\n",
    "\n",
    "\n",
    "        X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=get_raw_windows(dfList_exp1=dfList_exp1,\n",
    "                                                                                            dfList_exp2=dfList_exp2,\n",
    "                                                                                            window_size=window_size, \n",
    "                                                                                            step_width=exp_config.nn_step_width, \n",
    "                                                                                            user_idx_set=user_idx_set_without_user_47, \n",
    "                                                                                            scaler=exp_config.scaler, \n",
    "                                                                                            num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "                                                                                            EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "                                                                                            SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "                                                                                            Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "                                                                                            verbose=0)\n",
    "\n",
    "        if 29 in train_set:\n",
    "        # user 47 with index 29 is not present in the first cv fold\n",
    "            X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47=get_raw_windows_user_47(dfList_exp1_user_47=dfList_exp1_user_47,\n",
    "                                                                                                                                dfList_exp2_user_47=dfList_exp2_user_47, \n",
    "                                                                                                                                window_size=window_size, \n",
    "                                                                                                                                step_width=exp_config.nn_step_width, \n",
    "                                                                                                                                scaler=exp_config.scaler, \n",
    "                                                                                                                                num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "                                                                                                                                EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "                                                                                                                                SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "                                                                                                                                Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "                                                                                                                                verbose=0)\n",
    "\n",
    "            X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=append_user_47_to_data(X_exp1_dict=X_train_exp1_dict, \n",
    "                                                                                                       X_exp2_dict=X_train_exp2_dict, \n",
    "                                                                                                       fitted_scaler_exp2_dict=fitted_scaler_train_exp2_dict, \n",
    "                                                                                                       all_user_set=user_idx_set_without_user_47, \n",
    "                                                                                                       X_exp1_dict_user_47=X_train_exp1_dict_user_47, \n",
    "                                                                                                       X_exp2_dict_user_47=X_train_exp2_dict_user_47, \n",
    "                                                                                                       fitted_scaler_exp2_dict_user_47=fitted_scaler_train_exp2_dict_user_47, \n",
    "                                                                                                       verbose=0)\n",
    "            #--------------------\n",
    "\n",
    "        num_pair_limit=3*(NUM_PAIR_LIMIT_TRAIN_2000+NUM_PAIR_LIMIT_VALID_2000)\n",
    "\n",
    "        # train_pairs_dict = prep_X_y_pair(X_train_exp2_dict, X_train_exp1_dict, list(X_train_exp2_dict.keys()), fitted_scaler_train_exp2_dict, num_pair_limit=num_pair_limit)\n",
    "\n",
    "        train_pairs_dict = prep_X_y_pair_robust_minmax(X_exp2_dic=X_train_exp2_dict, \n",
    "                                                       X_exp1_dic=X_train_exp1_dict, \n",
    "                                                       user_id_list=list(X_train_exp2_dict.keys()), \n",
    "                                                       fitted_raw_Robust_scaler_dict=fitted_scaler_train_exp2_dict, \n",
    "                                                       is_train=True, # this will include -1 samples\n",
    "                                                       num_pair_limit=num_pair_limit)\n",
    "\n",
    "        X_train, y_train, X_train_distro_dic = train_pairs_dict[\"X\"], train_pairs_dict[\"y\"], train_pairs_dict[\"X_dic\"]\n",
    "\n",
    "\n",
    "        # 2D Filter Model needs flat 4th dimension\n",
    "        if exp_config.model_variant == \"2d\":\n",
    "            X_train[0] = X_train[0].reshape((*X_train[0].shape, 1))\n",
    "            X_train[1] = X_train[1].reshape((*X_train[1].shape, 1))\n",
    "\n",
    "        print(\n",
    "            f\"Training samples:   {y_train.shape[0]}, shape: {X_train[0].shape},\"\n",
    "            + f\" class balance: {np.unique(y_train, return_counts=True)}\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        for archi_name in tqdm(winsize_training_config_dict):\n",
    "            np.random.seed(SEED)\n",
    "            tf.random.set_seed(SEED)\n",
    "            print(archi_name)\n",
    "            archi_dict=winsize_training_config_dict[archi_name]\n",
    "            arg_dict=archi_dict[\"arg_dict\"]\n",
    "\n",
    "            archi_lr_epoch_log_dict=ast.literal_eval(archi_dict[\"lr_epoch_log_dict\"])\n",
    "            archi_loss_record_dict=archi_dict[\"loss_record_dict\"]\n",
    "            optimal_lr_epoch_dict=measure_optimal_lr_epoch_dict(archi_loss_record_dict, archi_lr_epoch_log_dict)\n",
    "\n",
    "            print(archi_lr_epoch_log_dict)\n",
    "            print(archi_loss_record_dict)\n",
    "            print(optimal_lr_epoch_dict)\n",
    "\n",
    "\n",
    "            create_model_func = get_create_model_func(exp_config.model_variant, exp_config.window_size, exp_config.feature_cols)\n",
    "\n",
    "            print(arg_dict)\n",
    "            loss_record_dict = {'loss': [], 'val_loss': []}\n",
    "            metric_record_dict = {}\n",
    "            model = create_model_func(arg_dict)\n",
    "\n",
    "            # Train\n",
    "            history = model.fit(\n",
    "                x=X_train,\n",
    "                y=y_train,\n",
    "                batch_size=arg_dict[\"batch_size\"],\n",
    "                epochs=len(optimal_lr_epoch_dict), #depends on the len optimal_lr_epoch_dict\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=[MetricsCallback((None, None, X_train, y_train), loss_record_dict=loss_record_dict, metric_record_dict=metric_record_dict, \n",
    "                                           epoch_evaluate_freq=10, save_plots=False, print_interm_epochs=False, early_stoping=False, \n",
    "                                           optimal_lr_epoch_dict=optimal_lr_epoch_dict,\n",
    "                                           verbose=0)],\n",
    "            )\n",
    "            print(loss_record_dict)\n",
    "            print(\"Training History:\")\n",
    "            loss_fig = utils_plot_training_loss(loss_record_dict)\n",
    "\n",
    "\n",
    "\n",
    "            custom_save_model_exp_notebook(model=model,\n",
    "                                           model_classifier_type=model_classifier_type, exp_num=exp_num, archi_name=archi_name, winsize=window_size, \n",
    "                                           arg_dict=arg_dict, loss_record_dict=loss_record_dict, metric_record_dict=metric_record_dict, \n",
    "                                           other_dict=None, save_name_suffix=f\"Butter33-SMA20-cv{cv_fold_idx}\")\n",
    "            del model\n",
    "            del history\n",
    "            K.clear_session()\n",
    "            tf.compat.v1.reset_default_graph()\n",
    "\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_config_dict(prep_type, cv_fold_idx):\n",
    "    with open(f\"{TRAINING_CONFIG_DICT_FOLDER_PATH}/{TRAINING_CONFIG_DICT_FILE_NAME_CV_DICT[prep_type][cv_fold_idx]}\", 'r') as file:\n",
    "        return json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0. No Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimizing and TestingFINAL_EXP_RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clip=False_experiments_results'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_EXP_RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000], 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['1000'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{WINDOW_SIZE_LST}, {EXP_NUM_0}\")\n",
    "TRAINING_CONFIG_DICT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5, 47]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "82\n",
      "0.11869422962522308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 1/20 [00:04<01:22,  4.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 2/20 [00:08<01:17,  4.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 3/20 [00:12<01:13,  4.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 4/20 [00:17<01:08,  4.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 5/20 [00:21<01:04,  4.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 6/20 [00:25<01:00,  4.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 7/20 [00:29<00:55,  4.26s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 8/20 [00:34<00:51,  4.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 9/20 [00:38<00:46,  4.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 10/20 [00:42<00:42,  4.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 11/20 [00:46<00:38,  4.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 12/20 [00:51<00:33,  4.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 13/20 [00:55<00:29,  4.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 14/20 [00:59<00:25,  4.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 15/20 [01:03<00:21,  4.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 16/20 [01:07<00:16,  4.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 17/20 [01:12<00:12,  4.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 18/20 [01:16<00:08,  4.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 19/20 [01:20<00:04,  4.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 20/20 [01:24<00:00,  4.24s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   31920, shape: (31920, 1000, 6), class balance: (array([0., 1.], dtype=float32), array([15960, 15960]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [5.552242279052734, 1.502982497215271, 0.38201701641082764, 0.13655543327331543, 0.06939662247896194, 0.056164104491472244, 0.05565778538584709, 0.05511616915464401, 0.0554816909134388, 0.03913825750350952, 0.03986441716551781, 0.03577597811818123, 0.0355619341135025, 0.03560847416520119, 0.034823473542928696, 0.03495441749691963, 0.03474854305386543, 0.03473513945937157, 0.034736793488264084, 0.034705717116594315], min_val_index: 19\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.00020000001, 10: 0.00020000001, 11: 4.0000003e-05, 12: 4.0000003e-05, 13: 4.0000003e-05, 14: 8.000001e-06, 15: 8.000001e-06, 16: 1.6000001e-06, 17: 1e-06, 18: 1e-06, 19: 1e-06}\n",
      "{'loss': [9.839420318603516, 3.276033639907837, 0.776054322719574, 0.20073671638965607, 0.09321451932191849, 0.06680723279714584, 0.058947667479515076, 0.057540878653526306, 0.056264474987983704, 0.04310597851872444, 0.04121261090040207, 0.03831620514392853, 0.037640102207660675, 0.037547823041677475, 0.03679259493947029, 0.03691203147172928, 0.036798782646656036, 0.03706244379281998, 0.03669255971908569, 0.036704450845718384], 'val_loss': [5.552242279052734, 1.502982497215271, 0.38201701641082764, 0.13655543327331543, 0.06939662247896194, 0.056164104491472244, 0.05565778538584709, 0.05511616915464401, 0.0554816909134388, 0.03913825750350952, 0.03986441716551781, 0.03577597811818123, 0.0355619341135025, 0.03560847416520119, 0.034823473542928696, 0.03495441749691963, 0.03474854305386543, 0.03473513945937157, 0.034736793488264084, 0.034705717116594315]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.00020000001, 10: 0.00020000001, 11: 4.0000003e-05, 12: 4.0000003e-05, 13: 4.0000003e-05, 14: 8.000001e-06, 15: 8.000001e-06, 16: 1.6000001e-06, 17: 1e-06, 18: 1e-06, 19: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.5], [0.5], [0.5]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [3], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['glorot_normal'], 'dense_dropouts': [0], 'dense_activations': ['relu'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 09:02:10.928727: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 09:02:11.444419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43490 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:17:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================[ Initial State ]================================"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 09:02:16.871792: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-07-14 09:02:17.820351: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2023-07-14 09:02:18.575161: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-14 09:02:18.575776: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-14 09:02:18.575792: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2023-07-14 09:02:18.577432: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-14 09:02:18.577498: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-07-14 09:02:19.149323: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN: roc_auc: 0.9014, eer: 0.1677, thres: 0.0357 => acc: 0.8323, f1: 0.8323\n",
      "\n",
      "Epoch 1/20\n",
      "125/125 [==============================] - 10s 56ms/step - loss: 8.0436\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 1.2650\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.1659\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.0683\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.0577\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.0561\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.0556\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.0550\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 7s 60ms/step - loss: 0.0543\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.0407\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 8s 64ms/step - loss: 0.0392\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 0.0361\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.0359\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 8s 65ms/step - loss: 0.0354\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 8s 60ms/step - loss: 0.0349\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 8s 61ms/step - loss: 0.0348\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 8s 62ms/step - loss: 0.0349\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 8s 60ms/step - loss: 0.0347\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 7s 59ms/step - loss: 0.0345\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 8s 61ms/step - loss: 0.0348\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9270, eer: 0.1326, thres: 0.1613 => acc: 0.8673, f1: 0.8673\n",
      "loss: 0.035\n",
      "{'loss': [8.043562889099121, 1.2650033235549927, 0.16585023701190948, 0.06827379763126373, 0.05765848606824875, 0.056083038449287415, 0.05555327981710434, 0.05497552827000618, 0.0543331541121006, 0.04066508635878563, 0.03917820751667023, 0.03613853082060814, 0.03589240834116936, 0.03535376489162445, 0.03486690670251846, 0.034812454134225845, 0.03487325459718704, 0.03471804037690163, 0.03451251983642578, 0.034752290695905685], 'val_loss': []}\n",
      "Training History:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 09:06:32.034335: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-OCSVM/0/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-OCSVM-0-SCNN_3_1_conv_1_dense_arg_dict_default-1000-model-optimal_lr-Max_2000x2_linear_1000_margin=0.5/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-OCSVM/0/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-OCSVM-0-SCNN_3_1_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-optimal_lr-Max_2000x2_linear_1000_margin=0.5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [04:27<00:00, 267.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [05:56<00:00, 356.42s/it]\u001b[A\n",
      "100%|██████████| 1/1 [05:56<00:00, 356.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-OCSVM/0/SCNN_3_1_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9EAAAHeCAYAAACc+YiPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAABuvAAAbrwFeGpEcAABEeElEQVR4nO3dfXxT5f3/8XeSNr2nLdBy05Y7UUCocitTcSo4QR0iThQU/OlAJs47NjYd46tO/bqhTmWIX8XhVGADZSA4pkNxuinKFIfcCqgIbYFSoPd3SZP8/qikSSkltE1OTvJ6Ph4+yDk5OecTeoG8z3Wd67J4PB6PAAAAAADAKVmNLgAAAAAAALMgRAMAAAAAECBCNAAAAAAAASJEAwAAAAAQIEI0AAAAAAABIkQDAAAAABAgQjQAAAAAAAEiRAMAAAAAECBCNAAAAAAAASJEAwAAAAAQIEI0AAAAAAABIkQDAAAAABAgQjQAAAAAAAEiRAMAAAAAECBCNAAAAAAAASJEAwAAAAAQoBijCwiVoqJyo0toVkZGiqTwrxPBQxuARDsAbQD1aAegDUCiHQTD8d/T1qAnGgAAAACAABGiAQAAAAAIECEaAAAAAIAAEaIBAAAAAAgQIRoAAAAAgAARogEAAAAACBAhGgAAAACAABGiAQAAAAAIECEaAAAAAIAAEaIBAAAAAAgQIRoAAAAAgAARogEAAAAACBAhGgAAAACAABGiAQAAAAAIECEaAAAAAGCYl1/+o2644RqjywgYITpMfHukUofLaowuAwAAAABOyxdfbNamTZ+2+PO33DJNy5e/0XYFBVmM0QWcrm+++UZPPPGENm/eLKfTqV69emnGjBm69NJLjS6txRZ/mqc//Guv4mKsevZHuRqYnWp0SQAAAAAMUuf2aFdhueLKHJKk0tKqkF07Psaqvp1SZLNaAv7Ma68tVffuPTVkyLAgVhY+TBWi3W63pk2bpnPPPVdvvfWWEhIS9Oc//1l33XWX1qxZo169ehldYou8vfOwJKm2zq1VWw8SogEAAIAo5ahza9qyzdpZWGFYDf06JeuPEwfKHnPqgcszZvxYW7dukc32L61c+Zp69z5LvXqdofz8PG3Zsln/+McHqq2t1bPPPq0NGz5UZWWFOnXqoltumarLLhstSVq06AX97W+rtWrV33Xw4AFNmHC1fv/7+frLXxZr+/atatcuVT/+8XRdddXVwf7qATFViD527JgKCgr04IMPKi0tTZJ044036ne/+52+/PLLZkN0RkZKiKo8fenJcVJRpSTpQLkjrGtF8PHzh0Q7AG0A9WgHoA1Enz2F5YYGaEnaWVihKqtVWQG0vxUrXtfIkSM1duxYzZw5U1OmTNH776/XQw89pB/84E+yWq165JFHtGPHVq1e/YbS09P1+uuv65FHHtT55w9Vjx49lJQUJ6vVooyMFNXWJkmSXn55oR599FH17t1bzz77rH7/+99p3LgrlZ6eHuyvf0qmeia6Y8eOGjJkiFasWKFjx47J6XTqL3/5i9LT0zV8+HCjy2uxHh2SvK/3Ha00sBIAAAAARurWIVG5WcaOTM3NSlW3Dokt/nyXLl00evRoWa31cfO+++7TsmXL1LFjR9lsNo0bN051dXXavn37Sc8xfvx49e3bVzExMfrhD38oh8OhvXv3trimtmSqnmhJmj9/vm677Tadf/75slgsSk9P17x589ShQ4dmP1dUVB6iCk9fh3ib93VxlVPf5BUrJd50Pxq00vE7zeHcVhF8tAPQBiDRDkAbiHYvXn+OviwsV1xSvCRjnokuKw78mi6XW1VVDhUVlcvhqFNmZhe/tpufn6cFC+Zp69bNqqyslMVS/7z1kSOlKioqV2Vlrdxuj4qKynXsWH2nYlpapvccVVUuSdKhQ8da/WeiLUZ3mCqpORwOTZs2Tb169dILL7yghIQErV69Wrfffrtef/119e7d2+gSWyQnLcFvO7+0Wv3iGboDAAAARCOb1aL+Xdr53EyxG1zR6YmNjfW+drvd+tnP7lSXLl314ouvqnPnLnI6nRo58oJmz3E8aIcjUw3n/uSTT7Rjxw7Nnj1bGRkZSk5O1k033aTs7Gz99a9/Nbq8FmscovOKqw2qBAAAAADaTnHxMR04UKBrr52gLl26ymKxaMeObUaX1SqmCtFut1uS5HK5/Pa7XC55PB4jSmoTWWnxftv5JawXDQAAAMAc4uMTVFCQp4qKCm9mOy41NU1JSUnaunWL6urqtGPHNi1fvlSJiUkqLDxkUMWtY6oQPXjwYHXs2FFPPvmkiouLVVtbq9dee0179+7VmDFjjC6vxZLjYtQhqWGIRl4JPdEAAAAAzGH8+Ou0YcOHmjDhapWWlvi9FxMTo9mzH9T776/XmDGX6P/+b77uvHOmrr56vBYv/pMWL/6TMUW3gsVjsi7cL7/8Uk899ZS2bdum2tpa9ezZUzNmzNCoUaOa/Vy4T8rwk9e36PP9JZKkQVnttHDiQEPrQegxgQgk2gFoA6hHOwBtABLtIBiibmIxSerbt68WLlxodBltrkeHJG+IzmM4NwAAAACEJVMN545kvuuwHal0qNrpauZoAAAAAIARCNFhokeHJL/tAnqjAQAAACDsEKLDRHefnmiJycUAAAAAIBwRosNE90Y90fmEaAAAAAAIO4ToMJGeGKuU+IZ53lgrGgAAAADCDyE6TFgsFr/nohnODQAAAADhhxAdRnxn6GY4NwAAAACEH0J0GOnhE6IPldXKUec2sBoAAAAAQGOE6DDiO7mYR9KBMp6LBgAAABCZPv/8M40YMVT5+XmSpEmTrtVLLy086fELFz6n664bG6ryTirm1IcgVLq391/mKr+kWj0a7QMAAACASPSXv6w0uoSA0BMdRnp09F/mKo8ZugEAAAAgrNATHUYyU+IUF2NV7XfPQhcwuRgAAAAQdTx1bjl2FKos7ogkqbqkKmTXtibEyt6/kyy2wPpbb7/9x+rWrbtmz37Qu+/AgQJdf/04PfPMc9q9e5fWrFmlo0eLlJLSTqNHX6np0++QxWI54VzXXTdWl19+haZPv0Nut1uLFr2gv//9TVVVVeqiiy5RampaW33NViFEhxGLxaKctAR9daRSEstcAQAAANHG46jTwUl/lmN7oQ4aVIO9fyd1+cuNsthPHRcvv/wKLVz4nH75y18rJqb++PXr1ykzs5MqKsr14ovP6f/+7yX17dtPX365Uz/96TRlZ+foqquubva869a9pb/8ZbGeeGKezj13kD788AP99rcPKyWlXZt8x9ZgOHeYyU6L977OZzg3AAAAEFWc+0vk2F5oaA2O7YVy7i8J6NhRo36gmppq/ec/n3j3vfvuOo0efaUuuugSvfHGW+rbt58kqW/ffurV6wzt2LHtlOddv36dhg+/QEOGDFNMTIwuuWSUzj13UIu+T1sjRIeZ7LQE7+sDpTWqc3sMrAYAAABAKMV2S5O9fydDa7D376TYbmkBHZuamqbvfe8CvffeO5Kkb7/dq6+/3qMrrrhKTqdTixa9oGuvvUojR16gkSMv0Jdf7pTD4TjleQsLD6lr165++3r06HXa3yUYGM4dZnJ8eqLr3B4VltcoKzWhmU8AAAAAiBQWe4y6vDZZju2FahcXK0kqCeNnoiVp9OgrNXfuo3I6nXr33X+of/9cdevWQ4899hv95z+f6LHHnlCfPv1ks9n0k5/cGtA5HQ6nLBb/Gjye8OhgJESHmaw0/8CcX0yIBgAAAKKJxWZV3Dld1C4jRZJUW1RucEXNu/DC70uy6LPP/qP169fphhtulCRt27ZFl1wyUmefPUCSVFVVpW+//UbdunU/5Tk7deqkQ4f8nwr/+us9bV57SzCcO8zkNArRTC4GAAAAIJzZ7XZdeukoLVu2RIWFhzRy5OWSpKysbO3evUvV1dU6dOig5s59RJ07d9Hhw4Wn7FW+8MLv65NPPtIXX/xXTqdT69e/ox07tofi65wSITrMdEqJU4y1Ybp3JhcDAAAAEO5Gj75SmzZ9qgsuuEjt2tXPoH3HHffI4XDohz+8TLNm3aMrrhirW2+9TTt37tCsWfc0e74f/eh6jR8/QQ88cL+uuuoyffjhB5owYWIovsopWTzhMrA8yIrCfAhExndDNYqKyvWjlz7V/uL6HuiLz+igJ6/pb2RpCBHfNoDoRTsAbQAS7QC0AdSjHbS947+nrUFPdBjyHdLNcG4AAAAACB+E6DDku1Z0QWmN3NExWAAAAAAAwh4hOgz59kTX1rl1pOLU66gBAAAAAIKPEB2GspmhGwAAAADCEiE6DPkO55akAmboBgAAAICwQIgOQ11T4+WzyhU90QAAAAAQJgjRYSjWZlXnlDjvdj4hGgAAAADCAiE6TPk+F53PcG4AAAAACAuE6DCVk+6/VrSHZa4AAAAAwHCE6DCVldowuVilw6WSaqeB1QAAAAAAJEJ02Mo5YZkrhnQDAAAAgNEI0WEqO90/RDO5GAAAAAAYjxAdprJT/deKJkQDAAAAgPEI0WEqPtamjGS7d5vh3AAAAABgvBijCzgdn376qX784x+fsL+urk7XXHONfvvb3xpQVfBkpyWoqMIhSSqgJxoAAAAADGeqED1s2DBt3brVb19RUZF++MMfavz48QZVFTw5afH6b36pJHqiAQAAACAcmH4494MPPqgrrrhC5513ntGltLlsnxm6S6qdqqitM7AaAAAAAICpeqIbe++99/T555/r3XffPeWxGRkpIaio9XzrPLtbuqRvvduVFqt6muR7oOXM0lYRXLQD0AYg0Q5AG0A92kF4MW1PtNvt1lNPPaXp06crOTnZ6HKCokeHJL/tb49WGlQJAAAAAEAycU/0unXrVFhYqJtuuimg44uKyoNcUescv7vkW2eSx+13zI79xRrehbtQkaqpNoDoQzsAbQAS7QC0AdSjHbS9tujVN21P9Jo1azRy5EjFxcUZXUrQJMfFKC0h1rudV8wM3QAAAABgJFOG6IqKCv373//WZZddZnQpQZeTFu99nV/KDN0AAAAAYCRThuidO3fK4XCoX79+RpcSdFk+M3Tns1Y0AAAAABjKlCH68OHDkqQOHToYXEnw+fZEF1U4VON0GVgNAAAAAEQ3U4boq666Srt27VJCQsKpDzY537WiJYZ0AwAAAICRTBmio8kJIZrJxQAAAADAMIToMOc7nFuS8nguGgAAAAAMQ4gOc2kJsUqy27zbBQznBgAAAADDEKLDnMViUY7PkG7WigYAAAAA4xCiTSDbd61ohnMDAAAAgGEI0SbgO7nYofJaOV1uA6sBAAAAgOhFiDYB3+Hcbo90gOeiAQAAAMAQhGgTyGo0Q3d+CSEaAAAAAIxAiDaBnEZrRbPMFQAAAAAYgxBtAh2T7YqLafhRMbkYAAAAABiDEG0CVotFWam+M3QznBsAAAAAjECINgm/taLpiQYAAAAAQxCiTcJ3masDpTVyuT0GVgMAAAAA0YkQbRI56Q3DuevcHhWW1xpYDQAAAABEJ0K0SWSnMkM3AAAAABiNEG0S2en+a0UXEKIBAAAAIOQI0SbRKSVeMVaLdzuPGboBAAAAIOQI0SYRY7Woq98yV/REAwAAAECoEaJNJDutIUTzTDQAAAAAhB4h2kR814rOL6mRx8MyVwAAAAAQSoRoE8nyCdG1dW4dqXQYWA0AAAAARB9CtInkpPnP0M2QbgAAAAAILUK0iWSn+a8Vnc8M3QAAAAAQUoRoE+naLl4Wn21m6AYAAACA0CJEm4g9xqrO7eK823nF9EQDAAAAQCgRok3Gd0h3QSk90QAAAAAQSoRok/Fd5iqvpJplrgAAAAAghAjRJpPtM0N3Ra1LpdV1BlYDAAAAANGFEG0yJ8zQzZBuAAAAAAgZQrTJ5DQK0awVDQAAAAChQ4g2mSyf4dySlM8M3QAAAAAQMoRok0mItaljkt27TU80AAAAAIQOIdqEcnx6o/NL6IkGAAAAgFAhRJtQls9z0fn0RAMAAABAyBCiTch3crHiaqcqalnmCgAAAABCwZQheuXKlRozZoxyc3M1atQovfzyy0aXFFLZjSYXK2BINwAAAACEhOlC9Nq1azV37lzNmTNHmzZt0mOPPably5dr27ZtRpcWMjnpLHMFAAAAAEaIMbqA07VgwQJNmzZNI0aMkCQNHz5cb731lsFVhVZ2KiEaAAAAAIxgqhB9+PBhff3110pMTNSkSZO0a9cuZWVlafr06Ro7dmyzn83ISAlRla0TSJ0ZktITY1Vc5ZQkHa1xmeb74dT4WUKiHYA2gHq0A9AGINEOwo2pQvShQ4ckScuXL9cTTzyhnJwcrVixQrNmzVLnzp01bNgwgysMne4dklRcVSJJ+vZopbHFAAAAAECUMFWI9ng8kqQpU6aoT58+kqSbb75Zb7zxhlatWtVsiC4qKg9JjS11/O5SoHV2Sor1vt5bVBH23w+ndrptAJGJdgDaACTaAWgDqEc7aHtt0atvqonFMjMzJUnp6el++7t3767CwkIjSjKM7zJXhyscqnG6DKwGAAAAAKKD6UJ0Zmamtm7d6rd/3759ysrKMqgqYzSeobuglGWuAAAAACDYTBWibTabpk6dqiVLlujjjz+Ww+HQ0qVLtXPnTk2aNMno8kIqK9V/reh8ZugGAAAAgKAz1TPRkvT//t//U0VFhe6//34dPXpUPXv21Isvvqh+/foZXVpInbhWND3RAAAAABBspgvRFotFd955p+68806jSzFUekKskuw2VTrqn4WmJxoAAAAAgs9Uw7nRwGKx+A3pJkQDAAAAQPARok3Md0g3w7kBAAAAIPgI0SaW7bPM1aGyGjldbgOrAQAAAIDIR4g2sZy0huHcbo90sKzWwGoAAAAAIPIRok3MtydakvJ4LhoAAAAAgooQbWKNQ3QBIRoAAAAAgooQbWIZyXbFxTT8CJlcDAAAAACCixBtYlaLRV1Z5goAAAAAQoYQbXI5PkO684oJ0QAAAAAQTIRok8v2maH7QFmNXG6PgdUAAAAAQGQjRJuc7+RiTpdHhytY5goAAAAAgoUQbXK+a0VLDOkGAAAAgGAiRJtc42Wu8kuZoRsAAAAAgoUQbXKd28XLZrV4t/PpiQYAAACAoCFEm1yM1aKu7eK823kscwUAAAAAQUOIjgC+Q7oLGM4NAAAAAEFDiI4AjdeK9nhY5goAAAAAgoEQHQGyfGborqlz62ilw8BqAAAAACByEaIjQE6jGbrzShjSDQAAAADBQIiOAI1DdD6TiwEAAABAUBCiI0DX1HhZfLYJ0QAAAAAQHIToCGCPsapTiu8yVwznBgAAAIBgIERHiOz0hiHd9EQDAAAAQHAQoiNEdmrDDN15JSxzBQAAAADBQIiOEL6Ti1XUulRaU2dgNQAAAAAQmQjREcJ3OLckFTCkGwAAAADaHCE6QuSkxfttM7kYAAAAALQ9QnSEyEr174nOoycaAAAAANocITpCJNpt6pBk924znBsAAAAA2h4hOoL4DulmODcAAAAAtD1CdATJSmOtaAAAAAAIJkJ0BPHtiT5W5VSlg2WuAAAAAKAtEaIjiO9a0ZKUz5BuAAAAAGhThOgIknVCiGZINwAAAAC0JUJ0BDlhrehiQjQAAAAAtKUYows4XTfddJM2b94sq9U//69Zs0Y9e/Y0qKrw0C4+VqnxMSqtqX8WOr+U4dwAAAAA0JZMF6JLS0v1i1/8QrfccovRpYSlrLQElR4ql8RwbgAAAABoa6YL0SUlJUpLSzvtz2VkpLR9MUHQ2jp7d0rRju9C9IGyWtN8bzTgZwaJdgDaAOrRDkAbgEQ7CDemeya6tLRUb7/9tkaPHq2hQ4fquuuu0/vvv290WWGjR4dE7+uDpTWqcboMrAYAAAAAIoupeqIdDofOPPNMde/eXY899pjsdrsWL16sGTNmaNmyZTr33HNP+tmiovIQVnr6jt9dam2d7e02v+0vvi5Srw5JrTonQqOt2gDMjXYA2gAk2gFoA6hHO2h7bdGrb6oQbbfbtXLlSr99M2bM0Lp167R8+fJmQ3S0yD5hhu4aQjQAAAAAtBHTDeduSrdu3VRYWGh0GWEhm7WiAQAAACBoTBWi9+/fr9/85jeqqKjw279nzx51797doKrCS/vEWCXGNgzpJkQDAAAAQNsxVYju0KGD3nnnHf3mN79RSUmJKisrNW/ePO3fv1+TJ082urywYLFYlOUzpDu/hLWiAQAAAKCtmCpEJyUl6eWXX1ZZWZlGjx6tCy64QBs3btTSpUvVq1cvo8sLGzk+Q7rz6IkGAAAAgDZjqonFJKl379564YUXjC4jrPk+F32orEZ1LrdibKa6XwIAAAAAYYlkFYF8Z+h2eaSDZbUGVgMAAAAAkYMQHYFyGs3QzZBuAAAAAGgbhOgI1HitaCYXAwAAAIC2QYiOQJkpcbLbLN5tlrkCAAAAgLZBiI5AVotFWanM0A0AAAAAbY0QHaF8h3QXMJwbAAAAANoEITpC5aQ39ETnl1bL5fYYWA0AAAAARAZCdITyHc7tdHlUVMEyVwAAAADQWoToCJWT7j9DN89FAwAAAEDrEaIjVOO1olnmCgAAAABajxAdoTqnxMlnlSuWuQIAAACANkCIjlAxNqu6pDYM6c6jJxoAAAAAWo0QHcGyfYZ00xMNAAAAAK1HiI5g2T490fkl1fJ4WOYKAAAAAFqDEB3BfNeKrna6dbTKaWA1AAAAAGB+hOgIlt1ohu4ChnQDAAAAQKsQoiNY42WuWCsaAAAAAFqHEB3BuqbGy2eVK2boBgAAAIBWIkRHsLgYqzJT4rzb+cX0RAMAAABAaxCiI1xOms8M3aX0RAMAAABAaxCiI1wWa0UDAAAAQJshREc438nFymrqVFrNMlcAAAAA0FKE6AjnO5xbYkg3AAAAALQGITrCZTVa5orJxQAAAACg5YIWoj0ej9/rnTt3qrS0NFiXw0lkN+qJZq1oAAAAAGi5oIToTZs2adSoUZLqA/TNN9+s8ePH6+KLL9bHH38cjEviJJLsMWqfGOvdZjg3AAAAALRcTDBO+uSTT2rixImSpPXr12vPnj1655139Nlnn2n+/Pk6//zzg3FZnER2WoKOVdVPKMZwbgAAAABouaD0RO/evVu33HKLJOmf//ynrrzySuXk5Ojqq6/WV199FYxLohm+k4sxnBsAAAAAWi4oIdpms8lms0mSPv74Y40YMUKS5Ha75XSyxFKoZftMLnasyqkqh8vAagAAAADAvIIynLtv37569tlnFRsbq7KyMu/w7XXr1qlHjx7BuCSakdN4hu6Sap2VmWxQNQAAAABgXkEJ0ffff79+/vOfq6ysTA888IASEhJ07Ngx3XfffXrmmWeCcUk0o/EM3YRoAAAAAGiZoITos88+W2+99Zbfvvbt2+udd95Rly5dgnFJNCO7UU90XgkzdAMAAABASwTlmei6ujq99tpr3u0PPvhAd9xxh/785z/L4XAE45JoRmpCrNrFN9wvyWdyMQAAAABokaCE6CeffFJ/+tOfJEkHDhzQXXfdpeTkZG3cuFGPP/54MC6JU8hKbRjSTYgGAAAAgJYJSoh+66239Pzzz0uS3nzzTZ177rl6/PHHNX/+fL333nttco1NmzapX79+mj9/fpucL9L5Ti7GcG4AAAAAaJmghOiysjJ1795dkrRhwwaNGjVKktSpUycdO3as1eevqanR7NmzlZSU1OpzRYvs9IYQfbi8VrV1bgOrAQAAAABzCkqITk9PV35+vg4fPqzPP/9cF110kSTp4MGDSkxMbPX5n3rqKfXs2VP9+vVr9bmiRbbPcG6PpAOl9EYDAAAAwOkKyuzcV199tSZOnCibzabBgwfrjDPOUGVlpe677z5dcsklrTr3Z599ptWrV2vNmjWaNWtWwJ/LyEhp1XVDJVh15vZ0+m2Xuc3zexJt+LlAoh2ANoB6tAPQBiDRDsJNUEL0vffeqzPPPFNlZWUaO3asJCk2Nlbdu3fXfffd1+LzVldXa/bs2brvvvvUqVOntio3KnTv4D8CYN+xKoMqAQAAAADzCkqIlqSrrrpKklReXq5jx46pffv2euSRR1p1zqeeeko9evTQtddee9qfLSoqb9W1g+343aWg1enxKCHWqmpn/bPQX+aXhP3vSbQJehuAKdAOQBuARDsAbQD1aAdtry169YMSop1Op/7whz9o+fLlKi+v/4G3a9dO119/vWbOnCmr9fQfxT4+jPvNN99s63KjgsViUXZagvYUVUqS8ljmCgAAAABOW1BC9IIFC7R27VrNmDFDZ5xxhjwej3bt2qUlS5aoXbt2uu222077nH/9619VVVWlq6++2ruvoqJCW7Zs0XvvvadVq1a15VeISL4hmrWiAQAAAOD0BSVEv/3223r++ed11llnefddfPHFuuCCC/SLX/yiRSH6/vvv1z333OO375577tHAgQM1bdq0VtccDXLSGmboPlhWqzqXWzG2oEzQDgAAAAARKSghuqioSL179z5h/9lnn63CwsIWnTM1NVWpqal+++x2u5KTk5WRkdGic0abrLSGtaJdbo8Oldcq22cfAAAAAKB5QQnRXbt21caNG3X++ef77d+4caO6dOnSZtdZvHhxm50rGvj2REv1z0UTogEAAAAgcEEJ0TfddJPuvPNOjR8/Xr179/Y+E7169WrdddddwbgkApDTKDDnl9QYVAkAAAAAmFNQQvTEiRNlt9u1dOlSrV69WhaLRd26ddNDDz2kcePGBeOSCEBGcpxibRY5XR5JTC4GAAAAAKcraOtEX3vttU2u53zNNdfojTfeCNZl0Qyb1aKs1Hh9e6w+POcVE6IBAAAA4HSEfGrmb775JtSXhA/fZ6DzSxnODQAAAACnI+Qh2mKxhPqS8OEbogtKquX2eAysBgAAAADMhUWCo4zvDN0Ol0eHy2sNrAYAAAAAzIUQHWUaL2lVwJBuAAAAAAhYm04s9stf/vKUx9TV1bXlJXGaGi9zlVdcrSE5acYUAwAAAAAm06Yh+uDBg6c8ZvDgwW15SZymLu3iZLNI361ypTzWigYAAACAgLVpiF68eHFbng5BEGOzqnO7eO8wbtaKBgAAAIDA8Ux0FPId0k2IBgAAAIDAEaKjUJbPDN35JTXysMwVAAAAAASEEB2FfHuiq5wuHatyGlgNAAAAAJgHIToKNV7miiHdAAAAABAYQnQUyvYZzi3VD+kGAAAAAJwaIToKZaX6h+g8eqIBAAAAICCE6CgUH2tTZrLdu81wbgAAAAAIDCE6SuWk+y5zxXBuAAAAAAgEITpKZaeyVjQAAAAAnC5CdJTynVystKZOZTUscwUAAAAAp0KIjlK+w7klhnQDAAAAQCAI0VHKdzi3xJBuAAAAAAgEITpKZaWxzBUAAAAAnC5CdJRKjotR+8RY7zbDuQEAAADg1AjRUSyLGboBAAAA4LQQoqNYTnrDkO48eqIBAAAA4JQI0VEsO62hJ/popUPVTpeB1QAAAABA+CNER7HsRpOLMaQbAAAAAJpHiI5iOWn+y1wxpBsAAAAAmkeIjmLZjUJ0fjE90QAAAADQHEJ0FEuNj1FKXIx3O7+UEA0AAAAAzSFERzGLxeL3XDTDuQEAAACgeYToKOc7pJvh3AAAAADQPEJ0lMvx6YkuLK+Vo85tYDUAAAAAEN4I0VEuy6cn2iPpQClDugEAAADgZEwXovfs2aPbb79dw4cP19ChQ3Xdddfp3XffNbos0zpxmSuGdAMAAADAyZgqRFdXV2vy5Mnq1q2b1q9frw0bNmjUqFG6++679dVXXxldnin5DueWpHx6ogEAAADgpEwXomfNmqWZM2cqOTlZdrtdkydPlsvl0u7du40uz5Q6JNkVH9PQDJhcDAAAAABOzuLxeDxGF9FSxcXFWrhwof7+97/rjTfeUHp6utElmdKYZ/6lLw+VS5IuPitDr/z4PIMrAgAAAIDwFGN0AS01YMAAOZ1O5ebm6qWXXiJAt0L3DoneEL3/WJXB1QAAAABA+DJtiN62bZuOHTumpUuX6sYbb9SyZcvUs2fPkx5fVFQewupOX0ZGiiRj6sxMiPW+3n+sSgcLyxRjtYS8jmhnZBtA+KAdgDYAiXYA2gDq0Q7a3vHf09Yw1TPRjbVv31533XWXOnXqpGXLlhldjmll+0wu5nJ7dKiMycUAAAAAoCmmCtHr16/XyJEjVVtb67ff4XDIZrMZVJX5ZTda5iqfZa4AAAAAoEmmCtGDBg1SdXW1Hn74YZWUlKi2tlavvPKK9u/fr8svv9zo8kwrJ71xiKYnGgAAAACaYqoQ3b59e7366qsqLCzUpZdeqgsuuEB/+9vf9Oyzz2rgwIFGl2damclxfs9A59ETDQAAAABNMt3EYmeeeab++Mc/Gl1GRLFZLcpKjde+79aIpicaAAAAAJpmqp5oBI/vkG6eiQYAAACAphGiIUnKSm2YobugtEZuj8fAagAAAAAgPBGiIUnK8Zmhu7bOraIKh4HVAAAAAEB4IkRDkpR9wgzdDOkGAAAAgMYI0ZAkZfsM55YI0QAAAADQFEI0JEldU+Pls8qV8pihGwAAAABOQIiGJCnWZlXndg290fREAwAAAMCJCNHwyknzDdH0RAMAAABAY4RoeGWn+a8V7WGZKwAAAADwQ4iGl2+IrnS4VFztNLAaAAAAAAg/hGh4+Q7nlhjSDQAAAACNEaLhlZXGWtEAAAAA0BxCNLwarxWdV0yIBgAAAABfhGh4xcfalJls927nlzKcGwAAAAB8EaLhJ6vRDN0AAAAAgAaEaPjxnVyM4dwAAAAA4I8QDT++y1yV1tSpvKbOwGoAAAAAILwQouEnu/EM3aX0RgMAAADAcYRo+Gm8VjRDugEAAACgASEafk7oiS5hhm4AAAAAOI4QDT/JcTFKT4j1bjNDNwAAAAA0IETjBNk+Q7oJ0QAAAADQgBCNE/gO6c5jODcAAAAAeBGicYIcnxB9pNKhaqfLwGoAAAAAIHwQonGCrEYzdBfQGw0AAAAAkgjRaEJOoxm683guGgAAAAAkEaLRhMYhmsnFAAAAAKAeIRonSE2IUZLd5t1mrWgAAAAAqEeIxgksFotfbzTDuQEAAACgHiEaTfJd5orh3AAAAABQjxCNJuWkN8zQXVheK0ed28BqAAAAACA8EKLRpOzUhp5ot0c6UMZz0QAAAABAiEaTstP914pmSDcAAAAAEKJxEicuc0VPNAAAAAAQotGkjkl2xcU0NA96ogEAAADAhCH66NGj+tWvfqURI0Zo8ODBuv766/Xxxx8bXVbEsVgsyk5rGNLNMlcAAAAAYMIQfccdd+jw4cNatWqVPv74Yw0fPlx33HGHCgsLjS4t4uT4LXPFcG4AAAAAiDG6gNNRXl6uM844Q1OnTlVGRoYk6bbbbtPChQu1ZcsW/eAHPzjpZzMyUkJVZquEU51ndmmn9786Kkk6WFaj9PZJirGZ7r6L6YRTG4BxaAegDUCiHYA2gHq0g/BiqhCdkpKixx57zG9fXl6eJKlz585GlBTRundI8r52ujw6WFqjnPaJBlYEAAAAAMYyVYhurKKiQr/61a80atQo5ebmNntsUVF5iKpqmeN3l8KpzrQYi9/2F98cUbwr3aBqIl84tgGEHu0AtAFItAPQBlCPdtD22qJX37RjcwsKCjRp0iR16NBBTz75pNHlRCTficUkZugGAAAAAFOG6C1btmjChAkaMmSIFi5cqMREhhgHQ6eUeMVYG3qj84qZXAwAAABAdDPdcO7du3frtttu04wZM3TLLbcYXU5Ei7Fa1DU1XvuL63ug6YkGAAAAEO1M1RPtcrl0//33a8KECQToEPFb5qqUEA0AAAAgupmqJ/q///2vtm/frt27d+uVV17xe2/cuHF69NFHDaoscvk+F51fUiO3xyOrxdLMJwAAAAAgcpkqRA8dOlS7du0yuoyoku3TE11b59aRCocyU+IMrAgAAAAAjGOq4dwIPd/h3BJDugEAAABEN0I0mpXVeJkrZugGAAAAEMUI0WhW13bx8lnlSnnM0A0AAAAgihGi0Sx7jFWdfZ6Bzi+hJxoAAABA9CJE45SyfJe5oicaAAAAQBQjROOUfCcXyyuplsfjMbAaAAAAADAOIRqn5LtWdKXDpZJqp4HVAAAAAIBxCNE4pROWueK5aAAAAABRihCNU8puFKKZoRsAAABAtCJE45ROWCuaEA0AAAAgShGicUoJsTZlJNu92wznBgAAABCtCNEISHZqQ280PdEAAAAAohUhGgHJ9lvmip5oAAAAANGJEI2A5KQ3hOiSaqcqausMrAYAAAAAjEGIRkCyUplcDAAAAAAI0QiIb0+0xJBuAAAAANGJEI2AZKf6h2h6ogEAAABEI0I0ApISH6PU+BjvNiEaAAAAQDQiRCNgvkO6Gc4NAAAAIBoRohEw32Wu6IkGAAAAEI0I0QhYTlrDDN1FFQ7VOF0GVgMAAAAAoUeIRsB8e6IlKb+UId0AAAAAogshGgE7IUQXM6QbAAAAQHQhRCNgvsO5JXqiAQAAAEQfQjQClpYQqyS7zbvN5GIAAAAAog0hGgGzWCx+Q7o/+bZY5TV1BlYEAAAAAKFFiMZpye2S4n1dUFqj+97cIafLbWBFAAAAABA6hGiclluHd1NGst27/en+Ev3u3T3yeDwGVgUAAAAAoUGIxmnJTInT09cMUEJsQ9NZs61QL/8nz8CqAAAAACA0CNE4bX06Jet/r+onq6Vh33Mffqt1Xx42rigAAAAACAFCNFrkojM66OeXnuG37zdv79IXBaUGVQQAAAAAwUeIRotdPyhLEwdnebcdLo9mrd7B0lcAAAAAIhYhGq1y78W9dFGv9t7tkmqn7l25TaXVTgOrAgAAAIDgIESjVWxWix69qp/6ZiZ79+0rrtYv1uyQo46lrwAAAABEFtOF6Ly8PE2ZMkV9+vRRfn6+0eVAUqLdpqfG91enlDjvvv/ml+p/39nN0lcAAAAAIoqpQvQ777yjG264QV27djW6FDSSkRynp8f3V5Ld5t339x2H9cdP9htYFQAAAAC0LVOF6JKSEi1ZskTjxo0zuhQ04cyMZP12bD/ZfJa+Wrhhn/6+o9C4ogAAAACgDVk8Jhxvu2HDBt16661av369srOzjS4HjSzduE+/XrXNu223WbV46nka3quDgVUBAAAAQOuZqica5nDT8O6a/v1e3m2Hy62fLNmkb4oqDKwKAAAAAFovxugCQqWoqNzoEpqVkZEiKfzrDNTUoVnac7BM/9xzRJJUUuXUzYs26k+TBiktMdbg6sJTpLUBtAztALQBSLQD0AZQj3bQ9o7/nrYGPdEICqvFooev6KP+nRsaaX5JjWat3q5alr4CAAAAYFKEaARNfKxNv7+mv7q0a1j66osDZXr47V1ym+9RfAAAAAAgRCO4OiTZ9cy1A5Qc17D01bpdRXphwz4DqwIAAACAljFViB49erRyc3M1ffp0SdKYMWOUm5urOXPmGFwZmtOrQ5J+N/Zs2awNa1+99Ml+vbntkIFVAQAAAMDpM9XEYv/4xz+MLgEtNLx7un51WW89um6Pd9//vrNHndvFaVi3dAMrAwAAAIDAmaonGuY2LreLbjkvx7vtcnv0yzU7tPdolYFVAQAAAEDgCNEIqRkjeugHfTK82xW1Lt27cquOVjoMrAoAAAAAAkOIRkhZLRY9OKaPzunazrvvQFmtZq3erhqny8DKAAAAAODUCNEIubgYq54cd7ayUuO9+7YdLNdDLH0FAAAAIMwRomGI9MT6pa/axTfMbbd+9xEt+Pe3xhUFAAAAAKdAiIZherRP1ONXn60Yn6WvXv00T6u2HDSwKgAAAAA4OUI0DDUkJ01zLj/Lb9/cd/fok2+PGVQRAAAAAJwcIRqGu6p/J037Xjfvtssj3f/mTn11pNLAqgAAAADgRIRohIXpF3TXmH6Z3u1Kh0szV27TkYpaA6sCAAAAAH+EaIQFi8Wi/7n8LA3Kalj66lB5rX72xnZVs/QVAAAAgDBBiEbYsMdY9fi4/uqWnuDdt7OwQv+z9ku53Cx9BQAAAMB4hGiElbSEWD0zfoBSfZa++uDro/rDv74xsCoAAAAAqEeIRtjJSU/Qk+P6K9bWsPTVnzcV6PXNBwysCgAAAAAI0QhTA7NT9eDoPn77nnzvK330DUtfAQAAADAOIRpha3S/TN1+YXfvttsjzf7bTu06XGFgVQAAAACiGSEaYe3Hw7vph/07ebernC79bNU2HS5n6SsAAAAAoUeIRlizWCya/YMzNTQn1bvvcIVDM1dtU5WDpa8AAAAAhBYhGmEv1mbV3KvPVo/2DUtf7S6q1K/X7mTpKwAAAAAhRYiGKbSLj9XT4wcoPSHWu+/Db47pqX9+LY+HIA0AAAAgNAjRMI3stAT9/pr+iotpaLavbT6gZf9l6SsAAAAAoUGIhqnkdm2nh8b4L3319D+/1gdfHTGoIgAAAADRhBAN07msT4buuqind9sjac7aL7WzsNy4ogAAAABEBUI0TGnKsGxdk9vZu11T59bMVdt1qKzGwKoAAAAARDpCNEzJYrHovlG9Nbx7mnff0UqHZq7aroraOuMKAwAAABDRCNEwrRibVb8be7Z6dUj07vvqSKV+9bedqmPpKwAAAABBQIiGqSXHxeiZaweofWLD0leffFusJ9Z/xdJXAAAAANocIRqm16VdvJ4aP8Bv6auVWw5qyWf5BlYFAAAAIBIRohER+ndO0aNX9pXFZ98f/rVX7+0uMqwmAAAAAJGHEI2IccmZHXXvJb389j3w1i5tO1hmUEUAAAAAIk2M0QUAbWnS4CzlFVdrxRcHJUm1dW79/I3tmnZ+d2Um29UxOU6ZyXa1T7TLZrWc4mwAAAAA4I8QjYhisVj085G9daCsRhv2FkuSjlU59fj6r/yOs1qkDkl2dUyyKzM5Th2T7cpItisjOa7h1yS72sXHyGIhbAMAAACoR4hGxImxWvTYD/vptmVfaE9RZZPHuD1SUYVDRRUO7SysOOm54mKs6pjUdMDumFwfwDOS7YqPtQXr6wAAAAAII4RoRKQke4yeGT9Av167U18UlKmli13V1rlVUFqjgtKaZo9LiYv5LlTXDxnPSGoI3cf3dUiyK4Yh5AAAAICpEaIRsTJT4vTixIGqc3t0tNKhIxW1Ovxd73NRRa2KKh0qKq//9UiFQ+W1dS2+Vnltncpr67T3aNVJj7FIap9k/y5g+/Zs14fsPnUedUyOU2m1UzarRVaLRVaLZLNaZLFYZLOIoeUAAACAwQjRiHgxVos6pcSpU0qc+jdzXLXTpSMVDh2uqG34tdIndH/3q8PVsn5tj6SjlQ4drXToy8MtOoUskqzW+kBttVj8wrbVYvF7r/Hr48fYTnKcxfte08dZvgv0Vp/jLN8tKtZUtj++63jw9z2k8fEBHePz7vH3LCccG8gxJ6/15Aec/IjmPtvseyd5MzExThaLVFXpaNGJW3LN+s818x1bcO+mqY+c7CZQ08eexrWaOPhk57R99+fGZrX4vbZa6v+uaNiu/zXG57XNalHMd22/8ee9r09yTm6AAQAQOUwXoqurqzV37lz961//UmlpqXr37q27775bF154odGlweQSYm3KSU9QTnrCSY/xeDwqq6mrD9SVtSoq/+7XCv+wfazKIXdLx5A3wyPJ5fbI5d0CYAYWqSGINwrmNov8wrg91iab1SKXy93keST/GwfN3XzyPbap4/wPP/GmWFM3oRruWfnXYLH4v2fx299wQd99jc9rOf453/0++3yvaPE510mP9fnuJ9TSEi38aEs+lpAQK8mimpqT31Br65tf9eds5r0W3lCs/2yLymnxNSPhvlVigl0eSdXVzdxURYu15u+CYPz5OpnERLskqarq9NtBS/+l6GnFPzHPzEjSmH6ZEb8KjulC9MMPP6wdO3Zo0aJF6tq1q1atWqXbb79dq1evVq9evU59AqAVLBaLUhNilZoQq94ZSSc9rs7t0bFKx3dDxeuHkTf82tDLXVbT8iHkAMzDo/q/F+rcHtUaXQwAAEFUUu3UTUOzjS4jqEwVoktLS/Xmm2/qmWeeUc+ePSVJEydO1LJly7Rs2TLNnj3b4AqBejFWizJT4pSZEicp5aTH1Thd3iHjNVariisdKi2vkdvtkdvjkcvtkdsjuTye+n2Sz3uS29Nw3PFearfHI5en6ePcHvmc1/84//f8jzu+7XZ/95nv3mvs+J1Lj3e7iWNOONbjt930+TxN7Gt8rM8xpzi2yYuc7O0WfpRxAgAAIBqdakLeSGCqEL19+3Y5nU7l5ub67T/nnHP0xRdfNPvZjIyTB5lwYpY60XZyjC4AYaWpGw/+7zfzXgvP29IbBfWfPfnNlEA0efPkNM7Z1O6TfVe3u/6GlMtd/1+d2y23W6pzu7/b9n2v/gZSncvnWJ/t4+epc/m8dnvkcrnl8kgut7v+HD7nbbzdcM0Tjz1+k8rj971O/Na+X7Wpm1eNbyid7Limz3fiDa6T3djy+JzYI493n8fj8avB890LT6NzeTzy+4z/uRvOJ99zNjre0/h4v7r9r9kSTbXLgD7Xwmue6mPNn7eZP+8h/jvklNds6XlbcRPzVH/Phpton1MhGD+v1pyx5X+mW/53SGuaQEuHrbf0mv26tNO9Y/oqI+3kj0dGAlOF6GPHjkmS0tLS/Panp6fr6NGjBlQEAG3rVP9Yavn/SKP7H2EAAABtxVQh+vidqCZnYj3FvyyLisqDUlNbOd4DHe51InhoA5BoB6ANoB7tALQBSLSDYGiLkb/WNqgjZDp27ChJKi4u9ttfXFzsfQ8AAAAAgGAxVYgeMGCA7Ha7Nm/e7Lf/888/19ChQ40pCgAAAAAQNUwVolNSUvSjH/1I8+fP1969e1VdXa1FixapoKBAEydONLo8AAAAAECEM9Uz0ZI0e/ZsPf7445o6darKysrUt29f/fGPf1RWVpbRpQEAAAAAIpzpQrTdbtecOXM0Z84co0sBAAAAAEQZUw3nBgAAAADASIRoAAAAAAACRIgGAAAAACBAhGgAAAAAAAJEiAYAAAAAIECEaAAAAAAAAkSIBgAAAAAgQIRoAAAAAAACRIgGAAAAACBAhGgAAAAAAAJk8Xg8HqOLAAAAAADADOiJBgAAAAAgQIRoAAAAAAACRIgGAAAAACBAhGiDVVdX66GHHtLIkSM1ZMgQ3XDDDfroo4+MLgshtmfPHt1+++0aPny4hg4dquuuu07vvvuu0WUhxFauXKkxY8YoNzdXo0aN0ssvv2x0SQixgwcPatasWbrooos0cOBA3Xrrrdq7d6/RZSHI8vLyNGXKFPXp00f5+fl+7y1dulRXXnmlBg0apJEjR+oPf/iD3G63QZUiWE7WBlasWKG+ffsqNzfX779nnnnGuGIRNCdrB06nU08//bQuu+wyDRw4UJdddpl+//vfy+FwGFhtdCNEG+zhhx/Wf//7Xy1atEgbNmzQ+PHjdfvtt+ubb74xujSESHV1tSZPnqxu3bpp/fr12rBhg0aNGqW7775bX331ldHlIUTWrl2ruXPnas6cOdq0aZMee+wxLV++XNu2bTO6NISIy+XS9OnTdfToUa1YsUIfffSRzjnnHE2dOlW1tbVGl4cgeeedd3TDDTeoa9euJ7y3bNkyPf3003rooYf02Wef6YknntDLL7+sxYsXG1ApgqW5NlBaWqqzzjpLW7du9fvv3nvvDX2hCKrm2sGCBQu0YsUKzZ8/X5s2bdL8+fO1cuVKPf/88wZUCokQbajS0lK9+eabuuuuu9SzZ0/FxcVp4sSJOuOMM7Rs2TKjy0OIVFdXa9asWZo5c6aSk5Nlt9s1efJkuVwu7d692+jyECILFizQtGnTNGLECNntdg0fPlxvvfWWBgwYYHRpCJG9e/dq9+7duvvuu9WpUyclJSXpnnvuUV1dndavX290eQiSkpISLVmyROPGjTvhPYfDoV/84hc677zzZLPZNGTIEH3ve9/TJ598YkClCJbm2kBpaanS09MNqAqh1lw72LZtm4YNG6Z+/frJZrOpX79+Ou+887RlyxYDKoVEiDbU9u3b5XQ6lZub67f/nHPO0RdffGFQVQi19u3ba8KECUpISJAkFRcX67nnnlPnzp11/vnnG1wdQuHw4cP6+uuvlZiYqEmTJmnw4MEaO3as3nzzTaNLQwhZLBZJ8huqa7ValZqaqq1btxpVFoJswoQJ6tWrV5Pv3Xzzzbrhhhu82x6PRwUFBerSpUuoykMINNcGSkpKdPToUd10000aNmyYdxgvo1MiT3PtYPTo0dq4caO2bNkil8ulL7/8Up9++qnGjBkT4ipxXIzRBUSzY8eOSZLS0tL89qenp+vo0aMGVASjDRgwwHtj5aWXXuLuc5Q4dOiQJGn58uV64oknlJOToxUrVmjWrFnq3Lmzhg0bZnCFCIUePXrorLPO0rx58zR37lylp6drxYoVys/PV0lJidHlIQwsWLBABw4c0IIFC4wuBSGSlpamTp066d5771Xfvn21efNmzZw5UxUVFXrwwQeNLg8hMmHCBOXn5+v666/37rv11lt13XXXGVhVdKMn2kAej0dSQ++Dr6b2IfJt27ZNH3/8sS6++GLdeOONTCgUJY7/XXB8MpHExETdfPPN6t+/v1atWmVwdQgVm82m5557TomJibrmmms0ZswYFRUVacSIEYqJ4Z53NHO5XHrssce0ePFiLVy4UNnZ2UaXhBD52c9+pkWLFik3N1exsbEaNmyYpk+frtdff111dXVGl4cQWbRokdasWaNly5Zpy5Yteu2117Ru3To9++yzRpcWtQjRBurYsaOk+uG7voqLi73vIfq0b99ed911lzp16sSz8VEiMzNTkk4YedC9e3cVFhYaURIMkpOTo+eff14bN27U+++/r5kzZ+rAgQNNTjSD6FBTU6MZM2boww8/1PLlyzVo0CCjS4LBunfvLqfTecK/HxG5XnrpJd14440aOHCg7Ha7zjnnHE2ePFlLliwxurSoRYg20IABA2S327V582a//Z9//rmGDh1qTFEIufXr12vkyJEnPN/kcDhks9kMqgqhlJmZqczMzBOee923b5+ysrIMqgpGePvtt/X11197twsLC7Vz504NHz7cwKpgFJfLpTvvvFPV1dVavny5evToYXRJCLEFCxbogw8+8Nu3a9cuJSYm0uESRVwu1wlL29XV1XlHsiH0CNEGSklJ0Y9+9CPNnz9fe/fuVXV1tRYtWqSCggJNnDjR6PIQIoMGDVJ1dbUefvhhlZSUqLa2Vq+88or279+vyy+/3OjyEAI2m01Tp07VkiVL9PHHH8vhcGjp0qXauXOnJk2aZHR5CKG//vWveuihh1RcXKzi4mLNmjVLw4YN0+DBg40uDQZYvHix9u3bp+eff14pKSlGlwMDHDt2TA8++KC2b9+uuro6bdy4US+99JJuvfVWHv2LIpdffrmWLVum7du3eycWW758ua688kqjS4taFg+3MAzlcDj0+OOP67333lNZWZn69u2rmTNnasiQIUaXhhDas2eP5s6dq02bNslqtapXr16aMWOGRo4caXRpCBGPx6MFCxbo9ddf19GjR9WzZ0/dd999GjFihNGlIYQOHz6s//mf/9Gnn34qm82mSy+9VL/+9a+VmppqdGkIktGjR+vAgQPyeDxyOp2KjY2VxWLRuHHjtHHjRhUUFDQ5KokZ2yNHc23ggQce0Pz587V27VoVFRUpIyNDU6ZM0c0338xotQjTXDuYPXu2FixYoHXr1qmoqEgdO3bU6NGjdeedd3pXd0FoEaIBAAAAAAgQw7kBAAAAAAgQIRoAAAAAgAARogEAAAAACBAhGgAAAACAABGiAQAAAAAIECEaAAAAAIAAEaIBAAAAAAgQIRoAAAAAgAARogEAAAAACBAhGgAAAACAABGiAQAAAAAIECEaAAAAAIAAEaIBAIDXlClT9Otf/9roMgAACFsxRhcAAADqTZkyRZ999pliYpr+3/OGDRuUkpIS4qoAAIAvQjQAAGHkqquu0pNPPml0GQAA4CQYzg0AgIn06dNHS5cu1fTp0zVw4EB973vf06JFi/yOWbZsmcaOHatBgwZp9OjRevrpp+VwOLzvb926VZMnT9agQYN0ySWX6Omnn5bL5fI7x7PPPqsLL7xQ55xzju6++25VVlZKkmpra/XQQw9pxIgROvfcczVy5Eg9//zz8ng8wf/yAACEAUI0AAAm8+KLL+q2227Tp59+qgceeECPP/64NmzYIElauXKl5s6dq/vvv1+ffvqp5s2bpzVr1mjevHmSpCNHjmjq1Kn6/ve/r08++UQvvfSSVq5cqRdeeMF7/g8++ECZmZn65z//qWXLlum9997TypUrJUmvvPKKNm3apFWrVmnz5s2aN2+eXn31Vf373/8O/W8EAAAGIEQDABBG1q5dq9zc3BP+mzNnjveYUaNGadiwYYqNjdWVV16pfv366R//+IckacmSJRo/frwuvPBCxcTEqG/fvpoyZYqWL1/uPb/VatW0adMUFxenXr16ad68eTrvvPO85+/atauuv/562e12nX322TrrrLO0Z88eSVJpaamsVqvi4+NlsViUm5urjz76SN///vdD+LsEAIBxeCYaAIAwEsgz0b169fLbzsnJ0aFDhyRJ+/fv13XXXef3/hlnnKHy8nKVlpZq37596tq1q6zWhvvogwcPPuF8vuLi4rzDwSdPnqwPP/xQF110kYYNG6YLL7xQY8eOVYcOHU7viwIAYFL0RAMAYDJut9tv2+PxyGKxSJIsFssJzycf33Y6nX7h+WSOn6spXbp00erVq/Xqq69qyJAhWr16tS6//HJt3br1dL8GAACmRIgGAMBk9u3b57e9f/9+de3aVZLUrVs37dq1y+/93bt3q127durQoYN69uyp/fv3y+l0et/fuHGj1qxZE9C1q6qqVFNTo3POOUe33367Vq5cqX79+mn16tWt/FYAAJgDIRoAAJN599139dlnn8npdGrt2rXatWuXrrjiCkn1a02vXr1aGzZskMvl0rZt27R48WJNmDBBFotFY8eOlSTNnz9fVVVV2r9/v2bPnq28vLyArv3Tn/5Us2fP1tGjRyXVB/qDBw+qZ8+ewfmyAACEGZ6JBgAgjKxdu9Y7SVhjjzzyiCRp4sSJWrhwof7zn/8oISFBc+bM0bBhwyRJ48aN05EjR/Too4/q4MGDyszM1OTJkzV16lRJUrt27bRkyRI98MADeuWVV5SWlqZx48bpJz/5SUD1/e53v9MjjzyiK664QrW1tcrIyNDVV1+tSZMmtcG3BwAg/Fk8LOwIAIBp9OnTR48++qgmTJhgdCkAAEQlhnMDAAAAABAgQjQAAAAAAAFiODcAAAAAAAGiJxoAAAAAgAARogEAAAAACBAhGgAAAACAABGiAQAAAAAIECEaAAAAAIAAEaIBAAAAAAgQIRoAAAAAgAARogEAAAAACBAhGgAAAACAABGiAQAAAAAIECEaAAAAAIAAEaIBAAAAAAgQIRoAAAAAgAARogEAAAAACBAhGgAAAACAABGiAQAAAAAI0P8HIxJqieIdvfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 985.14x486 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 985.14x486 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 985.14x486 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 985.14x486 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 985.14x486 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 985.14x486 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = None\n",
    "\n",
    "preprocessing_method=None\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm([\"OCSVM\"]):#since no preprocessing, all this shoud be identical for all of the classifiers\n",
    "\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_0}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Butterworth frequency Cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "    \n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": ffted_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_1_1}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_SIZE_LST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n",
      "cut_off_freq: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "674\n",
      "0.0026352922012168813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [01:52<35:44, 112.85s/it]\u001b[A\n",
      " 10%|█         | 2/20 [03:01<26:07, 87.08s/it] \u001b[A\n",
      " 15%|█▌        | 3/20 [05:13<30:26, 107.42s/it]\u001b[A\n",
      " 20%|██        | 4/20 [06:51<27:39, 103.74s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [08:32<25:40, 102.72s/it]\u001b[A\n",
      " 30%|███       | 6/20 [10:30<25:08, 107.75s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [12:26<23:59, 110.70s/it]\u001b[A\n",
      " 40%|████      | 8/20 [13:43<20:00, 100.01s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [15:55<20:07, 109.82s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [17:18<16:55, 101.51s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [19:16<16:00, 106.69s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [20:10<12:03, 90.47s/it] \u001b[A\n",
      " 65%|██████▌   | 13/20 [21:20<09:51, 84.47s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [22:33<08:05, 80.97s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [23:41<06:24, 76.98s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [24:54<05:02, 75.70s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [26:02<03:40, 73.38s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [27:17<02:27, 73.96s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [28:26<01:12, 72.59s/it]\u001b[A\n",
      "100%|██████████| 20/20 [29:45<00:00, 89.30s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 125, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [10.073803901672363, 5.2316508293151855, 2.340040922164917, 0.8859003186225891, 0.3108319342136383, 0.15190371870994568, 0.09389187395572662, 0.07091760635375977, 0.06357927620410919, 0.0586966946721077, 0.05836208164691925, 0.05583347752690315, 0.05745114013552666, 0.06016924977302551, 0.04976790025830269, 0.04962199553847313, 0.04936247318983078, 0.05050818994641304, 0.04984334483742714, 0.04723537713289261, 0.04707246646285057, 0.04699854552745819, 0.04694194719195366, 0.046913646161556244, 0.04711378365755081, 0.04651818796992302, 0.046422623097896576, 0.046488068997859955, 0.046345584094524384, 0.04634251445531845, 0.046352043747901917, 0.04632658138871193], min_val_index: 31\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1e-06}\n",
      "{'loss': [19.307357788085938, 10.999013900756836, 5.825511932373047, 2.449979782104492, 0.7712787389755249, 0.2303127646446228, 0.13105767965316772, 0.09462658315896988, 0.08004052191972733, 0.07200045138597488, 0.06866587698459625, 0.06663253158330917, 0.06691858917474747, 0.06677642464637756, 0.05915054306387901, 0.05827730894088745, 0.058497123420238495, 0.05832765996456146, 0.05839475616812706, 0.05617302656173706, 0.05578749254345894, 0.055978160351514816, 0.05588756501674652, 0.05580412596464157, 0.05566665530204773, 0.05518563091754913, 0.05531884357333183, 0.05521755665540695, 0.05475651100277901, 0.05511495843529701, 0.05531711503863335, 0.05502048879861832], 'val_loss': [10.073803901672363, 5.2316508293151855, 2.340040922164917, 0.8859003186225891, 0.3108319342136383, 0.15190371870994568, 0.09389187395572662, 0.07091760635375977, 0.06357927620410919, 0.0586966946721077, 0.05836208164691925, 0.05583347752690315, 0.05745114013552666, 0.06016924977302551, 0.04976790025830269, 0.04962199553847313, 0.04936247318983078, 0.05050818994641304, 0.04984334483742714, 0.04723537713289261, 0.04707246646285057, 0.04699854552745819, 0.04694194719195366, 0.046913646161556244, 0.04711378365755081, 0.04651818796992302, 0.046422623097896576, 0.046488068997859955, 0.046345584094524384, 0.04634251445531845, 0.046352043747901917, 0.04632658138871193]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 08:54:57.686713: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-31 08:54:58.425999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43490 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:ca:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================[ Initial State ]================================"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 08:55:00.917931: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-07-31 08:55:01.908982: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2023-07-31 08:55:02.731205: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-31 08:55:02.732725: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-31 08:55:02.732744: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2023-07-31 08:55:02.734182: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-07-31 08:55:02.734252: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-07-31 08:55:03.454379: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN: roc_auc: 0.7333, eer: 0.3269, thres: 0.1626 => acc: 0.6732, f1: 0.6732\n",
      "\n",
      "Epoch 1/32\n",
      "188/188 [==============================] - 6s 14ms/step - loss: 14.3311\n",
      "Epoch 2/32\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 4.5850\n",
      "Epoch 3/32\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.8699\n",
      "Epoch 4/32\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.1504\n",
      "Epoch 5/32\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0808\n",
      "Epoch 6/32\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0670\n",
      "Epoch 7/32\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0639\n",
      "Epoch 8/32\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0638\n",
      "Epoch 9/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0641\n",
      "Epoch 10/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0645\n",
      "Epoch 11/32\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0650\n",
      "Epoch 12/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0656\n",
      "Epoch 13/32\n",
      "188/188 [==============================] - 3s 13ms/step - loss: 0.0661\n",
      "Epoch 14/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0658\n",
      "Epoch 15/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0538\n",
      "Epoch 16/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0532\n",
      "Epoch 17/32\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0531\n",
      "Epoch 18/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0532\n",
      "Epoch 19/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0532\n",
      "Epoch 20/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0504\n",
      "Epoch 21/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0501\n",
      "Epoch 22/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0501\n",
      "Epoch 23/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0499\n",
      "Epoch 24/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0500\n",
      "Epoch 25/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0499\n",
      "Epoch 26/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0494\n",
      "Epoch 27/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0493\n",
      "Epoch 28/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0495\n",
      "Epoch 29/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0493\n",
      "Epoch 30/32\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0494\n",
      "Epoch 31/32\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0493\n",
      "Epoch 32/32\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0493\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8558, eer: 0.2159, thres: 0.1760 => acc: 0.7841, f1: 0.7841\n",
      "loss: 0.049\n",
      "{'loss': [14.331068992614746, 4.584993839263916, 0.8699262738227844, 0.15043844282627106, 0.08084409683942795, 0.06697234511375427, 0.06390488147735596, 0.0637931227684021, 0.06406378746032715, 0.06447290629148483, 0.06504429876804352, 0.06561491638422012, 0.06610292196273804, 0.06584705412387848, 0.053828928619623184, 0.05321599170565605, 0.053128935396671295, 0.053242508322000504, 0.05324793606996536, 0.05035930871963501, 0.050063252449035645, 0.05007302761077881, 0.04993487149477005, 0.04998844489455223, 0.04993252083659172, 0.04940580204129219, 0.049293823540210724, 0.049539364874362946, 0.049270156770944595, 0.04937383159995079, 0.049336496740579605, 0.049263183027505875], 'val_loss': []}\n",
      "Training History:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 08:59:16.555842: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [04:28<13:24, 268.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [15.716132164001465, 9.899250984191895, 5.343303680419922, 2.6842458248138428, 1.2409600019454956, 0.5659531950950623, 0.29382699728012085, 0.18657009303569794, 0.13462430238723755, 0.10718023777008057, 0.08937742561101913, 0.07547582685947418, 0.070892333984375, 0.06863418221473694, 0.06522392481565475, 0.06333685666322708, 0.06662758439779282, 0.06328468769788742, 0.05253357067704201, 0.05288194864988327, 0.05213325470685959, 0.05155077949166298, 0.0519898496568203, 0.052066631615161896, 0.04897097498178482, 0.04879341274499893, 0.04883032664656639, 0.048672936856746674, 0.04837457090616226, 0.048685215413570404, 0.04855845868587494, 0.04819939658045769, 0.048214737325906754, 0.04819599539041519, 0.04810255393385887, 0.048100072890520096, 0.04808347672224045], min_val_index: 36\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 0.00020000001, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 4.0000003e-05, 28: 4.0000003e-05, 29: 4.0000003e-05, 30: 4.0000003e-05, 31: 8.000001e-06, 32: 8.000001e-06, 33: 8.000001e-06, 34: 1.6000001e-06, 35: 1.6000001e-06, 36: 1e-06}\n",
      "{'loss': [25.248531341552734, 16.156810760498047, 9.830852508544922, 5.5560736656188965, 2.9108970165252686, 1.179227590560913, 0.4307638108730316, 0.2408261001110077, 0.16675181686878204, 0.12518851459026337, 0.1032550185918808, 0.08852171152830124, 0.08062610030174255, 0.07705776393413544, 0.07505006343126297, 0.07359594106674194, 0.07213423401117325, 0.07144277542829514, 0.061454009264707565, 0.06070183962583542, 0.060442641377449036, 0.06069989874958992, 0.06026182696223259, 0.06023913621902466, 0.057591576129198074, 0.05717514455318451, 0.05750635266304016, 0.05707888305187225, 0.057319968938827515, 0.057267021387815475, 0.057013969868421555, 0.056590501219034195, 0.056512702256441116, 0.056735310703516006, 0.05683928355574608, 0.05647706985473633, 0.056049227714538574], 'val_loss': [15.716132164001465, 9.899250984191895, 5.343303680419922, 2.6842458248138428, 1.2409600019454956, 0.5659531950950623, 0.29382699728012085, 0.18657009303569794, 0.13462430238723755, 0.10718023777008057, 0.08937742561101913, 0.07547582685947418, 0.070892333984375, 0.06863418221473694, 0.06522392481565475, 0.06333685666322708, 0.06662758439779282, 0.06328468769788742, 0.05253357067704201, 0.05288194864988327, 0.05213325470685959, 0.05155077949166298, 0.0519898496568203, 0.052066631615161896, 0.04897097498178482, 0.04879341274499893, 0.04883032664656639, 0.048672936856746674, 0.04837457090616226, 0.048685215413570404, 0.04855845868587494, 0.04819939658045769, 0.048214737325906754, 0.04819599539041519, 0.04810255393385887, 0.048100072890520096, 0.04808347672224045]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 0.00020000001, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 4.0000003e-05, 28: 4.0000003e-05, 29: 4.0000003e-05, 30: 4.0000003e-05, 31: 8.000001e-06, 32: 8.000001e-06, 33: 8.000001e-06, 34: 1.6000001e-06, 35: 1.6000001e-06, 36: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7217, eer: 0.3397, thres: 0.2693 => acc: 0.6603, f1: 0.6603\n",
      "\n",
      "Epoch 1/37\n",
      "188/188 [==============================] - 9s 25ms/step - loss: 20.4275\n",
      "Epoch 2/37\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 8.7539\n",
      "Epoch 3/37\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 3.2015\n",
      "Epoch 4/37\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.8748\n",
      "Epoch 5/37\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.2243\n",
      "Epoch 6/37\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.1195\n",
      "Epoch 7/37\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0866\n",
      "Epoch 8/37\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0761\n",
      "Epoch 9/37\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0703\n",
      "Epoch 10/37\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0685\n",
      "Epoch 11/37\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0681\n",
      "Epoch 12/37\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0679\n",
      "Epoch 13/37\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0669\n",
      "Epoch 14/37\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0673\n",
      "Epoch 15/37\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0672\n",
      "Epoch 16/37\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0677\n",
      "Epoch 17/37\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0677\n",
      "Epoch 18/37\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0685\n",
      "Epoch 19/37\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0550\n",
      "Epoch 20/37\n",
      "188/188 [==============================] - 6s 29ms/step - loss: 0.0546\n",
      "Epoch 21/37\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0544\n",
      "Epoch 22/37\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0543\n",
      "Epoch 23/37\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0542\n",
      "Epoch 24/37\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0540\n",
      "Epoch 25/37\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0509\n",
      "Epoch 26/37\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0506\n",
      "Epoch 27/37\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0507\n",
      "Epoch 28/37\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0506\n",
      "Epoch 29/37\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0507\n",
      "Epoch 30/37\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0507\n",
      "Epoch 31/37\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0506\n",
      "Epoch 32/37\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0499\n",
      "Epoch 33/37\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0499\n",
      "Epoch 34/37\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0498\n",
      "Epoch 35/37\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0499\n",
      "Epoch 36/37\n",
      "188/188 [==============================] - 3s 19ms/step - loss: 0.0495\n",
      "Epoch 37/37\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0498\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8482, eer: 0.2238, thres: 0.1721 => acc: 0.7763, f1: 0.7763\n",
      "loss: 0.050\n",
      "{'loss': [20.427520751953125, 8.753867149353027, 3.2015013694763184, 0.8747592568397522, 0.224307119846344, 0.1194695383310318, 0.08664532750844955, 0.07613041251897812, 0.07031498849391937, 0.06845827400684357, 0.06806149333715439, 0.0679386705160141, 0.0668521299958229, 0.06728081405162811, 0.06719370931386948, 0.0677064061164856, 0.06773090362548828, 0.06846915930509567, 0.05501948669552803, 0.05456719920039177, 0.054375022649765015, 0.05431841313838959, 0.05422849580645561, 0.05400744080543518, 0.05086423456668854, 0.05057429149746895, 0.050734080374240875, 0.050625067204236984, 0.050677791237831116, 0.05065569281578064, 0.05058369040489197, 0.049942005425691605, 0.04987233132123947, 0.049773119390010834, 0.04990333691239357, 0.04950104281306267, 0.0498105064034462], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [12:58<13:41, 410.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [18.328460693359375, 9.475564002990723, 4.6607985496521, 2.420276403427124, 1.0804342031478882, 0.5269112586975098, 0.3031426668167114, 0.19381529092788696, 0.14058607816696167, 0.11111706495285034, 0.0949573740363121, 0.08494645357131958, 0.08636436611413956, 0.08337599784135818, 0.08082424104213715, 0.08084236830472946, 0.08617961406707764, 0.06251432001590729, 0.06140502169728279, 0.06258787214756012, 0.06023702770471573, 0.06241462007164955, 0.06306242942810059, 0.05636637285351753, 0.056337662041187286, 0.05650179460644722, 0.055344391614198685, 0.055377986282110214, 0.055225420743227005, 0.05538150668144226, 0.055304836481809616, 0.05505130812525749, 0.05508407950401306, 0.05510381609201431, 0.05512810871005058], min_val_index: 31\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1.6000001e-06, 34: 1e-06}\n",
      "{'loss': [29.633056640625, 16.71976661682129, 9.06740665435791, 5.1932220458984375, 2.5454025268554688, 0.9640510678291321, 0.39349570870399475, 0.23068735003471375, 0.16094312071800232, 0.12150062620639801, 0.10155299305915833, 0.09135941416025162, 0.08808638155460358, 0.0856969878077507, 0.08519347757101059, 0.08515063673257828, 0.08545893430709839, 0.0671749860048294, 0.0657045841217041, 0.06559772044420242, 0.06594293564558029, 0.0661279559135437, 0.06618468463420868, 0.0607161708176136, 0.060191936790943146, 0.06036778911948204, 0.05916807800531387, 0.058996714651584625, 0.0587027370929718, 0.059210605919361115, 0.05899594724178314, 0.05886269733309746, 0.05885431170463562, 0.058706119656562805, 0.05866628512740135], 'val_loss': [18.328460693359375, 9.475564002990723, 4.6607985496521, 2.420276403427124, 1.0804342031478882, 0.5269112586975098, 0.3031426668167114, 0.19381529092788696, 0.14058607816696167, 0.11111706495285034, 0.0949573740363121, 0.08494645357131958, 0.08636436611413956, 0.08337599784135818, 0.08082424104213715, 0.08084236830472946, 0.08617961406707764, 0.06251432001590729, 0.06140502169728279, 0.06258787214756012, 0.06023702770471573, 0.06241462007164955, 0.06306242942810059, 0.05636637285351753, 0.056337662041187286, 0.05650179460644722, 0.055344391614198685, 0.055377986282110214, 0.055225420743227005, 0.05538150668144226, 0.055304836481809616, 0.05505130812525749, 0.05508407950401306, 0.05510381609201431, 0.05512810871005058]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.6936, eer: 0.3637, thres: 0.2309 => acc: 0.6363, f1: 0.6363\n",
      "\n",
      "Epoch 1/32\n",
      "188/188 [==============================] - 6s 18ms/step - loss: 23.6408\n",
      "Epoch 2/32\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.5498\n",
      "Epoch 3/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 3.2118\n",
      "Epoch 4/32\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.7506\n",
      "Epoch 5/32\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.2026\n",
      "Epoch 6/32\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.1132\n",
      "Epoch 7/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0884\n",
      "Epoch 8/32\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0806\n",
      "Epoch 9/32\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0790\n",
      "Epoch 10/32\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0806\n",
      "Epoch 11/32\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0820\n",
      "Epoch 12/32\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0839\n",
      "Epoch 13/32\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0843\n",
      "Epoch 14/32\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0864\n",
      "Epoch 15/32\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0875\n",
      "Epoch 16/32\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0881\n",
      "Epoch 17/32\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0895\n",
      "Epoch 18/32\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0624\n",
      "Epoch 19/32\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0608\n",
      "Epoch 20/32\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0614\n",
      "Epoch 21/32\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0612\n",
      "Epoch 22/32\n",
      "188/188 [==============================] - 6s 29ms/step - loss: 0.0611\n",
      "Epoch 23/32\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0612\n",
      "Epoch 24/32\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0543\n",
      "Epoch 25/32\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0536\n",
      "Epoch 26/32\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0536\n",
      "Epoch 27/32\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0523\n",
      "Epoch 28/32\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0521\n",
      "Epoch 29/32\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0523\n",
      "Epoch 30/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0521\n",
      "Epoch 31/32\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 0.0521\n",
      "Epoch 32/32\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0519\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8401, eer: 0.2299, thres: 0.1433 => acc: 0.7701, f1: 0.7701\n",
      "loss: 0.052\n",
      "{'loss': [23.640758514404297, 8.549793243408203, 3.2118031978607178, 0.7506214380264282, 0.2026318460702896, 0.11317221075296402, 0.08835731446743011, 0.08063913881778717, 0.07903557270765305, 0.08061753213405609, 0.08198007941246033, 0.083878293633461, 0.08434254676103592, 0.08644048869609833, 0.08746539056301117, 0.08810672909021378, 0.08945142477750778, 0.06241333857178688, 0.06084198132157326, 0.06144997105002403, 0.06117909029126167, 0.06111014261841774, 0.06122473254799843, 0.0543186217546463, 0.05357115715742111, 0.05360906943678856, 0.052278682589530945, 0.05206884816288948, 0.05232565850019455, 0.052098263055086136, 0.05205538123846054, 0.05190879851579666], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [20:29<07:08, 428.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [16.1472225189209, 9.74377155303955, 5.355837345123291, 2.660916566848755, 1.2759547233581543, 0.5929648280143738, 0.3076417148113251, 0.16896609961986542, 0.11618366092443466, 0.09114176779985428, 0.0780472382903099, 0.06940588355064392, 0.06748833507299423, 0.06541101634502411, 0.0631309375166893, 0.06268526613712311, 0.0656065046787262, 0.06300485134124756, 0.05234910547733307, 0.05240039899945259, 0.05306578055024147, 0.04979795962572098, 0.049649421125650406, 0.04983283206820488, 0.04987134411931038, 0.04921209067106247, 0.04923289269208908, 0.04931460693478584, 0.04918484762310982, 0.04918787255883217, 0.04918588697910309], min_val_index: 28\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "{'loss': [25.466976165771484, 16.001691818237305, 9.57153034210205, 5.394893646240234, 2.729457378387451, 1.1995576620101929, 0.5028349757194519, 0.23356568813323975, 0.15182852745056152, 0.11102017760276794, 0.09038108587265015, 0.0800522193312645, 0.07574814558029175, 0.07359826564788818, 0.07229837030172348, 0.07101862877607346, 0.0707181990146637, 0.07088498026132584, 0.06056097149848938, 0.06013413518667221, 0.05983705818653107, 0.057282354682683945, 0.05750850960612297, 0.05733435973525047, 0.05701452121138573, 0.05628787353634834, 0.05633494630455971, 0.05646124482154846, 0.05593077838420868, 0.05578995496034622, 0.056046780198812485], 'val_loss': [16.1472225189209, 9.74377155303955, 5.355837345123291, 2.660916566848755, 1.2759547233581543, 0.5929648280143738, 0.3076417148113251, 0.16896609961986542, 0.11618366092443466, 0.09114176779985428, 0.0780472382903099, 0.06940588355064392, 0.06748833507299423, 0.06541101634502411, 0.0631309375166893, 0.06268526613712311, 0.0656065046787262, 0.06300485134124756, 0.05234910547733307, 0.05240039899945259, 0.05306578055024147, 0.04979795962572098, 0.049649421125650406, 0.04983283206820488, 0.04987134411931038, 0.04921209067106247, 0.04923289269208908, 0.04931460693478584, 0.04918484762310982, 0.04918787255883217, 0.04918588697910309]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7108, eer: 0.3467, thres: 0.2663 => acc: 0.6532, f1: 0.6532\n",
      "\n",
      "Epoch 1/29\n",
      "188/188 [==============================] - 20s 55ms/step - loss: 20.4277\n",
      "Epoch 2/29\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 8.4249\n",
      "Epoch 3/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 2.9466\n",
      "Epoch 4/29\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.8065\n",
      "Epoch 5/29\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.1996\n",
      "Epoch 6/29\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0995\n",
      "Epoch 7/29\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0770\n",
      "Epoch 8/29\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0699\n",
      "Epoch 9/29\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0676\n",
      "Epoch 10/29\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0670\n",
      "Epoch 11/29\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0666\n",
      "Epoch 12/29\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0670\n",
      "Epoch 13/29\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0672\n",
      "Epoch 14/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0675\n",
      "Epoch 15/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0681\n",
      "Epoch 16/29\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0686\n",
      "Epoch 17/29\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0689\n",
      "Epoch 18/29\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0691\n",
      "Epoch 19/29\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0552\n",
      "Epoch 20/29\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0546\n",
      "Epoch 21/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0544\n",
      "Epoch 22/29\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0509\n",
      "Epoch 23/29\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0509\n",
      "Epoch 24/29\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0508\n",
      "Epoch 25/29\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0506\n",
      "Epoch 26/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0503\n",
      "Epoch 27/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0500\n",
      "Epoch 28/29\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0501\n",
      "Epoch 29/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0499\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8538, eer: 0.2182, thres: 0.1754 => acc: 0.7818, f1: 0.7818\n",
      "loss: 0.050\n",
      "{'loss': [20.42771339416504, 8.424866676330566, 2.9466099739074707, 0.8064623475074768, 0.19963586330413818, 0.09948010742664337, 0.07704966515302658, 0.06991749256849289, 0.06759069114923477, 0.06697113066911697, 0.06661931425333023, 0.0669923648238182, 0.06724227219820023, 0.06753240525722504, 0.06808876991271973, 0.06859680265188217, 0.06892994791269302, 0.06909266114234924, 0.055185236036777496, 0.054632630199193954, 0.054404422640800476, 0.05088505893945694, 0.05085873603820801, 0.05081724002957344, 0.05062803998589516, 0.0502987802028656, 0.049994178116321564, 0.05008988454937935, 0.04985560476779938], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_366750/2807832909.py:120: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig = plt.figure(figsize=(5.473, 2.7), dpi=180)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [32:13<00:00, 483.42s/it]\u001b[A\n",
      " 20%|██        | 1/5 [1:03:42<4:14:51, 3822.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "334\n",
      "0.010731381548280685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:47<15:09, 47.85s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:37<14:36, 48.67s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [02:26<13:52, 48.96s/it]\u001b[A\n",
      " 20%|██        | 4/20 [03:14<12:59, 48.70s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [04:05<12:20, 49.36s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:55<11:34, 49.63s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:44<10:41, 49.37s/it]\u001b[A\n",
      " 40%|████      | 8/20 [06:33<09:50, 49.21s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [07:23<09:05, 49.63s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [08:16<08:26, 50.63s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [09:07<07:36, 50.76s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [09:58<06:47, 50.97s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [10:47<05:50, 50.07s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [11:38<05:03, 50.50s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [12:27<04:09, 49.90s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [13:08<03:09, 47.45s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [13:34<02:02, 40.97s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [13:59<01:12, 36.16s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [14:23<00:32, 32.61s/it]\u001b[A\n",
      "100%|██████████| 20/20 [14:47<00:00, 44.39s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 250, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [8.022610664367676, 3.071751356124878, 1.1376173496246338, 0.4135195016860962, 0.16315872967243195, 0.08441072702407837, 0.05863469839096069, 0.05145920813083649, 0.047359660267829895, 0.04826939478516579, 0.048261936753988266, 0.03763797506690025, 0.03678135201334953, 0.036961156874895096, 0.03783790022134781, 0.034587495028972626, 0.03434363007545471, 0.03453003987669945, 0.03442705422639847, 0.033813998103141785, 0.03379299119114876, 0.03383506461977959, 0.03372379392385483, 0.03370225802063942, 0.03370136767625809, 0.03369686007499695, 0.03366869315505028], min_val_index: 26\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1.6000001e-06, 26: 1e-06}\n",
      "{'loss': [15.041680335998535, 6.976539134979248, 2.691495895385742, 1.0028644800186157, 0.3118303120136261, 0.12951219081878662, 0.08318999409675598, 0.06693684309720993, 0.06122104078531265, 0.05896305665373802, 0.058291904628276825, 0.04886726289987564, 0.047951389104127884, 0.04803202301263809, 0.04768538475036621, 0.0455087274312973, 0.04514753073453903, 0.04524724557995796, 0.04521365463733673, 0.044488418847322464, 0.04477939009666443, 0.044635459780693054, 0.04440568387508392, 0.044580139219760895, 0.044560596346855164, 0.04430617019534111, 0.04475046694278717], 'val_loss': [8.022610664367676, 3.071751356124878, 1.1376173496246338, 0.4135195016860962, 0.16315872967243195, 0.08441072702407837, 0.05863469839096069, 0.05145920813083649, 0.047359660267829895, 0.04826939478516579, 0.048261936753988266, 0.03763797506690025, 0.03678135201334953, 0.036961156874895096, 0.03783790022134781, 0.034587495028972626, 0.03434363007545471, 0.03453003987669945, 0.03442705422639847, 0.033813998103141785, 0.03379299119114876, 0.03383506461977959, 0.03372379392385483, 0.03370225802063942, 0.03370136767625809, 0.03369686007499695, 0.03366869315505028]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1.6000001e-06, 26: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8302, eer: 0.2341, thres: 0.1118 => acc: 0.7659, f1: 0.7659\n",
      "\n",
      "Epoch 1/27\n",
      "188/188 [==============================] - 11s 39ms/step - loss: 11.4282\n",
      "Epoch 2/27\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 2.7088\n",
      "Epoch 3/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.4403\n",
      "Epoch 4/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0999\n",
      "Epoch 5/27\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0630\n",
      "Epoch 6/27\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0556\n",
      "Epoch 7/27\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0551\n",
      "Epoch 8/27\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0556\n",
      "Epoch 9/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0557\n",
      "Epoch 10/27\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0561\n",
      "Epoch 11/27\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0565\n",
      "Epoch 12/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0444\n",
      "Epoch 13/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0437\n",
      "Epoch 14/27\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0437\n",
      "Epoch 15/27\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0438\n",
      "Epoch 16/27\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0407\n",
      "Epoch 17/27\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0407\n",
      "Epoch 18/27\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0406\n",
      "Epoch 19/27\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0406\n",
      "Epoch 20/27\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0400\n",
      "Epoch 21/27\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0400\n",
      "Epoch 22/27\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0399\n",
      "Epoch 23/27\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 0.0399\n",
      "Epoch 24/27\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0397\n",
      "Epoch 25/27\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0396\n",
      "Epoch 26/27\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0399\n",
      "Epoch 27/27\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0397\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9153, eer: 0.1474, thres: 0.1798 => acc: 0.8527, f1: 0.8527\n",
      "loss: 0.040\n",
      "{'loss': [11.428199768066406, 2.7088325023651123, 0.44025659561157227, 0.09990198910236359, 0.0629575252532959, 0.05556640028953552, 0.05508369207382202, 0.055625203996896744, 0.05565951392054558, 0.05613291636109352, 0.056458503007888794, 0.04443247616291046, 0.04370852932333946, 0.043673280626535416, 0.04381735622882843, 0.040722351521253586, 0.04071243852376938, 0.040565330535173416, 0.04059242829680443, 0.040007345378398895, 0.04001927748322487, 0.039862439036369324, 0.03990896791219711, 0.03966980800032616, 0.039641108363866806, 0.039886895567178726, 0.0396990105509758], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-250-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [10:01<30:05, 601.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [13.719284057617188, 7.237940311431885, 3.346856117248535, 1.5439828634262085, 0.6847800016403198, 0.3057108223438263, 0.1746453046798706, 0.12279069423675537, 0.0895361453294754, 0.07780041545629501, 0.07267268747091293, 0.05666689574718475, 0.055938560515642166, 0.05991484597325325, 0.05289963632822037, 0.055638331919908524, 0.053555458784103394, 0.04278402030467987, 0.04338499531149864, 0.04304652288556099, 0.039535269141197205, 0.03974034637212753, 0.040067508816719055, 0.03928963840007782, 0.039232540875673294, 0.03927629068493843, 0.039157379418611526, 0.03916643187403679, 0.03916396200656891, 0.0391770638525486], min_val_index: 26\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "{'loss': [21.234033584594727, 12.328080177307129, 6.433902740478516, 3.15848970413208, 1.4638696908950806, 0.5381588935852051, 0.23550570011138916, 0.14742466807365417, 0.10693318396806717, 0.08623898774385452, 0.07687821239233017, 0.07185065001249313, 0.06718268990516663, 0.06516599655151367, 0.06398168206214905, 0.0628662034869194, 0.06236274540424347, 0.05192605406045914, 0.05052511394023895, 0.050236187875270844, 0.04771808907389641, 0.04745751619338989, 0.04747933894395828, 0.04691145196557045, 0.046876005828380585, 0.04673789441585541, 0.04698207974433899, 0.046527713537216187, 0.04658568277955055, 0.04666915163397789], 'val_loss': [13.719284057617188, 7.237940311431885, 3.346856117248535, 1.5439828634262085, 0.6847800016403198, 0.3057108223438263, 0.1746453046798706, 0.12279069423675537, 0.0895361453294754, 0.07780041545629501, 0.07267268747091293, 0.05666689574718475, 0.055938560515642166, 0.05991484597325325, 0.05289963632822037, 0.055638331919908524, 0.053555458784103394, 0.04278402030467987, 0.04338499531149864, 0.04304652288556099, 0.039535269141197205, 0.03974034637212753, 0.040067508816719055, 0.03928963840007782, 0.039232540875673294, 0.03927629068493843, 0.039157379418611526, 0.03916643187403679, 0.03916396200656891, 0.0391770638525486]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8054, eer: 0.2648, thres: 0.1966 => acc: 0.7352, f1: 0.7352\n",
      "\n",
      "Epoch 1/27\n",
      "188/188 [==============================] - 35s 76ms/step - loss: 17.4809\n",
      "Epoch 2/27\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 6.4594\n",
      "Epoch 3/27\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 1.9680\n",
      "Epoch 4/27\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.5010\n",
      "Epoch 5/27\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.1538\n",
      "Epoch 6/27\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.0868\n",
      "Epoch 7/27\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.0704\n",
      "Epoch 8/27\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0635\n",
      "Epoch 9/27\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0606\n",
      "Epoch 10/27\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0594\n",
      "Epoch 11/27\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0585\n",
      "Epoch 12/27\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0588\n",
      "Epoch 13/27\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0588\n",
      "Epoch 14/27\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0595\n",
      "Epoch 15/27\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0594\n",
      "Epoch 16/27\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0601\n",
      "Epoch 17/27\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0604\n",
      "Epoch 18/27\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0467\n",
      "Epoch 19/27\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0461\n",
      "Epoch 20/27\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0462\n",
      "Epoch 21/27\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0429\n",
      "Epoch 22/27\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0426\n",
      "Epoch 23/27\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0426\n",
      "Epoch 24/27\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0418\n",
      "Epoch 25/27\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0419\n",
      "Epoch 26/27\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0417\n",
      "Epoch 27/27\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0418\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8989, eer: 0.1691, thres: 0.1728 => acc: 0.8309, f1: 0.8309\n",
      "loss: 0.042\n",
      "{'loss': [17.48086166381836, 6.459401607513428, 1.9680160284042358, 0.5010088086128235, 0.15377436578273773, 0.08684922009706497, 0.07035982608795166, 0.06353528052568436, 0.06058496981859207, 0.05937624350190163, 0.058501023799180984, 0.05875205993652344, 0.05881239101290703, 0.059470683336257935, 0.05942783132195473, 0.06007326394319534, 0.060434456914663315, 0.04667232558131218, 0.04605472832918167, 0.046218134462833405, 0.04288646578788757, 0.0426088385283947, 0.0426129512488842, 0.04179132357239723, 0.0419011116027832, 0.041717544198036194, 0.04184279218316078], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-250-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [25:03<25:56, 778.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [16.06092643737793, 7.002536296844482, 3.1336047649383545, 1.406762719154358, 0.6427517533302307, 0.28691548109054565, 0.1850229650735855, 0.10975118726491928, 0.09452447295188904, 0.08719901740550995, 0.08782390505075455, 0.08683504909276962, 0.0828746110200882, 0.08706428110599518, 0.08141083270311356, 0.08585070073604584, 0.08860708028078079, 0.06422331184148788, 0.06361318379640579, 0.06267119199037552, 0.06137562915682793, 0.06350789219141006, 0.06282760202884674, 0.057017065584659576, 0.057179346680641174, 0.057129815220832825, 0.0553491935133934, 0.055215541273355484, 0.055321160703897476, 0.055206216871738434, 0.05497457832098007, 0.0549384281039238, 0.05496808886528015, 0.05492394417524338], min_val_index: 33\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1e-06}\n",
      "{'loss': [25.851451873779297, 13.020587921142578, 6.203426837921143, 3.1416475772857666, 1.3789006471633911, 0.5557153820991516, 0.23950055241584778, 0.13158690929412842, 0.0951843187212944, 0.08424711227416992, 0.07982955127954483, 0.07815142720937729, 0.07723187655210495, 0.0773238018155098, 0.07801260054111481, 0.07856084406375885, 0.0794612392783165, 0.05846935138106346, 0.056799426674842834, 0.05656718835234642, 0.05721327289938927, 0.05714275687932968, 0.05711112916469574, 0.051684968173503876, 0.050862330943346024, 0.050940848886966705, 0.04993211850523949, 0.04974004626274109, 0.04955875873565674, 0.049628496170043945, 0.04967671260237694, 0.04965033382177353, 0.049727801233530045, 0.049379464238882065], 'val_loss': [16.06092643737793, 7.002536296844482, 3.1336047649383545, 1.406762719154358, 0.6427517533302307, 0.28691548109054565, 0.1850229650735855, 0.10975118726491928, 0.09452447295188904, 0.08719901740550995, 0.08782390505075455, 0.08683504909276962, 0.0828746110200882, 0.08706428110599518, 0.08141083270311356, 0.08585070073604584, 0.08860708028078079, 0.06422331184148788, 0.06361318379640579, 0.06267119199037552, 0.06137562915682793, 0.06350789219141006, 0.06282760202884674, 0.057017065584659576, 0.057179346680641174, 0.057129815220832825, 0.0553491935133934, 0.055215541273355484, 0.055321160703897476, 0.055206216871738434, 0.05497457832098007, 0.0549384281039238, 0.05496808886528015, 0.05492394417524338]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7629, eer: 0.3090, thres: 0.1685 => acc: 0.6910, f1: 0.6909\n",
      "\n",
      "Epoch 1/34\n",
      "188/188 [==============================] - 8s 24ms/step - loss: 20.3626\n",
      "Epoch 2/34\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 6.2543\n",
      "Epoch 3/34\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 1.9883\n",
      "Epoch 4/34\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.4617\n",
      "Epoch 5/34\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1234\n",
      "Epoch 6/34\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0876\n",
      "Epoch 7/34\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0755\n",
      "Epoch 8/34\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0731\n",
      "Epoch 9/34\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0726\n",
      "Epoch 10/34\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0739\n",
      "Epoch 11/34\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0758\n",
      "Epoch 12/34\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0765\n",
      "Epoch 13/34\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0794\n",
      "Epoch 14/34\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0787\n",
      "Epoch 15/34\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0796\n",
      "Epoch 16/34\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0815\n",
      "Epoch 17/34\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0820\n",
      "Epoch 18/34\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 0.0537\n",
      "Epoch 19/34\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0522\n",
      "Epoch 20/34\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0522\n",
      "Epoch 21/34\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0522\n",
      "Epoch 22/34\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0524\n",
      "Epoch 23/34\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0522\n",
      "Epoch 24/34\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0448\n",
      "Epoch 25/34\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0444\n",
      "Epoch 26/34\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0444\n",
      "Epoch 27/34\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0429\n",
      "Epoch 28/34\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0432\n",
      "Epoch 29/34\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0429\n",
      "Epoch 30/34\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0428\n",
      "Epoch 31/34\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0428\n",
      "Epoch 32/34\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0428\n",
      "Epoch 33/34\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0428\n",
      "Epoch 34/34\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0425\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9098, eer: 0.1545, thres: 0.1608 => acc: 0.8455, f1: 0.8455\n",
      "loss: 0.043\n",
      "{'loss': [20.362552642822266, 6.254260063171387, 1.9882892370224, 0.46173131465911865, 0.12338471412658691, 0.08757802844047546, 0.07549058645963669, 0.0730595737695694, 0.0725795105099678, 0.07390386611223221, 0.0757574588060379, 0.07652124017477036, 0.07940435409545898, 0.07866773754358292, 0.07957079261541367, 0.0815410390496254, 0.08204365521669388, 0.05371258407831192, 0.05219937115907669, 0.052242211997509, 0.05219504237174988, 0.05242065712809563, 0.052211910486221313, 0.04479999840259552, 0.0444457046687603, 0.0443689338862896, 0.042899344116449356, 0.043205421417951584, 0.042853716760873795, 0.04275159537792206, 0.04284868389368057, 0.04276126250624657, 0.04278821498155594, 0.0425298698246479], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-250-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [34:59<11:35, 695.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [13.988040924072266, 7.167835235595703, 3.2759127616882324, 1.4874988794326782, 0.6409854888916016, 0.29229143261909485, 0.13132067024707794, 0.08417432755231857, 0.06424303352832794, 0.057548888027668, 0.05355967953801155, 0.05006033554673195, 0.04834410920739174, 0.05006209388375282, 0.05023769289255142, 0.03921893984079361, 0.03891368955373764, 0.039318036288022995, 0.03906025364995003, 0.03607013449072838, 0.03611939027905464, 0.03612614423036575, 0.03546610847115517, 0.035406891256570816, 0.03542597219347954, 0.03529585152864456, 0.03529006242752075, 0.03530026599764824, 0.035295214504003525], min_val_index: 26\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1e-06}\n",
      "{'loss': [21.63566780090332, 12.25532341003418, 6.285008430480957, 2.9811642169952393, 1.37851881980896, 0.539926290512085, 0.20810410380363464, 0.11492785066366196, 0.08569546788930893, 0.07285721600055695, 0.0668247789144516, 0.06394296884536743, 0.062393855303525925, 0.06185298413038254, 0.06135902553796768, 0.05068586766719818, 0.05008673295378685, 0.049949489533901215, 0.0500921830534935, 0.04694260656833649, 0.04676368460059166, 0.046492256224155426, 0.04617926478385925, 0.045967455953359604, 0.045687563717365265, 0.04571142420172691, 0.04599945619702339, 0.04587535560131073, 0.04601392522454262], 'val_loss': [13.988040924072266, 7.167835235595703, 3.2759127616882324, 1.4874988794326782, 0.6409854888916016, 0.29229143261909485, 0.13132067024707794, 0.08417432755231857, 0.06424303352832794, 0.057548888027668, 0.05355967953801155, 0.05006033554673195, 0.04834410920739174, 0.05006209388375282, 0.05023769289255142, 0.03921893984079361, 0.03891368955373764, 0.039318036288022995, 0.03906025364995003, 0.03607013449072838, 0.03611939027905464, 0.03612614423036575, 0.03546610847115517, 0.035406891256570816, 0.03542597219347954, 0.03529585152864456, 0.03529006242752075, 0.03530026599764824, 0.035295214504003525]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06, 26: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7965, eer: 0.2728, thres: 0.1902 => acc: 0.7272, f1: 0.7272\n",
      "\n",
      "Epoch 1/27\n",
      "188/188 [==============================] - 16s 43ms/step - loss: 17.2544\n",
      "Epoch 2/27\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 5.8709\n",
      "Epoch 3/27\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 1.6019\n",
      "Epoch 4/27\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.3775\n",
      "Epoch 5/27\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.1159\n",
      "Epoch 6/27\n",
      "188/188 [==============================] - 12s 61ms/step - loss: 0.0743\n",
      "Epoch 7/27\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0627\n",
      "Epoch 8/27\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0599\n",
      "Epoch 9/27\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0587\n",
      "Epoch 10/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0585\n",
      "Epoch 11/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0588\n",
      "Epoch 12/27\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0592\n",
      "Epoch 13/27\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 0.0597\n",
      "Epoch 14/27\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0600\n",
      "Epoch 15/27\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0601\n",
      "Epoch 16/27\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0462\n",
      "Epoch 17/27\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0455\n",
      "Epoch 18/27\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0454\n",
      "Epoch 19/27\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0453\n",
      "Epoch 20/27\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0419\n",
      "Epoch 21/27\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0419\n",
      "Epoch 22/27\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0417\n",
      "Epoch 23/27\n",
      "188/188 [==============================] - 6s 29ms/step - loss: 0.0412\n",
      "Epoch 24/27\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0410\n",
      "Epoch 25/27\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0409\n",
      "Epoch 26/27\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0408\n",
      "Epoch 27/27\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0407\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9162, eer: 0.1469, thres: 0.1793 => acc: 0.8531, f1: 0.8531\n",
      "loss: 0.041\n",
      "{'loss': [17.254369735717773, 5.870927333831787, 1.6019090414047241, 0.3774605095386505, 0.11586753278970718, 0.07433861494064331, 0.06273353844881058, 0.05991485342383385, 0.05868551507592201, 0.05848146975040436, 0.05883629992604256, 0.059176187962293625, 0.059691719710826874, 0.060019880533218384, 0.060058023780584335, 0.04617919400334358, 0.045452870428562164, 0.045380886644124985, 0.04528208449482918, 0.041870079934597015, 0.0419272780418396, 0.04172024875879288, 0.04121467098593712, 0.041011448949575424, 0.04093252494931221, 0.040829140692949295, 0.040705349296331406], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-250-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [46:53<00:00, 703.36s/it]\u001b[A\n",
      " 40%|████      | 2/5 [2:06:50<3:10:05, 3801.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "166\n",
      "0.0434442589635651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:15<04:45, 15.05s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:30<04:37, 15.41s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:47<04:32, 16.04s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:04<04:20, 16.27s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [01:20<04:02, 16.17s/it]\u001b[A\n",
      " 30%|███       | 6/20 [01:35<03:42, 15.88s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [01:48<03:14, 14.98s/it]\u001b[A\n",
      " 40%|████      | 8/20 [01:59<02:42, 13.57s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [02:11<02:25, 13.23s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [02:24<02:10, 13.08s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [02:34<01:50, 12.29s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [02:44<01:32, 11.54s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [02:59<01:26, 12.42s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [03:15<01:21, 13.56s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [03:29<01:09, 13.84s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [03:44<00:56, 14.14s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [03:55<00:39, 13.16s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [04:11<00:28, 14.02s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [04:26<00:14, 14.25s/it]\u001b[A\n",
      "100%|██████████| 20/20 [04:42<00:00, 14.10s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 500, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [6.522996425628662, 1.897423267364502, 0.6083194613456726, 0.21401113271713257, 0.08813171088695526, 0.05403505265712738, 0.04320436716079712, 0.04149061068892479, 0.041574325412511826, 0.042647454887628555, 0.03128844127058983, 0.0310265701264143, 0.030802782624959946, 0.030683083459734917, 0.0320977084338665, 0.03108850307762623, 0.028071163222193718, 0.02812749333679676, 0.028341423720121384, 0.02769225463271141, 0.027663325890898705, 0.027668435126543045, 0.027537047863006592, 0.027512487024068832, 0.027512574568390846, 0.027499791234731674], min_val_index: 25\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "{'loss': [12.693218231201172, 4.617830753326416, 1.3939543962478638, 0.44669309258461, 0.1549777388572693, 0.07721690088510513, 0.057860877364873886, 0.05204594135284424, 0.05132969841361046, 0.051227666437625885, 0.04102921858429909, 0.04022754356265068, 0.04034404829144478, 0.0404810830950737, 0.04045167192816734, 0.0405232310295105, 0.03772096335887909, 0.0373336561024189, 0.03737645223736763, 0.03678572550415993, 0.036687713116407394, 0.036671191453933716, 0.03657878190279007, 0.036696236580610275, 0.03682679310441017, 0.03645867109298706], 'val_loss': [6.522996425628662, 1.897423267364502, 0.6083194613456726, 0.21401113271713257, 0.08813171088695526, 0.05403505265712738, 0.04320436716079712, 0.04149061068892479, 0.041574325412511826, 0.042647454887628555, 0.03128844127058983, 0.0310265701264143, 0.030802782624959946, 0.030683083459734917, 0.0320977084338665, 0.03108850307762623, 0.028071163222193718, 0.02812749333679676, 0.028341423720121384, 0.02769225463271141, 0.027663325890898705, 0.027668435126543045, 0.027537047863006592, 0.027512487024068832, 0.027512574568390846, 0.027499791234731674]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8993, eer: 0.1636, thres: 0.0838 => acc: 0.8364, f1: 0.8364\n",
      "\n",
      "Epoch 1/26\n",
      "188/188 [==============================] - 13s 50ms/step - loss: 9.8997\n",
      "Epoch 2/26\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 1.8273\n",
      "Epoch 3/26\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.2816\n",
      "Epoch 4/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0776\n",
      "Epoch 5/26\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0526\n",
      "Epoch 6/26\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 0.0500\n",
      "Epoch 7/26\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0496\n",
      "Epoch 8/26\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0501\n",
      "Epoch 9/26\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0499\n",
      "Epoch 10/26\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0502\n",
      "Epoch 11/26\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0379\n",
      "Epoch 12/26\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0373\n",
      "Epoch 13/26\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0375\n",
      "Epoch 14/26\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0374\n",
      "Epoch 15/26\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0374\n",
      "Epoch 16/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0372\n",
      "Epoch 17/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0339\n",
      "Epoch 18/26\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0340 0s - loss:\n",
      "Epoch 19/26\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0338\n",
      "Epoch 20/26\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0332\n",
      "Epoch 21/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0332\n",
      "Epoch 22/26\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0332\n",
      "Epoch 23/26\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0330\n",
      "Epoch 24/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0331\n",
      "Epoch 25/26\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0330\n",
      "Epoch 26/26\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0331\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9392, eer: 0.1145, thres: 0.1824 => acc: 0.8855, f1: 0.8855\n",
      "loss: 0.033\n",
      "{'loss': [9.899740219116211, 1.827323079109192, 0.28158968687057495, 0.07756926864385605, 0.052619028836488724, 0.05000421777367592, 0.04958580806851387, 0.05012239143252373, 0.04994085803627968, 0.050168585032224655, 0.037863314151763916, 0.037342753261327744, 0.037455152720212936, 0.037375252693891525, 0.037374451756477356, 0.03724708408117294, 0.03394882008433342, 0.03397798165678978, 0.033839404582977295, 0.033247362822294235, 0.03319966048002243, 0.03317004442214966, 0.03296392038464546, 0.033112555742263794, 0.0330122746527195, 0.03308972343802452], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-500-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [07:16<21:48, 436.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [12.212442398071289, 5.536579132080078, 2.244662046432495, 0.942560076713562, 0.4173784554004669, 0.18713660538196564, 0.10436266660690308, 0.0778433158993721, 0.06637708842754364, 0.05903482809662819, 0.05383395403623581, 0.0487741082906723, 0.04718055948615074, 0.04605387896299362, 0.047315921634435654, 0.047296226024627686, 0.03571662679314613, 0.036054641008377075, 0.03547251224517822, 0.03566674143075943, 0.03601919859647751, 0.03336884081363678, 0.03304728865623474, 0.03289983794093132, 0.033115454018116, 0.03312930837273598, 0.03245588392019272, 0.032405320554971695, 0.032405197620391846, 0.03230785205960274, 0.03230300545692444, 0.03227722644805908, 0.03226785734295845], min_val_index: 32\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1e-06}\n",
      "{'loss': [18.93611717224121, 9.826336860656738, 4.435931205749512, 1.8677289485931396, 0.7525865435600281, 0.30424878001213074, 0.14747513830661774, 0.09847836941480637, 0.07867435365915298, 0.06958836317062378, 0.06351405382156372, 0.05937354639172554, 0.05669206380844116, 0.055290210992097855, 0.0546923503279686, 0.05431809276342392, 0.04312082752585411, 0.04234587401151657, 0.04206281155347824, 0.042560916393995285, 0.042492788285017014, 0.03950522094964981, 0.03908124938607216, 0.0391947366297245, 0.03938167914748192, 0.039149317890405655, 0.03844918683171272, 0.03855506330728531, 0.03854049742221832, 0.038202524185180664, 0.03843722492456436, 0.03854554146528244, 0.03851673752069473], 'val_loss': [12.212442398071289, 5.536579132080078, 2.244662046432495, 0.942560076713562, 0.4173784554004669, 0.18713660538196564, 0.10436266660690308, 0.0778433158993721, 0.06637708842754364, 0.05903482809662819, 0.05383395403623581, 0.0487741082906723, 0.04718055948615074, 0.04605387896299362, 0.047315921634435654, 0.047296226024627686, 0.03571662679314613, 0.036054641008377075, 0.03547251224517822, 0.03566674143075943, 0.03601919859647751, 0.03336884081363678, 0.03304728865623474, 0.03289983794093132, 0.033115454018116, 0.03312930837273598, 0.03245588392019272, 0.032405320554971695, 0.032405197620391846, 0.03230785205960274, 0.03230300545692444, 0.03227722644805908, 0.03226785734295845]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8755, eer: 0.1984, thres: 0.1532 => acc: 0.8016, f1: 0.8016\n",
      "\n",
      "Epoch 1/33\n",
      "188/188 [==============================] - 10s 33ms/step - loss: 15.4561\n",
      "Epoch 2/33\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 4.6161\n",
      "Epoch 3/33\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 1.0821\n",
      "Epoch 4/33\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.2719\n",
      "Epoch 5/33\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0997\n",
      "Epoch 6/33\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0697\n",
      "Epoch 7/33\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0579\n",
      "Epoch 8/33\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0546\n",
      "Epoch 9/33\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0530\n",
      "Epoch 10/33\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0526\n",
      "Epoch 11/33\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0529\n",
      "Epoch 12/33\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0531\n",
      "Epoch 13/33\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0534\n",
      "Epoch 14/33\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0534\n",
      "Epoch 15/33\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0537\n",
      "Epoch 16/33\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0536\n",
      "Epoch 17/33\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0398\n",
      "Epoch 18/33\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0392\n",
      "Epoch 19/33\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0392\n",
      "Epoch 20/33\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0390\n",
      "Epoch 21/33\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0392\n",
      "Epoch 22/33\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0358\n",
      "Epoch 23/33\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0354\n",
      "Epoch 24/33\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0356\n",
      "Epoch 25/33\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0355\n",
      "Epoch 26/33\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0356\n",
      "Epoch 27/33\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0348\n",
      "Epoch 28/33\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0348\n",
      "Epoch 29/33\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0348\n",
      "Epoch 30/33\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0346\n",
      "Epoch 31/33\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0346\n",
      "Epoch 32/33\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0346\n",
      "Epoch 33/33\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0346\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9435, eer: 0.1166, thres: 0.1912 => acc: 0.8834, f1: 0.8834\n",
      "loss: 0.035\n",
      "{'loss': [15.45605182647705, 4.61610746383667, 1.0820926427841187, 0.271892786026001, 0.09965627640485764, 0.06969655305147171, 0.057903092354536057, 0.05460190400481224, 0.05299682542681694, 0.05264392867684364, 0.05292658135294914, 0.05310269817709923, 0.053429245948791504, 0.05336086452007294, 0.053667038679122925, 0.05362953618168831, 0.03978696092963219, 0.03920229151844978, 0.03919462114572525, 0.039035119116306305, 0.03917025402188301, 0.03581390157341957, 0.035357553511857986, 0.03561226278543472, 0.03546970337629318, 0.03558189421892166, 0.03481261059641838, 0.034778330475091934, 0.0348006971180439, 0.03464745357632637, 0.03457975015044212, 0.03456006571650505, 0.0346049889922142], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-500-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [17:56<18:32, 556.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [14.20686149597168, 5.529148578643799, 2.3002519607543945, 0.8938254117965698, 0.4981096684932709, 0.20136632025241852, 0.11165162175893784, 0.08806181699037552, 0.07822272926568985, 0.07249151915311813, 0.07732770591974258, 0.06847857683897018, 0.06070418655872345, 0.06889031827449799, 0.0684426873922348, 0.042322639375925064, 0.04132924601435661, 0.04248948022723198, 0.04137787967920303, 0.03564678877592087, 0.035448815673589706, 0.03527221083641052, 0.035246506333351135, 0.0353427417576313, 0.03398609161376953, 0.03410826623439789, 0.03411736339330673, 0.03383992612361908, 0.03380243107676506, 0.03378980606794357, 0.03376542031764984], min_val_index: 30\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "{'loss': [23.44154930114746, 10.538570404052734, 4.5191121101379395, 2.0188536643981934, 0.8940675258636475, 0.37499576807022095, 0.1255555897951126, 0.09117672592401505, 0.08055207133293152, 0.07567966729402542, 0.07265062630176544, 0.07124068588018417, 0.07047122716903687, 0.0706622451543808, 0.07119178026914597, 0.04924576357007027, 0.0476570650935173, 0.04774128645658493, 0.0477462001144886, 0.04232076555490494, 0.04176167771220207, 0.041921842843294144, 0.041392259299755096, 0.04184753820300102, 0.04070587456226349, 0.04027974605560303, 0.04029427096247673, 0.040161509066820145, 0.04017472639679909, 0.04034874960780144, 0.039963334798812866], 'val_loss': [14.20686149597168, 5.529148578643799, 2.3002519607543945, 0.8938254117965698, 0.4981096684932709, 0.20136632025241852, 0.11165162175893784, 0.08806181699037552, 0.07822272926568985, 0.07249151915311813, 0.07732770591974258, 0.06847857683897018, 0.06070418655872345, 0.06889031827449799, 0.0684426873922348, 0.042322639375925064, 0.04132924601435661, 0.04248948022723198, 0.04137787967920303, 0.03564678877592087, 0.035448815673589706, 0.03527221083641052, 0.035246506333351135, 0.0353427417576313, 0.03398609161376953, 0.03410826623439789, 0.03411736339330673, 0.03383992612361908, 0.03380243107676506, 0.03378980606794357, 0.03376542031764984]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8305, eer: 0.2494, thres: 0.1340 => acc: 0.7506, f1: 0.7506\n",
      "\n",
      "Epoch 1/31\n",
      "188/188 [==============================] - 7s 22ms/step - loss: 18.3835\n",
      "Epoch 2/31\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 4.5164\n",
      "Epoch 3/31\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 1.1822\n",
      "Epoch 4/31\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.2833\n",
      "Epoch 5/31\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0978\n",
      "Epoch 6/31\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0774\n",
      "Epoch 7/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0707\n",
      "Epoch 8/31\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0696\n",
      "Epoch 9/31\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0687\n",
      "Epoch 10/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0688\n",
      "Epoch 11/31\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0701\n",
      "Epoch 12/31\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0713\n",
      "Epoch 13/31\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0754\n",
      "Epoch 14/31\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0736\n",
      "Epoch 15/31\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0743\n",
      "Epoch 16/31\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0462\n",
      "Epoch 17/31\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0445\n",
      "Epoch 18/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0448\n",
      "Epoch 19/31\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0449\n",
      "Epoch 20/31\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0378\n",
      "Epoch 21/31\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0372\n",
      "Epoch 22/31\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0373\n",
      "Epoch 23/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0370\n",
      "Epoch 24/31\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0371\n",
      "Epoch 25/31\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0357\n",
      "Epoch 26/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0358\n",
      "Epoch 27/31\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0354\n",
      "Epoch 28/31\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0354\n",
      "Epoch 29/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0353\n",
      "Epoch 30/31\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0352\n",
      "Epoch 31/31\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0352\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9365, eer: 0.1230, thres: 0.1678 => acc: 0.8770, f1: 0.8770\n",
      "loss: 0.035\n",
      "{'loss': [18.383514404296875, 4.516384124755859, 1.1821513175964355, 0.28330519795417786, 0.09783753752708435, 0.07739221304655075, 0.07074879854917526, 0.06962115317583084, 0.06866385042667389, 0.06882753223180771, 0.07013518363237381, 0.07126147300004959, 0.07535016536712646, 0.07360780239105225, 0.07433389127254486, 0.04621868580579758, 0.044486917555332184, 0.044815544039011, 0.04491019248962402, 0.037776973098516464, 0.037167225033044815, 0.037273719906806946, 0.03701474145054817, 0.037149589508771896, 0.035690609365701675, 0.03577788546681404, 0.035448141396045685, 0.03537055104970932, 0.03530416637659073, 0.03524721413850784, 0.035246435552835464], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-500-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [25:05<08:18, 498.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [12.237417221069336, 5.252593994140625, 1.9715373516082764, 0.7905675172805786, 0.3242676258087158, 0.14129526913166046, 0.0815659686923027, 0.05920259281992912, 0.050309326499700546, 0.045530419796705246, 0.044200193136930466, 0.04436562582850456, 0.04220588132739067, 0.04330926388502121, 0.044167980551719666, 0.030524618923664093, 0.030082153156399727, 0.030481694266200066, 0.030285866931080818, 0.02696080319583416, 0.026776444166898727, 0.026860615238547325, 0.027058715000748634, 0.02624491974711418, 0.02619597315788269, 0.026226386427879333, 0.026070095598697662, 0.02605230174958706, 0.026057086884975433, 0.026052044704556465], min_val_index: 29\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "{'loss': [19.222633361816406, 9.582133293151855, 4.0900163650512695, 1.619570255279541, 0.623539388179779, 0.24504543840885162, 0.11374498903751373, 0.08143764734268188, 0.06624995917081833, 0.05937495455145836, 0.05642413720488548, 0.055050190538167953, 0.05501764640212059, 0.05472254008054733, 0.054824694991111755, 0.042609598487615585, 0.041817035526037216, 0.041678979992866516, 0.04179457947611809, 0.038692038506269455, 0.03845653310418129, 0.03827992081642151, 0.038357045501470566, 0.037713684141635895, 0.03770711272954941, 0.03767738863825798, 0.0374600812792778, 0.03745578974485397, 0.037573594599962234, 0.03752332553267479], 'val_loss': [12.237417221069336, 5.252593994140625, 1.9715373516082764, 0.7905675172805786, 0.3242676258087158, 0.14129526913166046, 0.0815659686923027, 0.05920259281992912, 0.050309326499700546, 0.045530419796705246, 0.044200193136930466, 0.04436562582850456, 0.04220588132739067, 0.04330926388502121, 0.044167980551719666, 0.030524618923664093, 0.030082153156399727, 0.030481694266200066, 0.030285866931080818, 0.02696080319583416, 0.026776444166898727, 0.026860615238547325, 0.027058715000748634, 0.02624491974711418, 0.02619597315788269, 0.026226386427879333, 0.026070095598697662, 0.02605230174958706, 0.026057086884975433, 0.026052044704556465]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8726, eer: 0.2021, thres: 0.1477 => acc: 0.7979, f1: 0.7979\n",
      "\n",
      "Epoch 1/30\n",
      "188/188 [==============================] - 15s 48ms/step - loss: 15.1245\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 3.9453\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.8009\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.1725\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0778\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0609\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0557\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0540\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0530\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0528\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0533\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0535\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0539\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0539\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0542\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0391\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0383\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0384\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0382\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0348\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0347\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0347\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0346\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0339\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0338\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0338\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0336\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 0.0337:\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0337\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0337\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9466, eer: 0.1097, thres: 0.1854 => acc: 0.8902, f1: 0.8902\n",
      "loss: 0.034\n",
      "{'loss': [15.124471664428711, 3.9453024864196777, 0.8008671402931213, 0.17249614000320435, 0.07781196385622025, 0.06087871268391609, 0.05567491427063942, 0.05401080846786499, 0.052988987416028976, 0.05280982330441475, 0.0533074289560318, 0.05348651111125946, 0.05387658253312111, 0.053936559706926346, 0.05421514809131622, 0.03911704942584038, 0.03834110125899315, 0.03839309513568878, 0.03824097663164139, 0.034794881939888, 0.03473173454403877, 0.034699466079473495, 0.03455055132508278, 0.03390514850616455, 0.0337502658367157, 0.03382998704910278, 0.0336044616997242, 0.033726032823324203, 0.033748239278793335, 0.03370201960206032], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-500-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [36:50<00:00, 552.73s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [2:48:54<1:47:17, 3218.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "110\n",
      "0.09893801652892562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:10<03:28, 10.99s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:22<03:20, 11.16s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:33<03:07, 11.05s/it]\u001b[A\n",
      " 20%|██        | 4/20 [00:44<02:56, 11.04s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:54<02:39, 10.66s/it]\u001b[A\n",
      " 30%|███       | 6/20 [01:03<02:24, 10.33s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [01:14<02:16, 10.50s/it]\u001b[A\n",
      " 40%|████      | 8/20 [01:24<02:03, 10.26s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [01:36<01:57, 10.72s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [01:46<01:45, 10.56s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [01:57<01:36, 10.69s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [02:06<01:21, 10.17s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [02:14<01:07,  9.62s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [02:22<00:55,  9.19s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [02:30<00:44,  8.83s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [02:40<00:35,  8.99s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [02:49<00:27,  9.06s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [02:57<00:17,  8.85s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [03:04<00:08,  8.28s/it]\u001b[A\n",
      "100%|██████████| 20/20 [03:11<00:00,  9.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 750, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [5.568518161773682, 1.372458577156067, 0.4098225235939026, 0.14075562357902527, 0.06305095553398132, 0.0443081296980381, 0.040305860340595245, 0.04131244122982025, 0.042006466537714005, 0.028693975880742073, 0.028188861906528473, 0.02849411778151989, 0.028883986175060272, 0.025118976831436157, 0.02526514232158661, 0.025275520980358124, 0.024565979838371277, 0.02454095520079136, 0.024572478607296944, 0.024425916373729706, 0.024438466876745224, 0.02445361390709877, 0.02444472908973694], min_val_index: 19\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.00020000001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 4.0000003e-05, 14: 4.0000003e-05, 15: 4.0000003e-05, 16: 8.000001e-06, 17: 8.000001e-06, 18: 8.000001e-06, 19: 1.6000001e-06, 20: 1.6000001e-06, 21: 1.6000001e-06, 22: 1e-06}\n",
      "{'loss': [11.47111988067627, 3.48923921585083, 0.874386727809906, 0.2583114802837372, 0.10284799337387085, 0.06356947869062424, 0.053053952753543854, 0.050492528825998306, 0.049838803708553314, 0.03841764107346535, 0.03766473010182381, 0.03771708160638809, 0.03740140423178673, 0.03468058630824089, 0.03423001989722252, 0.034276608377695084, 0.03351413831114769, 0.03364352136850357, 0.03359483554959297, 0.033521365374326706, 0.0334089919924736, 0.03351970389485359, 0.03339463844895363], 'val_loss': [5.568518161773682, 1.372458577156067, 0.4098225235939026, 0.14075562357902527, 0.06305095553398132, 0.0443081296980381, 0.040305860340595245, 0.04131244122982025, 0.042006466537714005, 0.028693975880742073, 0.028188861906528473, 0.02849411778151989, 0.028883986175060272, 0.025118976831436157, 0.02526514232158661, 0.025275520980358124, 0.024565979838371277, 0.02454095520079136, 0.024572478607296944, 0.024425916373729706, 0.024438466876745224, 0.02445361390709877, 0.02444472908973694]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.00020000001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 4.0000003e-05, 14: 4.0000003e-05, 15: 4.0000003e-05, 16: 8.000001e-06, 17: 8.000001e-06, 18: 8.000001e-06, 19: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9238, eer: 0.1376, thres: 0.0746 => acc: 0.8624, f1: 0.8624\n",
      "\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 17s 73ms/step - loss: 9.1515\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 1.4118\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.1946\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0643\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0495\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.0482\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0482\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 13s 68ms/step - loss: 0.0482\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.0483\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0354\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0347\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0347\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0349\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0314\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0313\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0314\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 0.0306\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0305\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0306\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0305\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9557, eer: 0.0951, thres: 0.1832 => acc: 0.9049, f1: 0.9049\n",
      "loss: 0.031\n",
      "{'loss': [9.151528358459473, 1.4117703437805176, 0.19460614025592804, 0.06433971971273422, 0.049461014568805695, 0.04823926463723183, 0.04821115359663963, 0.048230744898319244, 0.048292238265275955, 0.03542325273156166, 0.03471801429986954, 0.03470655903220177, 0.034944798797369, 0.03141886740922928, 0.031335294246673584, 0.03136775270104408, 0.030636269599199295, 0.030506763607263565, 0.030594678595662117, 0.030546361580491066], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-750-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [08:08<24:26, 488.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [11.595978736877441, 4.97177267074585, 1.9453920125961304, 0.8069358468055725, 0.3613681495189667, 0.1789848506450653, 0.1006772518157959, 0.06858660280704498, 0.054817456752061844, 0.046147897839546204, 0.04438421502709389, 0.04215136542916298, 0.03927742689847946, 0.0416056364774704, 0.04243731498718262, 0.027911759912967682, 0.02728237211704254, 0.027718383818864822, 0.027376538142561913, 0.023809008300304413, 0.02407022938132286, 0.023729268461465836, 0.023299163207411766, 0.023258542641997337, 0.023247044533491135, 0.02316739782691002, 0.023178042843937874, 0.023188168182969093, 0.02317860908806324], min_val_index: 25\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1e-06}\n",
      "{'loss': [17.96916961669922, 8.84709358215332, 3.7535061836242676, 1.495475172996521, 0.5982336401939392, 0.2642859220504761, 0.1410241425037384, 0.09213507920503616, 0.07167818397283554, 0.062038641422986984, 0.057295773178339005, 0.05433881655335426, 0.05309319123625755, 0.05219675227999687, 0.0512523353099823, 0.039564162492752075, 0.038752708584070206, 0.03859526664018631, 0.03865819424390793, 0.03559642285108566, 0.035257648676633835, 0.0355280265212059, 0.03466285765171051, 0.03458794951438904, 0.03486054390668869, 0.03459632769227028, 0.034566689282655716, 0.03455960005521774, 0.03461938723921776], 'val_loss': [11.595978736877441, 4.97177267074585, 1.9453920125961304, 0.8069358468055725, 0.3613681495189667, 0.1789848506450653, 0.1006772518157959, 0.06858660280704498, 0.054817456752061844, 0.046147897839546204, 0.04438421502709389, 0.04215136542916298, 0.03927742689847946, 0.0416056364774704, 0.04243731498718262, 0.027911759912967682, 0.02728237211704254, 0.027718383818864822, 0.027376538142561913, 0.023809008300304413, 0.02407022938132286, 0.023729268461465836, 0.023299163207411766, 0.023258542641997337, 0.023247044533491135, 0.02316739782691002, 0.023178042843937874, 0.023188168182969093, 0.02317860908806324]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9031, eer: 0.1701, thres: 0.1371 => acc: 0.8299, f1: 0.8299\n",
      "\n",
      "Epoch 1/26\n",
      "188/188 [==============================] - 18s 61ms/step - loss: 14.3589\n",
      "Epoch 2/26\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 3.6565\n",
      "Epoch 3/26\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.7320\n",
      "Epoch 4/26\n",
      "188/188 [==============================] - 12s 61ms/step - loss: 0.1665\n",
      "Epoch 5/26\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0763\n",
      "Epoch 6/26\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0572\n",
      "Epoch 7/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0517\n",
      "Epoch 8/26\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0499\n",
      "Epoch 9/26\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0493\n",
      "Epoch 10/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0491\n",
      "Epoch 11/26\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0492\n",
      "Epoch 12/26\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0495\n",
      "Epoch 13/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0515\n",
      "Epoch 14/26\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0507\n",
      "Epoch 15/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0506\n",
      "Epoch 16/26\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0364\n",
      "Epoch 17/26\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0356\n",
      "Epoch 18/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0355\n",
      "Epoch 19/26\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0354\n",
      "Epoch 20/26\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0321\n",
      "Epoch 21/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0319\n",
      "Epoch 22/26\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0318\n",
      "Epoch 23/26\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0311\n",
      "Epoch 24/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0313\n",
      "Epoch 25/26\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0313\n",
      "Epoch 26/26\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0309\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9481, eer: 0.1030, thres: 0.1732 => acc: 0.8970, f1: 0.8970\n",
      "loss: 0.031\n",
      "{'loss': [14.358872413635254, 3.6564528942108154, 0.7320411801338196, 0.1664760708808899, 0.07630059123039246, 0.05722350999712944, 0.05167316272854805, 0.04988456517457962, 0.04931735619902611, 0.049144722521305084, 0.0491873137652874, 0.04947691410779953, 0.051508113741874695, 0.050701405853033066, 0.050649210810661316, 0.03642851486802101, 0.035597819834947586, 0.035479411482810974, 0.03543129190802574, 0.032067056745290756, 0.031929172575473785, 0.03179820626974106, 0.03109239786863327, 0.031285565346479416, 0.03128279000520706, 0.03089028038084507], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-750-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [17:23<17:34, 527.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [13.20151138305664, 4.769459247589111, 1.8550313711166382, 0.8648294806480408, 0.3604327142238617, 0.1665297895669937, 0.09124862402677536, 0.07393977046012878, 0.07017211616039276, 0.07412126660346985, 0.06559789925813675, 0.06662802398204803, 0.07535384595394135, 0.040893953293561935, 0.04120684787631035, 0.04209008067846298, 0.034264687448740005, 0.03442883864045143, 0.03463733196258545, 0.033163852989673615, 0.03306930884718895, 0.03310902416706085, 0.03279227018356323, 0.032783932983875275, 0.032799169421195984, 0.03276439011096954], min_val_index: 25\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "{'loss': [22.274322509765625, 9.3052339553833, 3.695939540863037, 1.5463178157806396, 0.653832733631134, 0.30238083004951477, 0.10724207758903503, 0.08105707168579102, 0.07383153587579727, 0.07141190022230148, 0.06945125758647919, 0.06778408586978912, 0.06788519024848938, 0.046144068241119385, 0.044217854738235474, 0.04445498809218407, 0.03869776800274849, 0.038315366953611374, 0.03838130831718445, 0.037057988345623016, 0.03697146847844124, 0.0370333231985569, 0.03675205633044243, 0.03667660430073738, 0.03683241084218025, 0.03678887337446213], 'val_loss': [13.20151138305664, 4.769459247589111, 1.8550313711166382, 0.8648294806480408, 0.3604327142238617, 0.1665297895669937, 0.09124862402677536, 0.07393977046012878, 0.07017211616039276, 0.07412126660346985, 0.06559789925813675, 0.06662802398204803, 0.07535384595394135, 0.040893953293561935, 0.04120684787631035, 0.04209008067846298, 0.034264687448740005, 0.03442883864045143, 0.03463733196258545, 0.033163852989673615, 0.03306930884718895, 0.03310902416706085, 0.03279227018356323, 0.032783932983875275, 0.032799169421195984, 0.03276439011096954]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8639, eer: 0.2163, thres: 0.1198 => acc: 0.7837, f1: 0.7837\n",
      "\n",
      "Epoch 1/26\n",
      "188/188 [==============================] - 14s 51ms/step - loss: 16.8868\n",
      "Epoch 2/26\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 3.5238\n",
      "Epoch 3/26\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.8467\n",
      "Epoch 4/26\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.1600\n",
      "Epoch 5/26\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0785\n",
      "Epoch 6/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0693\n",
      "Epoch 7/26\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0658\n",
      "Epoch 8/26\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0648\n",
      "Epoch 9/26\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0658\n",
      "Epoch 10/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0666\n",
      "Epoch 11/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0679\n",
      "Epoch 12/26\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0691\n",
      "Epoch 13/26\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0742\n",
      "Epoch 14/26\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0430\n",
      "Epoch 15/26\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0416\n",
      "Epoch 16/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0417 1s\n",
      "Epoch 17/26\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0347\n",
      "Epoch 18/26\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0342\n",
      "Epoch 19/26\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0342\n",
      "Epoch 20/26\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0328\n",
      "Epoch 21/26\n",
      "188/188 [==============================] - 10s 50ms/step - loss: 0.0327\n",
      "Epoch 22/26\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0326\n",
      "Epoch 23/26\n",
      "188/188 [==============================] - 9s 51ms/step - loss: 0.0324\n",
      "Epoch 24/26\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0324\n",
      "Epoch 25/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0325\n",
      "Epoch 26/26\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0323\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9451, eer: 0.1148, thres: 0.1655 => acc: 0.8852, f1: 0.8852\n",
      "loss: 0.032\n",
      "{'loss': [16.88678550720215, 3.523757219314575, 0.846717119216919, 0.1599607914686203, 0.07849684357643127, 0.06926371902227402, 0.06581874191761017, 0.06478163599967957, 0.06575430929660797, 0.06662004441022873, 0.06785286217927933, 0.06912101805210114, 0.07416412979364395, 0.04302974417805672, 0.041568003594875336, 0.041654445230960846, 0.0347324013710022, 0.03418966382741928, 0.034223634749650955, 0.03282570466399193, 0.03267669677734375, 0.032606083899736404, 0.03238756209611893, 0.032446447759866714, 0.0325072705745697, 0.032265275716781616], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-750-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [26:26<08:54, 534.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [11.084163665771484, 4.205053806304932, 1.4511260986328125, 0.5593744516372681, 0.21604551374912262, 0.09728997200727463, 0.06465490907430649, 0.049508340656757355, 0.04518885537981987, 0.042302753776311874, 0.0427081435918808, 0.042227812111377716, 0.028915459290146828, 0.028574325144290924, 0.029553188011050224, 0.028994135558605194, 0.02530892938375473, 0.025287477299571037, 0.025379937142133713, 0.02463378943502903, 0.024632450193166733, 0.024632908403873444, 0.024509761482477188, 0.024500751867890358, 0.024515831843018532, 0.024486787617206573], min_val_index: 25\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "{'loss': [17.98252296447754, 8.105103492736816, 3.0367095470428467, 1.1027332544326782, 0.38946911692619324, 0.14880885183811188, 0.09135884046554565, 0.06793874502182007, 0.057995133101940155, 0.05422588810324669, 0.053287867456674576, 0.05297454446554184, 0.0407717190682888, 0.039908502250909805, 0.039807599037885666, 0.03991396725177765, 0.03658968210220337, 0.036281418055295944, 0.03625456988811493, 0.03562242537736893, 0.03565308451652527, 0.03572995215654373, 0.035166800022125244, 0.03540978953242302, 0.035416822880506516, 0.035319119691848755], 'val_loss': [11.084163665771484, 4.205053806304932, 1.4511260986328125, 0.5593744516372681, 0.21604551374912262, 0.09728997200727463, 0.06465490907430649, 0.049508340656757355, 0.04518885537981987, 0.042302753776311874, 0.0427081435918808, 0.042227812111377716, 0.028915459290146828, 0.028574325144290924, 0.029553188011050224, 0.028994135558605194, 0.02530892938375473, 0.025287477299571037, 0.025379937142133713, 0.02463378943502903, 0.024632450193166733, 0.024632908403873444, 0.024509761482477188, 0.024500751867890358, 0.024515831843018532, 0.024486787617206573]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9030, eer: 0.1690, thres: 0.1323 => acc: 0.8310, f1: 0.8310\n",
      "\n",
      "Epoch 1/26\n",
      "188/188 [==============================] - 18s 62ms/step - loss: 13.9880\n",
      "Epoch 2/26\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 3.0709\n",
      "Epoch 3/26\n",
      "188/188 [==============================] - 9s 51ms/step - loss: 0.5671\n",
      "Epoch 4/26\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.1259\n",
      "Epoch 5/26\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0694\n",
      "Epoch 6/26\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0550\n",
      "Epoch 7/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0513\n",
      "Epoch 8/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0503\n",
      "Epoch 9/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0503\n",
      "Epoch 10/26\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0504\n",
      "Epoch 11/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0504\n",
      "Epoch 12/26\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0509\n",
      "Epoch 13/26\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0366\n",
      "Epoch 14/26\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0357\n",
      "Epoch 15/26\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0356\n",
      "Epoch 16/26\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0356\n",
      "Epoch 17/26\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0322\n",
      "Epoch 18/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0320\n",
      "Epoch 19/26\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0320\n",
      "Epoch 20/26\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0313\n",
      "Epoch 21/26\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0312\n",
      "Epoch 22/26\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0311\n",
      "Epoch 23/26\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0310\n",
      "Epoch 24/26\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0312\n",
      "Epoch 25/26\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0311\n",
      "Epoch 26/26\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0310\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9578, eer: 0.0926, thres: 0.1879 => acc: 0.9074, f1: 0.9074\n",
      "loss: 0.031\n",
      "{'loss': [13.988024711608887, 3.070863962173462, 0.5671039819717407, 0.1258564591407776, 0.06941443681716919, 0.05498094856739044, 0.05128060281276703, 0.050303298979997635, 0.050339508801698685, 0.050367772579193115, 0.050355635583400726, 0.05090776085853577, 0.03659345582127571, 0.03566528484225273, 0.03564085066318512, 0.03564916178584099, 0.032219864428043365, 0.03200159966945648, 0.0319698341190815, 0.031299978494644165, 0.031178371980786324, 0.031062785536050797, 0.03104415535926819, 0.031155452132225037, 0.031069548800587654, 0.031018152832984924], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-750-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [37:06<00:00, 556.59s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [3:29:34<48:31, 2911.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "82\n",
      "0.17804134443783462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:07<02:31,  7.95s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:16<02:24,  8.01s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:22<02:04,  7.34s/it]\u001b[A\n",
      " 20%|██        | 4/20 [00:28<01:50,  6.91s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:35<01:39,  6.66s/it]\u001b[A\n",
      " 30%|███       | 6/20 [00:41<01:32,  6.62s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:48<01:25,  6.58s/it]\u001b[A\n",
      " 40%|████      | 8/20 [00:54<01:18,  6.52s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [01:00<01:10,  6.40s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [01:07<01:04,  6.44s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [01:13<00:58,  6.55s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [01:20<00:51,  6.50s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [01:27<00:46,  6.59s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [01:33<00:39,  6.66s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [01:40<00:33,  6.71s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [01:47<00:26,  6.70s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [01:54<00:20,  6.71s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [02:00<00:13,  6.71s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [02:07<00:06,  6.74s/it]\u001b[A\n",
      "100%|██████████| 20/20 [02:14<00:00,  6.72s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 1000, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [5.2903900146484375, 1.2590899467468262, 0.3746944069862366, 0.1274586319923401, 0.05892447009682655, 0.04271266981959343, 0.03856337070465088, 0.03740024194121361, 0.03970513492822647, 0.038411788642406464, 0.025734078139066696, 0.025485815480351448, 0.025581559166312218, 0.025991136208176613, 0.02256559580564499, 0.022411642596125603, 0.02233884297311306, 0.02262875624001026, 0.02182639203965664, 0.021810004487633705, 0.02184484340250492, 0.021703585982322693, 0.02170710265636444, 0.021698784083127975, 0.02167651429772377], min_val_index: 24\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 4.0000003e-05, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "{'loss': [11.018271446228027, 3.133528470993042, 0.7585542798042297, 0.23688584566116333, 0.09467794001102448, 0.0590105876326561, 0.05046132206916809, 0.04882611334323883, 0.04846294969320297, 0.04865361750125885, 0.03667241707444191, 0.03581447899341583, 0.035564955323934555, 0.03568851947784424, 0.03270084783434868, 0.03230397775769234, 0.03225164860486984, 0.03235739842057228, 0.03165803104639053, 0.03144896775484085, 0.03151445835828781, 0.03152072802186012, 0.03141235560178757, 0.031408727169036865, 0.031581103801727295], 'val_loss': [5.2903900146484375, 1.2590899467468262, 0.3746944069862366, 0.1274586319923401, 0.05892447009682655, 0.04271266981959343, 0.03856337070465088, 0.03740024194121361, 0.03970513492822647, 0.038411788642406464, 0.025734078139066696, 0.025485815480351448, 0.025581559166312218, 0.025991136208176613, 0.02256559580564499, 0.022411642596125603, 0.02233884297311306, 0.02262875624001026, 0.02182639203965664, 0.021810004487633705, 0.02184484340250492, 0.021703585982322693, 0.02170710265636444, 0.021698784083127975, 0.02167651429772377]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 4.0000003e-05, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9356, eer: 0.1255, thres: 0.0700 => acc: 0.8745, f1: 0.8745\n",
      "\n",
      "Epoch 1/25\n",
      "188/188 [==============================] - 17s 73ms/step - loss: 8.6848\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 1.1478\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.1408\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 0.0588\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 13s 72ms/step - loss: 0.0484\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.0478\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0476\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.0477\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0474\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.0473\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0341\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0333\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0335\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 0.0332\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0300\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.0299\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0297\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 13s 68ms/step - loss: 0.0299\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.0292\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.0290\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 13s 68ms/step - loss: 0.0291\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0290\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0290\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.0290 1s -\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.0290\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9560, eer: 0.0946, thres: 0.1866 => acc: 0.9055, f1: 0.9055\n",
      "loss: 0.029\n",
      "{'loss': [8.684837341308594, 1.1478337049484253, 0.1407972127199173, 0.05877967178821564, 0.04839484021067619, 0.04781350865960121, 0.04755628481507301, 0.047675080597400665, 0.047408610582351685, 0.04729582741856575, 0.034054841846227646, 0.033254921436309814, 0.03349511697888374, 0.03315513953566551, 0.030039889737963676, 0.029914414510130882, 0.02974313497543335, 0.029858725145459175, 0.029206186532974243, 0.029041139408946037, 0.02909662574529648, 0.02903721109032631, 0.028992880135774612, 0.02897460013628006, 0.029025429859757423], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-1000-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [11:17<33:52, 677.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [10.84984302520752, 4.22905158996582, 1.4852598905563354, 0.5830743312835693, 0.2373308688402176, 0.11404386907815933, 0.06835765391588211, 0.05240319296717644, 0.045905355364084244, 0.04201941564679146, 0.04099428653717041, 0.04042918235063553, 0.03992654010653496, 0.04091132804751396, 0.03866473212838173, 0.04289954528212547, 0.0441971980035305, 0.027509702369570732, 0.02761809155344963, 0.027413224801421165, 0.022990895435214043, 0.02280086651444435, 0.022870151326060295, 0.022847900167107582, 0.02222936414182186, 0.022270413115620613, 0.02220860682427883, 0.022106479853391647, 0.022102316841483116, 0.022098906338214874, 0.02208680473268032], min_val_index: 30\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "{'loss': [17.211856842041016, 7.849470615386963, 2.987563133239746, 1.0497833490371704, 0.38954001665115356, 0.17471477389335632, 0.09932422637939453, 0.06975796818733215, 0.058591630309820175, 0.054255228489637375, 0.0521068312227726, 0.05077457055449486, 0.04981599003076553, 0.04901786521077156, 0.04890107363462448, 0.049275822937488556, 0.049324195832014084, 0.03680843114852905, 0.03598741441965103, 0.035952966660261154, 0.03292851522564888, 0.03270839899778366, 0.03262150660157204, 0.03276596963405609, 0.032072167843580246, 0.03205157443881035, 0.03196162357926369, 0.03175001218914986, 0.03182007372379303, 0.03196384757757187, 0.031889658421278], 'val_loss': [10.84984302520752, 4.22905158996582, 1.4852598905563354, 0.5830743312835693, 0.2373308688402176, 0.11404386907815933, 0.06835765391588211, 0.05240319296717644, 0.045905355364084244, 0.04201941564679146, 0.04099428653717041, 0.04042918235063553, 0.03992654010653496, 0.04091132804751396, 0.03866473212838173, 0.04289954528212547, 0.0441971980035305, 0.027509702369570732, 0.02761809155344963, 0.027413224801421165, 0.022990895435214043, 0.02280086651444435, 0.022870151326060295, 0.022847900167107582, 0.02222936414182186, 0.022270413115620613, 0.02220860682427883, 0.022106479853391647, 0.022102316841483116, 0.022098906338214874, 0.02208680473268032]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9199, eer: 0.1505, thres: 0.1280 => acc: 0.8495, f1: 0.8495\n",
      "\n",
      "Epoch 1/31\n",
      "188/188 [==============================] - 23s 76ms/step - loss: 13.7741\n",
      "Epoch 2/31\n",
      "188/188 [==============================] - 16s 83ms/step - loss: 3.1363\n",
      "Epoch 3/31\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.5099\n",
      "Epoch 4/31\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 0.1296\n",
      "Epoch 5/31\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0656\n",
      "Epoch 6/31\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0529\n",
      "Epoch 7/31\n",
      "188/188 [==============================] - 15s 82ms/step - loss: 0.0496\n",
      "Epoch 8/31\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0494\n",
      "Epoch 9/31\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0485\n",
      "Epoch 10/31\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.0483\n",
      "Epoch 11/31\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 0.0486\n",
      "Epoch 12/31\n",
      "188/188 [==============================] - 13s 68ms/step - loss: 0.0484\n",
      "Epoch 13/31\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0515\n",
      "Epoch 14/31\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 0.0491\n",
      "Epoch 15/31\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0490\n",
      "Epoch 16/31\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0491\n",
      "Epoch 17/31\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 0.0487\n",
      "Epoch 18/31\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0340\n",
      "Epoch 19/31\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.0333\n",
      "Epoch 20/31\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.0330\n",
      "Epoch 21/31\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0299\n",
      "Epoch 22/31\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.0295\n",
      "Epoch 23/31\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0295\n",
      "Epoch 24/31\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0295\n",
      "Epoch 25/31\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0288\n",
      "Epoch 26/31\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0288\n",
      "Epoch 27/31\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0287\n",
      "Epoch 28/31\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0286\n",
      "Epoch 29/31\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0286\n",
      "Epoch 30/31\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0286\n",
      "Epoch 31/31\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0286\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9643, eer: 0.0859, thres: 0.1829 => acc: 0.9141, f1: 0.9141\n",
      "loss: 0.029\n",
      "{'loss': [13.774145126342773, 3.136340618133545, 0.5099180340766907, 0.12959228456020355, 0.06562239676713943, 0.05289238691329956, 0.04963035136461258, 0.04940670356154442, 0.04845324531197548, 0.04833630472421646, 0.048595208674669266, 0.048437345772981644, 0.05148135870695114, 0.04912055656313896, 0.04901775345206261, 0.049058351665735245, 0.048663344234228134, 0.03403933346271515, 0.03333673253655434, 0.033031389117240906, 0.0298717450350523, 0.02950565330684185, 0.02951875515282154, 0.02946462295949459, 0.028757205232977867, 0.028776753693819046, 0.02872094139456749, 0.028550943359732628, 0.028647223487496376, 0.028591664507985115, 0.028605984523892403], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-1000-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [28:27<29:30, 885.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [12.383509635925293, 4.190215587615967, 1.5539369583129883, 0.6349603533744812, 0.3501485586166382, 0.14039629697799683, 0.08900857716798782, 0.07428243011236191, 0.07082102447748184, 0.06530856341123581, 0.06504802405834198, 0.06359180063009262, 0.06421969830989838, 0.06442262977361679, 0.04059389606118202, 0.03996194154024124, 0.03931306302547455, 0.04090636223554611, 0.03943277895450592, 0.033576514571905136, 0.03393279016017914, 0.033825866878032684, 0.032648541033267975, 0.03251845762133598, 0.03261223062872887, 0.03254680335521698, 0.03231697529554367, 0.03233525902032852, 0.032332196831703186, 0.03231244534254074], min_val_index: 29\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "{'loss': [21.442821502685547, 8.33752155303955, 3.1509294509887695, 1.220460057258606, 0.5847354531288147, 0.20507438480854034, 0.09859170764684677, 0.07812722772359848, 0.07190463691949844, 0.06935711950063705, 0.06766286492347717, 0.06613849848508835, 0.06646942347288132, 0.06705992668867111, 0.04456624388694763, 0.042805157601833344, 0.04298485442996025, 0.043145082890987396, 0.043006476014852524, 0.037109073251485825, 0.03646533191204071, 0.03660693019628525, 0.03514997288584709, 0.03521839529275894, 0.03525039181113243, 0.035113926976919174, 0.03511536121368408, 0.03487575054168701, 0.034868691116571426, 0.034770116209983826], 'val_loss': [12.383509635925293, 4.190215587615967, 1.5539369583129883, 0.6349603533744812, 0.3501485586166382, 0.14039629697799683, 0.08900857716798782, 0.07428243011236191, 0.07082102447748184, 0.06530856341123581, 0.06504802405834198, 0.06359180063009262, 0.06421969830989838, 0.06442262977361679, 0.04059389606118202, 0.03996194154024124, 0.03931306302547455, 0.04090636223554611, 0.03943277895450592, 0.033576514571905136, 0.03393279016017914, 0.033825866878032684, 0.032648541033267975, 0.03251845762133598, 0.03261223062872887, 0.03254680335521698, 0.03231697529554367, 0.03233525902032852, 0.032332196831703186, 0.03231244534254074]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8854, eer: 0.1940, thres: 0.1120 => acc: 0.8060, f1: 0.8060\n",
      "\n",
      "Epoch 1/30\n",
      "  6/188 [..............................] - ETA: 16s - loss: 31.2662WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0479s). Check your callbacks.\n",
      "188/188 [==============================] - 16s 63ms/step - loss: 16.1971\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 3.0702\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.6464\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.1177\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0761\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0674\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0650\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0656\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0659\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0667\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0690\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0689\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0719\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0702\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0414\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0400\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0398\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0399\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0401\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0327\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0324\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0324\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0308\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0306\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0308\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0305\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0304\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 12s 61ms/step - loss: 0.0305\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0304\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0305\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9514, eer: 0.1010, thres: 0.1659 => acc: 0.8990, f1: 0.8990\n",
      "loss: 0.030\n",
      "{'loss': [16.197059631347656, 3.0701701641082764, 0.6464406251907349, 0.11768246442079544, 0.07607409358024597, 0.06737859547138214, 0.06496773660182953, 0.06563770025968552, 0.06586293876171112, 0.0666695162653923, 0.06895997375249863, 0.06891840696334839, 0.07186061143875122, 0.07022596150636673, 0.04138007387518883, 0.03997111693024635, 0.03975899517536163, 0.039887987077236176, 0.040135595947504044, 0.03267962858080864, 0.032400574535131454, 0.032385166734457016, 0.03082198090851307, 0.030573876574635506, 0.03078336827456951, 0.030528036877512932, 0.030351122841238976, 0.030509691685438156, 0.03036966361105442, 0.030490711331367493], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-1000-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [40:07<13:20, 800.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [10.472513198852539, 3.706251382827759, 1.2165172100067139, 0.4553709328174591, 0.1880861222743988, 0.09457378089427948, 0.06350080668926239, 0.0487222783267498, 0.04196978732943535, 0.03968574479222298, 0.040375716984272, 0.03982307016849518, 0.026223119348287582, 0.026216931641101837, 0.02649209089577198, 0.022763343527913094, 0.022674579173326492, 0.022657601162791252, 0.022631550207734108, 0.02258867584168911, 0.02187887392938137, 0.02185361087322235, 0.02187418006360531, 0.021737802773714066, 0.021733330562710762, 0.021733203902840614, 0.021707400679588318], min_val_index: 26\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 8.000001e-06, 21: 8.000001e-06, 22: 8.000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1.6000001e-06, 26: 1e-06}\n",
      "{'loss': [17.28658103942871, 7.301847457885742, 2.519874334335327, 0.8540040850639343, 0.3043789267539978, 0.14312517642974854, 0.08895040303468704, 0.06755109131336212, 0.0568193644285202, 0.05273045226931572, 0.0517595037817955, 0.051366522908210754, 0.03876540809869766, 0.037761569023132324, 0.03775102645158768, 0.03443809971213341, 0.034176699817180634, 0.034096989780664444, 0.03416391462087631, 0.03404122218489647, 0.03325333446264267, 0.033339932560920715, 0.03323186933994293, 0.03315076604485512, 0.033235400915145874, 0.033186815679073334, 0.033128511160612106], 'val_loss': [10.472513198852539, 3.706251382827759, 1.2165172100067139, 0.4553709328174591, 0.1880861222743988, 0.09457378089427948, 0.06350080668926239, 0.0487222783267498, 0.04196978732943535, 0.03968574479222298, 0.040375716984272, 0.03982307016849518, 0.026223119348287582, 0.026216931641101837, 0.02649209089577198, 0.022763343527913094, 0.022674579173326492, 0.022657601162791252, 0.022631550207734108, 0.02258867584168911, 0.02187887392938137, 0.02185361087322235, 0.02187418006360531, 0.021737802773714066, 0.021733330562710762, 0.021733203902840614, 0.021707400679588318]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 8.000001e-06, 21: 8.000001e-06, 22: 8.000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1.6000001e-06, 26: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9207, eer: 0.1505, thres: 0.1236 => acc: 0.8495, f1: 0.8495\n",
      "\n",
      "Epoch 1/27\n",
      "188/188 [==============================] - 21s 71ms/step - loss: 13.3103\n",
      "Epoch 2/27\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 2.5742\n",
      "Epoch 3/27\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 0.3907\n",
      "Epoch 4/27\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.1037\n",
      "Epoch 5/27\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0623\n",
      "Epoch 6/27\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0530\n",
      "Epoch 7/27\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0506\n",
      "Epoch 8/27\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0504\n",
      "Epoch 9/27\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0490\n",
      "Epoch 10/27\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0489\n",
      "Epoch 11/27\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0493\n",
      "Epoch 12/27\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 0.0494\n",
      "Epoch 13/27\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0347\n",
      "Epoch 14/27\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.0337\n",
      "Epoch 15/27\n",
      "188/188 [==============================] - 15s 80ms/step - loss: 0.0337\n",
      "Epoch 16/27\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0302\n",
      "Epoch 17/27\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0300\n",
      "Epoch 18/27\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0300\n",
      "Epoch 19/27\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0302\n",
      "Epoch 20/27\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0299\n",
      "Epoch 21/27\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0293\n",
      "Epoch 22/27\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.0292\n",
      "Epoch 23/27\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 0.0293\n",
      "Epoch 24/27\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.0292\n",
      "Epoch 25/27\n",
      "188/188 [==============================] - 15s 80ms/step - loss: 0.0292\n",
      "Epoch 26/27\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.0290\n",
      "Epoch 27/27\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.0291\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9512, eer: 0.1015, thres: 0.1865 => acc: 0.8985, f1: 0.8985\n",
      "loss: 0.029\n",
      "{'loss': [13.310287475585938, 2.5741562843322754, 0.39069876074790955, 0.10368765890598297, 0.062272146344184875, 0.05297385901212692, 0.05064215883612633, 0.0504121370613575, 0.049041278660297394, 0.048864807933568954, 0.0492916963994503, 0.04938286170363426, 0.03473906219005585, 0.03374411165714264, 0.033708106726408005, 0.030201423913240433, 0.030037447810173035, 0.029985863715410233, 0.03015133924782276, 0.029866432771086693, 0.029261944815516472, 0.029216015711426735, 0.029328858479857445, 0.029159434139728546, 0.02921096421778202, 0.029029235243797302, 0.0291186161339283], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-1000-model-Butter33-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [53:38<00:00, 804.64s/it]\u001b[A\n",
      "100%|██████████| 5/5 [4:25:47<00:00, 3189.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 29}\n",
      "test_set: {1, 3, 5, 6, 16, 19, 22, 24, 25, 28}\n",
      "cut_off_freq: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "674\n",
      "0.0026352922012168813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [01:42<32:32, 102.75s/it]\u001b[A\n",
      " 10%|█         | 2/20 [03:24<30:37, 102.10s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [05:04<28:43, 101.39s/it]\u001b[A\n",
      " 20%|██        | 4/20 [06:31<25:25, 95.34s/it] \u001b[A\n",
      " 25%|██▌       | 5/20 [07:57<23:04, 92.30s/it]\u001b[A\n",
      " 30%|███       | 6/20 [09:26<21:13, 90.95s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [11:05<20:18, 93.74s/it]\u001b[A\n",
      " 40%|████      | 8/20 [12:44<19:02, 95.19s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [14:14<17:09, 93.59s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [15:54<15:57, 95.80s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [17:29<14:19, 95.50s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [19:07<12:48, 96.07s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [20:43<11:13, 96.22s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [22:28<09:52, 98.81s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [24:14<08:25, 101.04s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [25:34<06:19, 94.76s/it] \u001b[A\n",
      " 85%|████████▌ | 17/20 [27:04<04:39, 93.18s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [28:41<03:08, 94.43s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [30:16<01:34, 94.60s/it]\u001b[A\n",
      "100%|██████████| 20/20 [32:01<00:00, 96.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 125, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [9.046125411987305, 3.9764983654022217, 1.5637214183807373, 0.6189866662025452, 0.22390589118003845, 0.10821475833654404, 0.06771299242973328, 0.05728413164615631, 0.05499403923749924, 0.052837975323200226, 0.051042139530181885, 0.049743134528398514, 0.05237916111946106, 0.05320284515619278, 0.042045846581459045, 0.041997943073511124, 0.04152173921465874, 0.04184269905090332, 0.041919805109500885, 0.03937344253063202, 0.03938453271985054, 0.03943774104118347, 0.03884066641330719, 0.03882034868001938, 0.03880687803030014, 0.038708727806806564, 0.038703978061676025, 0.038714319467544556, 0.03869529068470001], min_val_index: 28\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1e-06}\n",
      "{'loss': [16.81606674194336, 8.450301170349121, 3.871366262435913, 1.4537760019302368, 0.46934592723846436, 0.16748544573783875, 0.10079208761453629, 0.07932239770889282, 0.0712614431977272, 0.06761755794286728, 0.06534691154956818, 0.06428775191307068, 0.06420816481113434, 0.064483642578125, 0.055207397788763046, 0.054931048303842545, 0.0547679103910923, 0.05483162775635719, 0.055121902376413345, 0.052319448441267014, 0.05210766941308975, 0.05244011804461479, 0.05165177211165428, 0.05190061032772064, 0.05144123360514641, 0.05173612758517265, 0.05159991607069969, 0.0517708994448185, 0.051387157291173935], 'val_loss': [9.046125411987305, 3.9764983654022217, 1.5637214183807373, 0.6189866662025452, 0.22390589118003845, 0.10821475833654404, 0.06771299242973328, 0.05728413164615631, 0.05499403923749924, 0.052837975323200226, 0.051042139530181885, 0.049743134528398514, 0.05237916111946106, 0.05320284515619278, 0.042045846581459045, 0.041997943073511124, 0.04152173921465874, 0.04184269905090332, 0.041919805109500885, 0.03937344253063202, 0.03938453271985054, 0.03943774104118347, 0.03884066641330719, 0.03882034868001938, 0.03880687803030014, 0.038708727806806564, 0.038703978061676025, 0.038714319467544556, 0.03869529068470001]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7435, eer: 0.3175, thres: 0.1492 => acc: 0.6825, f1: 0.6825\n",
      "\n",
      "Epoch 1/29\n",
      "188/188 [==============================] - 7s 18ms/step - loss: 13.6463\n",
      "Epoch 2/29\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 4.0576\n",
      "Epoch 3/29\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.8024\n",
      "Epoch 4/29\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.1480\n",
      "Epoch 5/29\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0791\n",
      "Epoch 6/29\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0658\n",
      "Epoch 7/29\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0635\n",
      "Epoch 8/29\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0625\n",
      "Epoch 9/29\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0630\n",
      "Epoch 10/29\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0634\n",
      "Epoch 11/29\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0642\n",
      "Epoch 12/29\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0640\n",
      "Epoch 13/29\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0642\n",
      "Epoch 14/29\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0641\n",
      "Epoch 15/29\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0514\n",
      "Epoch 16/29\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0508\n",
      "Epoch 17/29\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0508\n",
      "Epoch 18/29\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0506\n",
      "Epoch 19/29\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0508\n",
      "Epoch 20/29\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0475\n",
      "Epoch 21/29\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0473\n",
      "Epoch 22/29\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0473\n",
      "Epoch 23/29\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0466\n",
      "Epoch 24/29\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0468\n",
      "Epoch 25/29\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0465\n",
      "Epoch 26/29\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0464\n",
      "Epoch 27/29\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0465\n",
      "Epoch 28/29\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0466\n",
      "Epoch 29/29\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0466\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8715, eer: 0.2026, thres: 0.1785 => acc: 0.7974, f1: 0.7974\n",
      "loss: 0.047\n",
      "{'loss': [13.646320343017578, 4.057587623596191, 0.8023695945739746, 0.14803814888000488, 0.07909399271011353, 0.06581473350524902, 0.0635162964463234, 0.06252764165401459, 0.06304478645324707, 0.06343627721071243, 0.06416098028421402, 0.06401396542787552, 0.06417631357908249, 0.06406181305646896, 0.051405169069767, 0.050849590450525284, 0.05079858750104904, 0.050625186413526535, 0.05084260180592537, 0.04750610515475273, 0.04731787368655205, 0.047343578189611435, 0.046597838401794434, 0.04678243771195412, 0.04653244838118553, 0.0464290976524353, 0.04654300957918167, 0.046571049839258194, 0.046595409512519836], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [05:36<16:49, 336.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [14.812698364257812, 8.606083869934082, 4.299416542053223, 2.1100382804870605, 1.0006197690963745, 0.4409504234790802, 0.21393248438835144, 0.14200134575366974, 0.10494368523359299, 0.0827862098813057, 0.07473748922348022, 0.06381116807460785, 0.06148984655737877, 0.05894789472222328, 0.05833466351032257, 0.058805882930755615, 0.05732264742255211, 0.05773181468248367, 0.060773786157369614, 0.04685124009847641, 0.04610669985413551, 0.04567787051200867, 0.04620946943759918, 0.04585114121437073, 0.04386350139975548, 0.04451404884457588, 0.044101227074861526, 0.04338301718235016, 0.04326246306300163, 0.04321625083684921, 0.04319673776626587, 0.04314905032515526, 0.04317495971918106, 0.04317018762230873, 0.043175410479307175], min_val_index: 31\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 0.00020000001, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1.6000001e-06, 34: 1e-06}\n",
      "{'loss': [23.50127601623535, 14.250173568725586, 8.060588836669922, 4.208579063415527, 2.1384851932525635, 0.9006555676460266, 0.3117154538631439, 0.182149276137352, 0.12881317734718323, 0.10211768001317978, 0.08744394034147263, 0.07811237871646881, 0.07213190197944641, 0.06963024288415909, 0.06887946277856827, 0.06759796291589737, 0.0678509995341301, 0.06739027053117752, 0.06753744184970856, 0.057003770023584366, 0.056194499135017395, 0.05611106753349304, 0.0561484731733799, 0.05608290806412697, 0.05319714918732643, 0.05351874604821205, 0.05300233140587807, 0.05279817059636116, 0.05225030332803726, 0.05282109975814819, 0.05281161516904831, 0.052744340151548386, 0.05259649083018303, 0.05248839035630226, 0.052365969866514206], 'val_loss': [14.812698364257812, 8.606083869934082, 4.299416542053223, 2.1100382804870605, 1.0006197690963745, 0.4409504234790802, 0.21393248438835144, 0.14200134575366974, 0.10494368523359299, 0.0827862098813057, 0.07473748922348022, 0.06381116807460785, 0.06148984655737877, 0.05894789472222328, 0.05833466351032257, 0.058805882930755615, 0.05732264742255211, 0.05773181468248367, 0.060773786157369614, 0.04685124009847641, 0.04610669985413551, 0.04567787051200867, 0.04620946943759918, 0.04585114121437073, 0.04386350139975548, 0.04451404884457588, 0.044101227074861526, 0.04338301718235016, 0.04326246306300163, 0.04321625083684921, 0.04319673776626587, 0.04314905032515526, 0.04317495971918106, 0.04317018762230873, 0.043175410479307175]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 0.00020000001, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7396, eer: 0.3241, thres: 0.2553 => acc: 0.6759, f1: 0.6759\n",
      "\n",
      "Epoch 1/32\n",
      "188/188 [==============================] - 10s 23ms/step - loss: 20.0763\n",
      "Epoch 2/32\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 8.4636\n",
      "Epoch 3/32\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 2.9781\n",
      "Epoch 4/32\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.8264\n",
      "Epoch 5/32\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.1782\n",
      "Epoch 6/32\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.1028\n",
      "Epoch 7/32\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0795\n",
      "Epoch 8/32\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0698\n",
      "Epoch 9/32\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0663\n",
      "Epoch 10/32\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0660\n",
      "Epoch 11/32\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0655\n",
      "Epoch 12/32\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0658\n",
      "Epoch 13/32\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0659\n",
      "Epoch 14/32\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0666\n",
      "Epoch 15/32\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0667\n",
      "Epoch 16/32\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0672\n",
      "Epoch 17/32\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0669\n",
      "Epoch 18/32\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0674\n",
      "Epoch 19/32\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0678\n",
      "Epoch 20/32\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0535\n",
      "Epoch 21/32\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0524\n",
      "Epoch 22/32\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0525\n",
      "Epoch 23/32\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0522\n",
      "Epoch 24/32\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0523\n",
      "Epoch 25/32\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0490\n",
      "Epoch 26/32\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0488\n",
      "Epoch 27/32\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0487\n",
      "Epoch 28/32\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0479\n",
      "Epoch 29/32\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0479\n",
      "Epoch 30/32\n",
      "188/188 [==============================] - 3s 19ms/step - loss: 0.0477\n",
      "Epoch 31/32\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0479\n",
      "Epoch 32/32\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0477\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8682, eer: 0.2077, thres: 0.1566 => acc: 0.7923, f1: 0.7923\n",
      "loss: 0.048\n",
      "{'loss': [20.076257705688477, 8.463577270507812, 2.978142023086548, 0.8264386653900146, 0.17818522453308105, 0.1028093621134758, 0.0795377865433693, 0.06984218209981918, 0.06626969575881958, 0.06603844463825226, 0.06554906070232391, 0.06576335430145264, 0.06592492759227753, 0.06657464802265167, 0.06665139645338058, 0.06721718609333038, 0.06694656610488892, 0.06744824349880219, 0.06783192604780197, 0.05353567376732826, 0.05241623893380165, 0.05250883474946022, 0.052246659994125366, 0.05233719199895859, 0.049019429832696915, 0.04876440390944481, 0.048746850341558456, 0.0479268953204155, 0.047864798456430435, 0.04770231992006302, 0.04787491261959076, 0.047702606767416], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [13:49<14:17, 428.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [17.153661727905273, 7.972463607788086, 3.7458183765411377, 1.8965067863464355, 0.8918663859367371, 0.41307368874549866, 0.22007498145103455, 0.14117670059204102, 0.10965005308389664, 0.0957743301987648, 0.08780524134635925, 0.07712841778993607, 0.07892715185880661, 0.07911864668130875, 0.05807376652956009, 0.05983055755496025, 0.05935705453157425, 0.05302389711141586, 0.051993079483509064, 0.05174835026264191, 0.05168096348643303, 0.051479071378707886, 0.05139804258942604, 0.05210866779088974, 0.050928812474012375, 0.05113895609974861, 0.051141154021024704, 0.051017776131629944, 0.05104045197367668, 0.05103762820363045], min_val_index: 24\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "{'loss': [27.807212829589844, 14.648508071899414, 7.2814507484436035, 3.9243288040161133, 1.939002513885498, 0.7715297341346741, 0.3183831572532654, 0.16971217095851898, 0.1283254623413086, 0.1063716933131218, 0.0945497378706932, 0.08754488080739975, 0.08526090532541275, 0.0843564122915268, 0.06546539813280106, 0.06404847651720047, 0.06374818086624146, 0.058985013514757156, 0.058439817279577255, 0.05816744640469551, 0.05820823460817337, 0.05843733996152878, 0.057785335928201675, 0.05832243338227272, 0.056488342583179474, 0.05650933459401131, 0.056480538100004196, 0.056413717567920685, 0.05599826201796532, 0.056463874876499176], 'val_loss': [17.153661727905273, 7.972463607788086, 3.7458183765411377, 1.8965067863464355, 0.8918663859367371, 0.41307368874549866, 0.22007498145103455, 0.14117670059204102, 0.10965005308389664, 0.0957743301987648, 0.08780524134635925, 0.07712841778993607, 0.07892715185880661, 0.07911864668130875, 0.05807376652956009, 0.05983055755496025, 0.05935705453157425, 0.05302389711141586, 0.051993079483509064, 0.05174835026264191, 0.05168096348643303, 0.051479071378707886, 0.05139804258942604, 0.05210866779088974, 0.050928812474012375, 0.05113895609974861, 0.051141154021024704, 0.051017776131629944, 0.05104045197367668, 0.05103762820363045]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7100, eer: 0.3484, thres: 0.2232 => acc: 0.6517, f1: 0.6517\n",
      "\n",
      "Epoch 1/25\n",
      "188/188 [==============================] - 7s 22ms/step - loss: 23.4224\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 8.0229\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 2.9653\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.9049\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.1887\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.1099\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0877\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0804\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0791\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0786\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0804\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0814\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0829\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0845\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0612\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0601\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0602\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0542\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0539\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0539\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0539\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0537\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0539\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0537\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0523\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8251, eer: 0.2505, thres: 0.1265 => acc: 0.7496, f1: 0.7496\n",
      "loss: 0.052\n",
      "{'loss': [23.42237091064453, 8.022933006286621, 2.9653160572052, 0.9048802256584167, 0.18865743279457092, 0.10994064062833786, 0.08774258196353912, 0.08041363209486008, 0.07911339402198792, 0.07861091941595078, 0.08044727146625519, 0.08144721388816833, 0.08289093524217606, 0.08446258306503296, 0.061219654977321625, 0.06005408242344856, 0.060153450816869736, 0.054193202406167984, 0.053894221782684326, 0.05394447222352028, 0.05392911285161972, 0.05369186773896217, 0.05394253879785538, 0.053740426898002625, 0.052302371710538864], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [19:19<06:23, 383.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [15.077553749084473, 8.333669662475586, 3.9913322925567627, 1.8654260635375977, 0.8928561210632324, 0.40304630994796753, 0.1777655929327011, 0.1149231567978859, 0.086712546646595, 0.07079988718032837, 0.06384692341089249, 0.058159176260232925, 0.05779647454619408, 0.056115567684173584, 0.0567040741443634, 0.05533530190587044, 0.055400583893060684, 0.055687401443719864, 0.04447701945900917, 0.04460933431982994, 0.04452597722411156, 0.04176442697644234, 0.04175781458616257, 0.04176948219537735, 0.04114726558327675, 0.04115263745188713, 0.041127026081085205, 0.04102083668112755, 0.041021041572093964, 0.041019171476364136, 0.041016075760126114], min_val_index: 30\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "{'loss': [23.792251586914062, 14.057868003845215, 7.5922088623046875, 3.847162961959839, 1.8298701047897339, 0.7627734541893005, 0.2703436613082886, 0.1542586386203766, 0.11443817615509033, 0.09174492210149765, 0.08026067912578583, 0.07431283593177795, 0.07094471156597137, 0.06900974363088608, 0.06810707598924637, 0.06772375106811523, 0.06735614687204361, 0.06746938824653625, 0.056657467037439346, 0.05592971667647362, 0.055667366832494736, 0.05308845266699791, 0.05282542482018471, 0.05293481424450874, 0.05222022160887718, 0.052330564707517624, 0.05236667022109032, 0.052336208522319794, 0.05206456035375595, 0.051859065890312195, 0.052222006022930145], 'val_loss': [15.077553749084473, 8.333669662475586, 3.9913322925567627, 1.8654260635375977, 0.8928561210632324, 0.40304630994796753, 0.1777655929327011, 0.1149231567978859, 0.086712546646595, 0.07079988718032837, 0.06384692341089249, 0.058159176260232925, 0.05779647454619408, 0.056115567684173584, 0.0567040741443634, 0.05533530190587044, 0.055400583893060684, 0.055687401443719864, 0.04447701945900917, 0.04460933431982994, 0.04452597722411156, 0.04176442697644234, 0.04175781458616257, 0.04176948219537735, 0.04114726558327675, 0.04115263745188713, 0.041127026081085205, 0.04102083668112755, 0.041021041572093964, 0.041019171476364136, 0.041016075760126114]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7240, eer: 0.3365, thres: 0.2504 => acc: 0.6634, f1: 0.6634\n",
      "\n",
      "Epoch 1/31\n",
      "188/188 [==============================] - 10s 25ms/step - loss: 20.2274\n",
      "Epoch 2/31\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 8.0212\n",
      "Epoch 3/31\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 2.6671\n",
      "Epoch 4/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.7661\n",
      "Epoch 5/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.1740\n",
      "Epoch 6/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0974\n",
      "Epoch 7/31\n",
      "188/188 [==============================] - 6s 29ms/step - loss: 0.0753\n",
      "Epoch 8/31\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0668\n",
      "Epoch 9/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0640\n",
      "Epoch 10/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0630\n",
      "Epoch 11/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0630\n",
      "Epoch 12/31\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0637\n",
      "Epoch 13/31\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0643\n",
      "Epoch 14/31\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0647\n",
      "Epoch 15/31\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0648\n",
      "Epoch 16/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0654\n",
      "Epoch 17/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0659\n",
      "Epoch 18/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0665\n",
      "Epoch 19/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0519\n",
      "Epoch 20/31\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0510\n",
      "Epoch 21/31\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0511\n",
      "Epoch 22/31\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0478\n",
      "Epoch 23/31\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0473\n",
      "Epoch 24/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0476\n",
      "Epoch 25/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0468\n",
      "Epoch 26/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0467\n",
      "Epoch 27/31\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0469\n",
      "Epoch 28/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0467\n",
      "Epoch 29/31\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0466\n",
      "Epoch 30/31\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0466\n",
      "Epoch 31/31\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0466\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8699, eer: 0.2059, thres: 0.1791 => acc: 0.7940, f1: 0.7940\n",
      "loss: 0.047\n",
      "{'loss': [20.227357864379883, 8.021180152893066, 2.6670830249786377, 0.7661042809486389, 0.17401503026485443, 0.09735990315675735, 0.07525672763586044, 0.0668182373046875, 0.06403275579214096, 0.06302990764379501, 0.06301384419202805, 0.06369168311357498, 0.06432591378688812, 0.064698226749897, 0.06484851986169815, 0.06536401063203812, 0.06589659303426743, 0.06645924597978592, 0.051904622465372086, 0.05103021860122681, 0.05112280324101448, 0.04778536781668663, 0.04731549322605133, 0.047617778182029724, 0.04679194092750549, 0.04668170586228371, 0.04687689617276192, 0.04669853299856186, 0.0465889610350132, 0.04659859836101532, 0.04658810421824455], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [27:06<00:00, 406.71s/it]\u001b[A\n",
      " 20%|██        | 1/5 [1:01:23<4:05:34, 3683.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "334\n",
      "0.010731381548280685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:36<11:26, 36.12s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:06<09:52, 32.91s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [01:32<08:22, 29.55s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:58<07:31, 28.25s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [02:28<07:12, 28.85s/it]\u001b[A\n",
      " 30%|███       | 6/20 [02:58<06:48, 29.15s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [03:23<06:04, 28.00s/it]\u001b[A\n",
      " 40%|████      | 8/20 [03:55<05:51, 29.27s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [04:36<06:00, 32.76s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [05:18<05:55, 35.58s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [06:02<05:44, 38.33s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [06:54<05:39, 42.41s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [07:48<05:20, 45.79s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [08:39<04:45, 47.58s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [09:31<04:04, 48.85s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [10:24<03:19, 49.98s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [11:14<02:30, 50.14s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [12:05<01:40, 50.24s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [12:51<00:49, 49.21s/it]\u001b[A\n",
      "100%|██████████| 20/20 [13:30<00:00, 40.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 250, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [7.28139066696167, 2.6099627017974854, 0.925430178642273, 0.3719845414161682, 0.13875849545001984, 0.07038275897502899, 0.052046339958906174, 0.04772956669330597, 0.04655502364039421, 0.04561062902212143, 0.04690605774521828, 0.04680366441607475, 0.03607533872127533, 0.03624332323670387, 0.036430761218070984, 0.03347361460328102, 0.033523108810186386, 0.03342552110552788, 0.0328935831785202, 0.03291035443544388, 0.032887279987335205, 0.03276844695210457, 0.03277090936899185, 0.03278229385614395, 0.032766543328762054], min_val_index: 24\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "{'loss': [13.845756530761719, 5.975625038146973, 2.1172492504119873, 0.8073040843009949, 0.2642681300640106, 0.10513021051883698, 0.07236934453248978, 0.06353636085987091, 0.06040128320455551, 0.05880138278007507, 0.05793415382504463, 0.057852260768413544, 0.047859612852334976, 0.04677065834403038, 0.04696183651685715, 0.044422972947359085, 0.04427292197942734, 0.04410400241613388, 0.04334321245551109, 0.043710459023714066, 0.04350535571575165, 0.04335850849747658, 0.04322318360209465, 0.043366577476263046, 0.043542779982089996], 'val_loss': [7.28139066696167, 2.6099627017974854, 0.925430178642273, 0.3719845414161682, 0.13875849545001984, 0.07038275897502899, 0.052046339958906174, 0.04772956669330597, 0.04655502364039421, 0.04561062902212143, 0.04690605774521828, 0.04680366441607475, 0.03607533872127533, 0.03624332323670387, 0.036430761218070984, 0.03347361460328102, 0.033523108810186386, 0.03342552110552788, 0.0328935831785202, 0.03291035443544388, 0.032887279987335205, 0.03276844695210457, 0.03277090936899185, 0.03278229385614395, 0.032766543328762054]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8341, eer: 0.2339, thres: 0.1053 => acc: 0.7661, f1: 0.7661\n",
      "\n",
      "Epoch 1/25\n",
      "188/188 [==============================] - 15s 40ms/step - loss: 11.1104\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 2.4021\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.3906\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0933\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0644\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0590\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0571\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0570\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0569\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0574\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0593\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0577\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0450\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0444\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0442\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0411\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0410\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0409\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0402\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0402\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0400\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0402\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0400\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0402\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0401\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9160, eer: 0.1506, thres: 0.1803 => acc: 0.8494, f1: 0.8494\n",
      "loss: 0.040\n",
      "{'loss': [11.110430717468262, 2.4020676612854004, 0.39061489701271057, 0.09325676411390305, 0.06444151699542999, 0.059014368802309036, 0.05705887824296951, 0.05698743835091591, 0.0569491870701313, 0.057372719049453735, 0.0592508502304554, 0.05767757445573807, 0.04495599865913391, 0.044399164617061615, 0.04421417415142059, 0.041073743253946304, 0.04099784791469574, 0.0409202016890049, 0.040212880820035934, 0.04018412530422211, 0.04004644602537155, 0.040176115930080414, 0.04000008478760719, 0.04020625725388527, 0.040126312524080276], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-250-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [09:01<27:03, 541.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [13.121234893798828, 6.585765361785889, 2.915379524230957, 1.2854821681976318, 0.563242495059967, 0.24053288996219635, 0.12444370985031128, 0.08988437801599503, 0.07177527993917465, 0.06989385187625885, 0.06214933842420578, 0.058371879160404205, 0.05832351744174957, 0.056818313896656036, 0.05494841933250427, 0.05954233929514885, 0.05538111925125122, 0.043284639716148376, 0.04299088194966316, 0.04302389174699783, 0.043539658188819885, 0.040163811296224594, 0.03973733261227608, 0.039904285222291946, 0.039696890860795975, 0.03914369270205498, 0.039254024624824524, 0.039222992956638336, 0.03911598399281502, 0.03910781070590019, 0.03910849988460541], min_val_index: 29\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "{'loss': [20.29572868347168, 11.322593688964844, 5.6797943115234375, 2.65218186378479, 1.165824055671692, 0.4167942702770233, 0.1805419623851776, 0.11336056888103485, 0.08907003700733185, 0.07764522731304169, 0.07014871388673782, 0.06613993644714355, 0.0632212832570076, 0.060798127204179764, 0.060117803514003754, 0.05981121584773064, 0.059702351689338684, 0.04864734038710594, 0.04751645401120186, 0.047590676695108414, 0.047388140112161636, 0.04461807385087013, 0.044346414506435394, 0.04405592754483223, 0.04434247314929962, 0.04367410019040108, 0.04381261020898819, 0.04372768476605415, 0.04358190298080444, 0.04329105466604233, 0.04338773712515831], 'val_loss': [13.121234893798828, 6.585765361785889, 2.915379524230957, 1.2854821681976318, 0.563242495059967, 0.24053288996219635, 0.12444370985031128, 0.08988437801599503, 0.07177527993917465, 0.06989385187625885, 0.06214933842420578, 0.058371879160404205, 0.05832351744174957, 0.056818313896656036, 0.05494841933250427, 0.05954233929514885, 0.05538111925125122, 0.043284639716148376, 0.04299088194966316, 0.04302389174699783, 0.043539658188819885, 0.040163811296224594, 0.03973733261227608, 0.039904285222291946, 0.039696890860795975, 0.03914369270205498, 0.039254024624824524, 0.039222992956638336, 0.03911598399281502, 0.03910781070590019, 0.03910849988460541]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8158, eer: 0.2561, thres: 0.1904 => acc: 0.7440, f1: 0.7440\n",
      "\n",
      "Epoch 1/30\n",
      "188/188 [==============================] - 16s 44ms/step - loss: 17.3717\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 6.1461\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 1.7925\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.4242\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.1225\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0799\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0664\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0615\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0599\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0597\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0598\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0595\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0596\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0598\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0602\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0605\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0608\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0469\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0457\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0458\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0457\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0423\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0420\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0423\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0425\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0414\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0415\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0414\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0412\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0413\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9006, eer: 0.1712, thres: 0.1637 => acc: 0.8288, f1: 0.8288\n",
      "loss: 0.041\n",
      "{'loss': [17.37165641784668, 6.146120071411133, 1.7925139665603638, 0.4241986870765686, 0.12249913066625595, 0.07994116842746735, 0.06638316065073013, 0.06146315857768059, 0.059900738298892975, 0.05973097309470177, 0.059836920350790024, 0.05951680243015289, 0.05957656353712082, 0.05977524071931839, 0.06018849462270737, 0.06048978492617607, 0.060804031789302826, 0.04690276458859444, 0.045701246708631516, 0.04584091529250145, 0.045707572251558304, 0.042327359318733215, 0.04204203933477402, 0.042271312326192856, 0.04246014729142189, 0.04144318029284477, 0.04149117320775986, 0.04137135297060013, 0.04118513688445091, 0.04130924493074417], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-250-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [21:02<21:34, 647.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [14.80878734588623, 5.9576921463012695, 2.572209596633911, 1.1106013059616089, 0.5012030601501465, 0.24278448522090912, 0.12281586229801178, 0.0892392247915268, 0.08430993556976318, 0.082526296377182, 0.08247905224561691, 0.0784202441573143, 0.07173582911491394, 0.07930935174226761, 0.07782929390668869, 0.052109818905591965, 0.0543770007789135, 0.051993925124406815, 0.051093488931655884, 0.05421604588627815, 0.051678504794836044, 0.04606376215815544, 0.0465300977230072, 0.046112023293972015, 0.04479702189564705, 0.04462789371609688, 0.04476835951209068, 0.04484902322292328, 0.044577814638614655, 0.044560886919498444, 0.044565606862306595], min_val_index: 29\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "{'loss': [24.506498336791992, 11.520289421081543, 5.153256416320801, 2.4562387466430664, 1.0582820177078247, 0.38983285427093506, 0.16350121796131134, 0.10363581031560898, 0.08981639891862869, 0.082640640437603, 0.07958192378282547, 0.07711091637611389, 0.0764441043138504, 0.07589742541313171, 0.0765453577041626, 0.05519109591841698, 0.05356593430042267, 0.05353683605790138, 0.05371670052409172, 0.05411317199468613, 0.053858499974012375, 0.048216406255960464, 0.04775715619325638, 0.04760575667023659, 0.04648083820939064, 0.04627033323049545, 0.04597121849656105, 0.04642816260457039, 0.04619324952363968, 0.04605121165513992, 0.04607531428337097], 'val_loss': [14.80878734588623, 5.9576921463012695, 2.572209596633911, 1.1106013059616089, 0.5012030601501465, 0.24278448522090912, 0.12281586229801178, 0.0892392247915268, 0.08430993556976318, 0.082526296377182, 0.08247905224561691, 0.0784202441573143, 0.07173582911491394, 0.07930935174226761, 0.07782929390668869, 0.052109818905591965, 0.0543770007789135, 0.051993925124406815, 0.051093488931655884, 0.05421604588627815, 0.051678504794836044, 0.04606376215815544, 0.0465300977230072, 0.046112023293972015, 0.04479702189564705, 0.04462789371609688, 0.04476835951209068, 0.04484902322292328, 0.044577814638614655, 0.044560886919498444, 0.044565606862306595]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7748, eer: 0.2946, thres: 0.1662 => acc: 0.7055, f1: 0.7054\n",
      "\n",
      "Epoch 1/30\n",
      "188/188 [==============================] - 9s 27ms/step - loss: 20.0434\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 5.3737\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 1.5147\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.3519\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.1047\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0816\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0753\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0742\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0748\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0754\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0810\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0793\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0794\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0800\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0809\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0533\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0518\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0519\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0517\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0516\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0514\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0444\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0441\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0440\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0428\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0423\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0427\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0425\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 6s 29ms/step - loss: 0.0422\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0421\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9043, eer: 0.1642, thres: 0.1650 => acc: 0.8357, f1: 0.8357\n",
      "loss: 0.042\n",
      "{'loss': [20.04336166381836, 5.373672008514404, 1.514711856842041, 0.35189294815063477, 0.104735367000103, 0.08155851066112518, 0.07528907060623169, 0.07416867464780807, 0.07478144764900208, 0.07543708384037018, 0.08104188740253448, 0.07926329970359802, 0.07940637320280075, 0.08002279698848724, 0.08089126646518707, 0.053303468972444534, 0.05180706828832626, 0.051853571087121964, 0.051688484847545624, 0.051622938364744186, 0.051366157829761505, 0.04438433051109314, 0.044067367911338806, 0.04401523619890213, 0.042771656066179276, 0.04231657460331917, 0.04265108332037926, 0.042499035596847534, 0.042182888835668564, 0.04209518805146217], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-250-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [29:15<09:36, 576.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [12.930015563964844, 5.960484504699707, 2.42167592048645, 0.9865363836288452, 0.4570516049861908, 0.20187689363956451, 0.10139001160860062, 0.07451745122671127, 0.06006704270839691, 0.05551980808377266, 0.052007101476192474, 0.05159149691462517, 0.05060699209570885, 0.051325712352991104, 0.04996282979846001, 0.0494314543902874, 0.05229664966464043, 0.05165809765458107, 0.038283128291368484, 0.03841366618871689, 0.03850414976477623, 0.03515090048313141, 0.035068921744823456, 0.03501175716519356, 0.03502144664525986, 0.03501040115952492, 0.0342966690659523, 0.034261304885149, 0.03427543863654137, 0.03414955735206604, 0.034154485911130905, 0.034151121973991394, 0.03412725403904915], min_val_index: 32\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1e-06}\n",
      "{'loss': [20.345443725585938, 10.769186973571777, 5.073962211608887, 2.145264148712158, 0.9108951687812805, 0.34209373593330383, 0.14530488848686218, 0.09759431332349777, 0.07838842272758484, 0.06882192939519882, 0.06459137797355652, 0.06212031841278076, 0.061327677220106125, 0.06047419086098671, 0.06043596565723419, 0.06060715392231941, 0.060425445437431335, 0.06070712208747864, 0.048515304923057556, 0.04756523668766022, 0.047384388744831085, 0.04433088377118111, 0.044138647615909576, 0.04419812932610512, 0.04427470266819, 0.04417027160525322, 0.043624237179756165, 0.04347267001867294, 0.04339573159813881, 0.04330137372016907, 0.04327418655157089, 0.04320001229643822, 0.0435166172683239], 'val_loss': [12.930015563964844, 5.960484504699707, 2.42167592048645, 0.9865363836288452, 0.4570516049861908, 0.20187689363956451, 0.10139001160860062, 0.07451745122671127, 0.06006704270839691, 0.05551980808377266, 0.052007101476192474, 0.05159149691462517, 0.05060699209570885, 0.051325712352991104, 0.04996282979846001, 0.0494314543902874, 0.05229664966464043, 0.05165809765458107, 0.038283128291368484, 0.03841366618871689, 0.03850414976477623, 0.03515090048313141, 0.035068921744823456, 0.03501175716519356, 0.03502144664525986, 0.03501040115952492, 0.0342966690659523, 0.034261304885149, 0.03427543863654137, 0.03414955735206604, 0.034154485911130905, 0.034151121973991394, 0.03412725403904915]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8044, eer: 0.2657, thres: 0.1824 => acc: 0.7343, f1: 0.7343\n",
      "\n",
      "Epoch 1/33\n",
      "188/188 [==============================] - 13s 37ms/step - loss: 17.0983\n",
      "Epoch 2/33\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 5.3363\n",
      "Epoch 3/33\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 1.3331\n",
      "Epoch 4/33\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.2987\n",
      "Epoch 5/33\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0996\n",
      "Epoch 6/33\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0727\n",
      "Epoch 7/33\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0630\n",
      "Epoch 8/33\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0599\n",
      "Epoch 9/33\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0588\n",
      "Epoch 10/33\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0588\n",
      "Epoch 11/33\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0601\n",
      "Epoch 12/33\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0592\n",
      "Epoch 13/33\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0597\n",
      "Epoch 14/33\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0598\n",
      "Epoch 15/33\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 0.0606\n",
      "Epoch 16/33\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0606\n",
      "Epoch 17/33\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0611\n",
      "Epoch 18/33\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0614\n",
      "Epoch 19/33\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0452\n",
      "Epoch 20/33\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0443\n",
      "Epoch 21/33\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0441\n",
      "Epoch 22/33\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0407\n",
      "Epoch 23/33\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0403\n",
      "Epoch 24/33\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0406\n",
      "Epoch 25/33\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0405\n",
      "Epoch 26/33\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0405\n",
      "Epoch 27/33\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0399\n",
      "Epoch 28/33\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0399\n",
      "Epoch 29/33\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0398\n",
      "Epoch 30/33\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0395\n",
      "Epoch 31/33\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0395\n",
      "Epoch 32/33\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0394\n",
      "Epoch 33/33\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0395\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9206, eer: 0.1471, thres: 0.1773 => acc: 0.8529, f1: 0.8529\n",
      "loss: 0.040\n",
      "{'loss': [17.0982608795166, 5.336348533630371, 1.3330540657043457, 0.298703670501709, 0.09957583248615265, 0.07272292673587799, 0.06299495697021484, 0.05987406149506569, 0.058840520679950714, 0.05881024897098541, 0.06006690114736557, 0.05919896066188812, 0.05970662832260132, 0.05981706827878952, 0.06057669222354889, 0.060606181621551514, 0.0610712431371212, 0.06144678592681885, 0.045185983180999756, 0.04432161897420883, 0.04407800734043121, 0.04072516784071922, 0.04030489921569824, 0.04055686667561531, 0.040505293756723404, 0.04046536237001419, 0.03986608237028122, 0.03986268863081932, 0.03979978710412979, 0.03947725519537926, 0.03946081921458244, 0.039449628442525864, 0.039517875760793686], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-250-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-250-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [42:57<00:00, 644.30s/it]\u001b[A\n",
      " 40%|████      | 2/5 [1:58:44<2:57:01, 3540.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 83\n",
      "len_exp2_user_47: 71\n",
      "166\n",
      "0.0434442589635651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:20<06:38, 20.97s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:40<06:03, 20.18s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:59<05:34, 19.68s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:18<05:12, 19.53s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [01:39<04:57, 19.85s/it]\u001b[A\n",
      " 30%|███       | 6/20 [01:54<04:14, 18.19s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [02:07<03:33, 16.43s/it]\u001b[A\n",
      " 40%|████      | 8/20 [02:20<03:06, 15.54s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [02:35<02:48, 15.28s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [02:50<02:31, 15.13s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [03:05<02:15, 15.05s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [03:19<01:59, 14.95s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [03:33<01:42, 14.66s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [03:47<01:25, 14.22s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [03:59<01:09, 13.81s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [04:13<00:55, 13.79s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [04:28<00:42, 14.18s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [04:44<00:29, 14.61s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [05:01<00:15, 15.38s/it]\u001b[A\n",
      "100%|██████████| 20/20 [05:19<00:00, 15.97s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 500, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [6.00636625289917, 1.7534335851669312, 0.6048403382301331, 0.24563878774642944, 0.09321588277816772, 0.05533170700073242, 0.04581654444336891, 0.04643179848790169, 0.04172777757048607, 0.04373812675476074, 0.04574884846806526, 0.03205595165491104, 0.031672488898038864, 0.032063599675893784, 0.03212437033653259, 0.0288996659219265, 0.02914573810994625, 0.029051994904875755, 0.028459517285227776, 0.028415990993380547, 0.028436211869120598, 0.028314294293522835, 0.02831210196018219, 0.028307171538472176, 0.028303811326622963], min_val_index: 24\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "{'loss': [11.9410400390625, 4.107529640197754, 1.2296887636184692, 0.44852277636528015, 0.16306059062480927, 0.07820750027894974, 0.05851895362138748, 0.05352107435464859, 0.05214383080601692, 0.05153418704867363, 0.051432475447654724, 0.0406072624027729, 0.03994369879364967, 0.03968716412782669, 0.0398009791970253, 0.036698367446660995, 0.0364721305668354, 0.03673620522022247, 0.03611663728952408, 0.03595053032040596, 0.036018259823322296, 0.03567108139395714, 0.03556198626756668, 0.0356564000248909, 0.035683900117874146], 'val_loss': [6.00636625289917, 1.7534335851669312, 0.6048403382301331, 0.24563878774642944, 0.09321588277816772, 0.05533170700073242, 0.04581654444336891, 0.04643179848790169, 0.04172777757048607, 0.04373812675476074, 0.04574884846806526, 0.03205595165491104, 0.031672488898038864, 0.032063599675893784, 0.03212437033653259, 0.0288996659219265, 0.02914573810994625, 0.029051994904875755, 0.028459517285227776, 0.028415990993380547, 0.028436211869120598, 0.028314294293522835, 0.02831210196018219, 0.028307171538472176, 0.028303811326622963]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8936, eer: 0.1703, thres: 0.0829 => acc: 0.8297, f1: 0.8297\n",
      "\n",
      "Epoch 1/25\n",
      "188/188 [==============================] - 15s 55ms/step - loss: 9.7063\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 1.7151\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.2800\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0797\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0566\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 10s 56ms/step - loss: 0.0533\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0519\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0517\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0523\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0523\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0551\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0405\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0395\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0393\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0391\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0358\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0359\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0358\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0350\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0351\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0350\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0349\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0349\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0349\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 16s 83ms/step - loss: 0.0350\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9259, eer: 0.1394, thres: 0.1806 => acc: 0.8606, f1: 0.8606\n",
      "loss: 0.035\n",
      "{'loss': [9.706328392028809, 1.7151446342468262, 0.28002551198005676, 0.07969608902931213, 0.05658977851271629, 0.05327705293893814, 0.05190974101424217, 0.0517042875289917, 0.05225672945380211, 0.05229196324944496, 0.055079683661460876, 0.04051363095641136, 0.039452675729990005, 0.03927851840853691, 0.03910612314939499, 0.035801421850919724, 0.0358990915119648, 0.03576448932290077, 0.03498617932200432, 0.03508376702666283, 0.035037849098443985, 0.03489340469241142, 0.034945596009492874, 0.03493225947022438, 0.034966547042131424], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-500-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [09:38<28:54, 578.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [11.889678955078125, 5.279019832611084, 2.1069400310516357, 0.9073384404182434, 0.40332379937171936, 0.17525163292884827, 0.09933388978242874, 0.07055659592151642, 0.060074012726545334, 0.05394281446933746, 0.04987061023712158, 0.04684684798121452, 0.046182166785001755, 0.04650377109646797, 0.04474131390452385, 0.04305769130587578, 0.04498221352696419, 0.0457213930785656, 0.03304809704422951, 0.0327402763068676, 0.0334254652261734, 0.031403910368680954, 0.03222331404685974, 0.0323450081050396, 0.02927294932305813, 0.028983870521187782, 0.02896561101078987, 0.02926984801888466, 0.028531420975923538, 0.028480689972639084, 0.02850440703332424, 0.02836437150835991, 0.028380198404192924, 0.02837366610765457, 0.028353406116366386], min_val_index: 34\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 0.00020000001, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 4.0000003e-05, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1.6000001e-06, 34: 1e-06}\n",
      "{'loss': [18.399436950683594, 9.296602249145508, 4.074118137359619, 1.7110161781311035, 0.7117024660110474, 0.28499624133110046, 0.13512694835662842, 0.09121346473693848, 0.07320887595415115, 0.06457050889730453, 0.06016140431165695, 0.05749499052762985, 0.055345937609672546, 0.05431294068694115, 0.05406876280903816, 0.053992561995983124, 0.05373086780309677, 0.05382496491074562, 0.041823647916316986, 0.04083557054400444, 0.04086008667945862, 0.04097830504179001, 0.04069351404905319, 0.04100792855024338, 0.03798240050673485, 0.037568796426057816, 0.037451714277267456, 0.03740512579679489, 0.03686382621526718, 0.03699028491973877, 0.036815986037254333, 0.03673997521400452, 0.036636121571063995, 0.03647828847169876, 0.03672102466225624], 'val_loss': [11.889678955078125, 5.279019832611084, 2.1069400310516357, 0.9073384404182434, 0.40332379937171936, 0.17525163292884827, 0.09933388978242874, 0.07055659592151642, 0.060074012726545334, 0.05394281446933746, 0.04987061023712158, 0.04684684798121452, 0.046182166785001755, 0.04650377109646797, 0.04474131390452385, 0.04305769130587578, 0.04498221352696419, 0.0457213930785656, 0.03304809704422951, 0.0327402763068676, 0.0334254652261734, 0.031403910368680954, 0.03222331404685974, 0.0323450081050396, 0.02927294932305813, 0.028983870521187782, 0.02896561101078987, 0.02926984801888466, 0.028531420975923538, 0.028480689972639084, 0.02850440703332424, 0.02836437150835991, 0.028380198404192924, 0.02837366610765457, 0.028353406116366386]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 0.00020000001, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 4.0000003e-05, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1.6000001e-06, 34: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8765, eer: 0.1978, thres: 0.1541 => acc: 0.8022, f1: 0.8022\n",
      "\n",
      "Epoch 1/35\n",
      "188/188 [==============================] - 34s 101ms/step - loss: 15.4819\n",
      "Epoch 2/35\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 4.5674\n",
      "Epoch 3/35\n",
      "188/188 [==============================] - 19s 99ms/step - loss: 1.0834\n",
      "Epoch 4/35\n",
      "188/188 [==============================] - 16s 84ms/step - loss: 0.2347\n",
      "Epoch 5/35\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0884\n",
      "Epoch 6/35\n",
      "188/188 [==============================] - 16s 84ms/step - loss: 0.0662\n",
      "Epoch 7/35\n",
      "188/188 [==============================] - 19s 101ms/step - loss: 0.0577\n",
      "Epoch 8/35\n",
      "188/188 [==============================] - 19s 102ms/step - loss: 0.0540\n",
      "Epoch 9/35\n",
      "188/188 [==============================] - 19s 101ms/step - loss: 0.0533\n",
      "Epoch 10/35\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0531\n",
      "Epoch 11/35\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0542\n",
      "Epoch 12/35\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0536\n",
      "Epoch 13/35\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0539\n",
      "Epoch 14/35\n",
      "188/188 [==============================] - 19s 99ms/step - loss: 0.0540\n",
      "Epoch 15/35\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0543\n",
      "Epoch 16/35\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0542\n",
      "Epoch 17/35\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0544\n",
      "Epoch 18/35\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0570\n",
      "Epoch 19/35\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0401\n",
      "Epoch 20/35\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0392\n",
      "Epoch 21/35\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0392\n",
      "Epoch 22/35\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0391\n",
      "Epoch 23/35\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0391\n",
      "Epoch 24/35\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0392\n",
      "Epoch 25/35\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0358\n",
      "Epoch 26/35\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0355\n",
      "Epoch 27/35\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0355\n",
      "Epoch 28/35\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0354\n",
      "Epoch 29/35\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0349\n",
      "Epoch 30/35\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0347\n",
      "Epoch 31/35\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0349\n",
      "Epoch 32/35\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0346\n",
      "Epoch 33/35\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0348\n",
      "Epoch 34/35\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0346\n",
      "Epoch 35/35\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0347\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9314, eer: 0.1364, thres: 0.1709 => acc: 0.8636, f1: 0.8636\n",
      "loss: 0.035\n",
      "{'loss': [15.481942176818848, 4.567432403564453, 1.0834431648254395, 0.23470865190029144, 0.08837971091270447, 0.06619738787412643, 0.057660333812236786, 0.053977176547050476, 0.053266119211912155, 0.053119100630283356, 0.054237931966781616, 0.05361097678542137, 0.05389097332954407, 0.05399034172296524, 0.054272182285785675, 0.054206281900405884, 0.05444083362817764, 0.057016871869564056, 0.04006613418459892, 0.039222270250320435, 0.039197687059640884, 0.039119523018598557, 0.03907625004649162, 0.0392441526055336, 0.03582921624183655, 0.03554953634738922, 0.03552449867129326, 0.03544314205646515, 0.034944187849760056, 0.034707363694906235, 0.034862227737903595, 0.034566886723041534, 0.0348464734852314, 0.03459571674466133, 0.03469455614686012], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-500-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [30:33<32:33, 976.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [12.597457885742188, 4.451789855957031, 1.8130178451538086, 0.7095269560813904, 0.3575737476348877, 0.1455754041671753, 0.09803875535726547, 0.07873720675706863, 0.07751200348138809, 0.07429587095975876, 0.07639514654874802, 0.06864941865205765, 0.07428381592035294, 0.07653000205755234, 0.05078347772359848, 0.04604048281908035, 0.05083980783820152, 0.04803181439638138, 0.04106768220663071, 0.04173796623945236, 0.040828339755535126, 0.04172437638044357, 0.04137956723570824, 0.04039319232106209, 0.040242623537778854, 0.03999389708042145, 0.03990170359611511, 0.03974660113453865, 0.039871204644441605, 0.03976631537079811, 0.03964158520102501, 0.039620377123355865, 0.03967108950018883, 0.03971239551901817], min_val_index: 31\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1e-06}\n",
      "{'loss': [22.028648376464844, 8.86683464050293, 3.5896363258361816, 1.500304937362671, 0.6517763137817383, 0.24561510980129242, 0.1029934510588646, 0.08276276290416718, 0.0758984312415123, 0.07255040854215622, 0.0713132843375206, 0.07094379514455795, 0.07030334323644638, 0.0700502097606659, 0.04798736050724983, 0.04604477062821388, 0.04600653797388077, 0.04600696265697479, 0.040252458304166794, 0.03989890217781067, 0.03974306955933571, 0.03967772796750069, 0.039639368653297424, 0.03851417824625969, 0.038383353501558304, 0.03838418796658516, 0.038414303213357925, 0.03819211572408676, 0.038459986448287964, 0.038651980459690094, 0.0381503663957119, 0.03820442035794258, 0.038138389587402344, 0.0380016453564167], 'val_loss': [12.597457885742188, 4.451789855957031, 1.8130178451538086, 0.7095269560813904, 0.3575737476348877, 0.1455754041671753, 0.09803875535726547, 0.07873720675706863, 0.07751200348138809, 0.07429587095975876, 0.07639514654874802, 0.06864941865205765, 0.07428381592035294, 0.07653000205755234, 0.05078347772359848, 0.04604048281908035, 0.05083980783820152, 0.04803181439638138, 0.04106768220663071, 0.04173796623945236, 0.040828339755535126, 0.04172437638044357, 0.04137956723570824, 0.04039319232106209, 0.040242623537778854, 0.03999389708042145, 0.03990170359611511, 0.03974660113453865, 0.039871204644441605, 0.03976631537079811, 0.03964158520102501, 0.039620377123355865, 0.03967108950018883, 0.03971239551901817]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 8.000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8338, eer: 0.2433, thres: 0.1360 => acc: 0.7567, f1: 0.7567\n",
      "\n",
      "Epoch 1/32\n",
      "188/188 [==============================] - 22s 64ms/step - loss: 17.8307\n",
      "Epoch 2/32\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 4.1021\n",
      "Epoch 3/32\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 1.1361\n",
      "Epoch 4/32\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.2718\n",
      "Epoch 5/32\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0876\n",
      "Epoch 6/32\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0735\n",
      "Epoch 7/32\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0695\n",
      "Epoch 8/32\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 0.0686\n",
      "Epoch 9/32\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0696\n",
      "Epoch 10/32\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0711\n",
      "Epoch 11/32\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.0756\n",
      "Epoch 12/32\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0729\n",
      "Epoch 13/32\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0737\n",
      "Epoch 14/32\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0742\n",
      "Epoch 15/32\n",
      "188/188 [==============================] - 6s 35ms/step - loss: 0.0463\n",
      "Epoch 16/32\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0448\n",
      "Epoch 17/32\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0450\n",
      "Epoch 18/32\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0462\n",
      "Epoch 19/32\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0379: 1s \n",
      "Epoch 20/32\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0373\n",
      "Epoch 21/32\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0373\n",
      "Epoch 22/32\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0372\n",
      "Epoch 23/32\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0374\n",
      "Epoch 24/32\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0360\n",
      "Epoch 25/32\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0359\n",
      "Epoch 26/32\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0358\n",
      "Epoch 27/32\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0358\n",
      "Epoch 28/32\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0357\n",
      "Epoch 29/32\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0359\n",
      "Epoch 30/32\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0358\n",
      "Epoch 31/32\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0355\n",
      "Epoch 32/32\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0356\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9262, eer: 0.1416, thres: 0.1731 => acc: 0.8585, f1: 0.8585\n",
      "loss: 0.036\n",
      "{'loss': [17.83069610595703, 4.102087020874023, 1.1361061334609985, 0.2718130350112915, 0.08762602508068085, 0.07348132133483887, 0.06952564418315887, 0.06861967593431473, 0.06959206610918045, 0.07113279402256012, 0.07557457685470581, 0.07288755476474762, 0.07367279380559921, 0.07420562207698822, 0.04625806212425232, 0.04479755088686943, 0.045032914727926254, 0.04618324711918831, 0.03792587295174599, 0.03728993982076645, 0.03731144964694977, 0.03722893074154854, 0.03738098219037056, 0.03601893037557602, 0.03588701784610748, 0.03580697625875473, 0.03582074120640755, 0.03566727042198181, 0.03591682016849518, 0.03584768623113632, 0.035507988184690475, 0.03558434918522835], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-500-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [42:57<14:30, 870.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [11.279906272888184, 4.442124843597412, 1.5999177694320679, 0.6440188884735107, 0.298705130815506, 0.11546763777732849, 0.07359505444765091, 0.05680105462670326, 0.049032390117645264, 0.04670295491814613, 0.045610491186380386, 0.04446261003613472, 0.04600954055786133, 0.04557795077562332, 0.03227479010820389, 0.032594311982393265, 0.03259982168674469, 0.029257962480187416, 0.02931985631585121, 0.029182376340031624, 0.02855125442147255, 0.02855227142572403, 0.028547275811433792, 0.028402116149663925, 0.028405416756868362, 0.028403742238879204, 0.028386015444993973], min_val_index: 26\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 8.000001e-06, 21: 8.000001e-06, 22: 8.000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1.6000001e-06, 26: 1e-06}\n",
      "{'loss': [18.21863555908203, 8.412568092346191, 3.3237011432647705, 1.2309508323669434, 0.5039085149765015, 0.2184237837791443, 0.10106711089611053, 0.07512129843235016, 0.06320282816886902, 0.057974785566329956, 0.055733710527420044, 0.05517718568444252, 0.05503465607762337, 0.05500190332531929, 0.04294424131512642, 0.04163924604654312, 0.04178037866950035, 0.03862440213561058, 0.038232505321502686, 0.03814101591706276, 0.03757508471608162, 0.03745606914162636, 0.03733111917972565, 0.037373706698417664, 0.037442464381456375, 0.037154506891965866, 0.03725755214691162], 'val_loss': [11.279906272888184, 4.442124843597412, 1.5999177694320679, 0.6440188884735107, 0.298705130815506, 0.11546763777732849, 0.07359505444765091, 0.05680105462670326, 0.049032390117645264, 0.04670295491814613, 0.045610491186380386, 0.04446261003613472, 0.04600954055786133, 0.04557795077562332, 0.03227479010820389, 0.032594311982393265, 0.03259982168674469, 0.029257962480187416, 0.02931985631585121, 0.029182376340031624, 0.02855125442147255, 0.02855227142572403, 0.028547275811433792, 0.028402116149663925, 0.028405416756868362, 0.028403742238879204, 0.028386015444993973]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 8.000001e-06, 21: 8.000001e-06, 22: 8.000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1.6000001e-06, 26: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8696, eer: 0.2021, thres: 0.1459 => acc: 0.7979, f1: 0.7979\n",
      "\n",
      "Epoch 1/27\n",
      "188/188 [==============================] - 37s 100ms/step - loss: 15.1321\n",
      "Epoch 2/27\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 3.8093\n",
      "Epoch 3/27\n",
      "188/188 [==============================] - 19s 101ms/step - loss: 0.7705\n",
      "Epoch 4/27\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.1768\n",
      "Epoch 5/27\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0789\n",
      "Epoch 6/27\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0613\n",
      "Epoch 7/27\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0551\n",
      "Epoch 8/27\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0534\n",
      "Epoch 9/27\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0535\n",
      "Epoch 10/27\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0539\n",
      "Epoch 11/27\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0560\n",
      "Epoch 12/27\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0543\n",
      "Epoch 13/27\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 0.0546\n",
      "Epoch 14/27\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.0549\n",
      "Epoch 15/27\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0396\n",
      "Epoch 16/27\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0387\n",
      "Epoch 17/27\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0389\n",
      "Epoch 18/27\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.0355\n",
      "Epoch 19/27\n",
      "188/188 [==============================] - 19s 99ms/step - loss: 0.0352\n",
      "Epoch 20/27\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0350\n",
      "Epoch 21/27\n",
      "188/188 [==============================] - 17s 93ms/step - loss: 0.0343\n",
      "Epoch 22/27\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0344\n",
      "Epoch 23/27\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0343\n",
      "Epoch 24/27\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0342\n",
      "Epoch 25/27\n",
      "188/188 [==============================] - 6s 30ms/step - loss: 0.0344\n",
      "Epoch 26/27\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0344\n",
      "Epoch 27/27\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0343\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9429, eer: 0.1211, thres: 0.1833 => acc: 0.8789, f1: 0.8789\n",
      "loss: 0.034\n",
      "{'loss': [15.132108688354492, 3.8093063831329346, 0.770508885383606, 0.17677511274814606, 0.07890437543392181, 0.061264876276254654, 0.055093489587306976, 0.0534353107213974, 0.05353899300098419, 0.0539131797850132, 0.056026484817266464, 0.05427063629031181, 0.0545940101146698, 0.05491358041763306, 0.03963800147175789, 0.038743190467357635, 0.038899511098861694, 0.03552717715501785, 0.035166624933481216, 0.03500808775424957, 0.03429534658789635, 0.034404996782541275, 0.03434521704912186, 0.03418246656656265, 0.034364715218544006, 0.0343657061457634, 0.034290861338377], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-500-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-500-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [56:48<00:00, 852.10s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [3:01:32<2:01:29, 3644.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 55\n",
      "len_exp2_user_47: 47\n",
      "110\n",
      "0.09893801652892562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:09<02:53,  9.15s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:16<02:21,  7.89s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:22<02:04,  7.33s/it]\u001b[A\n",
      " 20%|██        | 4/20 [00:31<02:06,  7.91s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:43<02:19,  9.31s/it]\u001b[A\n",
      " 30%|███       | 6/20 [00:53<02:11,  9.42s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [01:00<01:53,  8.73s/it]\u001b[A\n",
      " 40%|████      | 8/20 [01:06<01:36,  8.00s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [01:13<01:22,  7.54s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [01:34<01:56, 11.66s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [01:51<02:00, 13.38s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [02:06<01:52, 14.00s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [02:22<01:40, 14.36s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [02:38<01:29, 14.98s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [02:59<01:23, 16.67s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [03:14<01:05, 16.29s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [03:30<00:48, 16.33s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [03:37<00:26, 13.40s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [03:44<00:11, 11.35s/it]\u001b[A\n",
      "100%|██████████| 20/20 [03:50<00:00, 11.54s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 750, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [5.357789993286133, 1.3135310411453247, 0.3989841341972351, 0.13486284017562866, 0.06217481568455696, 0.04800935089588165, 0.043355852365493774, 0.04263303056359291, 0.04138236492872238, 0.04134821891784668, 0.040878407657146454, 0.04125960171222687, 0.040022123605012894, 0.04288369044661522, 0.04383351653814316, 0.028947260230779648, 0.028669089078903198, 0.02902054786682129, 0.028438882902264595, 0.02851623296737671, 0.02860889583826065, 0.025240285322070122, 0.025212323293089867, 0.025078799575567245, 0.02510877698659897, 0.0253688246011734, 0.024523913860321045, 0.024474795907735825, 0.024525946006178856, 0.024392856284976006, 0.024389315396547318, 0.024379121139645576, 0.02437559701502323], min_val_index: 32\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1e-06}\n",
      "{'loss': [11.145522117614746, 3.311089515686035, 0.822333037853241, 0.24775564670562744, 0.09308292716741562, 0.05985221266746521, 0.05274434760212898, 0.05030503496527672, 0.04962510988116264, 0.04981870949268341, 0.04972097650170326, 0.049770787358284, 0.049741119146347046, 0.05011161416769028, 0.04993102326989174, 0.037546999752521515, 0.03641067072749138, 0.03636925667524338, 0.03638336807489395, 0.03637268766760826, 0.0361299104988575, 0.03317020460963249, 0.03290528059005737, 0.032935526221990585, 0.032966431230306625, 0.032899461686611176, 0.032119594514369965, 0.03222190961241722, 0.03223767504096031, 0.03201979026198387, 0.03204122558236122, 0.032085321843624115, 0.03216775506734848], 'val_loss': [5.357789993286133, 1.3135310411453247, 0.3989841341972351, 0.13486284017562866, 0.06217481568455696, 0.04800935089588165, 0.043355852365493774, 0.04263303056359291, 0.04138236492872238, 0.04134821891784668, 0.040878407657146454, 0.04125960171222687, 0.040022123605012894, 0.04288369044661522, 0.04383351653814316, 0.028947260230779648, 0.028669089078903198, 0.02902054786682129, 0.028438882902264595, 0.02851623296737671, 0.02860889583826065, 0.025240285322070122, 0.025212323293089867, 0.025078799575567245, 0.02510877698659897, 0.0253688246011734, 0.024523913860321045, 0.024474795907735825, 0.024525946006178856, 0.024392856284976006, 0.024389315396547318, 0.024379121139645576, 0.02437559701502323]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 8.000001e-06, 27: 8.000001e-06, 28: 8.000001e-06, 29: 1.6000001e-06, 30: 1.6000001e-06, 31: 1.6000001e-06, 32: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9091, eer: 0.1510, thres: 0.0756 => acc: 0.8490, f1: 0.8490\n",
      "\n",
      "Epoch 1/33\n",
      "188/188 [==============================] - 13s 53ms/step - loss: 8.9323\n",
      "Epoch 2/33\n",
      "188/188 [==============================] - 12s 61ms/step - loss: 1.2689\n",
      "Epoch 3/33\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.1729\n",
      "Epoch 4/33\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 0.0637\n",
      "Epoch 5/33\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0515\n",
      "Epoch 6/33\n",
      "188/188 [==============================] - 13s 71ms/step - loss: 0.0497\n",
      "Epoch 7/33\n",
      "188/188 [==============================] - 14s 74ms/step - loss: 0.0494\n",
      "Epoch 8/33\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0496\n",
      "Epoch 9/33\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0497\n",
      "Epoch 10/33\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0496\n",
      "Epoch 11/33\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0522\n",
      "Epoch 12/33\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0508\n",
      "Epoch 13/33\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0500\n",
      "Epoch 14/33\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0500\n",
      "Epoch 15/33\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.0500 1s - loss - ETA: 0s - loss: \n",
      "Epoch 16/33\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 0.0360\n",
      "Epoch 17/33\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0352\n",
      "Epoch 18/33\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0352\n",
      "Epoch 19/33\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0349\n",
      "Epoch 20/33\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0349\n",
      "Epoch 21/33\n",
      "188/188 [==============================] - 12s 64ms/step - loss: 0.0351\n",
      "Epoch 22/33\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0320\n",
      "Epoch 23/33\n",
      "188/188 [==============================] - 19s 100ms/step - loss: 0.0316\n",
      "Epoch 24/33\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 0.0318\n",
      "Epoch 25/33\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 0.0318\n",
      "Epoch 26/33\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0319\n",
      "Epoch 27/33\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0311\n",
      "Epoch 28/33\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0311\n",
      "Epoch 29/33\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0309\n",
      "Epoch 30/33\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0309 1s - l\n",
      "Epoch 31/33\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0309\n",
      "Epoch 32/33\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0309\n",
      "Epoch 33/33\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0308\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9342, eer: 0.1351, thres: 0.1912 => acc: 0.8649, f1: 0.8649\n",
      "loss: 0.031\n",
      "{'loss': [8.93233585357666, 1.2688939571380615, 0.17294034361839294, 0.06373225152492523, 0.05154678598046303, 0.049683284014463425, 0.04935184866189957, 0.04955758526921272, 0.04969640076160431, 0.04956086352467537, 0.05224359408020973, 0.050806593149900436, 0.05004105344414711, 0.04995746910572052, 0.04999189078807831, 0.03597050905227661, 0.035218991339206696, 0.035217612981796265, 0.034926146268844604, 0.03485601395368576, 0.03508094698190689, 0.03200257942080498, 0.03161242604255676, 0.03184480592608452, 0.031807541847229004, 0.03185524418950081, 0.03112642839550972, 0.031054235994815826, 0.03092413954436779, 0.03094470500946045, 0.030927486717700958, 0.030902745202183723, 0.030840791761875153], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-750-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [12:52<38:38, 772.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [11.22115421295166, 4.565544605255127, 1.6899858713150024, 0.6676825881004333, 0.2934996485710144, 0.12752020359039307, 0.07558032125234604, 0.060408078134059906, 0.0533573143184185, 0.05050627887248993, 0.05203092098236084, 0.05391864478588104, 0.0355079211294651, 0.035921916365623474, 0.03484620526432991, 0.03471444547176361, 0.034446392208337784, 0.03578702732920647, 0.035175733268260956, 0.03127330541610718, 0.031538225710392, 0.031626537442207336, 0.030827665701508522, 0.030730504542589188, 0.030734945088624954, 0.03059297427535057, 0.030604181811213493, 0.03058002144098282, 0.03057728335261345], min_val_index: 28\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1e-06}\n",
      "{'loss': [17.5261173248291, 8.27985954284668, 3.2938013076782227, 1.2483590841293335, 0.48484867811203003, 0.19463108479976654, 0.10313721001148224, 0.07428725063800812, 0.0633755549788475, 0.058122728019952774, 0.05501626059412956, 0.05299680680036545, 0.04114362969994545, 0.040168337523937225, 0.039970893412828445, 0.039829839020967484, 0.03973780572414398, 0.03950602561235428, 0.03927251324057579, 0.036329563707113266, 0.03579806163907051, 0.0358315072953701, 0.03543546050786972, 0.03507757931947708, 0.035092148929834366, 0.035147618502378464, 0.03503444045782089, 0.03492426499724388, 0.0348997563123703], 'val_loss': [11.22115421295166, 4.565544605255127, 1.6899858713150024, 0.6676825881004333, 0.2934996485710144, 0.12752020359039307, 0.07558032125234604, 0.060408078134059906, 0.0533573143184185, 0.05050627887248993, 0.05203092098236084, 0.05391864478588104, 0.0355079211294651, 0.035921916365623474, 0.03484620526432991, 0.03471444547176361, 0.034446392208337784, 0.03578702732920647, 0.035175733268260956, 0.03127330541610718, 0.031538225710392, 0.031626537442207336, 0.030827665701508522, 0.030730504542589188, 0.030734945088624954, 0.03059297427535057, 0.030604181811213493, 0.03058002144098282, 0.03057728335261345]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 1.6000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8969, eer: 0.1723, thres: 0.1412 => acc: 0.8277, f1: 0.8277\n",
      "\n",
      "Epoch 1/29\n",
      "188/188 [==============================] - 12s 39ms/step - loss: 14.4776\n",
      "Epoch 2/29\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 3.6530\n",
      "Epoch 3/29\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.6936\n",
      "Epoch 4/29\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.1387\n",
      "Epoch 5/29\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0696\n",
      "Epoch 6/29\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0563\n",
      "Epoch 7/29\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0513\n",
      "Epoch 8/29\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0503\n",
      "Epoch 9/29\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0503\n",
      "Epoch 10/29\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0506\n",
      "Epoch 11/29\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0520\n",
      "Epoch 12/29\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0510\n",
      "Epoch 13/29\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0377\n",
      "Epoch 14/29\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0369:\n",
      "Epoch 15/29\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0369\n",
      "Epoch 16/29\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0368\n",
      "Epoch 17/29\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0369\n",
      "Epoch 18/29\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0371\n",
      "Epoch 19/29\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0366\n",
      "Epoch 20/29\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0333\n",
      "Epoch 21/29\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0332\n",
      "Epoch 22/29\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0332\n",
      "Epoch 23/29\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0323\n",
      "Epoch 24/29\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0326\n",
      "Epoch 25/29\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0326\n",
      "Epoch 26/29\n",
      "188/188 [==============================] - 12s 64ms/step - loss: 0.0324\n",
      "Epoch 27/29\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0322\n",
      "Epoch 28/29\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0324\n",
      "Epoch 29/29\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0324\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9371, eer: 0.1311, thres: 0.1791 => acc: 0.8689, f1: 0.8689\n",
      "loss: 0.032\n",
      "{'loss': [14.477571487426758, 3.6529533863067627, 0.6935520172119141, 0.13868123292922974, 0.06962940096855164, 0.05628781393170357, 0.051302388310432434, 0.05033228173851967, 0.050328947603702545, 0.05058308318257332, 0.0519990473985672, 0.05103248730301857, 0.03769434988498688, 0.036880973726511, 0.03686657175421715, 0.036830585449934006, 0.03690888360142708, 0.037120986729860306, 0.03658200055360794, 0.033329129219055176, 0.03322248160839081, 0.03318924456834793, 0.03233761712908745, 0.032592326402664185, 0.03261434659361839, 0.032420940697193146, 0.03221723809838295, 0.03242701292037964, 0.032407164573669434], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-750-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [23:27<23:02, 691.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [11.636056900024414, 3.782895088195801, 1.416144847869873, 0.5536706447601318, 0.2911255657672882, 0.12092147022485733, 0.0780777707695961, 0.0690750703215599, 0.07186348736286163, 0.0675043910741806, 0.07492927461862564, 0.07596931606531143, 0.05004190281033516, 0.043813880532979965, 0.04503616318106651, 0.044285498559474945, 0.037574976682662964, 0.037344932556152344, 0.03715416043996811, 0.03726007416844368, 0.03762384504079819, 0.03615403547883034, 0.03610110282897949, 0.03596402332186699, 0.03588958829641342, 0.03591349720954895, 0.035748131573200226, 0.03575611114501953, 0.03573398292064667, 0.03571092337369919], min_val_index: 29\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 8.000001e-06, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "{'loss': [20.95825958251953, 7.717789649963379, 2.837627410888672, 1.1540203094482422, 0.4048768877983093, 0.18389809131622314, 0.09208574891090393, 0.0760066881775856, 0.06928712874650955, 0.0665229931473732, 0.06593767553567886, 0.06590365618467331, 0.04408614709973335, 0.04250112548470497, 0.0426480807363987, 0.04291630536317825, 0.03676670044660568, 0.03628312796354294, 0.03614877909421921, 0.036063775420188904, 0.03609904646873474, 0.03491714596748352, 0.03479781746864319, 0.03470365330576897, 0.03486855328083038, 0.034781765192747116, 0.034626554697752, 0.03454742953181267, 0.03434617444872856, 0.03446215018630028], 'val_loss': [11.636056900024414, 3.782895088195801, 1.416144847869873, 0.5536706447601318, 0.2911255657672882, 0.12092147022485733, 0.0780777707695961, 0.0690750703215599, 0.07186348736286163, 0.0675043910741806, 0.07492927461862564, 0.07596931606531143, 0.05004190281033516, 0.043813880532979965, 0.04503616318106651, 0.044285498559474945, 0.037574976682662964, 0.037344932556152344, 0.03715416043996811, 0.03726007416844368, 0.03762384504079819, 0.03615403547883034, 0.03610110282897949, 0.03596402332186699, 0.03588958829641342, 0.03591349720954895, 0.035748131573200226, 0.03575611114501953, 0.03573398292064667, 0.03571092337369919]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 0.00020000001, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 8.000001e-06, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 1.6000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8598, eer: 0.2150, thres: 0.1236 => acc: 0.7849, f1: 0.7849\n",
      "\n",
      "Epoch 1/30\n",
      "188/188 [==============================] - 13s 50ms/step - loss: 16.3498\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 3.1555\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.8386\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.1431\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0755\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0669\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0652\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0657\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0664\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0676\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0733\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0701\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 9s 45ms/step - loss: 0.0434\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0421\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0422: 0s - loss: 0.04\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 9s 47ms/step - loss: 0.0422\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0353\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0350\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0349\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0349\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 6s 31ms/step - loss: 0.0349\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.0335\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.0335\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0334\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0335\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0336\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0332\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.0330\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0332\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0331\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9427, eer: 0.1269, thres: 0.1845 => acc: 0.8731, f1: 0.8731\n",
      "loss: 0.033\n",
      "{'loss': [16.34982681274414, 3.155477523803711, 0.8385763168334961, 0.1430838704109192, 0.07545571029186249, 0.0668967217206955, 0.06516876816749573, 0.06569118797779083, 0.06640197336673737, 0.0676245391368866, 0.0733075737953186, 0.07012173533439636, 0.04335319995880127, 0.04213080555200577, 0.04220907390117645, 0.04215560853481293, 0.035332657396793365, 0.03497766703367233, 0.034945614635944366, 0.0348825566470623, 0.03491387516260147, 0.0335150882601738, 0.033474527299404144, 0.03340360149741173, 0.03345422446727753, 0.03356962278485298, 0.033210378140211105, 0.03297283127903938, 0.03319346904754639, 0.03305724263191223], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-750-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [33:18<10:45, 645.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [10.327657699584961, 3.634469747543335, 1.1747580766677856, 0.45573681592941284, 0.1803700178861618, 0.08791797608137131, 0.05762108787894249, 0.046331409364938736, 0.04183076694607735, 0.04161311686038971, 0.04174037277698517, 0.041757285594940186, 0.028599979355931282, 0.028891462832689285, 0.02856685034930706, 0.024908432736992836, 0.024878527969121933, 0.024924416095018387, 0.02415669895708561, 0.024144012480974197, 0.024147121235728264, 0.02402285858988762, 0.024024568498134613, 0.024019882082939148, 0.024012021720409393], min_val_index: 24\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "{'loss': [17.199161529541016, 7.222646713256836, 2.5041377544403076, 0.8396718502044678, 0.31941136717796326, 0.13069915771484375, 0.0809929370880127, 0.06213090196251869, 0.05470654368400574, 0.05269806459546089, 0.05208927392959595, 0.05179847031831741, 0.03931088745594025, 0.03850603103637695, 0.03842504322528839, 0.03514698147773743, 0.03491385653614998, 0.03479543700814247, 0.03403641656041145, 0.03413475677371025, 0.03394760936498642, 0.03391587361693382, 0.033886171877384186, 0.03377192094922066, 0.0339033268392086], 'val_loss': [10.327657699584961, 3.634469747543335, 1.1747580766677856, 0.45573681592941284, 0.1803700178861618, 0.08791797608137131, 0.05762108787894249, 0.046331409364938736, 0.04183076694607735, 0.04161311686038971, 0.04174037277698517, 0.041757285594940186, 0.028599979355931282, 0.028891462832689285, 0.02856685034930706, 0.024908432736992836, 0.024878527969121933, 0.024924416095018387, 0.02415669895708561, 0.024144012480974197, 0.024147121235728264, 0.02402285858988762, 0.024024568498134613, 0.024019882082939148, 0.024012021720409393]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8915, eer: 0.1772, thres: 0.1327 => acc: 0.8229, f1: 0.8229\n",
      "\n",
      "Epoch 1/25\n",
      "188/188 [==============================] - 12s 40ms/step - loss: 14.0223\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 2.9453\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 11s 61ms/step - loss: 0.4824\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.1135\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0666\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 9s 46ms/step - loss: 0.0549\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0516\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0516\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0516\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0519\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0530\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0516\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0372\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0364\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0364\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 0.0330\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0328\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0327\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 8s 41ms/step - loss: 0.0319\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 8s 43ms/step - loss: 0.0318\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0319\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0318\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0316\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 8s 44ms/step - loss: 0.0318\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0316\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9496, eer: 0.1102, thres: 0.1937 => acc: 0.8898, f1: 0.8898\n",
      "loss: 0.032\n",
      "{'loss': [14.022287368774414, 2.9452857971191406, 0.48235195875167847, 0.11345650255680084, 0.06655368953943253, 0.05494759604334831, 0.051613178104162216, 0.05161093547940254, 0.05164571478962898, 0.05185813456773758, 0.05301172658801079, 0.051613710820674896, 0.037201616913080215, 0.03639382869005203, 0.036380585283041, 0.03299238160252571, 0.032832805067300797, 0.032716989517211914, 0.03188376873731613, 0.03183173015713692, 0.03193606808781624, 0.031764544546604156, 0.03156314417719841, 0.031755540519952774, 0.031642939895391464], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-750-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-750-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [42:37<00:00, 639.28s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [3:48:17<55:13, 3313.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 41\n",
      "len_exp2_user_47: 35\n",
      "82\n",
      "0.17804134443783462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:05<01:41,  5.36s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:10<01:33,  5.20s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:15<01:27,  5.15s/it]\u001b[A\n",
      " 20%|██        | 4/20 [00:20<01:21,  5.12s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:25<01:17,  5.14s/it]\u001b[A\n",
      " 30%|███       | 6/20 [00:30<01:12,  5.16s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:36<01:07,  5.16s/it]\u001b[A\n",
      " 40%|████      | 8/20 [00:41<01:01,  5.11s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [00:45<00:54,  4.96s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [00:54<00:59,  5.99s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [00:58<00:50,  5.60s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [01:04<00:44,  5.53s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [01:08<00:36,  5.29s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [01:13<00:30,  5.08s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [01:18<00:24,  4.96s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [01:22<00:19,  4.89s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [01:27<00:14,  4.77s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [01:31<00:09,  4.70s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [01:36<00:04,  4.66s/it]\u001b[A\n",
      "100%|██████████| 20/20 [01:41<00:00,  5.06s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 1000, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [4.904307842254639, 1.0948026180267334, 0.32753998041152954, 0.10855068266391754, 0.056074369698762894, 0.04518870264291763, 0.04066723957657814, 0.04169084504246712, 0.041678640991449356, 0.028632953763008118, 0.028377026319503784, 0.02846728265285492, 0.028433604165911674, 0.025268930941820145, 0.025365788489580154, 0.025326678529381752, 0.02461104840040207, 0.0245793629437685, 0.024604877457022667, 0.02446296624839306, 0.024465160444378853, 0.024460241198539734, 0.02445036917924881], min_val_index: 22\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.00020000001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 4.0000003e-05, 14: 4.0000003e-05, 15: 4.0000003e-05, 16: 8.000001e-06, 17: 8.000001e-06, 18: 8.000001e-06, 19: 1.6000001e-06, 20: 1.6000001e-06, 21: 1.6000001e-06, 22: 1e-06}\n",
      "{'loss': [10.557413101196289, 2.79931640625, 0.6474319100379944, 0.19837845861911774, 0.08166208118200302, 0.056223347783088684, 0.05057859793305397, 0.0490272119641304, 0.04847696051001549, 0.03636603429913521, 0.0353873148560524, 0.03538985922932625, 0.0352063849568367, 0.032255787402391434, 0.03195957466959953, 0.032038357108831406, 0.031195351853966713, 0.0313723087310791, 0.03130226582288742, 0.031168652698397636, 0.03104591555893421, 0.031166162341833115, 0.03124496527016163], 'val_loss': [4.904307842254639, 1.0948026180267334, 0.32753998041152954, 0.10855068266391754, 0.056074369698762894, 0.04518870264291763, 0.04066723957657814, 0.04169084504246712, 0.041678640991449356, 0.028632953763008118, 0.028377026319503784, 0.02846728265285492, 0.028433604165911674, 0.025268930941820145, 0.025365788489580154, 0.025326678529381752, 0.02461104840040207, 0.0245793629437685, 0.024604877457022667, 0.02446296624839306, 0.024465160444378853, 0.024460241198539734, 0.02445036917924881]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.00020000001, 10: 0.00020000001, 11: 0.00020000001, 12: 0.00020000001, 13: 4.0000003e-05, 14: 4.0000003e-05, 15: 4.0000003e-05, 16: 8.000001e-06, 17: 8.000001e-06, 18: 8.000001e-06, 19: 1.6000001e-06, 20: 1.6000001e-06, 21: 1.6000001e-06, 22: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9197, eer: 0.1412, thres: 0.0718 => acc: 0.8588, f1: 0.8588\n",
      "\n",
      "Epoch 1/23\n",
      "188/188 [==============================] - 15s 66ms/step - loss: 8.6033\n",
      "Epoch 2/23\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 1.1110\n",
      "Epoch 3/23\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.1510\n",
      "Epoch 4/23\n",
      "188/188 [==============================] - 15s 82ms/step - loss: 0.0619\n",
      "Epoch 5/23\n",
      "188/188 [==============================] - 17s 88ms/step - loss: 0.0519\n",
      "Epoch 6/23\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 0.0497\n",
      "Epoch 7/23\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0491\n",
      "Epoch 8/23\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0485\n",
      "Epoch 9/23\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0485\n",
      "Epoch 10/23\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0350\n",
      "Epoch 11/23\n",
      "188/188 [==============================] - 12s 67ms/step - loss: 0.0346\n",
      "Epoch 12/23\n",
      "188/188 [==============================] - 12s 64ms/step - loss: 0.0345\n",
      "Epoch 13/23\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0345 0s -\n",
      "Epoch 14/23\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0310\n",
      "Epoch 15/23\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0309\n",
      "Epoch 16/23\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 0.0307\n",
      "Epoch 17/23\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0300\n",
      "Epoch 18/23\n",
      "188/188 [==============================] - 13s 68ms/step - loss: 0.0299\n",
      "Epoch 19/23\n",
      "188/188 [==============================] - 12s 64ms/step - loss: 0.0300\n",
      "Epoch 20/23\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.0300\n",
      "Epoch 21/23\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0300\n",
      "Epoch 22/23\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.0301\n",
      "Epoch 23/23\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.0301\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9558, eer: 0.1025, thres: 0.1946 => acc: 0.8975, f1: 0.8975\n",
      "loss: 0.030\n",
      "{'loss': [8.603255271911621, 1.1110402345657349, 0.15100185573101044, 0.06188332661986351, 0.051860261708498, 0.049681536853313446, 0.04906008765101433, 0.04848804697394371, 0.04849342629313469, 0.03499741479754448, 0.034578900784254074, 0.03446338698267937, 0.034462131559848785, 0.031008582562208176, 0.030865022912621498, 0.03071310929954052, 0.03004712611436844, 0.029889889061450958, 0.030039578676223755, 0.02998415008187294, 0.030016781762242317, 0.030058952048420906, 0.030095933005213737], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-1000-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [08:52<26:37, 532.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [10.50240707397461, 3.8888652324676514, 1.3224576711654663, 0.5118352174758911, 0.212541401386261, 0.10039360076189041, 0.06930331885814667, 0.05414222180843353, 0.04920818656682968, 0.055167507380247116, 0.04803136736154556, 0.04524781554937363, 0.04441678896546364, 0.046068355441093445, 0.04241325706243515, 0.04629921913146973, 0.04380324110388756, 0.029717931523919106, 0.028723066672682762, 0.028284378349781036, 0.02757791243493557, 0.028236951678991318, 0.02960871160030365, 0.025808028876781464, 0.025603383779525757, 0.025425121188163757, 0.025332238525152206, 0.02538865990936756, 0.02468825690448284, 0.024720866233110428, 0.024670233950018883, 0.024556690827012062, 0.024553442373871803, 0.024573778733611107, 0.02455195039510727], min_val_index: 34\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 4.0000003e-05, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1.6000001e-06, 34: 1e-06}\n",
      "{'loss': [16.781421661376953, 7.342933177947998, 2.6468141078948975, 0.9185539484024048, 0.356909841299057, 0.1458338350057602, 0.08640164881944656, 0.06570762395858765, 0.05751710757613182, 0.05373523384332657, 0.051146917045116425, 0.049999579787254333, 0.049292389303445816, 0.04902168735861778, 0.04880344495177269, 0.04879005625844002, 0.04887453466653824, 0.036043308675289154, 0.035030726343393326, 0.035044338554143906, 0.034981004893779755, 0.034730203449726105, 0.03507163003087044, 0.03182496502995491, 0.031564582139253616, 0.03152093291282654, 0.031549546867609024, 0.03161518648266792, 0.030777670443058014, 0.030738094821572304, 0.030911603942513466, 0.030705813318490982, 0.030612295493483543, 0.030775779858231544, 0.03073907271027565], 'val_loss': [10.50240707397461, 3.8888652324676514, 1.3224576711654663, 0.5118352174758911, 0.212541401386261, 0.10039360076189041, 0.06930331885814667, 0.05414222180843353, 0.04920818656682968, 0.055167507380247116, 0.04803136736154556, 0.04524781554937363, 0.04441678896546364, 0.046068355441093445, 0.04241325706243515, 0.04629921913146973, 0.04380324110388756, 0.029717931523919106, 0.028723066672682762, 0.028284378349781036, 0.02757791243493557, 0.028236951678991318, 0.02960871160030365, 0.025808028876781464, 0.025603383779525757, 0.025425121188163757, 0.025332238525152206, 0.02538865990936756, 0.02468825690448284, 0.024720866233110428, 0.024670233950018883, 0.024556690827012062, 0.024553442373871803, 0.024573778733611107, 0.02455195039510727]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 0.00020000001, 22: 0.00020000001, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 4.0000003e-05, 26: 4.0000003e-05, 27: 4.0000003e-05, 28: 8.000001e-06, 29: 8.000001e-06, 30: 8.000001e-06, 31: 1.6000001e-06, 32: 1.6000001e-06, 33: 1.6000001e-06, 34: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9112, eer: 0.1555, thres: 0.1335 => acc: 0.8445, f1: 0.8445\n",
      "\n",
      "Epoch 1/35\n",
      "188/188 [==============================] - 13s 48ms/step - loss: 13.9855\n",
      "Epoch 2/35\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 3.2411\n",
      "Epoch 3/35\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.5434\n",
      "Epoch 4/35\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.1214\n",
      "Epoch 5/35\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0641\n",
      "Epoch 6/35\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0532\n",
      "Epoch 7/35\n",
      "188/188 [==============================] - 12s 63ms/step - loss: 0.0496\n",
      "Epoch 8/35\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0488\n",
      "Epoch 9/35\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0491\n",
      "Epoch 10/35\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0491\n",
      "Epoch 11/35\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0512\n",
      "Epoch 12/35\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.0502\n",
      "Epoch 13/35\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0502\n",
      "Epoch 14/35\n",
      "188/188 [==============================] - 9s 49ms/step - loss: 0.0504\n",
      "Epoch 15/35\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 0.0503\n",
      "Epoch 16/35\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.0501\n",
      "Epoch 17/35\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.0507\n",
      "Epoch 18/35\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0354\n",
      "Epoch 19/35\n",
      "188/188 [==============================] - 17s 89ms/step - loss: 0.0348\n",
      "Epoch 20/35\n",
      "188/188 [==============================] - 16s 88ms/step - loss: 0.0349\n",
      "Epoch 21/35\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0347\n",
      "Epoch 22/35\n",
      "188/188 [==============================] - 18s 93ms/step - loss: 0.0347\n",
      "Epoch 23/35\n",
      "188/188 [==============================] - 16s 87ms/step - loss: 0.0346\n",
      "Epoch 24/35\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.0312\n",
      "Epoch 25/35\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.0312\n",
      "Epoch 26/35\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.0311\n",
      "Epoch 27/35\n",
      "188/188 [==============================] - 13s 70ms/step - loss: 0.0308\n",
      "Epoch 28/35\n",
      "188/188 [==============================] - 17s 89ms/step - loss: 0.0311\n",
      "Epoch 29/35\n",
      "188/188 [==============================] - 17s 90ms/step - loss: 0.0302\n",
      "Epoch 30/35\n",
      "188/188 [==============================] - 17s 89ms/step - loss: 0.0304\n",
      "Epoch 31/35\n",
      "188/188 [==============================] - 16s 88ms/step - loss: 0.0303\n",
      "Epoch 32/35\n",
      "188/188 [==============================] - 17s 88ms/step - loss: 0.0302\n",
      "Epoch 33/35\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0303\n",
      "Epoch 34/35\n",
      "188/188 [==============================] - 13s 66ms/step - loss: 0.0300\n",
      "Epoch 35/35\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0301\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9442, eer: 0.1206, thres: 0.1829 => acc: 0.8794, f1: 0.8794\n",
      "loss: 0.030\n",
      "{'loss': [13.985479354858398, 3.241124391555786, 0.5433984398841858, 0.12139660865068436, 0.06410939246416092, 0.05318664014339447, 0.049642641097307205, 0.04878087714314461, 0.049100182950496674, 0.04908864200115204, 0.05117809399962425, 0.05021921172738075, 0.05024086311459541, 0.0503927581012249, 0.05026309937238693, 0.05008535832166672, 0.05068372189998627, 0.03537031263113022, 0.03477776423096657, 0.03486141562461853, 0.034669067710638046, 0.034699179232120514, 0.034629520028829575, 0.03122013807296753, 0.031219612807035446, 0.031103523448109627, 0.03083149343729019, 0.03113165684044361, 0.030237076804041862, 0.030375374481081963, 0.030310258269309998, 0.03020920604467392, 0.030250534415245056, 0.030036509037017822, 0.030065907165408134], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-1000-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [25:34<26:57, 808.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [10.831977844238281, 3.3473563194274902, 1.2489993572235107, 0.45440712571144104, 0.1897336095571518, 0.08527456223964691, 0.06411857157945633, 0.06728584319353104, 0.06341521441936493, 0.0779445692896843, 0.0674959272146225, 0.042359668761491776, 0.039977721869945526, 0.044939521700143814, 0.053546562790870667, 0.0460120365023613, 0.046192485839128494, 0.044617462903261185, 0.04403957352042198, 0.04391639307141304, 0.04373353347182274, 0.043788131326436996], min_val_index: 12\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.00020000001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 8.000001e-06, 18: 8.000001e-06, 19: 1.6000001e-06, 20: 1.6000001e-06, 21: 1e-06}\n",
      "{'loss': [20.101856231689453, 6.877913475036621, 2.3944075107574463, 0.8625936508178711, 0.2970896363258362, 0.10981180518865585, 0.07876134663820267, 0.07058945298194885, 0.06730785220861435, 0.0660991296172142, 0.06553290039300919, 0.042866479605436325, 0.040831033140420914, 0.04098883643746376, 0.040717676281929016, 0.03488187491893768, 0.03429602086544037, 0.03303702548146248, 0.03294096142053604, 0.032796990126371384, 0.03250812739133835, 0.03267829865217209], 'val_loss': [10.831977844238281, 3.3473563194274902, 1.2489993572235107, 0.45440712571144104, 0.1897336095571518, 0.08527456223964691, 0.06411857157945633, 0.06728584319353104, 0.06341521441936493, 0.0779445692896843, 0.0674959272146225, 0.042359668761491776, 0.039977721869945526, 0.044939521700143814, 0.053546562790870667, 0.0460120365023613, 0.046192485839128494, 0.044617462903261185, 0.04403957352042198, 0.04391639307141304, 0.04373353347182274, 0.043788131326436996]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.00020000001, 12: 0.00020000001}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.8786, eer: 0.1963, thres: 0.1158 => acc: 0.8037, f1: 0.8037\n",
      "\n",
      "Epoch 1/13\n",
      "188/188 [==============================] - 17s 66ms/step - loss: 15.7862\n",
      "Epoch 2/13\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 2.7941\n",
      "Epoch 3/13\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.6018\n",
      "Epoch 4/13\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.1254\n",
      "Epoch 5/13\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 0.0712\n",
      "Epoch 6/13\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0665\n",
      "Epoch 7/13\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.0654\n",
      "Epoch 8/13\n",
      "188/188 [==============================] - 8s 45ms/step - loss: 0.0663\n",
      "Epoch 9/13\n",
      "188/188 [==============================] - 10s 52ms/step - loss: 0.0679\n",
      "Epoch 10/13\n",
      "188/188 [==============================] - 12s 62ms/step - loss: 0.0686\n",
      "Epoch 11/13\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0730\n",
      "Epoch 12/13\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0423\n",
      "Epoch 13/13\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 0.0409\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9414, eer: 0.1263, thres: 0.1530 => acc: 0.8737, f1: 0.8737\n",
      "loss: 0.041\n",
      "{'loss': [15.786151885986328, 2.7940738201141357, 0.60176682472229, 0.12544438242912292, 0.07118799537420273, 0.06646540015935898, 0.0654170885682106, 0.06633995473384857, 0.06794747710227966, 0.06864142417907715, 0.07298188656568527, 0.04232903569936752, 0.04089099168777466], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-1000-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [32:07<10:18, 618.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [9.604743957519531, 3.066030979156494, 0.9072335362434387, 0.32996439933776855, 0.13975562155246735, 0.07335364073514938, 0.053664226084947586, 0.048048049211502075, 0.0437348410487175, 0.043288785964250565, 0.047295596450567245, 0.04499192163348198, 0.029568523168563843, 0.029609085991978645, 0.030059082433581352, 0.026652703061699867, 0.026677407324314117, 0.0266429353505373, 0.0258307084441185, 0.025812361389398575, 0.0258321575820446, 0.025679418817162514, 0.025669105350971222, 0.02567915804684162, 0.025657130405306816], min_val_index: 24\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "{'loss': [16.456754684448242, 6.346758842468262, 1.9779884815216064, 0.6041990518569946, 0.2111593633890152, 0.10403770208358765, 0.06902096420526505, 0.056435372680425644, 0.051807139068841934, 0.05086538568139076, 0.050454121083021164, 0.05041632056236267, 0.03710940480232239, 0.036170464009046555, 0.03597775846719742, 0.03268222138285637, 0.03238977491855621, 0.03229010850191116, 0.031595628708601, 0.0315047912299633, 0.03141261264681816, 0.03153043985366821, 0.0313941054046154, 0.031208427622914314, 0.031427185982465744], 'val_loss': [9.604743957519531, 3.066030979156494, 0.9072335362434387, 0.32996439933776855, 0.13975562155246735, 0.07335364073514938, 0.053664226084947586, 0.048048049211502075, 0.0437348410487175, 0.043288785964250565, 0.047295596450567245, 0.04499192163348198, 0.029568523168563843, 0.029609085991978645, 0.030059082433581352, 0.026652703061699867, 0.026677407324314117, 0.0266429353505373, 0.0258307084441185, 0.025812361389398575, 0.0258321575820446, 0.025679418817162514, 0.025669105350971222, 0.02567915804684162, 0.025657130405306816]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 4.0000003e-05, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 1.6000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.9079, eer: 0.1594, thres: 0.1252 => acc: 0.8407, f1: 0.8407\n",
      "\n",
      "Epoch 1/25\n",
      "188/188 [==============================] - 26s 86ms/step - loss: 13.4047\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 16s 87ms/step - loss: 2.5075\n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.3642\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0985\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0613\n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.0521\n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0506\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 0.0508\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 16s 86ms/step - loss: 0.0511\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 0.0509\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 17s 88ms/step - loss: 0.0530\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 0.0516\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0363\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 0.0353\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 17s 93ms/step - loss: 0.0354\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 14s 75ms/step - loss: 0.0316\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 16s 84ms/step - loss: 0.0315\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 12s 65ms/step - loss: 0.0312\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 13s 67ms/step - loss: 0.0306\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 17s 92ms/step - loss: 0.0306\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 17s 90ms/step - loss: 0.0307\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 16s 84ms/step - loss: 0.0307\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 12s 66ms/step - loss: 0.0306\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 16s 84ms/step - loss: 0.0306\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 15s 82ms/step - loss: 0.0307\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.9416, eer: 0.1289, thres: 0.1912 => acc: 0.8712, f1: 0.8712\n",
      "loss: 0.031\n",
      "{'loss': [13.404743194580078, 2.507465124130249, 0.36420395970344543, 0.0984714925289154, 0.06131507083773613, 0.05210951343178749, 0.05061738193035126, 0.05075708404183388, 0.0510580949485302, 0.050870608538389206, 0.05304407700896263, 0.05156717076897621, 0.036344725638628006, 0.03530886769294739, 0.03540373593568802, 0.03164026886224747, 0.03145188093185425, 0.03123018704354763, 0.030635153874754906, 0.03058839589357376, 0.03074236772954464, 0.030704215168952942, 0.030638571828603745, 0.0305503960698843, 0.030653346329927444], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-1000-model-Butter33-cv1/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-1000-deep_feature_extractor-Butter33-cv1/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [48:23<00:00, 725.85s/it]\u001b[A\n",
      "100%|██████████| 5/5 [4:38:36<00:00, 3343.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n",
      "cut_off_freq: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 337\n",
      "len_exp2_user_47: 289\n",
      "674\n",
      "0.002773991790754612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/19 [01:14<22:27, 74.87s/it]\u001b[A\n",
      " 11%|█         | 2/19 [02:22<19:55, 70.35s/it]\u001b[A\n",
      " 16%|█▌        | 3/19 [03:33<18:56, 71.03s/it]\u001b[A\n",
      " 21%|██        | 4/19 [05:07<19:56, 79.76s/it]\u001b[A\n",
      " 26%|██▋       | 5/19 [06:35<19:18, 82.75s/it]\u001b[A\n",
      " 32%|███▏      | 6/19 [08:10<18:50, 86.94s/it]\u001b[A\n",
      " 37%|███▋      | 7/19 [09:43<17:49, 89.10s/it]\u001b[A\n",
      " 42%|████▏     | 8/19 [11:13<16:22, 89.33s/it]\u001b[A\n",
      " 47%|████▋     | 9/19 [12:36<14:33, 87.35s/it]\u001b[A\n",
      " 53%|█████▎    | 10/19 [14:05<13:10, 87.78s/it]\u001b[A\n",
      " 58%|█████▊    | 11/19 [15:29<11:33, 86.67s/it]\u001b[A\n",
      " 63%|██████▎   | 12/19 [17:09<10:35, 90.78s/it]\u001b[A\n",
      " 68%|██████▊   | 13/19 [19:00<09:40, 96.75s/it]\u001b[A\n",
      " 74%|███████▎  | 14/19 [20:51<08:26, 101.26s/it]\u001b[A\n",
      " 79%|███████▉  | 15/19 [22:45<07:00, 105.04s/it]\u001b[A\n",
      " 84%|████████▍ | 16/19 [24:32<05:17, 105.68s/it]\u001b[A\n",
      " 89%|████████▉ | 17/19 [26:25<03:35, 107.93s/it]\u001b[A\n",
      " 95%|█████████▍| 18/19 [28:19<01:49, 109.51s/it]\u001b[A\n",
      "100%|██████████| 19/19 [29:48<00:00, 94.14s/it] \u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 125, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [8.602618217468262, 3.652348041534424, 1.4177967309951782, 0.557289183139801, 0.22583766281604767, 0.1064765676856041, 0.0730322077870369, 0.06109796091914177, 0.0582902766764164, 0.05617038533091545, 0.05791623517870903, 0.05802079662680626, 0.04540479555726051, 0.048167772591114044, 0.04940473660826683, 0.0460255891084671, 0.045706696808338165, 0.04529851675033569, 0.045235857367515564, 0.04517265409231186, 0.04515043646097183, 0.045083533972501755, 0.04498331993818283, 0.04494183138012886, 0.04495013505220413, 0.04492408037185669], min_val_index: 25\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 8.000001e-06, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "{'loss': [15.65463638305664, 7.600696086883545, 3.261394739151001, 1.2790461778640747, 0.4632375240325928, 0.16815486550331116, 0.10268822312355042, 0.08144934475421906, 0.07410575449466705, 0.07034707069396973, 0.06854362785816193, 0.06771621108055115, 0.05781245231628418, 0.05678519979119301, 0.05684251710772514, 0.05442792922258377, 0.05412929132580757, 0.053222090005874634, 0.05364512279629707, 0.05383254587650299, 0.0533631294965744, 0.053593918681144714, 0.05334949865937233, 0.053648918867111206, 0.05345365032553673, 0.053198542445898056], 'val_loss': [8.602618217468262, 3.652348041534424, 1.4177967309951782, 0.557289183139801, 0.22583766281604767, 0.1064765676856041, 0.0730322077870369, 0.06109796091914177, 0.0582902766764164, 0.05617038533091545, 0.05791623517870903, 0.05802079662680626, 0.04540479555726051, 0.048167772591114044, 0.04940473660826683, 0.0460255891084671, 0.045706696808338165, 0.04529851675033569, 0.045235857367515564, 0.04517265409231186, 0.04515043646097183, 0.045083533972501755, 0.04498331993818283, 0.04494183138012886, 0.04495013505220413, 0.04492408037185669]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.00020000001, 13: 0.00020000001, 14: 0.00020000001, 15: 4.0000003e-05, 16: 4.0000003e-05, 17: 8.000001e-06, 18: 8.000001e-06, 19: 8.000001e-06, 20: 8.000001e-06, 21: 8.000001e-06, 22: 1.6000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7775, eer: 0.2957, thres: 0.1651 => acc: 0.7043, f1: 0.7043\n",
      "\n",
      "Epoch 1/26\n",
      "188/188 [==============================] - 7s 19ms/step - loss: 12.6428\n",
      "Epoch 2/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 3.4257\n",
      "Epoch 3/26\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.5955\n",
      "Epoch 4/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.1158\n",
      "Epoch 5/26\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0729\n",
      "Epoch 6/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0648\n",
      "Epoch 7/26\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0663\n",
      "Epoch 8/26\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0629\n",
      "Epoch 9/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0633\n",
      "Epoch 10/26\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0635\n",
      "Epoch 11/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0637\n",
      "Epoch 12/26\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0643\n",
      "Epoch 13/26\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0524\n",
      "Epoch 14/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0514\n",
      "Epoch 15/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0512\n",
      "Epoch 16/26\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0484\n",
      "Epoch 17/26\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0483\n",
      "Epoch 18/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0476\n",
      "Epoch 19/26\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0477\n",
      "Epoch 20/26\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0476\n",
      "Epoch 21/26\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0476\n",
      "Epoch 22/26\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0477\n",
      "Epoch 23/26\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0473\n",
      "Epoch 24/26\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0474\n",
      "Epoch 25/26\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0475\n",
      "Epoch 26/26\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0471\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8620, eer: 0.2134, thres: 0.1634 => acc: 0.7866, f1: 0.7866\n",
      "loss: 0.047\n",
      "{'loss': [12.642834663391113, 3.4257314205169678, 0.5954979658126831, 0.11583054810762405, 0.07285099476575851, 0.06475942581892014, 0.06628823280334473, 0.06287384778261185, 0.06327522546052933, 0.06349950283765793, 0.06368301063776016, 0.06427861750125885, 0.05235230177640915, 0.05140800029039383, 0.051167894154787064, 0.04837953299283981, 0.04834277927875519, 0.04759350046515465, 0.04774221032857895, 0.04761601239442825, 0.04757753014564514, 0.0476701483130455, 0.047292012721300125, 0.04740586131811142, 0.04745868965983391, 0.047120630741119385], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-model-Butter33-cv2/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_1_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [04:36<13:50, 276.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [14.429282188415527, 8.094974517822266, 3.928118944168091, 1.8304784297943115, 0.8822214007377625, 0.4055923521518707, 0.20177334547042847, 0.1303991973400116, 0.09612330049276352, 0.08429249376058578, 0.07326162606477737, 0.0658232569694519, 0.06566572189331055, 0.06216391921043396, 0.06032411381602287, 0.06097879260778427, 0.06636689603328705, 0.05109454691410065, 0.054108746349811554, 0.05254598706960678, 0.050639886409044266, 0.05059182643890381, 0.04866212233901024, 0.04965012148022652, 0.04991418868303299, 0.04949914664030075, 0.049116261303424835, 0.04905295744538307, 0.04894859343767166, 0.04896807670593262], min_val_index: 22\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 4.0000003e-05, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "{'loss': [22.088958740234375, 13.084685325622559, 7.164034843444824, 3.649895668029785, 1.8065744638442993, 0.7671687006950378, 0.31375589966773987, 0.1686965972185135, 0.12193576991558075, 0.09848110377788544, 0.08577130734920502, 0.07900835573673248, 0.07492813467979431, 0.07181922346353531, 0.07036778330802917, 0.06978428363800049, 0.06925375014543533, 0.05894656106829643, 0.057558249682188034, 0.05779418721795082, 0.054961107671260834, 0.0547366626560688, 0.054365068674087524, 0.05453861877322197, 0.05469916760921478, 0.05405151844024658, 0.05391395464539528, 0.053657762706279755, 0.05363517999649048, 0.05358823388814926], 'val_loss': [14.429282188415527, 8.094974517822266, 3.928118944168091, 1.8304784297943115, 0.8822214007377625, 0.4055923521518707, 0.20177334547042847, 0.1303991973400116, 0.09612330049276352, 0.08429249376058578, 0.07326162606477737, 0.0658232569694519, 0.06566572189331055, 0.06216391921043396, 0.06032411381602287, 0.06097879260778427, 0.06636689603328705, 0.05109454691410065, 0.054108746349811554, 0.05254598706960678, 0.050639886409044266, 0.05059182643890381, 0.04866212233901024, 0.04965012148022652, 0.04991418868303299, 0.04949914664030075, 0.049116261303424835, 0.04905295744538307, 0.04894859343767166, 0.04896807670593262]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.00020000001, 18: 0.00020000001, 19: 0.00020000001, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 4.0000003e-05}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7779, eer: 0.2970, thres: 0.2811 => acc: 0.7030, f1: 0.7030\n",
      "\n",
      "Epoch 1/23\n",
      "188/188 [==============================] - 15s 38ms/step - loss: 18.8191\n",
      "Epoch 2/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 7.3677\n",
      "Epoch 3/23\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 2.3865\n",
      "Epoch 4/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.5443\n",
      "Epoch 5/23\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.1572\n",
      "Epoch 6/23\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0972\n",
      "Epoch 7/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0822\n",
      "Epoch 8/23\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0718\n",
      "Epoch 9/23\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0685\n",
      "Epoch 10/23\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0672\n",
      "Epoch 11/23\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0662\n",
      "Epoch 12/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0663\n",
      "Epoch 13/23\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0677\n",
      "Epoch 14/23\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0667\n",
      "Epoch 15/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0669\n",
      "Epoch 16/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0673\n",
      "Epoch 17/23\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0691\n",
      "Epoch 18/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0544\n",
      "Epoch 19/23\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0535\n",
      "Epoch 20/23\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0532\n",
      "Epoch 21/23\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0500\n",
      "Epoch 22/23\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0500\n",
      "Epoch 23/23\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0499\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8430, eer: 0.2341, thres: 0.1460 => acc: 0.7659, f1: 0.7659\n",
      "loss: 0.050\n",
      "{'loss': [18.819072723388672, 7.367651462554932, 2.3864586353302, 0.5443492531776428, 0.1572229266166687, 0.09724285453557968, 0.08224409818649292, 0.07181672006845474, 0.06847590953111649, 0.06719442456960678, 0.06619739532470703, 0.06630965322256088, 0.06768694519996643, 0.06670694053173065, 0.06692343950271606, 0.06732770055532455, 0.06913642585277557, 0.05441512539982796, 0.05347133055329323, 0.05324520915746689, 0.05000947415828705, 0.05001333728432655, 0.049857333302497864], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-model-Butter33-cv2/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_2_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [13:02<13:42, 411.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [16.242395401000977, 7.0695719718933105, 3.1311914920806885, 1.3720077276229858, 0.6506114602088928, 0.3231518864631653, 0.15324625372886658, 0.10984797030687332, 0.09146129339933395, 0.08607461303472519, 0.08532910794019699, 0.08417610079050064, 0.08019371330738068, 0.08343231678009033, 0.08484002202749252, 0.058344222605228424, 0.05744305998086929, 0.05809745937585831, 0.05795343965291977, 0.051914799958467484, 0.0522092804312706, 0.052097540348768234, 0.05086725950241089, 0.05088267847895622, 0.050755590200424194, 0.05081290006637573, 0.050986599177122116, 0.05066468566656113, 0.0506945438683033, 0.05067197233438492], min_val_index: 27\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1e-06}\n",
      "{'loss': [26.069438934326172, 13.015055656433105, 6.099874973297119, 3.044999122619629, 1.3499912023544312, 0.5461317896842957, 0.2093200385570526, 0.12986715137958527, 0.10411905497312546, 0.09371469914913177, 0.08882205188274384, 0.08557070791721344, 0.08519298583269119, 0.08553583920001984, 0.08525571972131729, 0.06391894072294235, 0.06211162358522415, 0.06191688030958176, 0.062014687806367874, 0.057054370641708374, 0.05618941783905029, 0.055835600942373276, 0.05458129569888115, 0.05486750975251198, 0.05446561425924301, 0.05474255234003067, 0.054525453597307205, 0.05450456589460373, 0.0542600154876709, 0.053865134716033936], 'val_loss': [16.242395401000977, 7.0695719718933105, 3.1311914920806885, 1.3720077276229858, 0.6506114602088928, 0.3231518864631653, 0.15324625372886658, 0.10984797030687332, 0.09146129339933395, 0.08607461303472519, 0.08532910794019699, 0.08417610079050064, 0.08019371330738068, 0.08343231678009033, 0.08484002202749252, 0.058344222605228424, 0.05744305998086929, 0.05809745937585831, 0.05795343965291977, 0.051914799958467484, 0.0522092804312706, 0.052097540348768234, 0.05086725950241089, 0.05088267847895622, 0.050755590200424194, 0.05081290006637573, 0.050986599177122116, 0.05066468566656113, 0.0506945438683033, 0.05067197233438492]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.00020000001, 16: 0.00020000001, 17: 0.00020000001, 18: 0.00020000001, 19: 4.0000003e-05, 20: 4.0000003e-05, 21: 4.0000003e-05, 22: 8.000001e-06, 23: 8.000001e-06, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7549, eer: 0.3168, thres: 0.2445 => acc: 0.6832, f1: 0.6832\n",
      "\n",
      "Epoch 1/28\n",
      "188/188 [==============================] - 9s 26ms/step - loss: 21.6090\n",
      "Epoch 2/28\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 6.7141\n",
      "Epoch 3/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 2.1627\n",
      "Epoch 4/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.5017\n",
      "Epoch 5/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.1357\n",
      "Epoch 6/28\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0939\n",
      "Epoch 7/28\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0875\n",
      "Epoch 8/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0819\n",
      "Epoch 9/28\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0818\n",
      "Epoch 10/28\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0819\n",
      "Epoch 11/28\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0828\n",
      "Epoch 12/28\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0842\n",
      "Epoch 13/28\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0864\n",
      "Epoch 14/28\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0869\n",
      "Epoch 15/28\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0880\n",
      "Epoch 16/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0602\n",
      "Epoch 17/28\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0591\n",
      "Epoch 18/28\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0589\n",
      "Epoch 19/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0589\n",
      "Epoch 20/28\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0521\n",
      "Epoch 21/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0514\n",
      "Epoch 22/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0514\n",
      "Epoch 23/28\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0501\n",
      "Epoch 24/28\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0500\n",
      "Epoch 25/28\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0501\n",
      "Epoch 26/28\n",
      "188/188 [==============================] - 5s 24ms/step - loss: 0.0496\n",
      "Epoch 27/28\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0500\n",
      "Epoch 28/28\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0497\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8532, eer: 0.2229, thres: 0.1394 => acc: 0.7771, f1: 0.7771\n",
      "loss: 0.050\n",
      "{'loss': [21.608964920043945, 6.714132308959961, 2.162688970565796, 0.501654326915741, 0.13569727540016174, 0.0938916802406311, 0.08749668300151825, 0.08193668723106384, 0.08179233223199844, 0.08186395466327667, 0.08284354209899902, 0.08424684405326843, 0.08644890785217285, 0.08691170811653137, 0.08799217641353607, 0.06023509055376053, 0.05906686186790466, 0.05886777117848396, 0.058852728456258774, 0.052059754729270935, 0.05142766237258911, 0.05142286419868469, 0.050059475004673004, 0.05002804100513458, 0.05007409304380417, 0.049574460834264755, 0.05000736936926842, 0.049727946519851685], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-model-Butter33-cv2/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_1_3_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_1_3_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 3/4 [20:41<07:13, 433.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_123_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [14.526293754577637, 7.6207427978515625, 3.5465245246887207, 1.5909897089004517, 0.7439176440238953, 0.32489803433418274, 0.1508004367351532, 0.10234124958515167, 0.08215905725955963, 0.06857545673847198, 0.06259076297283173, 0.06004181504249573, 0.05808168649673462, 0.056107766926288605, 0.05784072354435921, 0.05505749583244324, 0.056806501001119614, 0.05591348186135292, 0.04380409047007561, 0.043994124978780746, 0.04416656866669655, 0.04075966775417328, 0.04072835296392441, 0.04074830561876297, 0.040054723620414734, 0.04005882143974304, 0.040075819939374924, 0.039953455328941345, 0.039953771978616714, 0.039940182119607925, 0.03993526101112366], min_val_index: 30\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "{'loss': [22.249191284179688, 12.718871116638184, 6.612429618835449, 3.2377395629882812, 1.5181454420089722, 0.6242299675941467, 0.23394694924354553, 0.1386222541332245, 0.10637357831001282, 0.08935488015413284, 0.07991413027048111, 0.0752929151058197, 0.07299605011940002, 0.07143697142601013, 0.07043670862913132, 0.06999655812978745, 0.0692889541387558, 0.07072112709283829, 0.05831187590956688, 0.05764036625623703, 0.057043325155973434, 0.05426792800426483, 0.05331195518374443, 0.05371341109275818, 0.05289582163095474, 0.052618466317653656, 0.052750274538993835, 0.052735209465026855, 0.05268527939915657, 0.05278221145272255, 0.05261251702904701], 'val_loss': [14.526293754577637, 7.6207427978515625, 3.5465245246887207, 1.5909897089004517, 0.7439176440238953, 0.32489803433418274, 0.1508004367351532, 0.10234124958515167, 0.08215905725955963, 0.06857545673847198, 0.06259076297283173, 0.06004181504249573, 0.05808168649673462, 0.056107766926288605, 0.05784072354435921, 0.05505749583244324, 0.056806501001119614, 0.05591348186135292, 0.04380409047007561, 0.043994124978780746, 0.04416656866669655, 0.04075966775417328, 0.04072835296392441, 0.04074830561876297, 0.040054723620414734, 0.04005882143974304, 0.040075819939374924, 0.039953455328941345, 0.039953771978616714, 0.039940182119607925, 0.03993526101112366]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.00020000001, 19: 0.00020000001, 20: 0.00020000001, 21: 4.0000003e-05, 22: 4.0000003e-05, 23: 4.0000003e-05, 24: 8.000001e-06, 25: 8.000001e-06, 26: 8.000001e-06, 27: 1.6000001e-06, 28: 1.6000001e-06, 29: 1.6000001e-06, 30: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32], [32, 32], [32, 32, 32]], 'kernels_streams': [[3], [5, 3], [7, 5, 3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3, 3], [3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1], [1, 1], [1, 1, 1]], 'paddings_streams': [['same'], ['same', 'same'], ['same', 'same', 'same']], 'dropouts_streams': [[0.25], [0.25, 0.25], [0.25, 0.25, 0.25]], 'activations_streams': [['tanh'], ['tanh', 'tanh'], ['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7653, eer: 0.3077, thres: 0.2743 => acc: 0.6923, f1: 0.6923\n",
      "\n",
      "Epoch 1/31\n",
      "188/188 [==============================] - 14s 36ms/step - loss: 18.7323\n",
      "Epoch 2/31\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 6.8301\n",
      "Epoch 3/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 1.9514\n",
      "Epoch 4/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.4483\n",
      "Epoch 5/31\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.1283\n",
      "Epoch 6/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0862\n",
      "Epoch 7/31\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0740\n",
      "Epoch 8/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0679\n",
      "Epoch 9/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0661\n",
      "Epoch 10/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0658\n",
      "Epoch 11/31\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0656\n",
      "Epoch 12/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0660\n",
      "Epoch 13/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0668\n",
      "Epoch 14/31\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 0.0664\n",
      "Epoch 15/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0666\n",
      "Epoch 16/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0671\n",
      "Epoch 17/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0681\n",
      "Epoch 18/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0675\n",
      "Epoch 19/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0524\n",
      "Epoch 20/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0516\n",
      "Epoch 21/31\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0515\n",
      "Epoch 22/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0481\n",
      "Epoch 23/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0478\n",
      "Epoch 24/31\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0479\n",
      "Epoch 25/31\n",
      "188/188 [==============================] - 7s 34ms/step - loss: 0.0471\n",
      "Epoch 26/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0470\n",
      "Epoch 27/31\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0470\n",
      "Epoch 28/31\n",
      "188/188 [==============================] - 6s 34ms/step - loss: 0.0468\n",
      "Epoch 29/31\n",
      "188/188 [==============================] - 7s 36ms/step - loss: 0.0467\n",
      "Epoch 30/31\n",
      "188/188 [==============================] - 7s 35ms/step - loss: 0.0469\n",
      "Epoch 31/31\n",
      "188/188 [==============================] - 7s 37ms/step - loss: 0.0468\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8671, eer: 0.2097, thres: 0.1690 => acc: 0.7903, f1: 0.7903\n",
      "loss: 0.047\n",
      "{'loss': [18.7323055267334, 6.830075263977051, 1.9513643980026245, 0.4482976198196411, 0.1282968372106552, 0.08622121065855026, 0.07403063774108887, 0.0679202601313591, 0.06608214229345322, 0.06583835929632187, 0.0656457394361496, 0.0659923106431961, 0.06680789589881897, 0.06639548391103745, 0.06660468876361847, 0.06711454689502716, 0.0680599957704544, 0.06754986941814423, 0.05243964120745659, 0.05158224329352379, 0.05145726725459099, 0.04812563583254814, 0.04776574671268463, 0.04793019965291023, 0.047115352004766464, 0.04700550064444542, 0.04700813069939613, 0.046843476593494415, 0.0467473603785038, 0.04692860692739487, 0.04683421924710274], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-model-Butter33-cv2/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125/SCNN-standalone-1.2-SCNN_3_123_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-cv2/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/1.2/SCNN_3_123_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [31:32<00:00, 473.05s/it]\u001b[A\n",
      " 20%|██        | 1/5 [1:03:20<4:13:23, 3800.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 167\n",
      "len_exp2_user_47: 143\n",
      "334\n",
      "0.011296191103453352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/19 [00:41<12:25, 41.44s/it]\u001b[A\n",
      " 11%|█         | 2/19 [01:21<11:32, 40.72s/it]\u001b[A\n",
      " 16%|█▌        | 3/19 [02:01<10:45, 40.37s/it]\u001b[A\n",
      " 21%|██        | 4/19 [02:42<10:06, 40.41s/it]\u001b[A\n",
      " 26%|██▋       | 5/19 [03:19<09:11, 39.42s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "clf_type=\"standalone\"\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "\n",
    "    train_set, test_set=THREE_FOLD_CV[cv_fold_idx]\n",
    "    print(f\"train_set: {train_set}\")\n",
    "    print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    #--------------butter33----------------------\n",
    "    P.cut_off_freq=33\n",
    "\n",
    "    P.Butter_per_win_argdict={\n",
    "        \"filter_order\": P.filter_order,\n",
    "        \"cut_off_freq\": P.cut_off_freq,\n",
    "        \"sampling_freq\": P.sampling_freq,\n",
    "        \"filtfilt\": P.filtfilt,\n",
    "        }   \n",
    "\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    if 29 in train_set:\n",
    "        ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "    #--------------butter33----------------------\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "    }\n",
    "\n",
    "    if 29 in train_set:\n",
    "        dfList_dict[\"dfList_exp1_user_47\"] = raw_dfList_exp1_user_47\n",
    "        dfList_dict[\"dfList_exp2_user_47\"] = ffted_dfList_exp2_user_47\n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_1_2, \"cv_fold_idx\": cv_fold_idx}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=get_training_config_dict('Butter', cv_fold_idx), save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "    \n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    \n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_1_2}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Butterworth frequency Cut-off + EMA span\n",
    "## 2.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "rival_test_hyperparameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_2_1}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[125, 250, 500, 750, 1000]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_SIZE_LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n",
      "cut_off_freq: 33, EMA span: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "674\n",
      "0.0026352922012168813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [01:11<22:30, 71.09s/it]\u001b[A\n",
      " 10%|█         | 2/20 [02:40<24:37, 82.08s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [04:22<25:46, 90.96s/it]\u001b[A\n",
      " 20%|██        | 4/20 [06:03<25:17, 94.84s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [07:38<23:43, 94.93s/it]\u001b[A\n",
      " 30%|███       | 6/20 [09:08<21:47, 93.36s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [10:44<20:23, 94.09s/it]\u001b[A\n",
      " 40%|████      | 8/20 [12:12<18:28, 92.37s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [13:27<15:54, 86.74s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "clf_type=\"standalone\"\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "\n",
    "    train_set, test_set=THREE_FOLD_CV[cv_fold_idx]\n",
    "    print(f\"train_set: {train_set}\")\n",
    "    print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    #--------------butter33-EMA20----------------------\n",
    "\n",
    "    P.cut_off_freq=33\n",
    "    P.span=20\n",
    "\n",
    "    P.Butter_per_win_argdict={\n",
    "        \"filter_order\": P.filter_order,\n",
    "        \"cut_off_freq\": P.cut_off_freq,\n",
    "        \"sampling_freq\": P.sampling_freq,\n",
    "        \"filtfilt\": P.filtfilt,\n",
    "        }   \n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "    if 29 in train_set:\n",
    "        ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "        EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    #--------------butter33-EMA20----------------------\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "    }\n",
    "\n",
    "    if 29 in train_set:\n",
    "        dfList_dict[\"dfList_exp1_user_47\"] = raw_dfList_exp1_user_47\n",
    "        dfList_dict[\"dfList_exp2_user_47\"] = EMAed_dfList_exp2_user_47\n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_2_2, \"cv_fold_idx\": cv_fold_idx}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=get_training_config_dict('Butter-EMA', cv_fold_idx), save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "    \n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_2_2}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. EMA span\n",
    "## 3.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_3_1}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.span=rival_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_3_2}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. SMA winsize\n",
    "## 4.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"train_set: {train_set+[47]}\")\n",
    "# print(f\"test_set: {test_set}\")\n",
    "# P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing_method=\"Naive\"\n",
    "# time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "# rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "# rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "# P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "# print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "# rival_test_hyperparameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_4_1}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_4_2}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Butterworth frequency Cut-off + SMA winsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.1 Naive Approach\n",
    "### Optimizing and Testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "rival_test_hyperparameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_5_1}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n",
      "cut_off_freq: 33, winsize: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was set to: 567\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "674\n",
      "0.0026352922012168813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [01:56<36:51, 116.41s/it]\u001b[A\n",
      " 10%|█         | 2/20 [03:42<33:02, 110.16s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [05:22<29:58, 105.77s/it]\u001b[A\n",
      " 20%|██        | 4/20 [07:00<27:22, 102.65s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [08:37<25:08, 100.60s/it]\u001b[A\n",
      " 30%|███       | 6/20 [10:33<24:41, 105.81s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [12:28<23:36, 108.98s/it]\u001b[A\n",
      " 40%|████      | 8/20 [14:16<21:42, 108.51s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [16:04<19:52, 108.42s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [18:04<18:40, 112.04s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [20:05<17:10, 114.55s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [22:03<15:24, 115.59s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [23:43<12:57, 111.05s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [25:42<11:20, 113.46s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [27:41<09:35, 115.04s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [29:35<07:39, 114.88s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [31:23<05:37, 112.58s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [33:23<03:50, 115.00s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [35:24<01:56, 116.62s/it]\u001b[A\n",
      "100%|██████████| 20/20 [37:15<00:00, 111.78s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:   47880, shape: (47880, 125, 6), class balance: (array([0., 1.], dtype=float32), array([23940, 23940]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_1_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [11.046598434448242, 6.373229503631592, 2.6117777824401855, 0.8367705941200256, 0.32204312086105347, 0.16401107609272003, 0.08851628750562668, 0.0581001341342926, 0.04795345291495323, 0.042256224900484085, 0.04183576628565788, 0.038790687918663025, 0.039297424256801605, 0.04165218770503998, 0.03351644426584244, 0.033454250544309616, 0.033529132604599, 0.03168799355626106, 0.031712308526039124, 0.03172925114631653, 0.03133147209882736, 0.031332310289144516, 0.03137184679508209, 0.03127146139740944, 0.03126631677150726, 0.03123767301440239], min_val_index: 25\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 8.000001e-06, 21: 8.000001e-06, 22: 8.000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "{'loss': [23.283376693725586, 14.374837875366211, 8.310855865478516, 2.8524200916290283, 0.5838606357574463, 0.25072574615478516, 0.14254935085773468, 0.09274151176214218, 0.07359649986028671, 0.06481359153985977, 0.061573199927806854, 0.060009509325027466, 0.05904630944132805, 0.05928013101220131, 0.05324182286858559, 0.052965328097343445, 0.05286921188235283, 0.05125882849097252, 0.05119906738400459, 0.05116720497608185, 0.05083443969488144, 0.050610095262527466, 0.050572626292705536, 0.050751447677612305, 0.05038929358124733, 0.05060658976435661], 'val_loss': [11.046598434448242, 6.373229503631592, 2.6117777824401855, 0.8367705941200256, 0.32204312086105347, 0.16401107609272003, 0.08851628750562668, 0.0581001341342926, 0.04795345291495323, 0.042256224900484085, 0.04183576628565788, 0.038790687918663025, 0.039297424256801605, 0.04165218770503998, 0.03351644426584244, 0.033454250544309616, 0.033529132604599, 0.03168799355626106, 0.031712308526039124, 0.03172925114631653, 0.03133147209882736, 0.031332310289144516, 0.03137184679508209, 0.03127146139740944, 0.03126631677150726, 0.03123767301440239]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.00020000001, 15: 0.00020000001, 16: 0.00020000001, 17: 4.0000003e-05, 18: 4.0000003e-05, 19: 4.0000003e-05, 20: 8.000001e-06, 21: 8.000001e-06, 22: 8.000001e-06, 23: 1.6000001e-06, 24: 1.6000001e-06, 25: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[64], [64], [64]], 'kernels_streams': [[7], [5], [3]], 'kernels_init_streams': [['glorot_normal'], ['glorot_normal'], ['glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3], [3], [3]], 'conv_kernel_regularizer_streams': [['l1_l2'], ['l1_l2'], ['l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01]], [[0.01, 0.01]], [[0.01, 0.01]]], 'strides_streams': [[1], [1], [1]], 'paddings_streams': [['same'], ['same'], ['same']], 'dropouts_streams': [[0.25], [0.25], [0.25]], 'activations_streams': [['tanh'], ['tanh'], ['tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:46:05.869532: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 15:46:06.443275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43490 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:ca:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================[ Initial State ]================================"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:46:08.913313: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-08-01 15:46:09.969299: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2023-08-01 15:46:10.815401: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-01 15:46:10.816673: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-01 15:46:10.816692: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2023-08-01 15:46:10.818522: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-08-01 15:46:10.818595: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-08-01 15:46:11.497570: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN: roc_auc: 0.7700, eer: 0.2991, thres: 0.3056 => acc: 0.7009, f1: 0.7009\n",
      "\n",
      "Epoch 1/26\n",
      "188/188 [==============================] - 5s 14ms/step - loss: 15.0719\n",
      "Epoch 2/26\n",
      "188/188 [==============================] - 3s 13ms/step - loss: 5.0437\n",
      "Epoch 3/26\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8653\n",
      "Epoch 4/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.1299\n",
      "Epoch 5/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0699\n",
      "Epoch 6/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0602\n",
      "Epoch 7/26\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0581\n",
      "Epoch 8/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0578\n",
      "Epoch 9/26\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0574\n",
      "Epoch 10/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0582\n",
      "Epoch 11/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0588\n",
      "Epoch 12/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0594\n",
      "Epoch 13/26\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0602\n",
      "Epoch 14/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0603\n",
      "Epoch 15/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0486\n",
      "Epoch 16/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0480\n",
      "Epoch 17/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0477\n",
      "Epoch 18/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0450\n",
      "Epoch 19/26\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0448\n",
      "Epoch 20/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0449\n",
      "Epoch 21/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0442\n",
      "Epoch 22/26\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0442\n",
      "Epoch 23/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0441\n",
      "Epoch 24/26\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0441\n",
      "Epoch 25/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0440\n",
      "Epoch 26/26\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0440\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8648, eer: 0.2104, thres: 0.1984 => acc: 0.7896, f1: 0.7896\n",
      "loss: 0.044\n",
      "{'loss': [15.071895599365234, 5.043694972991943, 0.8653083443641663, 0.1298988312482834, 0.06993109732866287, 0.06021636351943016, 0.05811333283782005, 0.05775666609406471, 0.05744941532611847, 0.058204781264066696, 0.05880475044250488, 0.05938056483864784, 0.060171496123075485, 0.06030667573213577, 0.04863731935620308, 0.048040084540843964, 0.047705017030239105, 0.04502660408616066, 0.04482791945338249, 0.044926758855581284, 0.044191986322402954, 0.04424653574824333, 0.044133350253105164, 0.044087354093790054, 0.044004734605550766, 0.04400911182165146], 'val_loss': []}\n",
      "Training History:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:49:39.733209: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/5.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-5.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-model-Butter33-SMA20-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/5.2/SCNN_3_1_conv_1_dense_arg_dict_default/125/SCNN-standalone-5.2-SCNN_3_1_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-SMA20-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/5.2/SCNN_3_1_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [03:42<11:08, 222.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_3_2_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [17.062219619750977, 10.958915710449219, 6.264116287231445, 3.39951229095459, 1.6262004375457764, 0.8348351120948792, 0.5005972981452942, 0.31863582134246826, 0.20969714224338531, 0.14484906196594238, 0.10562804341316223, 0.08071769773960114, 0.06941834837198257, 0.06439413130283356, 0.05685391649603844, 0.05497286096215248, 0.05640444532036781, 0.0545375794172287, 0.05118783935904503, 0.05176861956715584, 0.05098193511366844, 0.05055930092930794, 0.048788510262966156, 0.052384357899427414, 0.051307834684848785, 0.037272993475198746, 0.03812715411186218, 0.03798730671405792, 0.03494406118988991, 0.034873612225055695, 0.034831453114748, 0.034781601279973984, 0.03478185459971428, 0.0342995785176754, 0.0342685841023922, 0.03414221853017807, 0.03421304002404213, 0.03411305323243141, 0.0339849554002285, 0.033957310020923615, 0.03396609425544739, 0.03396930173039436], min_val_index: 39\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.001, 19: 0.001, 20: 0.001, 21: 0.001, 22: 0.001, 23: 0.001, 24: 0.001, 25: 0.00020000001, 26: 0.00020000001, 27: 0.00020000001, 28: 4.0000003e-05, 29: 4.0000003e-05, 30: 4.0000003e-05, 31: 4.0000003e-05, 32: 4.0000003e-05, 33: 8.000001e-06, 34: 8.000001e-06, 35: 8.000001e-06, 36: 8.000001e-06, 37: 8.000001e-06, 38: 1.6000001e-06, 39: 1.6000001e-06, 40: 1.6000001e-06, 41: 1e-06}\n",
      "{'loss': [28.621721267700195, 19.017850875854492, 11.962013244628906, 6.855172634124756, 3.3931713104248047, 1.3687292337417603, 0.6647021770477295, 0.41659852862358093, 0.2760518491268158, 0.1912308633327484, 0.1413363665342331, 0.1109628826379776, 0.0944085344672203, 0.08475308865308762, 0.07903757691383362, 0.07553831487894058, 0.07314631342887878, 0.07216352969408035, 0.0703328475356102, 0.06916648894548416, 0.06846626847982407, 0.06779368221759796, 0.06816809624433517, 0.06777312606573105, 0.06752894073724747, 0.05691888555884361, 0.05572158843278885, 0.05553896352648735, 0.0527990460395813, 0.05265359580516815, 0.05292458459734917, 0.05269395187497139, 0.05261826515197754, 0.05213005468249321, 0.05183353275060654, 0.052106767892837524, 0.0518522746860981, 0.05197396129369736, 0.05173131451010704, 0.05179126560688019, 0.052132830023765564, 0.051652200520038605], 'val_loss': [17.062219619750977, 10.958915710449219, 6.264116287231445, 3.39951229095459, 1.6262004375457764, 0.8348351120948792, 0.5005972981452942, 0.31863582134246826, 0.20969714224338531, 0.14484906196594238, 0.10562804341316223, 0.08071769773960114, 0.06941834837198257, 0.06439413130283356, 0.05685391649603844, 0.05497286096215248, 0.05640444532036781, 0.0545375794172287, 0.05118783935904503, 0.05176861956715584, 0.05098193511366844, 0.05055930092930794, 0.048788510262966156, 0.052384357899427414, 0.051307834684848785, 0.037272993475198746, 0.03812715411186218, 0.03798730671405792, 0.03494406118988991, 0.034873612225055695, 0.034831453114748, 0.034781601279973984, 0.03478185459971428, 0.0342995785176754, 0.0342685841023922, 0.03414221853017807, 0.03421304002404213, 0.03411305323243141, 0.0339849554002285, 0.033957310020923615, 0.03396609425544739, 0.03396930173039436]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.001, 19: 0.001, 20: 0.001, 21: 0.001, 22: 0.001, 23: 0.001, 24: 0.001, 25: 0.00020000001, 26: 0.00020000001, 27: 0.00020000001, 28: 4.0000003e-05, 29: 4.0000003e-05, 30: 4.0000003e-05, 31: 4.0000003e-05, 32: 4.0000003e-05, 33: 8.000001e-06, 34: 8.000001e-06, 35: 8.000001e-06, 36: 8.000001e-06, 37: 8.000001e-06, 38: 1.6000001e-06, 39: 1.6000001e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2, 0.2, 0.2], 'filters_streams': [[32, 32], [32, 32], [32, 32]], 'kernels_streams': [[7, 3], [5, 3], [3, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal'], ['glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3], [3, 3], [3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2'], ['l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]], [[0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1], [1, 1], [1, 1]], 'paddings_streams': [['same', 'same'], ['same', 'same'], ['same', 'same']], 'dropouts_streams': [[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], 'activations_streams': [['tanh', 'tanh'], ['tanh', 'tanh'], ['tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7755, eer: 0.2947, thres: 0.4097 => acc: 0.7053, f1: 0.7053\n",
      "\n",
      "Epoch 1/40\n",
      "188/188 [==============================] - 10s 27ms/step - loss: 20.9568\n",
      "Epoch 2/40\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 9.1292\n",
      "Epoch 3/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 3.1227\n",
      "Epoch 4/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.7169\n",
      "Epoch 5/40\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.1943\n",
      "Epoch 6/40\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0989\n",
      "Epoch 7/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0717\n",
      "Epoch 8/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0639\n",
      "Epoch 9/40\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0620\n",
      "Epoch 10/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0620\n",
      "Epoch 11/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0628\n",
      "Epoch 12/40\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0618\n",
      "Epoch 13/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0625\n",
      "Epoch 14/40\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0628\n",
      "Epoch 15/40\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0632\n",
      "Epoch 16/40\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0641\n",
      "Epoch 17/40\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0643\n",
      "Epoch 18/40\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0646\n",
      "Epoch 19/40\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0652\n",
      "Epoch 20/40\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0656\n",
      "Epoch 21/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0656\n",
      "Epoch 22/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0659\n",
      "Epoch 23/40\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0660\n",
      "Epoch 24/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0662\n",
      "Epoch 25/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0674\n",
      "Epoch 26/40\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0511\n",
      "Epoch 27/40\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0501\n",
      "Epoch 28/40\n",
      "188/188 [==============================] - 5s 29ms/step - loss: 0.0501\n",
      "Epoch 29/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0463\n",
      "Epoch 30/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0462\n",
      "Epoch 31/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0460\n",
      "Epoch 32/40\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0460\n",
      "Epoch 33/40\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0459\n",
      "Epoch 34/40\n",
      "188/188 [==============================] - 5s 26ms/step - loss: 0.0453\n",
      "Epoch 35/40\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0451\n",
      "Epoch 36/40\n",
      "188/188 [==============================] - 5s 25ms/step - loss: 0.0451\n",
      "Epoch 37/40\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0452\n",
      "Epoch 38/40\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0452\n",
      "Epoch 39/40\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0449\n",
      "Epoch 40/40\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0450\n",
      "================================[ Final State ]================================\n",
      "TRAIN: roc_auc: 0.8630, eer: 0.2117, thres: 0.1757 => acc: 0.7883, f1: 0.7883\n",
      "loss: 0.045\n",
      "{'loss': [20.956768035888672, 9.129182815551758, 3.122668981552124, 0.7168548703193665, 0.194301575422287, 0.09889870882034302, 0.07167168706655502, 0.06390603631734848, 0.06202838569879532, 0.062012962996959686, 0.06282690912485123, 0.061769723892211914, 0.06248493120074272, 0.06278946250677109, 0.06320583820343018, 0.06406404823064804, 0.06426697969436646, 0.06461291760206223, 0.06516770273447037, 0.06557738780975342, 0.06557081639766693, 0.06588584184646606, 0.06596026569604874, 0.06619521975517273, 0.06743772327899933, 0.05111919343471527, 0.050074148923158646, 0.05012083798646927, 0.04626404494047165, 0.046188708394765854, 0.046030543744564056, 0.04604017361998558, 0.045904193073511124, 0.04533590003848076, 0.04509943351149559, 0.04508786275982857, 0.04520922526717186, 0.04520430788397789, 0.04487612843513489, 0.04500975087285042], 'val_loss': []}\n",
      "Training History:\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/5.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-5.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-model-Butter33-SMA20-cv0/assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/5.2/SCNN_3_2_conv_1_dense_arg_dict_default/125/SCNN-standalone-5.2-SCNN_3_2_conv_1_dense_arg_dict_default-125-deep_feature_extractor-Butter33-SMA20-cv0/assets\n",
      "saved model at clip=False_experiments_results/SCNN_trained_models/SCNN-standalone/5.2/SCNN_3_2_conv_1_dense_arg_dict_default/125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 2/4 [13:38<14:44, 442.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCNN_1_3_conv_1_dense_arg_dict_default\n",
      "loss_record_dict: [18.66312026977539, 10.949298858642578, 7.341053485870361, 3.514509916305542, 1.6383378505706787, 0.898186981678009, 0.546657145023346, 0.3647083640098572, 0.2521425485610962, 0.18585464358329773, 0.14025811851024628, 0.10755830258131027, 0.086550273001194, 0.08144301921129227, 0.06857037544250488, 0.06552053242921829, 0.06901140511035919, 0.062412697821855545, 0.06286408007144928, 0.060765936970710754, 0.06523219496011734, 0.06113116815686226, 0.04115040972828865, 0.041816361248493195, 0.040159374475479126, 0.04050064831972122, 0.04172297567129135, 0.03614763915538788, 0.03537073731422424, 0.03541455417871475, 0.03570428490638733, 0.03426877409219742, 0.03427722305059433, 0.03424777835607529, 0.0339910164475441, 0.033985450863838196, 0.03397851437330246, 0.03394975885748863], min_val_index: 37\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.001, 19: 0.001, 20: 0.001, 21: 0.001, 22: 0.00020000001, 23: 0.00020000001, 24: 0.00020000001, 25: 0.00020000001, 26: 0.00020000001, 27: 4.0000003e-05, 28: 4.0000003e-05, 29: 4.0000003e-05, 30: 4.0000003e-05, 31: 8.000001e-06, 32: 8.000001e-06, 33: 8.000001e-06, 34: 1.6000001e-06, 35: 1.6000001e-06, 36: 1.6000001e-06, 37: 1e-06}\n",
      "{'loss': [33.384071350097656, 19.9542293548584, 11.974198341369629, 7.393381595611572, 3.3204598426818848, 1.3079711198806763, 0.6965958476066589, 0.46273839473724365, 0.32346558570861816, 0.23486347496509552, 0.1785278171300888, 0.14109712839126587, 0.11532463133335114, 0.09981665760278702, 0.09085413068532944, 0.08485997468233109, 0.08236994594335556, 0.0805775597691536, 0.07958382368087769, 0.07889281213283539, 0.07996949553489685, 0.08073507994413376, 0.062021926045417786, 0.06098959594964981, 0.06127185747027397, 0.06099437177181244, 0.061142999678850174, 0.05590454861521721, 0.055440474301576614, 0.055639274418354034, 0.055696580559015274, 0.054471615701913834, 0.054237060248851776, 0.054310392588377, 0.054155025631189346, 0.054226845502853394, 0.05431718751788139, 0.05416823551058769], 'val_loss': [18.66312026977539, 10.949298858642578, 7.341053485870361, 3.514509916305542, 1.6383378505706787, 0.898186981678009, 0.546657145023346, 0.3647083640098572, 0.2521425485610962, 0.18585464358329773, 0.14025811851024628, 0.10755830258131027, 0.086550273001194, 0.08144301921129227, 0.06857037544250488, 0.06552053242921829, 0.06901140511035919, 0.062412697821855545, 0.06286408007144928, 0.060765936970710754, 0.06523219496011734, 0.06113116815686226, 0.04115040972828865, 0.041816361248493195, 0.040159374475479126, 0.04050064831972122, 0.04172297567129135, 0.03614763915538788, 0.03537073731422424, 0.03541455417871475, 0.03570428490638733, 0.03426877409219742, 0.03427722305059433, 0.03424777835607529, 0.0339910164475441, 0.033985450863838196, 0.03397851437330246, 0.03394975885748863]}\n",
      "{0: 0.001, 1: 0.001, 2: 0.001, 3: 0.001, 4: 0.001, 5: 0.001, 6: 0.001, 7: 0.001, 8: 0.001, 9: 0.001, 10: 0.001, 11: 0.001, 12: 0.001, 13: 0.001, 14: 0.001, 15: 0.001, 16: 0.001, 17: 0.001, 18: 0.001, 19: 0.001, 20: 0.001, 21: 0.001, 22: 0.00020000001, 23: 0.00020000001, 24: 0.00020000001, 25: 0.00020000001, 26: 0.00020000001, 27: 4.0000003e-05, 28: 4.0000003e-05, 29: 4.0000003e-05, 30: 4.0000003e-05, 31: 8.000001e-06, 32: 8.000001e-06, 33: 8.000001e-06, 34: 1.6000001e-06, 35: 1.6000001e-06, 36: 1.6000001e-06, 37: 1e-06}\n",
      "Using Model variant multi_head_fcn...\n",
      "{'input_dropout_streams': [0.2], 'filters_streams': [[64, 64, 64]], 'kernels_streams': [[7, 5, 3]], 'kernels_init_streams': [['glorot_normal', 'glorot_normal', 'glorot_normal']], 'kernels_Max_Norm_constraint_streams': [[3, 3, 3]], 'conv_kernel_regularizer_streams': [['l1_l2', 'l1_l2', 'l1_l2']], 'conv_kernel_regularizer_strength_streams': [[[0.01, 0.01], [0.01, 0.01], [0.01, 0.01]]], 'strides_streams': [[1, 1, 1]], 'paddings_streams': [['same', 'same', 'same']], 'dropouts_streams': [[0.25, 0.25, 0.25]], 'activations_streams': [['tanh', 'tanh', 'tanh']], 'dense_layers': [64], 'dense_kernel_Max_Norm_constraints': [5], 'dense_kernel_regularizer': ['l1_l2'], 'dense_kernel_regularizer_strength': [[0.01, 0.01]], 'dense_kernel_inits': ['he_normal'], 'dense_dropouts': [0], 'dense_activations': ['linear'], 'loss_func_name': 'k_contrastive_loss', 'contrastive_loss_margin': 0.5, 'optimizer_name': 'Adam', 'optimizer_lr': 0.001, 'optimizer_decay': None, 'batch_size': 256}\n",
      "================================[ Initial State ]================================\n",
      "TRAIN: roc_auc: 0.7574, eer: 0.3105, thres: 0.2962 => acc: 0.6895, f1: 0.6895\n",
      "\n",
      "Epoch 1/38\n",
      "188/188 [==============================] - 7s 19ms/step - loss: 24.7664\n",
      "Epoch 2/38\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 9.2781\n",
      "Epoch 3/38\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 3.5250\n",
      "Epoch 4/38\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 1.1208\n",
      "Epoch 5/38\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.2860\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "clf_type=\"standalone\"\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "\n",
    "    train_set, test_set=THREE_FOLD_CV[cv_fold_idx]\n",
    "    print(f\"train_set: {train_set}\")\n",
    "    print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    # --------------butter33-SMA20----------------------\n",
    "    P.winsize=20\n",
    "    P.cut_off_freq=33\n",
    "\n",
    "    P.Butter_per_win_argdict={\n",
    "        \"filter_order\": P.filter_order,\n",
    "        \"cut_off_freq\": P.cut_off_freq,\n",
    "        \"sampling_freq\": P.sampling_freq,\n",
    "        \"filtfilt\": P.filtfilt,\n",
    "         }   \n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "    # only if user 47 in train_set\n",
    "    if 29 in train_set:\n",
    "        ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "        SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "    # --------------butter33-SMA20----------------------\n",
    "\n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "    }\n",
    "\n",
    "    if 29 in train_set:\n",
    "        dfList_dict[\"dfList_exp1_user_47\"] = raw_dfList_exp1_user_47\n",
    "        dfList_dict[\"dfList_exp2_user_47\"] = SMAed_dfList_exp2_user_47\n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_5_2, \"cv_fold_idx\": cv_fold_idx}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=get_training_config_dict('Butter-SMA', cv_fold_idx), save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    \n",
    "    rival_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/WACA-{clf_type}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "    rival_test_hyperparameters_df = pd.read_json(rival_test_hyperparameters_file_name)\n",
    "\n",
    "    P.winsize=rival_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "    P.cut_off_freq=rival_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "    \n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_5_2}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=OVERLAP, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The effect of Varying Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for clf_type in tqdm(CLASSIFIER_TYPE_LST):\n",
    "    overlap*=0.01\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "    max_num_windows=max(len(getIndices(sampleSize=max_window_size, step=step_width, numSamplePoints=P.num_sample_points_per_exp)), 100)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "    save_info_dict={\"model_classifier_type\": f\"SCNN-{clf_type}\", \"exp_num\": EXP_NUM_6}\n",
    "    model_training_with_training_config_dict(dfList_dict=dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, overlap=overlap, \n",
    "                                             training_config_dict=TRAINING_CONFIG_DICT, save_info_dict=save_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=return_and_save_final_result_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, \n",
    "                                                             exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.style.hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df.style.hide(axis='index').to_latex()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
