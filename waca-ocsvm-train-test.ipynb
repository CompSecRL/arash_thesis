{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "EXP_PATH_NAME=\"WACA-OCSVM\"\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "Numpy Seed was set to: 567\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "from sklearn.svm import OneClassSVM\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "%run ./Classification_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "\n",
    "FINAL_EXP_RESULTS_PATH=\"clip=False_experiments_results\"\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"Numpy Seed was set to: {SEED}\")\n",
    "\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__dir__()\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "        \n",
    "    user_ids: list\n",
    "    num_sample_points_per_exp: int\n",
    "    exp_begin_cutoff_idx: int\n",
    "    exp_end_cutoff_idx: int\n",
    "        \n",
    "    \n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    window_size: int  # After resampling\n",
    "    ocsvm_step_width: int  # After resampling\n",
    "    scaler: str  # StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_kernel: str # ocsvm kernel\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects=29,\n",
    "    max_test_subjects=10,\n",
    "    user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49],\n",
    "    num_sample_points_per_exp=21000,\n",
    "    exp_begin_cutoff_idx=500,\n",
    "    exp_end_cutoff_idx=-500,\n",
    "    seconds_per_subject_train=210,\n",
    "    seconds_per_subject_test=210,    \n",
    "    window_size=250,\n",
    "    ocsvm_step_width=250,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_kernel=\"rbf\",\n",
    "    ocsvm_nu=None,\n",
    "    ocsvm_gamma=None,\n",
    "    feature_cols=[\n",
    "        \"x_a\",\n",
    "        \"y_a\",\n",
    "        \"z_a\",\n",
    "        \"x_g\",\n",
    "        \"y_g\",\n",
    "        \"z_g\",\n",
    "    ],\n",
    "    exclude_subjects=[],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM_125 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=125\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "\n",
    "VALID_ROBUST_OCSVM_250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_2000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=2000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "# NORMALIZER_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_NORMALIZER_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-NORMALIZER-OCSVM\",\n",
    "    scaler=\"Normalizer\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.074,\n",
    "    ocsvm_gamma= 0.029,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM_2000\n",
    "P.ocsvm_step_width = int(P.window_size * .5)\n",
    "P.classifier=\"OCSVM\"\n",
    "P.ocsvm_kernel = \"rbf\"\n",
    "P.train_cores=1 # 20 cores for every user and 1 core for the nested crossval function\n",
    "P.test_cores=2 # 10 cores for every user and 2 for the nested crossval function\n",
    "\n",
    "P.scaler_clip=False\n",
    "P.is_NN=False\n",
    "\n",
    "param_dist = {\n",
    "    \"model__gamma\": np.logspace(-9, 3), \n",
    "    \"model__nu\": np.linspace(0.0001, 0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>VALID-ROBUST-OCSVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_subjects</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_test_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_ids</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sample_points_per_exp</th>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_begin_cutoff_idx</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_end_cutoff_idx</th>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_train</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_test</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_step_width</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_scope</th>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_global</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_kernel</th>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_nu</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_gamma</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_cols</th>\n",
       "      <td>[x_a, y_a, z_a, x_g, y_g, z_g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclude_subjects</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Value\n",
       "name                                                      VALID-ROBUST-OCSVM\n",
       "frequency                                                                100\n",
       "max_subjects                                                              29\n",
       "max_test_subjects                                                         10\n",
       "user_ids                   [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...\n",
       "num_sample_points_per_exp                                              21000\n",
       "exp_begin_cutoff_idx                                                     500\n",
       "exp_end_cutoff_idx                                                      -500\n",
       "seconds_per_subject_train                                                210\n",
       "seconds_per_subject_test                                                 210\n",
       "window_size                                                             2000\n",
       "ocsvm_step_width                                                        1000\n",
       "scaler                                                          RobustScaler\n",
       "scaler_scope                                                         subject\n",
       "scaler_global                                                          False\n",
       "ocsvm_kernel                                                             rbf\n",
       "ocsvm_nu                                                                None\n",
       "ocsvm_gamma                                                             None\n",
       "feature_cols                                  [x_a, y_a, z_a, x_g, y_g, z_g]\n",
       "exclude_subjects                                                          []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(utils_eer, greater_is_better=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_eer_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n",
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n",
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n",
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n",
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n",
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n",
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n",
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n",
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n",
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n",
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n",
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n",
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n",
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n",
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n",
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n",
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n",
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n",
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n",
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n",
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n",
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n",
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n",
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n",
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n",
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n",
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n",
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n",
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n"
     ]
    }
   ],
   "source": [
    "#include 47 later\n",
    "# user_ids = [9]\n",
    "df_exps_dict = load_data_frames(P.user_ids, P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, P.num_sample_points_per_exp)\n",
    "raw_dfList_exp1, raw_dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# dfList_exp1[i][['x_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['y_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['z_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['x_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['y_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['z_g']].plot(figsize=(30, 6))\n",
    "\n",
    "# dfList_exp2[i][['x_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['y_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['z_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['x_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['y_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['z_g']].plot(figsize=(30, 6))\n",
    "# exp1 idx 10 has corrupted data frist 50 sec\n",
    "# exp2 idx 12 has some artifacts first 12.5 sec\n",
    "# exp1 idx 17 has some artifacts first 75 sec\n",
    "# exp2 idx 23 has some artifacts last 6.5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "randomized_data_idx = list(range(len(P.user_ids)))\n",
    "random.Random(SEED).shuffle(randomized_data_idx)\n",
    "split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "train_set = randomized_data_idx[: split_idx]\n",
    "test_set = randomized_data_idx[split_idx: ]\n",
    "# train_set = randomized_data_idx\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")\n",
    "# train_set = test_set\n",
    "# test_set = train_set\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n",
      "47) accel_count: 17718, gyro_count: 18353\n"
     ]
    }
   ],
   "source": [
    "num_sample_points_per_exp_user_47 = 18000\n",
    "df_exps_dict_user_47 = load_data_frames([47], P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "raw_dfList_exp2_user_47 = dfList_exp2_user_47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_set: {train_set}\")\n",
    "# print(f\"X_exp1_train_dic: {X_exp1_train_dic.keys()}\")\n",
    "# print(f\"X_exp2_train_dic: {X_exp2_train_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_set: {test_set}\")\n",
    "# print(f\"X_exp1_test_dic: {X_exp1_test_dic.keys()}\")\n",
    "# print(f\"X_exp2_test_dic: {X_exp2_test_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH_NAME\n",
    "THREE_FOLD_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOW_SIZE_LST=[2000]\n",
    "DASH_MACRO_NUM\n",
    "THREE_FOLD_CV\n",
    "# P.scaler=None\n",
    "P.scaler\n",
    "P.smoothing\n",
    "preprocessing_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. No Smoothing\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = None\n",
    "\n",
    "\n",
    "# /clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\n",
    "preprocessing_method=None\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": raw_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "# for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "#     train_set, test_set = THREE_FOLD_CV[cv_fold_idx]\n",
    "#     print(f\"train_set: {train_set}\")\n",
    "#     print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    \n",
    "#     test_dict_key=DASH_MACRO_NUM\n",
    "#     EER_df_train_dict[test_dict_key] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "#                                                                                                extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "#                                                                                                param_dist=param_dist)\n",
    "\n",
    "#     with open(train_file_name, \"a\") as f:\n",
    "#         f.write(\"\\n\" + \"-\"*22 + f\"Training results for cv_fold_idx: {cv_fold_idx}\" + \"-\"*22 + \"\\n\")        \n",
    "#         f.write(f\"\\Test_dict_key: {test_dict_key}\\n\")\n",
    "#         f.write(EER_df_train_dict[test_dict_key].to_string())\n",
    "\n",
    "\n",
    "\n",
    "#     min_key=test_dict_key\n",
    "#     EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "#                                                                                        extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "#                                                                                        best_param_df=EER_df_train_dict[min_key])\n",
    "#     with open(test_file_name, \"a\") as f:\n",
    "#         f.write(\"\\n\" + \"-\"*22 + f\"Testing results for cv_fold_idx: {cv_fold_idx}\" + \"-\"*22 + \"\\n\")\n",
    "#         f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "#         f.write(EER_df_test_dict[min_key].to_string())\n",
    "#     #-------\n",
    "#     #-------\n",
    "#     key_column= [\"cut_off_freq\"]\n",
    "#     EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "#     eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "#     EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df_cv{cv_fold_idx}.json')\n",
    "#     eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df_cv{cv_fold_idx}.json')\n",
    "#     #-------\n",
    "\n",
    "min_key=DASH_MACRO_NUM\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Butterworth frequency Cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "old_test_hyperparameters_df\n",
    "oth=old_test_hyperparameters_df\n",
    "oth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "min_key=P.cut_off_freq\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": ffted_dfList_exp1,\n",
    "            \"dfList_exp2\": ffted_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for cut_off_freq in tqdm(CUT_OFF_FREQ_RANGE):\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": ffted_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                param_dist=param_dist)\n",
    "\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "        \n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "\n",
    "\n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "min_key=P.cut_off_freq\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": ffted_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for cut_off_freq in tqdm(CUT_OFF_FREQ_RANGE):\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                    param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "\n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Butterworth frequency Cut-off + EMA span\n",
    "## 2.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "min_key= P.cut_off_freq, P.span\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "    \n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_span_pairs):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, span = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.span=span\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"span: {P.span}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------  \n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "P.EMA_per_win_span=P.span\n",
    "\n",
    "min_key= P.cut_off_freq, P.span\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_span_pairs):\n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, span = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=cut_off_freq\n",
    "    \n",
    "    \n",
    "    P.span=span\n",
    "    P.EMA_per_win_span=span\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"span: {P.span}\")\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EMA span\n",
    "## 3.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "min_key=P.span\n",
    "print(f\"EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "\n",
    "EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for span in tqdm(EMA_SPAN_RANGE):\n",
    "    P.span=span\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                    param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "    \n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "P.EMA_per_win_span=P.span\n",
    "min_key=P.span\n",
    "print(f\"EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for span in tqdm(EMA_SPAN_RANGE):\n",
    "    P.span=span\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                    param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SMA winsize\n",
    "## 4.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "min_key=P.winsize\n",
    "print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "    \n",
    "\n",
    "\n",
    "key_column= [\"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for winsize in tqdm(SMA_WINSIZE_RANGE):\n",
    "    P.winsize=winsize\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                       param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.SMA_per_win_winsize=P.winsize\n",
    "min_key=P.winsize\n",
    "print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for winsize in tqdm(SMA_WINSIZE_RANGE):\n",
    "    P.winsize=winsize\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                       param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Butterworth frequency Cut-off + SMA winsize\n",
    "## 5.1 Naive Approach\n",
    "### Optimizing and Testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "min_key= P.cut_off_freq, P.winsize\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_winsize_pairs):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, winsize = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.winsize=winsize\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "min_key= P.cut_off_freq, P.winsize\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "    \n",
    "        \n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_winsize_pairs):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, winsize = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.winsize=winsize\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "    \n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The effect of Varying Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap: 0.01\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  8.098896443843842\n",
      "MakeWACAXExpDicUnknown Time:  38.60075428336859\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15494.29it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:32, 16.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21879.52it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:31<00:15, 15.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14926.35it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:45<00:00, 15.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20908.79it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20203.78it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:06<00:09,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17534.72it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:09<00:06,  3.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18600.02it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:12<00:03,  3.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 8192.80it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:15<00:00,  3.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [01:49<14:39, 109.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  3.654866699129343\n",
      "MakeWACAXExpDicUnknown Time:  19.957633148878813\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20934.88it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:08<00:17,  8.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20345.88it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:17<00:08,  8.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20976.76it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:25<00:00,  8.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 22345.79it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20585.54it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:03<00:05,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16247.55it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:05<00:03,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18876.26it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:06<00:01,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 21339.63it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:08<00:00,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [02:48<09:17, 79.60s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.0593677135184407\n",
      "MakeWACAXExpDicUnknown Time:  10.275187748484313\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20092.47it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23166.55it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21034.62it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:16<00:00,  5.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16209.87it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20799.92it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21055.74it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18157.16it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 14445.68it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [03:22<05:52, 58.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.515742003917694\n",
      "MakeWACAXExpDicUnknown Time:  7.48105703946203\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15732.57it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:10,  5.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19436.07it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:10<00:05,  5.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15563.28it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:15<00:00,  5.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 11591.28it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22417.45it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17292.53it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 20810.24it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 19944.38it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [03:50<03:53, 46.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.4271309580653906\n",
      "MakeWACAXExpDicUnknown Time:  6.162808519788086\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20697.28it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 9357.06it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:04,  4.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24585.60it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:15<00:00,  5.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 23147.37it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19710.08it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20836.09it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22832.36it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 23689.94it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [04:17<02:38, 39.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.1523620346561074\n",
      "MakeWACAXExpDicUnknown Time:  6.219248995184898\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21410.43it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:07<00:14,  7.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20743.34it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:13<00:06,  6.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 26512.67it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20515.06it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22844.79it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24723.28it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 27077.50it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 26689.81it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [04:48<01:49, 36.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.203616394661367\n",
      "MakeWACAXExpDicUnknown Time:  6.578476556576788\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15851.49it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:12,  6.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17997.44it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19673.10it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 28407.07it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21071.61it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22203.83it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 20636.18it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 22963.61it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [05:19<01:09, 34.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.02846076246351\n",
      "MakeWACAXExpDicUnknown Time:  5.419889377430081\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 22086.91it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:12,  6.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23001.39it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22592.53it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18315.74it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22969.90it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23147.37it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 17137.09it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 24463.72it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [05:47<00:32, 32.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.0178816579282284\n",
      "MakeWACAXExpDicUnknown Time:  3.7912202328443527\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12023.23it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17133.59it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:10<00:05,  5.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17851.90it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:17<00:00,  5.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21426.84it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19108.45it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24001.74it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22714.89it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 20555.28it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [06:12<00:00, 41.44s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 170\n",
      "len_exp2_user_47: 146\n",
      "MakeWACAXExpDicOwner Time:  3.0085429744794965\n",
      "MakeWACAXExpDicUnknown Time:  18.191877293400466\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11484.95it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12997.53it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8665.92it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13374.69it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8683.86it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:24<03:12, 24.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 85\n",
      "len_exp2_user_47: 72\n",
      "MakeWACAXExpDicOwner Time:  1.6425723657011986\n",
      "MakeWACAXExpDicUnknown Time:  9.320150422863662\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10441.38it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10650.85it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7978.51it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11028.94it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 5896.67it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [00:37<02:03, 17.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 42\n",
      "len_exp2_user_47: 36\n",
      "MakeWACAXExpDicOwner Time:  0.8776673413813114\n",
      "MakeWACAXExpDicUnknown Time:  4.711092174984515\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 8996.79it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9404.27it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6735.67it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 6345.39it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11519.65it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [00:44<01:16, 12.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 28\n",
      "len_exp2_user_47: 24\n",
      "MakeWACAXExpDicOwner Time:  0.6049384465441108\n",
      "MakeWACAXExpDicUnknown Time:  3.8998494977131486\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10089.74it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6212.86it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9489.38it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8245.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9224.33it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [00:50<00:50, 10.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 21\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  0.6516987197101116\n",
      "MakeWACAXExpDicUnknown Time:  2.6850986927747726\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13888.42it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 7986.11it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13622.29it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 12683.11it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10749.11it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [00:54<00:32,  8.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 16\n",
      "len_exp2_user_47: 14\n",
      "MakeWACAXExpDicOwner Time:  0.45888128131628036\n",
      "MakeWACAXExpDicUnknown Time:  2.377389690838754\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 5536.30it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9476.51it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11732.32it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8356.85it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 15152.83it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [00:58<00:20,  6.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  0.4439499843865633\n",
      "MakeWACAXExpDicUnknown Time:  2.036906295455992\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10485.76it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11428.62it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13311.03it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 16288.56it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10053.46it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [01:02<00:11,  5.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  0.3976971749216318\n",
      "MakeWACAXExpDicUnknown Time:  2.67906510271132\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10472.67it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  5.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9008.38it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  5.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12846.26it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  5.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8363.52it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7222.84it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [01:06<00:05,  5.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 10\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  0.38526147697120905\n",
      "MakeWACAXExpDicUnknown Time:  1.8038084115833044\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 8703.68it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  5.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9300.01it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14079.57it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8794.93it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8639.14it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [01:10<00:00,  7.81s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 29}\n",
      "test_set: {1, 3, 5, 6, 16, 19, 22, 24, 25, 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 170\n",
      "len_exp2_user_47: 146\n",
      "MakeWACAXExpDicOwner Time:  6.974567290395498\n",
      "MakeWACAXExpDicUnknown Time:  48.95133208949119\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15046.83it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:24<00:49, 24.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21231.61it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:46<00:22, 22.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21664.79it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:04<00:00, 21.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 22086.91it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19200.29it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:06<00:09,  3.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 25520.56it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:09<00:06,  3.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18604.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:13<00:03,  3.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17772.47it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:16<00:00,  3.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [02:18<18:27, 138.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 85\n",
      "len_exp2_user_47: 72\n",
      "MakeWACAXExpDicOwner Time:  3.5842079427093267\n",
      "MakeWACAXExpDicUnknown Time:  20.154762452468276\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 26412.49it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:09<00:18,  9.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15531.58it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:20<00:10, 10.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18641.35it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:31<00:00, 10.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21492.72it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22417.45it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14295.51it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:02,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 10549.05it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 19920.70it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:07<00:00,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [03:21<10:58, 94.09s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 42\n",
      "len_exp2_user_47: 36\n",
      "MakeWACAXExpDicOwner Time:  2.0290301144123077\n",
      "MakeWACAXExpDicUnknown Time:  14.089617162011564\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15586.41it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15360.94it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20799.92it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 19807.81it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14100.87it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23858.38it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 24420.98it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 23844.82it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [04:01<06:57, 69.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 28\n",
      "len_exp2_user_47: 24\n",
      "MakeWACAXExpDicOwner Time:  1.4365299874916673\n",
      "MakeWACAXExpDicUnknown Time:  9.679211930371821\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18914.56it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21919.54it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 25289.74it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 24528.09it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20164.92it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17144.10it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19576.68it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 18024.51it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [04:37<04:40, 56.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 21\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  1.2969455029815435\n",
      "MakeWACAXExpDicUnknown Time:  5.824820451438427\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 24125.99it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:07<00:14,  7.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15839.52it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:14<00:07,  7.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22659.67it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:22<00:00,  7.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20155.23it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 25474.06it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22863.47it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 21236.98it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 24230.53it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [05:10<03:10, 47.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 16\n",
      "len_exp2_user_47: 14\n",
      "MakeWACAXExpDicOwner Time:  1.0850357795134187\n",
      "MakeWACAXExpDicUnknown Time:  5.698524680919945\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20267.23it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19604.13it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:04,  4.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17901.43it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:14<00:00,  4.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 27165.18it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16244.40it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24694.17it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19512.93it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 20692.18it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [05:35<02:00, 40.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  1.051544020883739\n",
      "MakeWACAXExpDicUnknown Time:  5.9870230024680495\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21366.81it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22616.90it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14070.12it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17836.72it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23777.23it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22174.49it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22387.53it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17682.56it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [06:04<01:12, 36.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  0.9918067725375295\n",
      "MakeWACAXExpDicUnknown Time:  5.5931746531277895\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21608.99it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20015.77it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15741.43it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:17<00:00,  5.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 26462.49it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 24686.90it/s]\n",
      "/tmp/ipykernel_3197292/1897070050.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 30207.45it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19549.31it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16733.71it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [06:31<00:33, 33.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 10\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  1.0103327156975865\n",
      "MakeWACAXExpDicUnknown Time:  4.985259951092303\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16175.49it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23001.39it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21161.98it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:16<00:00,  5.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15966.14it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16045.54it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16039.40it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19901.80it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 30023.65it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [06:57<00:00, 46.37s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.723875345662236\n",
      "MakeWACAXExpDicUnknown Time:  17.916942971758544\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13948.47it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12203.39it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 5692.60it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 5997.00it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12045.67it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:23<03:09, 23.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.8022535471245646\n",
      "MakeWACAXExpDicUnknown Time:  8.958262667991221\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11615.35it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8743.60it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9116.07it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13902.23it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8128.50it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [00:36<02:00, 17.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.9005413874983788\n",
      "MakeWACAXExpDicUnknown Time:  4.906572541221976\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9194.00it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10968.37it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14169.95it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9639.86it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10182.82it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [00:43<01:16, 12.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.6482502184808254\n",
      "MakeWACAXExpDicUnknown Time:  3.4875416569411755\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 14051.27it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 5550.22it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9102.22it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13644.45it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13404.61it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [00:49<00:49,  9.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.5011843619868159\n",
      "MakeWACAXExpDicUnknown Time:  2.8491109190508723\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 12368.93it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  5.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6604.16it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8119.06it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  5.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11625.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13538.75it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [00:53<00:31,  7.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.427385276183486\n",
      "MakeWACAXExpDicUnknown Time:  2.2108767945319414\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 14583.81it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11673.54it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8224.13it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 5362.87it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11573.69it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [00:57<00:19,  6.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.485203824006021\n",
      "MakeWACAXExpDicUnknown Time:  2.284234589897096\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11385.19it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6573.11it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8222.51it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8707.29it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10133.62it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [01:01<00:11,  5.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.4548709439113736\n",
      "MakeWACAXExpDicUnknown Time:  1.8995078327134252\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 12300.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9871.27it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11069.69it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14508.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  5.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 14037.16it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [01:05<00:05,  5.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.358316863887012\n",
      "MakeWACAXExpDicUnknown Time:  1.6314779557287693\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10202.64it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12260.46it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10019.84it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  5.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8859.96it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12014.62it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [01:08<00:00,  7.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 170\n",
      "len_exp2_user_47: 146\n",
      "MakeWACAXExpDicOwner Time:  6.402058723382652\n",
      "MakeWACAXExpDicUnknown Time:  43.03844966460019\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15141.89it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:19<00:39, 19.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 19755.03it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:36<00:17, 18.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 20742.26it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:54<00:00, 18.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14539.64it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 18417.33it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:06<00:09,  3.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 21503.45it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:09<00:06,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 21116.00it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:12<00:03,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 18269.55it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:15<00:00,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [02:00<16:03, 120.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 85\n",
      "len_exp2_user_47: 72\n",
      "MakeWACAXExpDicOwner Time:  3.7785013439133763\n",
      "MakeWACAXExpDicUnknown Time:  21.887731213122606\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 18107.65it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:09<00:19,  9.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 25420.02it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:18<00:09,  9.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 20288.13it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:27<00:00,  9.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14793.35it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 8962.19it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 23315.32it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 21200.26it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 21929.49it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [03:00<09:53, 84.80s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 42\n",
      "len_exp2_user_47: 36\n",
      "MakeWACAXExpDicOwner Time:  1.9803686272352934\n",
      "MakeWACAXExpDicUnknown Time:  11.751763271167874\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 19513.17it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 22397.91it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:13<00:06,  6.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19413.34it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 21411.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 24047.01it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19161.28it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 22717.15it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 19623.68it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [03:38<06:20, 63.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 28\n",
      "len_exp2_user_47: 24\n",
      "MakeWACAXExpDicOwner Time:  1.3258246844634414\n",
      "MakeWACAXExpDicUnknown Time:  7.997018750756979\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 16809.06it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 24340.80it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:05,  5.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 27517.88it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:14<00:00,  4.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14547.60it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 26977.58it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 20883.59it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 22404.21it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 18307.32it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [04:05<04:06, 49.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 21\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  1.2604202730581164\n",
      "MakeWACAXExpDicUnknown Time:  6.228522413410246\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 20423.32it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:08,  4.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 15343.05it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:04,  4.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19589.92it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:13<00:00,  4.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 19967.87it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 13737.59it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 6322.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 25599.67it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 23888.42it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [04:31<02:42, 40.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 16\n",
      "len_exp2_user_47: 14\n",
      "MakeWACAXExpDicOwner Time:  1.005695546977222\n",
      "MakeWACAXExpDicUnknown Time:  5.312880489043891\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 18252.81it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:08<00:16,  8.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 22118.17it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:16<00:08,  8.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 15337.14it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:24<00:00,  8.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 19385.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 17908.26it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19735.46it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 24513.00it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 15903.37it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [05:05<01:55, 38.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  1.085991283878684\n",
      "MakeWACAXExpDicUnknown Time:  7.505860981531441\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 18698.21it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:07<00:15,  7.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 18256.99it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:15<00:07,  7.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14274.01it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:23<00:00,  7.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15973.50it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:02<00:08,  2.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 19818.89it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:03<00:05,  1.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 11996.35it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:05<00:03,  1.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 16400.86it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:07<00:01,  1.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 12960.12it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:09<00:00,  1.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [05:47<01:19, 39.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  3.184864643961191\n",
      "MakeWACAXExpDicUnknown Time:  13.798951306380332\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15564.80it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:13<00:27, 13.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 18706.99it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:28<00:14, 14.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 16959.31it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:43<00:00, 14.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 27922.84it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 25949.78it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:02,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14523.74it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 14089.78it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 22743.09it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [06:52<00:47, 47.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 10\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  1.1775426929816604\n",
      "MakeWACAXExpDicUnknown Time:  5.258089699782431\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 11743.56it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:08<00:16,  8.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 16482.27it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:17<00:09,  9.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 15127.52it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:29<00:00,  9.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15653.46it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 464.31it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 18277.93it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 12362.98it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 17997.24it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [07:33<00:00, 50.44s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  3.4072422748431563\n",
      "MakeWACAXExpDicUnknown Time:  68.1426739692688\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7672.04it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11281.08it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:03<00:04,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8601.94it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:03,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 6431.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:06<00:01,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10740.86it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:07<00:00,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [01:19<10:37, 79.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  4.521204488351941\n",
      "MakeWACAXExpDicUnknown Time:  21.50705394335091\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9749.66it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12737.03it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13569.41it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11507.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9763.28it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [01:51<05:59, 51.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.5578326787799597\n",
      "MakeWACAXExpDicUnknown Time:  11.89823672734201\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7551.86it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10433.59it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9939.11it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11456.72it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9173.89it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [02:08<03:34, 35.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.2163211964070797\n",
      "MakeWACAXExpDicUnknown Time:  7.051723526790738\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7436.71it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8166.48it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10087.31it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9523.85it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11178.85it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [02:19<02:09, 25.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.129080948419869\n",
      "MakeWACAXExpDicUnknown Time:  6.389300592243671\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13400.33it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10757.38it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12494.20it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14543.36it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9770.10it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [02:29<01:21, 20.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.2080251555889845\n",
      "MakeWACAXExpDicUnknown Time:  6.078016218729317\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10567.66it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8423.99it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13460.54it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13801.59it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13976.35it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [02:39<00:50, 16.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.833745239302516\n",
      "MakeWACAXExpDicUnknown Time:  3.655712799169123\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9497.97it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 13920.69it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7025.63it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 7035.06it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9922.65it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [02:46<00:26, 13.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.6792307207360864\n",
      "MakeWACAXExpDicUnknown Time:  3.7202917961403728\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7546.43it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 5332.87it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14349.31it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13530.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7954.30it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [02:52<00:11, 11.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.7039652392268181\n",
      "MakeWACAXExpDicUnknown Time:  4.300215764902532\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13675.59it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12056.06it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10297.82it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14820.86it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9779.21it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [03:00<00:00, 20.08s/it]\u001b[A\n",
      "  4%|         | 1/25 [26:03<10:25:30, 1563.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap: 0.05\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  13.44922476168722\n",
      "MakeWACAXExpDicUnknown Time:  106.76592712290585\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17780.01it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:41<01:23, 41.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15169.27it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [01:29<00:45, 45.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19244.34it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [02:16<00:00, 45.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18279.82it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:05<00:22,  5.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19934.90it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:11<00:16,  5.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23090.03it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:17<00:11,  5.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18604.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:22<00:05,  5.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 15809.66it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:27<00:00,  5.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [04:47<38:19, 287.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  5.017404213547707\n",
      "MakeWACAXExpDicUnknown Time:  63.83331601973623\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 13695.69it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:32<01:05, 32.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23334.10it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [01:02<00:31, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 11011.56it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:39<00:00, 33.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14319.92it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:08<00:32,  8.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15866.48it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:14<00:21,  7.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16225.55it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:20<00:13,  6.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 13711.36it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:26<00:06,  6.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 19253.17it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:32<00:00,  6.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [08:10<27:43, 237.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  9.124296789057553\n",
      "MakeWACAXExpDicUnknown Time:  51.07904012687504\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 8806.01it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:26<00:53, 26.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 12801.17it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:45<00:21, 21.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 10875.93it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:06<00:00, 22.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15738.48it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:02<00:11,  2.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 9764.41it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:05<00:08,  2.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 11087.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:08<00:05,  2.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14425.81it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:10<00:02,  2.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16178.61it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:13<00:00,  2.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [10:31<19:22, 193.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  3.643716244958341\n",
      "MakeWACAXExpDicUnknown Time:  35.95035358890891\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 13981.01it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:27<00:55, 27.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 13344.91it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:55<00:27, 27.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15670.85it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:21<00:00, 27.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17567.77it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:04<00:16,  4.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 18884.75it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:07<00:11,  3.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19996.68it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:10<00:06,  3.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14942.30it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:13<00:03,  3.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16082.45it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:13<00:00,  2.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [12:48<14:15, 171.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.7226130049675703\n",
      "MakeWACAXExpDicUnknown Time:  17.64414941519499\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14146.05it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:10<00:21, 10.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14217.98it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:19<00:09,  9.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15682.57it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:31<00:00, 10.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15993.53it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 13471.35it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16082.45it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 24413.88it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 22197.96it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [13:44<08:39, 129.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.48500682041049\n",
      "MakeWACAXExpDicUnknown Time:  10.227495177648962\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14724.61it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:11<00:22, 11.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17564.09it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:19<00:09,  9.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22209.71it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:30<00:00, 10.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 11634.69it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16750.42it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 721.50it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:02,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14455.64it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 14490.60it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [14:34<05:07, 102.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.1189033444970846\n",
      "MakeWACAXExpDicUnknown Time:  13.17762834019959\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12080.37it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:13<00:27, 13.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 7078.40it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:27<00:13, 13.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20966.28it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:40<00:00, 13.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17396.53it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23026.65it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15011.83it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 23590.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17935.87it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [15:37<02:59, 89.55s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.9856747211888433\n",
      "MakeWACAXExpDicUnknown Time:  12.793324812315404\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14470.60it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:12<00:25, 12.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20605.77it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:23<00:11, 11.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19821.85it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:35<00:00, 11.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15400.42it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 12125.77it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18641.35it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:02,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 13675.59it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17893.79it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [16:35<01:19, 79.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.298408350907266\n",
      "MakeWACAXExpDicUnknown Time:  11.188969055190682\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17924.38it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:14<00:28, 14.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 24701.44it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:25<00:12, 12.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 11500.70it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:35<00:00, 11.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15375.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16159.91it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18691.19it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 15744.38it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17346.17it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [17:29<00:00, 116.64s/it][A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 177\n",
      "len_exp2_user_47: 152\n",
      "MakeWACAXExpDicOwner Time:  5.646578682586551\n",
      "MakeWACAXExpDicUnknown Time:  28.26496188621968\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7590.13it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6946.51it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7271.68it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 6247.10it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 6154.52it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:37<05:01, 37.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 88\n",
      "len_exp2_user_47: 75\n",
      "MakeWACAXExpDicOwner Time:  2.6389266876503825\n",
      "MakeWACAXExpDicUnknown Time:  29.032219405286014\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 6065.52it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 4923.47it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 4743.61it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 12108.27it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13327.94it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [01:12<04:11, 35.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 44\n",
      "len_exp2_user_47: 37\n",
      "MakeWACAXExpDicOwner Time:  1.570518552325666\n",
      "MakeWACAXExpDicUnknown Time:  12.084281113930047\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7399.97it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 7603.89it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6938.47it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9666.52it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10212.57it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [01:28<02:41, 26.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 29\n",
      "len_exp2_user_47: 25\n",
      "MakeWACAXExpDicOwner Time:  1.255798996426165\n",
      "MakeWACAXExpDicUnknown Time:  7.694261500611901\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9376.94it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9191.99it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14558.50it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10007.88it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11444.21it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [01:40<01:44, 20.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 22\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  1.0342196822166443\n",
      "MakeWACAXExpDicUnknown Time:  5.801073816604912\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11081.38it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9333.12it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10843.60it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10202.64it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 5344.42it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [01:48<01:05, 16.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 17\n",
      "len_exp2_user_47: 15\n",
      "MakeWACAXExpDicOwner Time:  0.6764977378770709\n",
      "MakeWACAXExpDicUnknown Time:  7.845889360643923\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10664.39it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12314.46it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12035.31it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 12246.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9244.66it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [02:02<00:46, 15.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  1.6253250045701861\n",
      "MakeWACAXExpDicUnknown Time:  9.590213736519217\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 3622.65it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 2768.52it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11005.78it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11831.61it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 142.48it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [02:19<00:31, 15.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  2.3164569037035108\n",
      "MakeWACAXExpDicUnknown Time:  10.783875731751323\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 8454.55it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11217.72it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7124.69it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 139.66it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8320.38it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [02:38<00:17, 17.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 11\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  2.1874612076207995\n",
      "MakeWACAXExpDicUnknown Time:  9.51250284910202\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7777.31it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 7791.76it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 144.90it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8623.16it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12014.62it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [02:57<00:00, 19.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 29}\n",
      "test_set: {1, 3, 5, 6, 16, 19, 22, 24, 25, 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 177\n",
      "len_exp2_user_47: 152\n",
      "MakeWACAXExpDicOwner Time:  34.60823003668338\n",
      "MakeWACAXExpDicUnknown Time:  168.01018220931292\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16584.83it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:49<01:39, 49.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 18204.44it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [01:41<00:50, 50.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17989.72it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [02:26<00:00, 48.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17560.41it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:15,  3.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20223.26it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:07<00:10,  3.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 12620.14it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:11<00:07,  3.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 10818.43it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:18<00:05,  5.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 8963.15it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:23<00:00,  4.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [06:18<50:29, 378.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 88\n",
      "len_exp2_user_47: 75\n",
      "MakeWACAXExpDicOwner Time:  9.293520550243556\n",
      "MakeWACAXExpDicUnknown Time:  59.82032685074955\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16138.15it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:24<00:49, 25.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15299.30it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:49<00:24, 24.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17989.72it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:13<00:00, 24.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21119.36it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16760.46it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:05<00:08,  2.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23295.22it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:07<00:04,  2.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 24556.81it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:10<00:02,  2.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17836.72it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:13<00:00,  2.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [08:56<29:01, 248.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 44\n",
      "len_exp2_user_47: 37\n",
      "MakeWACAXExpDicOwner Time:  4.157510015182197\n",
      "MakeWACAXExpDicUnknown Time:  28.85785575862974\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17140.60it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:32, 16.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17465.35it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:37<00:19, 19.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16513.01it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:57<00:00, 19.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14619.39it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:02<00:10,  2.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20641.26it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14016.05it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:06<00:04,  2.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 13718.08it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:08<00:02,  2.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 13536.56it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:10<00:00,  2.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [10:39<18:13, 182.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 29\n",
      "len_exp2_user_47: 25\n",
      "MakeWACAXExpDicOwner Time:  4.485120779834688\n",
      "MakeWACAXExpDicUnknown Time:  24.304850295186043\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16710.37it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:21<00:42, 21.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17667.67it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:45<00:22, 22.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16584.83it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:15<00:00, 25.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 280.37it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:05<00:20,  5.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15966.14it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:09<00:13,  4.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14753.09it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:12<00:08,  4.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14203.54it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:15<00:03,  3.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 11891.99it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:18<00:00,  3.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [12:43<13:16, 159.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 22\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  6.80146892182529\n",
      "MakeWACAXExpDicUnknown Time:  34.2798173064366\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 13747.31it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:27<00:54, 27.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 18424.35it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:41<00:19, 19.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16493.53it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:53<00:00, 17.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12748.64it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22104.37it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20810.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22239.15it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 12637.25it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [14:26<09:15, 138.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 17\n",
      "len_exp2_user_47: 15\n",
      "MakeWACAXExpDicOwner Time:  3.028493197634816\n",
      "MakeWACAXExpDicUnknown Time:  18.4162190342322\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14203.54it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:32, 16.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15650.39it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:41<00:21, 21.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 13580.39it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:08<00:00, 22.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21092.80it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:14,  3.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 13072.48it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:07<00:11,  3.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14239.70it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:11<00:07,  3.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14100.87it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:14<00:03,  3.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 21432.31it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:18<00:00,  3.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [16:16<06:26, 128.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  5.723335294984281\n",
      "MakeWACAXExpDicUnknown Time:  20.778546553105116\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15960.06it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:33, 16.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14818.24it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:27<00:13, 13.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22369.62it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:40<00:00, 13.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 19257.59it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 12717.72it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 13558.44it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 25221.31it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 23425.32it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [17:28<03:40, 110.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  1.3907674914225936\n",
      "MakeWACAXExpDicUnknown Time:  7.342415659688413\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17168.66it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:11<00:22, 11.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14639.80it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:20<00:09,  9.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 13332.18it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:27<00:00,  9.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12766.11it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14670.53it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18078.90it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 20510.04it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 20375.54it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [18:10<01:28, 88.61s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 11\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  1.4088567923754454\n",
      "MakeWACAXExpDicUnknown Time:  6.435919989831746\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18012.90it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23140.99it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:13<00:06,  6.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17091.70it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 25358.55it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23844.82it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17634.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18157.16it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16116.44it/s]\n",
      "/tmp/ipykernel_3197292/1897070050.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [18:41<00:00, 124.60s/it][A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  3.95137061458081\n",
      "MakeWACAXExpDicUnknown Time:  31.834782402031124\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 6068.15it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10252.52it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12706.16it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9943.82it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9845.78it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:40<05:24, 40.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.0745624285191298\n",
      "MakeWACAXExpDicUnknown Time:  17.033634278923273\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9802.07it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 13617.87it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9848.10it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8075.29it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12045.67it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [01:02<03:28, 29.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.0295411655679345\n",
      "MakeWACAXExpDicUnknown Time:  10.922234673984349\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9713.53it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10675.25it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7487.15it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 5466.32it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8954.53it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [01:17<02:18, 23.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.3289865450933576\n",
      "MakeWACAXExpDicUnknown Time:  6.870485887862742\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11125.47it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8856.22it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13582.59it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10506.77it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7123.48it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [01:29<01:32, 18.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.8527107750996947\n",
      "MakeWACAXExpDicUnknown Time:  4.912846205756068\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9806.65it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 4783.65it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10648.14it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8427.37it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9153.87it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [01:37<00:58, 14.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.8118496034294367\n",
      "MakeWACAXExpDicUnknown Time:  4.558354647830129\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 5997.86it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8709.10it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11755.34it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10804.49it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 4976.63it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [01:44<00:36, 12.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.5281705372035503\n",
      "MakeWACAXExpDicUnknown Time:  4.3306869100779295\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9543.35it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8101.80it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10379.37it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8880.59it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7247.80it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [01:51<00:20, 10.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.7715822532773018\n",
      "MakeWACAXExpDicUnknown Time:  4.1501827938482165\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 6020.24it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8950.71it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6010.75it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14227.63it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7966.39it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [01:57<00:09,  9.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.4177145939320326\n",
      "MakeWACAXExpDicUnknown Time:  3.526060733012855\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 5833.52it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 5871.09it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6793.50it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10190.24it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 5888.40it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [02:03<00:00, 13.76s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 177\n",
      "len_exp2_user_47: 152\n",
      "MakeWACAXExpDicOwner Time:  9.285374538041651\n",
      "MakeWACAXExpDicUnknown Time:  95.71120078209788\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14338.21it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [01:01<02:02, 61.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 13718.67it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [02:41<01:23, 83.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14455.25it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [03:47<00:00, 75.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15777.43it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:07<00:29,  7.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 13610.89it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:14<00:21,  7.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14568.88it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:20<00:13,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 12113.05it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:26<00:06,  6.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 430.97it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:31<00:00,  6.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [06:05<48:44, 365.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 88\n",
      "len_exp2_user_47: 75\n",
      "MakeWACAXExpDicOwner Time:  15.585523591376841\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": raw_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "for overlap in tqdm(OVERLAP_EXP_RANGE):\n",
    "\n",
    "    train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap={overlap}_Mean_EER_df_train_dict.txt\"\n",
    "    test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap={overlap}_Mean_EER_df_test_dict.txt\"\n",
    "    \n",
    "    with open(train_file_name, \"w\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    with open(test_file_name, \"w\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "    overlap*=0.01\n",
    "    print(f\"overlap: {overlap}\")\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "\n",
    "\n",
    "    key_column= [\"overlap\"]\n",
    "    #-----CV_FOLD-------\n",
    "    for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "        process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                    cv_fold_idx=cv_fold_idx, \n",
    "                                    cv_sets=THREE_FOLD_CV, \n",
    "                                    dfList_dict=dfList_dict, \n",
    "                                    window_size_lst=WINDOW_SIZE_LST, \n",
    "                                    exp_config=P, \n",
    "                                    extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                    overlap=overlap, \n",
    "                                    param_dist=param_dist, \n",
    "                                    train_file_name=train_file_name, \n",
    "                                    test_file_name=test_file_name, \n",
    "                                    preprocessing_params=overlap, \n",
    "                                    key_column=key_column,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for overlap in tqdm(OVERLAP_EXP_RANGE):\n",
    "    overlap*=0.01\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "    # max_num_windows=min(len(getIndices(sampleSize=max_window_size, step=step_width, numSamplePoints=P.num_sample_points_per_exp)), N_NEIGHBORS_PARAMS[-1]+1)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[overlap] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                     extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                     param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\overlap: {overlap}\\n\")\n",
    "        f.write(EER_df_train_dict[overlap].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "overlap=min_key\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"overlap\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"cut_off_freq\" and \"SMA_winsize\" in EER_df_test_dict_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 EER per window for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "def return_and_save_final_result_df_as_json(final_exp_results_path, exp_path_name, window_size_lst):\n",
    "    window_size_cols=[('Window Size', winsize) for winsize in window_size_lst]\n",
    "    preprocessing_methods=[\"Naive\", \"Realworld-per_unknown_window\"]\n",
    "    smoothing_methods=[\"Butterworth\", \"EMA\", \"SMA\", \"Butter+EMA\", \"Butter+SMA\"]\n",
    "    concate_df_lst=[]\n",
    "    \n",
    "    \n",
    "    test_file_name=f\"{final_exp_results_path}/{exp_path_name}/clip={P.scaler_clip}-None_Mean_EER_None_df_test_dict.txt\"\n",
    "    eer_per_window_size_col_df = pd.read_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json').drop([\"('', 'mean')\", \"('', 'var')\"], axis=1)#\"('index', '')\", \n",
    "    # print(eer_per_window_size_col_df)\n",
    "    # Convert the string representation of tuples back to tuples\n",
    "    idx_tuples = [eval(i) for i in eer_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "    # Convert list of tuples back to a MultiIndex\n",
    "    multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "    eer_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "    eer_per_window_size_col_df[(\"\", 'type')] = 'None'\n",
    "    \n",
    "    concate_df_lst.append(eer_per_window_size_col_df)\n",
    "            \n",
    "            \n",
    "    for sm in smoothing_methods:\n",
    "        for pm in preprocessing_methods:\n",
    "            test_file_name=f\"{final_exp_results_path}/{exp_path_name}/clip={P.scaler_clip}-{sm}_Mean_EER_{pm}_df_test_dict.txt\"\n",
    "            eer_per_window_size_col_df = pd.read_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json').drop([\"('', 'mean')\", \"('', 'var')\"], axis=1)#\"('index', '')\", \n",
    "            # print(eer_per_window_size_col_df)\n",
    "            # Convert the string representation of tuples back to tuples\n",
    "            idx_tuples = [eval(i) for i in eer_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "            # Convert list of tuples back to a MultiIndex\n",
    "            multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "            eer_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "            if pm ==\"Realworld-per_unknown_window\":\n",
    "                pm=\"Real\"\n",
    "            eer_per_window_size_col_df[(\"\", 'type')] = f'{pm}'\n",
    "\n",
    "            concate_df_lst.append(eer_per_window_size_col_df)\n",
    "\n",
    "    df = pd.concat(concate_df_lst)\n",
    "    # # add a new column 'Mean' which is the mean of each row across the columns '125', '1500', and '2000'\n",
    "    # df['Mean'] = df[['125', '1500', '2000']].mean(axis=1)\n",
    "    df=df[[\n",
    "        (           '', 'cut_off_freq'),\n",
    "        (           '',     'EMA_span'),\n",
    "        (           '',  'SMA_winsize'),\n",
    "        (           '', 'type'),\n",
    "        ]+window_size_cols]\n",
    "\n",
    "    df = df.fillna(DASH_MACRO_NUM).reset_index(drop=True)\n",
    "\n",
    "    df[(\"\", 'cut_off_freq')] = df[(\"\", 'cut_off_freq')].astype(np.int64)\n",
    "    df[(\"\", 'EMA_span')] = df[(\"\", 'EMA_span')].astype(np.int64)\n",
    "    df[(\"\", 'SMA_winsize')] = df[(\"\", 'SMA_winsize')].astype(np.int64)\n",
    "\n",
    "    df[(\"\", \"mean\")] = df[window_size_cols].mean(axis=1)\n",
    "    df[(\"\", \"variance\")] = df[window_size_cols].var(axis=1)\n",
    "\n",
    "    df[(\"\", 'mean rank')] = df[(\"\", \"mean\")].rank(method='min').astype(np.int64)\n",
    "    cols = list(df.columns)\n",
    "    df = df[[cols[-1]] + cols[:-1]]\n",
    "\n",
    "    df.replace(DASH_MACRO_NUM, \"-\", inplace=True)\n",
    "\n",
    "    df.to_json(f\"{final_exp_results_path}/{exp_path_name}/{exp_path_name}-df.json\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=return_and_save_final_result_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Relative improvment of EER per window for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "df.style.format(STYLER_ERR_FORMAT_DICT).hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df.style.format(STYLER_IMPROVEMENT_FORMAT_DICT).hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Gini coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_result_df=return_and_save_final_Gini_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "gini_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_and_save_final_relative_gini_result_df_as_json(gini_result_df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, \n",
    "                                                      exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row number 4 is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
