{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "EXP_PATH_NAME=\"WACA-OCSVM\"\n",
    "joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mNeural Networks utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "EER: 0.333, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.400, Threshold: 0.200 <-- Worse case\n",
      "EER: 0.167, Threshold: 0.600 <-- Arbitrary case\n",
      "EER: 0.000, Threshold: 0.900 <-- Best case\n",
      "EER: 1.000, Threshold: 0.900 <-- Worse case\n",
      "EER: 0.333, Threshold: 1.000 <-- Worse case\n",
      "--------------------\u001b[32mUtility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mPreprocessing utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mWACA utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "Python 3.9.10\n",
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "FINAL_EXP_RESULTS_PATH: clip=False_experiments_results\n",
      "--------------------\u001b[32mSEED and CONSTANTS imported\u001b[0m--------------------\n",
      "Numpy Seed was set to: 567\n",
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "from sklearn.svm import OneClassSVM\n",
    "from dataclasses import asdict\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "%run ./Classification_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "\n",
    "FINAL_EXP_RESULTS_PATH=\"clip=False_experiments_results\"\n",
    "\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"Numpy Seed was set to: {SEED}\")\n",
    "\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__dir__()\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "        \n",
    "    user_ids: list\n",
    "    num_sample_points_per_exp: int\n",
    "    exp_begin_cutoff_idx: int\n",
    "    exp_end_cutoff_idx: int\n",
    "        \n",
    "    \n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    window_size: int  # After resampling\n",
    "    ocsvm_step_width: int  # After resampling\n",
    "    scaler: str  # StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_kernel: str # ocsvm kernel\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects=29,\n",
    "    max_test_subjects=10,\n",
    "    user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49],\n",
    "    num_sample_points_per_exp=21000,\n",
    "    exp_begin_cutoff_idx=500,\n",
    "    exp_end_cutoff_idx=-500,\n",
    "    seconds_per_subject_train=210,\n",
    "    seconds_per_subject_test=210,    \n",
    "    window_size=250,\n",
    "    ocsvm_step_width=250,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_kernel=\"rbf\",\n",
    "    ocsvm_nu=None,\n",
    "    ocsvm_gamma=None,\n",
    "    feature_cols=[\n",
    "        \"x_a\",\n",
    "        \"y_a\",\n",
    "        \"z_a\",\n",
    "        \"x_g\",\n",
    "        \"y_g\",\n",
    "        \"z_g\",\n",
    "    ],\n",
    "    exclude_subjects=[],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM_125 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=125\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "\n",
    "VALID_ROBUST_OCSVM_250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1250 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1250\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1500 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1500\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_1750 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=1750\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "VALID_ROBUST_OCSVM_2000 = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"RobustScaler\",\n",
    "    scaler_global=False,\n",
    "    window_size=2000\n",
    "#     ocsvm_nu=0.037,\n",
    "#     ocsvm_gamma= 0.001,\n",
    ")\n",
    "\n",
    "# NORMALIZER_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_NORMALIZER_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-NORMALIZER-OCSVM\",\n",
    "    scaler=\"Normalizer\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.074,\n",
    "    ocsvm_gamma= 0.029,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM_2000\n",
    "P.ocsvm_step_width = int(P.window_size * .5)\n",
    "P.classifier=\"OCSVM\"\n",
    "P.ocsvm_kernel = \"rbf\"\n",
    "P.train_cores=1 # 20 cores for every user and 1 core for the nested crossval function\n",
    "P.test_cores=2 # 10 cores for every user and 2 for the nested crossval function\n",
    "\n",
    "P.scaler_clip=False\n",
    "P.is_NN=False\n",
    "\n",
    "param_dist = {\n",
    "    \"model__gamma\": np.logspace(-9, 3), \n",
    "    \"model__nu\": np.linspace(0.0001, 0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>VALID-ROBUST-OCSVM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_subjects</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_test_subjects</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_ids</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sample_points_per_exp</th>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_begin_cutoff_idx</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_end_cutoff_idx</th>\n",
       "      <td>-500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_train</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_per_subject_test</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_step_width</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <td>RobustScaler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_scope</th>\n",
       "      <td>subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_global</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_kernel</th>\n",
       "      <td>rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_nu</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ocsvm_gamma</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_cols</th>\n",
       "      <td>[x_a, y_a, z_a, x_g, y_g, z_g]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exclude_subjects</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Value\n",
       "name                                                      VALID-ROBUST-OCSVM\n",
       "frequency                                                                100\n",
       "max_subjects                                                              29\n",
       "max_test_subjects                                                         10\n",
       "user_ids                   [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 2...\n",
       "num_sample_points_per_exp                                              21000\n",
       "exp_begin_cutoff_idx                                                     500\n",
       "exp_end_cutoff_idx                                                      -500\n",
       "seconds_per_subject_train                                                210\n",
       "seconds_per_subject_test                                                 210\n",
       "window_size                                                             2000\n",
       "ocsvm_step_width                                                        1000\n",
       "scaler                                                          RobustScaler\n",
       "scaler_scope                                                         subject\n",
       "scaler_global                                                          False\n",
       "ocsvm_kernel                                                             rbf\n",
       "ocsvm_nu                                                                None\n",
       "ocsvm_gamma                                                             None\n",
       "feature_cols                                  [x_a, y_a, z_a, x_g, y_g, z_g]\n",
       "exclude_subjects                                                          []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_scorer(utils_eer, greater_is_better=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils_eer_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "1) accel_count: 28388, gyro_count: 31997\n",
      "2) accel_count: 26010, gyro_count: 28954\n",
      "3) accel_count: 28227, gyro_count: 31814\n",
      "4) accel_count: 24860, gyro_count: 26105\n",
      "5) accel_count: 24270, gyro_count: 24347\n",
      "6) accel_count: 25012, gyro_count: 25060\n",
      "7) accel_count: 25301, gyro_count: 25382\n",
      "8) accel_count: 21975, gyro_count: 21658\n",
      "19) accel_count: 24110, gyro_count: 25050\n",
      "21) accel_count: 24326, gyro_count: 23809\n",
      "22) accel_count: 29123, gyro_count: 28724\n",
      "26) accel_count: 23148, gyro_count: 24291\n",
      "27) accel_count: 24299, gyro_count: 23589\n",
      "28) accel_count: 23807, gyro_count: 24523\n",
      "29) accel_count: 24030, gyro_count: 23457\n",
      "35) accel_count: 24388, gyro_count: 23673\n",
      "36) accel_count: 24228, gyro_count: 24208\n",
      "37) accel_count: 31945, gyro_count: 31816\n",
      "38) accel_count: 22135, gyro_count: 22327\n",
      "39) accel_count: 23573, gyro_count: 23459\n",
      "40) accel_count: 23057, gyro_count: 24296\n",
      "41) accel_count: 24102, gyro_count: 23681\n",
      "42) accel_count: 24074, gyro_count: 24328\n",
      "43) accel_count: 22631, gyro_count: 23835\n",
      "44) accel_count: 24473, gyro_count: 23749\n",
      "45) accel_count: 23974, gyro_count: 23229\n",
      "46) accel_count: 23614, gyro_count: 23827\n",
      "48) accel_count: 22828, gyro_count: 23904\n",
      "49) accel_count: 24183, gyro_count: 24633\n",
      "Loading exp2 data:\n",
      "1) accel_count: 24049, gyro_count: 26943\n",
      "2) accel_count: 24468, gyro_count: 27667\n",
      "3) accel_count: 24611, gyro_count: 27000\n",
      "4) accel_count: 24972, gyro_count: 26798\n",
      "5) accel_count: 23573, gyro_count: 23372\n",
      "6) accel_count: 23800, gyro_count: 23890\n",
      "7) accel_count: 23347, gyro_count: 24145\n",
      "8) accel_count: 22947, gyro_count: 22660\n",
      "19) accel_count: 26156, gyro_count: 25815\n",
      "21) accel_count: 23566, gyro_count: 24408\n",
      "22) accel_count: 23844, gyro_count: 24589\n",
      "26) accel_count: 23179, gyro_count: 23925\n",
      "27) accel_count: 25109, gyro_count: 25820\n",
      "28) accel_count: 23133, gyro_count: 24028\n",
      "29) accel_count: 23180, gyro_count: 24314\n",
      "35) accel_count: 23299, gyro_count: 23854\n",
      "36) accel_count: 25497, gyro_count: 25059\n",
      "37) accel_count: 25994, gyro_count: 25232\n",
      "38) accel_count: 21164, gyro_count: 21182\n",
      "39) accel_count: 24214, gyro_count: 23585\n",
      "40) accel_count: 23944, gyro_count: 23170\n",
      "41) accel_count: 23193, gyro_count: 24111\n",
      "42) accel_count: 26505, gyro_count: 25697\n",
      "43) accel_count: 22690, gyro_count: 23981\n",
      "44) accel_count: 23002, gyro_count: 23829\n",
      "45) accel_count: 23978, gyro_count: 23350\n",
      "46) accel_count: 21128, gyro_count: 21848\n",
      "48) accel_count: 27996, gyro_count: 27205\n",
      "49) accel_count: 23061, gyro_count: 24129\n"
     ]
    }
   ],
   "source": [
    "#include 47 later\n",
    "# user_ids = [9]\n",
    "df_exps_dict = load_data_frames(P.user_ids, P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, P.num_sample_points_per_exp)\n",
    "raw_dfList_exp1, raw_dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i=0\n",
    "# dfList_exp1[i][['x_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['y_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['z_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['x_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['y_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp1[i][['z_g']].plot(figsize=(30, 6))\n",
    "\n",
    "# dfList_exp2[i][['x_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['y_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['z_a']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['x_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['y_g']].plot(figsize=(30, 6))\n",
    "# dfList_exp2[i][['z_g']].plot(figsize=(30, 6))\n",
    "# exp1 idx 10 has corrupted data frist 50 sec\n",
    "# exp2 idx 12 has some artifacts first 12.5 sec\n",
    "# exp1 idx 17 has some artifacts first 75 sec\n",
    "# exp2 idx 23 has some artifacts last 6.5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n",
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n",
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "randomized_data_idx = list(range(len(P.user_ids)))\n",
    "random.Random(SEED).shuffle(randomized_data_idx)\n",
    "split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "train_set = randomized_data_idx[: split_idx]\n",
    "test_set = randomized_data_idx[split_idx: ]\n",
    "# train_set = randomized_data_idx\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")\n",
    "# train_set = test_set\n",
    "# test_set = train_set\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading exp1 data:\n",
      "47) accel_count: 22777, gyro_count: 22226\n",
      "Loading exp2 data:\n",
      "47) accel_count: 17718, gyro_count: 18353\n"
     ]
    }
   ],
   "source": [
    "num_sample_points_per_exp_user_47 = 18000\n",
    "df_exps_dict_user_47 = load_data_frames([47], P.exp_begin_cutoff_idx, P.exp_end_cutoff_idx, num_sample_points_per_exp_user_47)\n",
    "dfList_exp1_user_47, dfList_exp2_user_47 = df_exps_dict_user_47['dfList_exp1'], df_exps_dict_user_47['dfList_exp2']\n",
    "\n",
    "raw_dfList_exp1_user_47 = dfList_exp1_user_47\n",
    "raw_dfList_exp2_user_47 = dfList_exp2_user_47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: [7, 24, 8, 11, 13, 19, 28, 21, 26, 3, 20, 22, 6, 25, 16, 1, 17, 27, 5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_set: {train_set}\")\n",
    "# print(f\"X_exp1_train_dic: {X_exp1_train_dic.keys()}\")\n",
    "# print(f\"X_exp2_train_dic: {X_exp2_train_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set: [0, 12, 14, 9, 18, 23, 2, 15, 10, 4]\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_set: {test_set}\")\n",
    "# print(f\"X_exp1_test_dic: {X_exp1_test_dic.keys()}\")\n",
    "# print(f\"X_exp2_test_dic: {X_exp2_test_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH_NAME\n",
    "THREE_FOLD_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOW_SIZE_LST=[2000]\n",
    "DASH_MACRO_NUM\n",
    "THREE_FOLD_CV\n",
    "# P.scaler=None\n",
    "P.scaler\n",
    "P.smoothing\n",
    "preprocessing_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. No Smoothing\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = None\n",
    "\n",
    "\n",
    "# /clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\n",
    "preprocessing_method=None\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": raw_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "# for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "#     train_set, test_set = THREE_FOLD_CV[cv_fold_idx]\n",
    "#     print(f\"train_set: {train_set}\")\n",
    "#     print(f\"test_set: {test_set}\")\n",
    "    \n",
    "    \n",
    "#     test_dict_key=DASH_MACRO_NUM\n",
    "#     EER_df_train_dict[test_dict_key] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "#                                                                                                extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "#                                                                                                param_dist=param_dist)\n",
    "\n",
    "#     with open(train_file_name, \"a\") as f:\n",
    "#         f.write(\"\\n\" + \"-\"*22 + f\"Training results for cv_fold_idx: {cv_fold_idx}\" + \"-\"*22 + \"\\n\")        \n",
    "#         f.write(f\"\\Test_dict_key: {test_dict_key}\\n\")\n",
    "#         f.write(EER_df_train_dict[test_dict_key].to_string())\n",
    "\n",
    "\n",
    "\n",
    "#     min_key=test_dict_key\n",
    "#     EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "#                                                                                        extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "#                                                                                        best_param_df=EER_df_train_dict[min_key])\n",
    "#     with open(test_file_name, \"a\") as f:\n",
    "#         f.write(\"\\n\" + \"-\"*22 + f\"Testing results for cv_fold_idx: {cv_fold_idx}\" + \"-\"*22 + \"\\n\")\n",
    "#         f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "#         f.write(EER_df_test_dict[min_key].to_string())\n",
    "#     #-------\n",
    "#     #-------\n",
    "#     key_column= [\"cut_off_freq\"]\n",
    "#     EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "#     eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "#     EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df_cv{cv_fold_idx}.json')\n",
    "#     eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df_cv{cv_fold_idx}.json')\n",
    "#     #-------\n",
    "\n",
    "min_key=DASH_MACRO_NUM\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Butterworth frequency Cut-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "old_test_hyperparameters_df\n",
    "oth=old_test_hyperparameters_df\n",
    "oth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "min_key=P.cut_off_freq\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": ffted_dfList_exp1,\n",
    "            \"dfList_exp2\": ffted_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for cut_off_freq in tqdm(CUT_OFF_FREQ_RANGE):\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": ffted_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": ffted_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                param_dist=param_dist)\n",
    "\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "        \n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "\n",
    "\n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "min_key=P.cut_off_freq\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": ffted_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butterworth\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for cut_off_freq in tqdm(CUT_OFF_FREQ_RANGE):\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=cut_off_freq\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": ffted_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": ffted_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.cut_off_freq] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                                    param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq: {P.cut_off_freq}\\n\")\n",
    "        f.write(EER_df_train_dict[P.cut_off_freq].to_string())\n",
    "\n",
    "\n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Butterworth frequency Cut-off + EMA span\n",
    "## 2.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "min_key= P.cut_off_freq, P.span\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "    \n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_span_pairs):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, span = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.span=span\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"span: {P.span}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(ffted_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(ffted_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------  \n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "P.EMA_per_win_span=P.span\n",
    "\n",
    "min_key= P.cut_off_freq, P.span\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_2)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_span_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_span_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_span_pairs):\n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, span = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=cut_off_freq\n",
    "    \n",
    "    \n",
    "    P.span=span\n",
    "    P.EMA_per_win_span=span\n",
    "\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"span: {P.span}\")\n",
    "\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(ffted_dfList_exp2, span=P.span)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(ffted_dfList_exp2_user_47, span=P.span)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, span: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EMA span\n",
    "## 3.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "min_key=P.span\n",
    "print(f\"EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "\n",
    "EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for span in tqdm(EMA_SPAN_RANGE):\n",
    "    P.span=span\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    \n",
    "    EMAed_dfList_exp1 = get_EMAed_dfList(raw_dfList_exp1, span=P.span)\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp1_user_47 = get_EMAed_dfList(raw_dfList_exp1_user_47, span=P.span)\n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": EMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": EMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                    param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "    \n",
    "\n",
    "EER_df_test_dict={}\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.span=old_test_hyperparameters_df[\"EMA_span\"][0]\n",
    "P.EMA_per_win_span=P.span\n",
    "min_key=P.span\n",
    "print(f\"EMA span: {P.span}\")\n",
    "\n",
    "\n",
    "EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "\n",
    "EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"EMA_span\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"EMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for span in tqdm(EMA_SPAN_RANGE):\n",
    "    P.span=span\n",
    "    print(f\"EMA span: {P.span}\")\n",
    "\n",
    "    P.EMA_per_win_span=P.span\n",
    "\n",
    "    EMAed_dfList_exp2 = get_EMAed_dfList(raw_dfList_exp2, span=P.span)\n",
    "    \n",
    "    EMAed_dfList_exp2_user_47 = get_EMAed_dfList(raw_dfList_exp2_user_47, span=P.span)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": EMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": EMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.span] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                    extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                    param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\EMA span: {P.span}\\n\")\n",
    "        f.write(EER_df_train_dict[P.span].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"EMA_span\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SMA winsize\n",
    "## 4.1 Naive Approach\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "min_key=P.winsize\n",
    "print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "    \n",
    "\n",
    "\n",
    "key_column= [\"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for winsize in tqdm(SMA_WINSIZE_RANGE):\n",
    "    P.winsize=winsize\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(raw_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(raw_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                       param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.SMA_per_win_winsize=P.winsize\n",
    "min_key=P.winsize\n",
    "print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "key_column= [\"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for winsize in tqdm(SMA_WINSIZE_RANGE):\n",
    "    P.winsize=winsize\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "    print(f\"SMA winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(raw_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(raw_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[P.winsize] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                       extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                       param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\SMA winsize: {P.winsize}\\n\")\n",
    "        f.write(EER_df_train_dict[P.winsize].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Butterworth frequency Cut-off + SMA winsize\n",
    "## 5.1 Naive Approach\n",
    "### Optimizing and Testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "min_key= P.cut_off_freq, P.winsize\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Naive\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_winsize_pairs):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, winsize = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.winsize=winsize\n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp1 = get_ffted_dfList(raw_dfList_exp1, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1 = get_SMAed_dfList(ffted_dfList_exp1, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp1_user_47 = get_ffted_dfList(raw_dfList_exp1_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "\n",
    "    SMAed_dfList_exp1_user_47 = get_SMAed_dfList(ffted_dfList_exp1_user_47, winsize=P.winsize)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": SMAed_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": SMAed_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Realworld Approach (per unknown window application of filter)\n",
    "### Optimizing and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-Smoothing={P.smoothing}-Prep={preprocessing_method}-EER_df_test_dict.txt\"\n",
    "old_test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/old_{time_of_execution}_{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_test_dict={}\n",
    "\n",
    "    \n",
    "old_test_hyperparameters_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict_raw_df.json\"\n",
    "old_test_hyperparameters_df = pd.read_json(old_test_hyperparameters_file_name)\n",
    "old_test_hyperparameters_df.to_json(f'{old_test_file_name[:-4]}_raw_df.json')\n",
    "\n",
    "P.winsize=old_test_hyperparameters_df[\"SMA_winsize\"][0]\n",
    "P.cut_off_freq=old_test_hyperparameters_df[\"cut_off_freq\"][0]\n",
    "\n",
    "P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "P.SMA_per_win_winsize=P.winsize\n",
    "\n",
    "min_key= P.cut_off_freq, P.winsize\n",
    "print(f\"cut_off_freq: {P.cut_off_freq}, winsize: {P.winsize}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "\n",
    "ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "}\n",
    "    \n",
    "        \n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "#-----CV_FOLD-------\n",
    "for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "    process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                cv_fold_idx=cv_fold_idx, \n",
    "                                cv_sets=THREE_FOLD_CV, \n",
    "                                dfList_dict=dfList_dict, \n",
    "                                window_size_lst=WINDOW_SIZE_LST, \n",
    "                                exp_config=P, \n",
    "                                extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                overlap=OVERLAP, \n",
    "                                param_dist=param_dist, \n",
    "                                train_file_name=train_file_name, \n",
    "                                test_file_name=test_file_name, \n",
    "                                preprocessing_params=min_key, \n",
    "                                key_column=key_column,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P, exp_num=EXP_NUM_5)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "P.smoothing = \"Butter+SMA\"\n",
    "\n",
    "\n",
    "\n",
    "preprocessing_method=\"Realworld-per_unknown_window\"\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "indices = list(range(1, 50))\n",
    "mesh = np.array(np.meshgrid(indices, indices))\n",
    "index_pairs = mesh.T.reshape(-1, 2)\n",
    "\n",
    "print(f\"total cut_off_winsize_pairs: {index_pairs.shape}, choice_num: {CHOICE_NUM_PAIRS}\")\n",
    "cut_off_winsize_pairs = index_pairs[np.random.choice(index_pairs.shape[0], size=CHOICE_NUM_PAIRS, replace=False), :]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "P.Butter_per_win_argdict={\n",
    "    \"filter_order\": P.filter_order,\n",
    "    \"cut_off_freq\": None,\n",
    "    \"sampling_freq\": P.sampling_freq,\n",
    "    \"filtfilt\": P.filtfilt,\n",
    "    }\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "\n",
    "for key_pair in tqdm(cut_off_winsize_pairs):\n",
    "    \n",
    "    key_pair = tuple(key_pair)\n",
    "    cut_off_freq, winsize = key_pair[0], key_pair[1]\n",
    "    P.cut_off_freq=cut_off_freq\n",
    "    P.Butter_per_win_argdict[\"cut_off_freq\"]=P.cut_off_freq\n",
    "    P.winsize=winsize\n",
    "    P.SMA_per_win_winsize=P.winsize\n",
    "    \n",
    "    print(f\"cut_off_freq: {P.cut_off_freq}\")\n",
    "    print(f\"winsize: {P.winsize}\")\n",
    "\n",
    "    \n",
    "    ffted_dfList_exp2 = get_ffted_dfList(raw_dfList_exp2, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2 = get_SMAed_dfList(ffted_dfList_exp2, winsize=P.winsize)\n",
    "    \n",
    "    ffted_dfList_exp2_user_47 = get_ffted_dfList(raw_dfList_exp2_user_47, cut_off_freq=P.cut_off_freq, filter_order=P.filter_order, sampling_freq=P.sampling_freq, filtfilt=P.filtfilt)\n",
    "    SMAed_dfList_exp2_user_47 = get_SMAed_dfList(ffted_dfList_exp2_user_47, winsize=P.winsize)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": SMAed_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": SMAed_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[key_pair] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                      extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                      param_dist=param_dist)\n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\cut_off_freq, winsize: {key_pair}\\n\")\n",
    "        f.write(EER_df_train_dict[key_pair].to_string())\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"cut_off_freq\", \"SMA_winsize\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The effect of Varying Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reseting experiment params successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap: 0.01\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  8.098896443843842\n",
      "MakeWACAXExpDicUnknown Time:  38.60075428336859\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15494.29it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:32, 16.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21879.52it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:31<00:15, 15.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14926.35it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:45<00:00, 15.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20908.79it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20203.78it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:06<00:09,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17534.72it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:09<00:06,  3.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18600.02it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:12<00:03,  3.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 8192.80it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:15<00:00,  3.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [01:49<14:39, 109.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  3.654866699129343\n",
      "MakeWACAXExpDicUnknown Time:  19.957633148878813\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20934.88it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:08<00:17,  8.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20345.88it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:17<00:08,  8.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20976.76it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:25<00:00,  8.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 22345.79it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20585.54it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:03<00:05,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16247.55it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:05<00:03,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18876.26it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:06<00:01,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 21339.63it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:08<00:00,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [02:48<09:17, 79.60s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.0593677135184407\n",
      "MakeWACAXExpDicUnknown Time:  10.275187748484313\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20092.47it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23166.55it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21034.62it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:16<00:00,  5.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16209.87it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20799.92it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21055.74it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18157.16it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 14445.68it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [03:22<05:52, 58.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.515742003917694\n",
      "MakeWACAXExpDicUnknown Time:  7.48105703946203\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15732.57it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:10,  5.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19436.07it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:10<00:05,  5.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15563.28it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:15<00:00,  5.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 11591.28it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22417.45it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17292.53it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 20810.24it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 19944.38it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [03:50<03:53, 46.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.4271309580653906\n",
      "MakeWACAXExpDicUnknown Time:  6.162808519788086\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20697.28it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 9357.06it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:04,  4.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24585.60it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:15<00:00,  5.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 23147.37it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19710.08it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20836.09it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22832.36it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 23689.94it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [04:17<02:38, 39.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.1523620346561074\n",
      "MakeWACAXExpDicUnknown Time:  6.219248995184898\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21410.43it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:07<00:14,  7.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20743.34it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:13<00:06,  6.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 26512.67it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20515.06it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22844.79it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24723.28it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 27077.50it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 26689.81it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [04:48<01:49, 36.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.203616394661367\n",
      "MakeWACAXExpDicUnknown Time:  6.578476556576788\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15851.49it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:12,  6.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17997.44it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19673.10it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 28407.07it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21071.61it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22203.83it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 20636.18it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 22963.61it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [05:19<01:09, 34.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.02846076246351\n",
      "MakeWACAXExpDicUnknown Time:  5.419889377430081\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 22086.91it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:12,  6.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23001.39it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22592.53it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18315.74it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22969.90it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23147.37it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 17137.09it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 24463.72it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [05:47<00:32, 32.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.0178816579282284\n",
      "MakeWACAXExpDicUnknown Time:  3.7912202328443527\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12023.23it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17133.59it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:10<00:05,  5.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17851.90it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:17<00:00,  5.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21426.84it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19108.45it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24001.74it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22714.89it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 20555.28it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [06:12<00:00, 41.44s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 170\n",
      "len_exp2_user_47: 146\n",
      "MakeWACAXExpDicOwner Time:  3.0085429744794965\n",
      "MakeWACAXExpDicUnknown Time:  18.191877293400466\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11484.95it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12997.53it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8665.92it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13374.69it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8683.86it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:24<03:12, 24.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 85\n",
      "len_exp2_user_47: 72\n",
      "MakeWACAXExpDicOwner Time:  1.6425723657011986\n",
      "MakeWACAXExpDicUnknown Time:  9.320150422863662\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10441.38it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10650.85it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7978.51it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11028.94it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 5896.67it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [00:37<02:03, 17.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 42\n",
      "len_exp2_user_47: 36\n",
      "MakeWACAXExpDicOwner Time:  0.8776673413813114\n",
      "MakeWACAXExpDicUnknown Time:  4.711092174984515\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 8996.79it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9404.27it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6735.67it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 6345.39it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11519.65it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [00:44<01:16, 12.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 28\n",
      "len_exp2_user_47: 24\n",
      "MakeWACAXExpDicOwner Time:  0.6049384465441108\n",
      "MakeWACAXExpDicUnknown Time:  3.8998494977131486\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10089.74it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6212.86it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9489.38it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8245.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9224.33it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [00:50<00:50, 10.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 21\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  0.6516987197101116\n",
      "MakeWACAXExpDicUnknown Time:  2.6850986927747726\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13888.42it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 7986.11it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13622.29it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 12683.11it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10749.11it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [00:54<00:32,  8.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 16\n",
      "len_exp2_user_47: 14\n",
      "MakeWACAXExpDicOwner Time:  0.45888128131628036\n",
      "MakeWACAXExpDicUnknown Time:  2.377389690838754\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 5536.30it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9476.51it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11732.32it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8356.85it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 15152.83it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [00:58<00:20,  6.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  0.4439499843865633\n",
      "MakeWACAXExpDicUnknown Time:  2.036906295455992\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10485.76it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11428.62it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13311.03it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 16288.56it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10053.46it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [01:02<00:11,  5.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  0.3976971749216318\n",
      "MakeWACAXExpDicUnknown Time:  2.67906510271132\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10472.67it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  5.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9008.38it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  5.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12846.26it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  5.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8363.52it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7222.84it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [01:06<00:05,  5.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 10\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  0.38526147697120905\n",
      "MakeWACAXExpDicUnknown Time:  1.8038084115833044\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 8703.68it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  5.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9300.01it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14079.57it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8794.93it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8639.14it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [01:10<00:00,  7.81s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 29}\n",
      "test_set: {1, 3, 5, 6, 16, 19, 22, 24, 25, 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 170\n",
      "len_exp2_user_47: 146\n",
      "MakeWACAXExpDicOwner Time:  6.974567290395498\n",
      "MakeWACAXExpDicUnknown Time:  48.95133208949119\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15046.83it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:24<00:49, 24.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21231.61it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:46<00:22, 22.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21664.79it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:04<00:00, 21.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 22086.91it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19200.29it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:06<00:09,  3.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 25520.56it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:09<00:06,  3.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18604.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:13<00:03,  3.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17772.47it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:16<00:00,  3.27s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [02:18<18:27, 138.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 85\n",
      "len_exp2_user_47: 72\n",
      "MakeWACAXExpDicOwner Time:  3.5842079427093267\n",
      "MakeWACAXExpDicUnknown Time:  20.154762452468276\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 26412.49it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:09<00:18,  9.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15531.58it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:20<00:10, 10.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18641.35it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:31<00:00, 10.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21492.72it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22417.45it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14295.51it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:02,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 10549.05it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 19920.70it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:07<00:00,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [03:21<10:58, 94.09s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 42\n",
      "len_exp2_user_47: 36\n",
      "MakeWACAXExpDicOwner Time:  2.0290301144123077\n",
      "MakeWACAXExpDicUnknown Time:  14.089617162011564\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15586.41it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15360.94it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20799.92it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 19807.81it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14100.87it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23858.38it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 24420.98it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 23844.82it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [04:01<06:57, 69.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 28\n",
      "len_exp2_user_47: 24\n",
      "MakeWACAXExpDicOwner Time:  1.4365299874916673\n",
      "MakeWACAXExpDicUnknown Time:  9.679211930371821\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18914.56it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 21919.54it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 25289.74it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 24528.09it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20164.92it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17144.10it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19576.68it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 18024.51it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [04:37<04:40, 56.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 21\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  1.2969455029815435\n",
      "MakeWACAXExpDicUnknown Time:  5.824820451438427\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 24125.99it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:07<00:14,  7.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15839.52it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:14<00:07,  7.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22659.67it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:22<00:00,  7.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20155.23it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 25474.06it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22863.47it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 21236.98it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 24230.53it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [05:10<03:10, 47.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 16\n",
      "len_exp2_user_47: 14\n",
      "MakeWACAXExpDicOwner Time:  1.0850357795134187\n",
      "MakeWACAXExpDicUnknown Time:  5.698524680919945\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 20267.23it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19604.13it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:04,  4.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17901.43it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:14<00:00,  4.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 27165.18it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16244.40it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 24694.17it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19512.93it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 20692.18it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [05:35<02:00, 40.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  1.051544020883739\n",
      "MakeWACAXExpDicUnknown Time:  5.9870230024680495\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21366.81it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22616.90it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:12<00:06,  6.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14070.12it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17836.72it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23777.23it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22174.49it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22387.53it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17682.56it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [06:04<01:12, 36.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  0.9918067725375295\n",
      "MakeWACAXExpDicUnknown Time:  5.5931746531277895\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21608.99it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:05<00:11,  5.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20015.77it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15741.43it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:17<00:00,  5.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 26462.49it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 24686.90it/s]\n",
      "/tmp/ipykernel_3197292/1897070050.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 30207.45it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19549.31it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16733.71it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [06:31<00:33, 33.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 10\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  1.0103327156975865\n",
      "MakeWACAXExpDicUnknown Time:  4.985259951092303\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16175.49it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23001.39it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:11<00:05,  5.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 21161.98it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:16<00:00,  5.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15966.14it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16045.54it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16039.40it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 19901.80it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 30023.65it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [06:57<00:00, 46.37s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.723875345662236\n",
      "MakeWACAXExpDicUnknown Time:  17.916942971758544\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13948.47it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12203.39it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 5692.60it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 5997.00it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12045.67it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:23<03:09, 23.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.8022535471245646\n",
      "MakeWACAXExpDicUnknown Time:  8.958262667991221\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11615.35it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8743.60it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9116.07it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13902.23it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8128.50it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [00:36<02:00, 17.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.9005413874983788\n",
      "MakeWACAXExpDicUnknown Time:  4.906572541221976\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9194.00it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10968.37it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14169.95it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9639.86it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10182.82it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [00:43<01:16, 12.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.6482502184808254\n",
      "MakeWACAXExpDicUnknown Time:  3.4875416569411755\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 14051.27it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 5550.22it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9102.22it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13644.45it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13404.61it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [00:49<00:49,  9.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.5011843619868159\n",
      "MakeWACAXExpDicUnknown Time:  2.8491109190508723\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 12368.93it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  5.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6604.16it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8119.06it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  5.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11625.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13538.75it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [00:53<00:31,  7.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.427385276183486\n",
      "MakeWACAXExpDicUnknown Time:  2.2108767945319414\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 14583.81it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11673.54it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8224.13it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 5362.87it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11573.69it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [00:57<00:19,  6.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.485203824006021\n",
      "MakeWACAXExpDicUnknown Time:  2.284234589897096\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11385.19it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6573.11it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8222.51it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8707.29it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10133.62it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [01:01<00:11,  5.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.4548709439113736\n",
      "MakeWACAXExpDicUnknown Time:  1.8995078327134252\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 12300.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9871.27it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11069.69it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  4.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14508.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  5.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 14037.16it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [01:05<00:05,  5.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.358316863887012\n",
      "MakeWACAXExpDicUnknown Time:  1.6314779557287693\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10202.64it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12260.46it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  4.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10019.84it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  5.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8859.96it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:00<00:00,  4.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12014.62it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  4.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [01:08<00:00,  7.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 170\n",
      "len_exp2_user_47: 146\n",
      "MakeWACAXExpDicOwner Time:  6.402058723382652\n",
      "MakeWACAXExpDicUnknown Time:  43.03844966460019\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15141.89it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:19<00:39, 19.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 19755.03it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:36<00:17, 18.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 20742.26it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:54<00:00, 18.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14539.64it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 18417.33it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:06<00:09,  3.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 21503.45it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:09<00:06,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 21116.00it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:12<00:03,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 18269.55it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:15<00:00,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [02:00<16:03, 120.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 85\n",
      "len_exp2_user_47: 72\n",
      "MakeWACAXExpDicOwner Time:  3.7785013439133763\n",
      "MakeWACAXExpDicUnknown Time:  21.887731213122606\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 18107.65it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:09<00:19,  9.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 25420.02it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:18<00:09,  9.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 20288.13it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:27<00:00,  9.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14793.35it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 8962.19it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 23315.32it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 21200.26it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 21929.49it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [03:00<09:53, 84.80s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 42\n",
      "len_exp2_user_47: 36\n",
      "MakeWACAXExpDicOwner Time:  1.9803686272352934\n",
      "MakeWACAXExpDicUnknown Time:  11.751763271167874\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 19513.17it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 22397.91it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:13<00:06,  6.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19413.34it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 21411.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 24047.01it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19161.28it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 22717.15it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 19623.68it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [03:38<06:20, 63.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 28\n",
      "len_exp2_user_47: 24\n",
      "MakeWACAXExpDicOwner Time:  1.3258246844634414\n",
      "MakeWACAXExpDicUnknown Time:  7.997018750756979\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 16809.06it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:09,  4.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 24340.80it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:05,  5.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 27517.88it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:14<00:00,  4.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14547.60it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 26977.58it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 20883.59it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 22404.21it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 18307.32it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [04:05<04:06, 49.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 21\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  1.2604202730581164\n",
      "MakeWACAXExpDicUnknown Time:  6.228522413410246\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 20423.32it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:04<00:08,  4.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 15343.05it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:09<00:04,  4.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19589.92it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:13<00:00,  4.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 19967.87it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 13737.59it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 6322.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 25599.67it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 23888.42it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [04:31<02:42, 40.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 16\n",
      "len_exp2_user_47: 14\n",
      "MakeWACAXExpDicOwner Time:  1.005695546977222\n",
      "MakeWACAXExpDicUnknown Time:  5.312880489043891\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 18252.81it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:08<00:16,  8.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 22118.17it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:16<00:08,  8.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 15337.14it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:24<00:00,  8.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 19385.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 17908.26it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 19735.46it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 24513.00it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 15903.37it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [05:05<01:55, 38.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  1.085991283878684\n",
      "MakeWACAXExpDicUnknown Time:  7.505860981531441\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 18698.21it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:07<00:15,  7.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 18256.99it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:15<00:07,  7.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14274.01it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:23<00:00,  7.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15973.50it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:02<00:08,  2.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 19818.89it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:03<00:05,  1.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 11996.35it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:05<00:03,  1.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 16400.86it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:07<00:01,  1.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 12960.12it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:09<00:00,  1.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [05:47<01:19, 39.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  3.184864643961191\n",
      "MakeWACAXExpDicUnknown Time:  13.798951306380332\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15564.80it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:13<00:27, 13.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 18706.99it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:28<00:14, 14.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 16959.31it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:43<00:00, 14.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 27922.84it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 25949.78it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:02,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14523.74it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 14089.78it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 22743.09it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [06:52<00:47, 47.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 10\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  1.1775426929816604\n",
      "MakeWACAXExpDicUnknown Time:  5.258089699782431\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 11743.56it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:08<00:16,  8.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 16482.27it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:17<00:09,  9.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 15127.52it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:29<00:00,  9.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15653.46it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 464.31it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 18277.93it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 12362.98it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 17997.24it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [07:33<00:00, 50.44s/it]\u001b[A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  3.4072422748431563\n",
      "MakeWACAXExpDicUnknown Time:  68.1426739692688\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7672.04it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11281.08it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:03<00:04,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 8601.94it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:03,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 6431.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:06<00:01,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10740.86it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:07<00:00,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [01:19<10:37, 79.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  4.521204488351941\n",
      "MakeWACAXExpDicUnknown Time:  21.50705394335091\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9749.66it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12737.03it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13569.41it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11507.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9763.28it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [01:51<05:59, 51.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.5578326787799597\n",
      "MakeWACAXExpDicUnknown Time:  11.89823672734201\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7551.86it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10433.59it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9939.11it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11456.72it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9173.89it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [02:08<03:34, 35.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.2163211964070797\n",
      "MakeWACAXExpDicUnknown Time:  7.051723526790738\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7436.71it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8166.48it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10087.31it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9523.85it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11178.85it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [02:19<02:09, 25.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.129080948419869\n",
      "MakeWACAXExpDicUnknown Time:  6.389300592243671\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13400.33it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10757.38it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12494.20it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14543.36it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9770.10it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [02:29<01:21, 20.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.2080251555889845\n",
      "MakeWACAXExpDicUnknown Time:  6.078016218729317\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10567.66it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8423.99it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13460.54it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13801.59it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13976.35it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [02:39<00:50, 16.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.833745239302516\n",
      "MakeWACAXExpDicUnknown Time:  3.655712799169123\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9497.97it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 13920.69it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7025.63it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 7035.06it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9922.65it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [02:46<00:26, 13.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.6792307207360864\n",
      "MakeWACAXExpDicUnknown Time:  3.7202917961403728\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7546.43it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 5332.87it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14349.31it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 13530.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7954.30it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [02:52<00:11, 11.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.7039652392268181\n",
      "MakeWACAXExpDicUnknown Time:  4.300215764902532\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 13675.59it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12056.06it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10297.82it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14820.86it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9779.21it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [03:00<00:00, 20.08s/it]\u001b[A\n",
      "  4%|         | 1/25 [26:03<10:25:30, 1563.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap: 0.05\n",
      "train_set: {0, 1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 16, 18, 19, 22, 23, 24, 25, 28}\n",
      "test_set: {7, 8, 11, 13, 17, 20, 21, 26, 27, 29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  13.44922476168722\n",
      "MakeWACAXExpDicUnknown Time:  106.76592712290585\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17780.01it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:41<01:23, 41.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15169.27it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [01:29<00:45, 45.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19244.34it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [02:16<00:00, 45.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18279.82it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:05<00:22,  5.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 19934.90it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:11<00:16,  5.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23090.03it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:17<00:11,  5.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18604.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:22<00:05,  5.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 15809.66it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:27<00:00,  5.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [04:47<38:19, 287.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  5.017404213547707\n",
      "MakeWACAXExpDicUnknown Time:  63.83331601973623\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 13695.69it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:32<01:05, 32.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23334.10it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [01:02<00:31, 31.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 11011.56it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:39<00:00, 33.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14319.92it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:08<00:32,  8.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15866.48it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:14<00:21,  7.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16225.55it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:20<00:13,  6.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 13711.36it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:26<00:06,  6.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 19253.17it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:32<00:00,  6.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [08:10<27:43, 237.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  9.124296789057553\n",
      "MakeWACAXExpDicUnknown Time:  51.07904012687504\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 8806.01it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:26<00:53, 26.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 12801.17it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:45<00:21, 21.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 10875.93it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:06<00:00, 22.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15738.48it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:02<00:11,  2.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 9764.41it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:05<00:08,  2.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 11087.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:08<00:05,  2.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14425.81it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:10<00:02,  2.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16178.61it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:13<00:00,  2.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [10:31<19:22, 193.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  3.643716244958341\n",
      "MakeWACAXExpDicUnknown Time:  35.95035358890891\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 13981.01it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:27<00:55, 27.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 13344.91it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:55<00:27, 27.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15670.85it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:21<00:00, 27.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17567.77it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:04<00:16,  4.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 18884.75it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:07<00:11,  3.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19996.68it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:10<00:06,  3.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14942.30it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:13<00:03,  3.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16082.45it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:13<00:00,  2.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [12:48<14:15, 171.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.7226130049675703\n",
      "MakeWACAXExpDicUnknown Time:  17.64414941519499\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14146.05it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:10<00:21, 10.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14217.98it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:19<00:09,  9.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15682.57it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:31<00:00, 10.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15993.53it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 13471.35it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16082.45it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 24413.88it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 22197.96it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [13:44<08:39, 129.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  1.48500682041049\n",
      "MakeWACAXExpDicUnknown Time:  10.227495177648962\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14724.61it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:11<00:22, 11.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17564.09it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:19<00:09,  9.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22209.71it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:30<00:00, 10.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 11634.69it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:06,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16750.42it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 721.50it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:02,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14455.64it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 14490.60it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [14:34<05:07, 102.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.1189033444970846\n",
      "MakeWACAXExpDicUnknown Time:  13.17762834019959\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12080.37it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:13<00:27, 13.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 7078.40it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:27<00:13, 13.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20966.28it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:40<00:00, 13.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17396.53it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23026.65it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 15011.83it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 23590.01it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17935.87it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [15:37<02:59, 89.55s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.9856747211888433\n",
      "MakeWACAXExpDicUnknown Time:  12.793324812315404\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14470.60it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:12<00:25, 12.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20605.77it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:23<00:11, 11.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 19821.85it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:35<00:00, 11.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15400.42it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:05,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 12125.77it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:04,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18641.35it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:04<00:02,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 13675.59it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17893.79it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [16:35<01:19, 79.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 20\n",
      "len(exp2_df_user_set_dict): 20\n",
      "MakeWACAXExpDicOwner Time:  2.298408350907266\n",
      "MakeWACAXExpDicUnknown Time:  11.188969055190682\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17924.38it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:14<00:28, 14.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 24701.44it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:25<00:12, 12.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 11500.70it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:35<00:00, 11.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15375.01it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16159.91it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18691.19it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 15744.38it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17346.17it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [17:29<00:00, 116.64s/it][A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 177\n",
      "len_exp2_user_47: 152\n",
      "MakeWACAXExpDicOwner Time:  5.646578682586551\n",
      "MakeWACAXExpDicUnknown Time:  28.26496188621968\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7590.13it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 6946.51it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7271.68it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 6247.10it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 6154.52it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:37<05:01, 37.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 88\n",
      "len_exp2_user_47: 75\n",
      "MakeWACAXExpDicOwner Time:  2.6389266876503825\n",
      "MakeWACAXExpDicUnknown Time:  29.032219405286014\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 6065.52it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 4923.47it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 4743.61it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 12108.27it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 13327.94it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [01:12<04:11, 35.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 44\n",
      "len_exp2_user_47: 37\n",
      "MakeWACAXExpDicOwner Time:  1.570518552325666\n",
      "MakeWACAXExpDicUnknown Time:  12.084281113930047\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7399.97it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 7603.89it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6938.47it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9666.52it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 10212.57it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [01:28<02:41, 26.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 29\n",
      "len_exp2_user_47: 25\n",
      "MakeWACAXExpDicOwner Time:  1.255798996426165\n",
      "MakeWACAXExpDicUnknown Time:  7.694261500611901\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9376.94it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9191.99it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 14558.50it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10007.88it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 11444.21it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  2.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [01:40<01:44, 20.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 22\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  1.0342196822166443\n",
      "MakeWACAXExpDicUnknown Time:  5.801073816604912\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11081.38it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:00,  4.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 9333.12it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10843.60it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10202.64it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 5344.42it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [01:48<01:05, 16.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 17\n",
      "len_exp2_user_47: 15\n",
      "MakeWACAXExpDicOwner Time:  0.6764977378770709\n",
      "MakeWACAXExpDicUnknown Time:  7.845889360643923\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 10664.39it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 12314.46it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12035.31it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 12246.14it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9244.66it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [02:02<00:46, 15.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  1.6253250045701861\n",
      "MakeWACAXExpDicUnknown Time:  9.590213736519217\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 3622.65it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 2768.52it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11005.78it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 11831.61it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 142.48it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [02:19<00:31, 15.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  2.3164569037035108\n",
      "MakeWACAXExpDicUnknown Time:  10.783875731751323\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 8454.55it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 11217.72it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7124.69it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 139.66it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8320.38it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [02:38<00:17, 17.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 9\n",
      "len(exp2_df_user_set_dict): 9\n",
      "len(X_exp1_dict_user_47[47]): 11\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  2.1874612076207995\n",
      "MakeWACAXExpDicUnknown Time:  9.51250284910202\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 7777.31it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 7791.76it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 144.90it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8623.16it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:04<00:01,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12014.62it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:05<00:00,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [02:57<00:00, 19.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 29}\n",
      "test_set: {1, 3, 5, 6, 16, 19, 22, 24, 25, 28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 177\n",
      "len_exp2_user_47: 152\n",
      "MakeWACAXExpDicOwner Time:  34.60823003668338\n",
      "MakeWACAXExpDicUnknown Time:  168.01018220931292\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16584.83it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:49<01:39, 49.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 18204.44it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [01:41<00:50, 50.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17989.72it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [02:26<00:00, 48.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17560.41it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:15,  3.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20223.26it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:07<00:10,  3.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 12620.14it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:11<00:07,  3.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 10818.43it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:18<00:05,  5.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 8963.15it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:23<00:00,  4.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [06:18<50:29, 378.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 88\n",
      "len_exp2_user_47: 75\n",
      "MakeWACAXExpDicOwner Time:  9.293520550243556\n",
      "MakeWACAXExpDicUnknown Time:  59.82032685074955\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16138.15it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:24<00:49, 25.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15299.30it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:49<00:24, 24.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17989.72it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:13<00:00, 24.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21119.36it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:12,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 16760.46it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:05<00:08,  2.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 23295.22it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:07<00:04,  2.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 24556.81it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:10<00:02,  2.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 17836.72it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:13<00:00,  2.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [08:56<29:01, 248.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 44\n",
      "len_exp2_user_47: 37\n",
      "MakeWACAXExpDicOwner Time:  4.157510015182197\n",
      "MakeWACAXExpDicUnknown Time:  28.85785575862974\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17140.60it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:32, 16.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17465.35it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:37<00:19, 19.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16513.01it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:57<00:00, 19.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14619.39it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:02<00:10,  2.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 20641.26it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:04<00:07,  2.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14016.05it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:06<00:04,  2.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 13718.08it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:08<00:02,  2.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 13536.56it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:10<00:00,  2.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [10:39<18:13, 182.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 29\n",
      "len_exp2_user_47: 25\n",
      "MakeWACAXExpDicOwner Time:  4.485120779834688\n",
      "MakeWACAXExpDicUnknown Time:  24.304850295186043\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 16710.37it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:21<00:42, 21.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 17667.67it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:45<00:22, 22.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16584.83it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:15<00:00, 25.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 280.37it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:05<00:20,  5.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15966.14it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:09<00:13,  4.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14753.09it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:12<00:08,  4.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14203.54it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:15<00:03,  3.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 11891.99it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:18<00:00,  3.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [12:43<13:16, 159.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 22\n",
      "len_exp2_user_47: 18\n",
      "MakeWACAXExpDicOwner Time:  6.80146892182529\n",
      "MakeWACAXExpDicUnknown Time:  34.2798173064366\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 13747.31it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:27<00:54, 27.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 18424.35it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:41<00:19, 19.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 16493.53it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:53<00:00, 17.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12748.64it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 22104.37it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 20810.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:03<00:02,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 22239.15it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:05<00:01,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 12637.25it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:06<00:00,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [14:26<09:15, 138.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 17\n",
      "len_exp2_user_47: 15\n",
      "MakeWACAXExpDicOwner Time:  3.028493197634816\n",
      "MakeWACAXExpDicUnknown Time:  18.4162190342322\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 14203.54it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:32, 16.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 15650.39it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:41<00:21, 21.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 13580.39it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:08<00:00, 22.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 21092.80it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:03<00:14,  3.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 13072.48it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:07<00:11,  3.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 14239.70it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:11<00:07,  3.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 14100.87it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:14<00:03,  3.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 21432.31it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:18<00:00,  3.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [16:16<06:26, 128.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 14\n",
      "len_exp2_user_47: 12\n",
      "MakeWACAXExpDicOwner Time:  5.723335294984281\n",
      "MakeWACAXExpDicUnknown Time:  20.778546553105116\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 15960.06it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:16<00:33, 16.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14818.24it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:27<00:13, 13.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 22369.62it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:40<00:00, 13.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 19257.59it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 12717.72it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 13558.44it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 25221.31it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 23425.32it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [17:28<03:40, 110.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 12\n",
      "len_exp2_user_47: 10\n",
      "MakeWACAXExpDicOwner Time:  1.3907674914225936\n",
      "MakeWACAXExpDicUnknown Time:  7.342415659688413\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 17168.66it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:11<00:22, 11.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14639.80it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:20<00:09,  9.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 13332.18it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:27<00:00,  9.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 12766.11it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 14670.53it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 18078.90it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 20510.04it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 20375.54it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [18:10<01:28, 88.61s/it] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 11\n",
      "len_exp2_user_47: 9\n",
      "MakeWACAXExpDicOwner Time:  1.4088567923754454\n",
      "MakeWACAXExpDicUnknown Time:  6.435919989831746\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 18012.90it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [00:06<00:13,  6.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23140.99it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [00:13<00:06,  6.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17091.70it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 20/20 [00:00<00:00, 25358.55it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 20/20 [00:00<00:00, 23844.82it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 20/20 [00:00<00:00, 17634.24it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 20/20 [00:00<00:00, 18157.16it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 20/20 [00:00<00:00, 16116.44it/s]\n",
      "/tmp/ipykernel_3197292/1897070050.py:65: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:03<00:00,  1.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [18:41<00:00, 124.60s/it][A\n",
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  3.95137061458081\n",
      "MakeWACAXExpDicUnknown Time:  31.834782402031124\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 6068.15it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:03,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10252.52it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:02,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 12706.16it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 9943.82it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:03<00:00,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9845.78it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:04<00:00,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [00:40<05:24, 40.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.0745624285191298\n",
      "MakeWACAXExpDicUnknown Time:  17.033634278923273\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9802.07it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:02,  1.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 13617.87it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:01<00:01,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 9848.10it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:01,  1.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8075.29it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 12045.67it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|       | 2/9 [01:02<03:28, 29.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  2.0295411655679345\n",
      "MakeWACAXExpDicUnknown Time:  10.922234673984349\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9713.53it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 10675.25it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 7487.15it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 5466.32it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 8954.53it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|      | 3/9 [01:17<02:18, 23.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  1.3289865450933576\n",
      "MakeWACAXExpDicUnknown Time:  6.870485887862742\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 11125.47it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:01<00:04,  1.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8856.22it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:02<00:03,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 13582.59it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:02<00:01,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10506.77it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:02<00:00,  1.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7123.48it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:02<00:00,  1.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|     | 4/9 [01:29<01:32, 18.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.8527107750996947\n",
      "MakeWACAXExpDicUnknown Time:  4.912846205756068\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9806.65it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 4783.65it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10648.14it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8427.37it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 9153.87it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|    | 5/9 [01:37<00:58, 14.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.8118496034294367\n",
      "MakeWACAXExpDicUnknown Time:  4.558354647830129\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 5997.86it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8709.10it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 11755.34it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10804.49it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 4976.63it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|   | 6/9 [01:44<00:36, 12.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1500\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.5281705372035503\n",
      "MakeWACAXExpDicUnknown Time:  4.3306869100779295\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 9543.35it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  2.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8101.80it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 10379.37it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 8880.59it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7247.80it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|  | 7/9 [01:51<00:20, 10.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 1750\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.7715822532773018\n",
      "MakeWACAXExpDicUnknown Time:  4.1501827938482165\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 6020.24it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 8950.71it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:00,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6010.75it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:00<00:00,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 14227.63it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 7966.39it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%| | 8/9 [01:57<00:09,  9.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2000\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 10\n",
      "len(exp2_df_user_set_dict): 10\n",
      "MakeWACAXExpDicOwner Time:  0.4177145939320326\n",
      "MakeWACAXExpDicUnknown Time:  3.526060733012855\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 10/10 [00:00<00:00, 5833.52it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:00<00:01,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 10/10 [00:00<00:00, 5871.09it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:00<00:01,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 10/10 [00:00<00:00, 6793.50it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:01<00:00,  2.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 10/10 [00:00<00:00, 10190.24it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:01<00:00,  2.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 10/10 [00:00<00:00, 5888.40it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:01<00:00,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 9/9 [02:03<00:00, 13.76s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: {1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29}\n",
      "test_set: {0, 2, 4, 9, 10, 12, 14, 15, 18, 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 125\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 177\n",
      "len_exp2_user_47: 152\n",
      "MakeWACAXExpDicOwner Time:  9.285374538041651\n",
      "MakeWACAXExpDicUnknown Time:  95.71120078209788\n",
      "Done extracting features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 14338.21it/s]\n",
      "\n",
      "\n",
      " 33%|      | 1/3 [01:01<02:02, 61.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 13718.67it/s]\n",
      "\n",
      "\n",
      " 67%|   | 2/3 [02:41<01:23, 83.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14455.25it/s]\n",
      "\n",
      "\n",
      "100%|| 3/3 [03:47<00:00, 75.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 0: 100%|| 19/19 [00:00<00:00, 15777.43it/s]\n",
      "\n",
      "\n",
      " 20%|        | 1/5 [00:07<00:29,  7.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 1: 100%|| 19/19 [00:00<00:00, 13610.89it/s]\n",
      "\n",
      "\n",
      " 40%|      | 2/5 [00:14<00:21,  7.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 2: 100%|| 19/19 [00:00<00:00, 14568.88it/s]\n",
      "\n",
      "\n",
      " 60%|    | 3/5 [00:20<00:13,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 3: 100%|| 19/19 [00:00<00:00, 12113.05it/s]\n",
      "\n",
      "\n",
      " 80%|  | 4/5 [00:26<00:06,  6.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "run: 4: 100%|| 19/19 [00:00<00:00, 430.97it/s]\n",
      "\n",
      "\n",
      "100%|| 5/5 [00:31<00:00,  6.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|         | 1/9 [06:05<48:44, 365.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 250\n",
      "WACA preprocessing\n",
      "len(exp1_df_user_set_dict): 19\n",
      "len(exp2_df_user_set_dict): 19\n",
      "len(X_exp1_dict_user_47[47]): 88\n",
      "len_exp2_user_47: 75\n",
      "MakeWACAXExpDicOwner Time:  15.585523591376841\n"
     ]
    }
   ],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "\n",
    "dfList_dict={\n",
    "            \"dfList_exp1\": raw_dfList_exp1,\n",
    "            \"dfList_exp2\": raw_dfList_exp2,\n",
    "            \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "            \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "}\n",
    "\n",
    "for overlap in tqdm(OVERLAP_EXP_RANGE):\n",
    "\n",
    "    train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap={overlap}_Mean_EER_df_train_dict.txt\"\n",
    "    test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap={overlap}_Mean_EER_df_test_dict.txt\"\n",
    "    \n",
    "    with open(train_file_name, \"w\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    with open(test_file_name, \"w\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "    overlap*=0.01\n",
    "    print(f\"overlap: {overlap}\")\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "\n",
    "\n",
    "    key_column= [\"overlap\"]\n",
    "    #-----CV_FOLD-------\n",
    "    for cv_fold_idx in range(len(THREE_FOLD_CV)):\n",
    "        process_cv_fold_OCSVM_LOF_IF(\\\n",
    "                                    cv_fold_idx=cv_fold_idx, \n",
    "                                    cv_sets=THREE_FOLD_CV, \n",
    "                                    dfList_dict=dfList_dict, \n",
    "                                    window_size_lst=WINDOW_SIZE_LST, \n",
    "                                    exp_config=P, \n",
    "                                    extract_features_dict=EXTRACT_WACA_features_DICT, \n",
    "                                    overlap=overlap, \n",
    "                                    param_dist=param_dist, \n",
    "                                    train_file_name=train_file_name, \n",
    "                                    test_file_name=test_file_name, \n",
    "                                    preprocessing_params=overlap, \n",
    "                                    key_column=key_column,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_experiment_params(exp_config=P)\n",
    "\n",
    "print(f\"train_set: {train_set+[47]}\")\n",
    "print(f\"test_set: {test_set}\")\n",
    "\n",
    "\n",
    "\n",
    "time_of_execution = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
    "train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_train_dict.txt\"\n",
    "test_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/overlap_Mean_EER_df_test_dict.txt\"\n",
    "with open(train_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{train_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "with open(test_file_name, \"w\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{time_of_execution}\" + \"-\"*40 + \"\\n\")\n",
    "    f.write(\"\\n\" + \"-\"*40 + f\"{test_file_name}\" + \"-\"*40 + \"\\n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "EER_df_train_dict={}\n",
    "EER_df_test_dict={}\n",
    "for overlap in tqdm(OVERLAP_EXP_RANGE):\n",
    "    overlap*=0.01\n",
    "    max_window_size=2000\n",
    "    step_width = int(max_window_size * (1-overlap))\n",
    "    # max_num_windows=min(len(getIndices(sampleSize=max_window_size, step=step_width, numSamplePoints=P.num_sample_points_per_exp)), N_NEIGHBORS_PARAMS[-1]+1)\n",
    "    \n",
    "    dfList_dict={\n",
    "                \"dfList_exp1\": raw_dfList_exp1,\n",
    "                \"dfList_exp2\": raw_dfList_exp2,\n",
    "                \"dfList_exp1_user_47\": raw_dfList_exp1_user_47,\n",
    "                \"dfList_exp2_user_47\": raw_dfList_exp2_user_47\n",
    "    }\n",
    "    \n",
    "\n",
    "    EER_df_train_dict[overlap] = calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, train_set=train_set, exp_config=P, \n",
    "                                                                                     extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                     param_dist=param_dist)\n",
    "        \n",
    "    with open(train_file_name, \"a\") as f:\n",
    "        f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "        f.write(f\"\\overlap: {overlap}\\n\")\n",
    "        f.write(EER_df_train_dict[overlap].to_string())\n",
    "\n",
    "\n",
    "        \n",
    "mean_EER_train_dict={}\n",
    "for key in EER_df_train_dict:\n",
    "    mean_EER_train_dict[key] = EER_df_train_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "#-------\n",
    "train_lst = list(mean_EER_train_dict.items())\n",
    "train_lst.sort(key=lambda i: i[1], reverse=False) #sort ascending as it is an error rate\n",
    "\n",
    "with open(train_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(train_lst)):\n",
    "        f.write(f\"{i+1}) {train_lst[i]}\\n\")\n",
    "        \n",
    "\n",
    "min_key=train_lst[0][0]\n",
    "overlap=min_key\n",
    "EER_df_test_dict[min_key] = calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst=WINDOW_SIZE_LST, test_set=test_set, exp_config=P, \n",
    "                                                                                   extract_features_func_dict=EXTRACT_WACA_features_DICT, overlap=OVERLAP, \n",
    "                                                                                   best_param_df=EER_df_train_dict[min_key])\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\Top smoothing parameter/s: {min_key}\\n\")\n",
    "    f.write(EER_df_test_dict[min_key].to_string())\n",
    "#-------\n",
    "#-------\n",
    "key_column= [\"overlap\"]\n",
    "EER_df_test_dict_df=make_raw_exp_df_results(EER_df_test_dict, key_column)\n",
    "eer_per_window_size_col_df =make_eer_per_window_size_col_df(EER_df_test_dict_df, key_column, window_size_lst=WINDOW_SIZE_LST)\n",
    "\n",
    "EER_df_test_dict_df.to_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "eer_per_window_size_col_df.to_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json')\n",
    "#-------\n",
    "\n",
    "mean_EER_test_dict={}\n",
    "for key in EER_df_test_dict:\n",
    "    mean_EER_test_dict[key] = EER_df_test_dict[key][\"Mean_EER\"].mean()\n",
    "    \n",
    "l = list(mean_EER_test_dict.items())\n",
    "l.sort(key=lambda i: i[1])\n",
    "\n",
    "with open(test_file_name, \"a\") as f:\n",
    "    f.write(\"\\n\" + \"-\"*22 + \"\\n\")\n",
    "    f.write(f\"\\nSorting based on Mean EER among windows\\n\")\n",
    "    for i in range(len(l)):\n",
    "        f.write(f\"{i+1}) {l[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"cut_off_freq\" and \"SMA_winsize\" in EER_df_test_dict_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 EER per window for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_file_name=f\"{FINAL_EXP_RESULTS_PATH}/{EXP_PATH_NAME}/clip={P.scaler_clip}-{P.smoothing}_Mean_EER_{preprocessing_method}_df_train_dict.txt\"\n",
    "def return_and_save_final_result_df_as_json(final_exp_results_path, exp_path_name, window_size_lst):\n",
    "    window_size_cols=[('Window Size', winsize) for winsize in window_size_lst]\n",
    "    preprocessing_methods=[\"Naive\", \"Realworld-per_unknown_window\"]\n",
    "    smoothing_methods=[\"Butterworth\", \"EMA\", \"SMA\", \"Butter+EMA\", \"Butter+SMA\"]\n",
    "    concate_df_lst=[]\n",
    "    \n",
    "    \n",
    "    test_file_name=f\"{final_exp_results_path}/{exp_path_name}/clip={P.scaler_clip}-None_Mean_EER_None_df_test_dict.txt\"\n",
    "    eer_per_window_size_col_df = pd.read_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json').drop([\"('', 'mean')\", \"('', 'var')\"], axis=1)#\"('index', '')\", \n",
    "    # print(eer_per_window_size_col_df)\n",
    "    # Convert the string representation of tuples back to tuples\n",
    "    idx_tuples = [eval(i) for i in eer_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "    # Convert list of tuples back to a MultiIndex\n",
    "    multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "    eer_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "    eer_per_window_size_col_df[(\"\", 'type')] = 'None'\n",
    "    \n",
    "    concate_df_lst.append(eer_per_window_size_col_df)\n",
    "            \n",
    "            \n",
    "    for sm in smoothing_methods:\n",
    "        for pm in preprocessing_methods:\n",
    "            test_file_name=f\"{final_exp_results_path}/{exp_path_name}/clip={P.scaler_clip}-{sm}_Mean_EER_{pm}_df_test_dict.txt\"\n",
    "            eer_per_window_size_col_df = pd.read_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json').drop([\"('', 'mean')\", \"('', 'var')\"], axis=1)#\"('index', '')\", \n",
    "            # print(eer_per_window_size_col_df)\n",
    "            # Convert the string representation of tuples back to tuples\n",
    "            idx_tuples = [eval(i) for i in eer_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "            # Convert list of tuples back to a MultiIndex\n",
    "            multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "            eer_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "            if pm ==\"Realworld-per_unknown_window\":\n",
    "                pm=\"Real\"\n",
    "            eer_per_window_size_col_df[(\"\", 'type')] = f'{pm}'\n",
    "\n",
    "            concate_df_lst.append(eer_per_window_size_col_df)\n",
    "\n",
    "    df = pd.concat(concate_df_lst)\n",
    "    # # add a new column 'Mean' which is the mean of each row across the columns '125', '1500', and '2000'\n",
    "    # df['Mean'] = df[['125', '1500', '2000']].mean(axis=1)\n",
    "    df=df[[\n",
    "        (           '', 'cut_off_freq'),\n",
    "        (           '',     'EMA_span'),\n",
    "        (           '',  'SMA_winsize'),\n",
    "        (           '', 'type'),\n",
    "        ]+window_size_cols]\n",
    "\n",
    "    df = df.fillna(DASH_MACRO_NUM).reset_index(drop=True)\n",
    "\n",
    "    df[(\"\", 'cut_off_freq')] = df[(\"\", 'cut_off_freq')].astype(np.int64)\n",
    "    df[(\"\", 'EMA_span')] = df[(\"\", 'EMA_span')].astype(np.int64)\n",
    "    df[(\"\", 'SMA_winsize')] = df[(\"\", 'SMA_winsize')].astype(np.int64)\n",
    "\n",
    "    df[(\"\", \"mean\")] = df[window_size_cols].mean(axis=1)\n",
    "    df[(\"\", \"variance\")] = df[window_size_cols].var(axis=1)\n",
    "\n",
    "    df[(\"\", 'mean rank')] = df[(\"\", \"mean\")].rank(method='min').astype(np.int64)\n",
    "    cols = list(df.columns)\n",
    "    df = df[[cols[-1]] + cols[:-1]]\n",
    "\n",
    "    df.replace(DASH_MACRO_NUM, \"-\", inplace=True)\n",
    "\n",
    "    df.to_json(f\"{final_exp_results_path}/{exp_path_name}/{exp_path_name}-df.json\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th colspan=\"9\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>1250</th>\n",
       "      <th>1500</th>\n",
       "      <th>1750</th>\n",
       "      <th>2000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.164775</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.067537</td>\n",
       "      <td>0.059697</td>\n",
       "      <td>0.048925</td>\n",
       "      <td>0.048507</td>\n",
       "      <td>0.038162</td>\n",
       "      <td>0.039565</td>\n",
       "      <td>0.039611</td>\n",
       "      <td>0.068256</td>\n",
       "      <td>0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.159846</td>\n",
       "      <td>0.098326</td>\n",
       "      <td>0.063561</td>\n",
       "      <td>0.053899</td>\n",
       "      <td>0.044065</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.036337</td>\n",
       "      <td>0.034686</td>\n",
       "      <td>0.039778</td>\n",
       "      <td>0.063805</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.159401</td>\n",
       "      <td>0.099102</td>\n",
       "      <td>0.063275</td>\n",
       "      <td>0.053091</td>\n",
       "      <td>0.046486</td>\n",
       "      <td>0.043368</td>\n",
       "      <td>0.039396</td>\n",
       "      <td>0.036425</td>\n",
       "      <td>0.044870</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.001613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>25</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.150082</td>\n",
       "      <td>0.100466</td>\n",
       "      <td>0.064342</td>\n",
       "      <td>0.054128</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>0.033745</td>\n",
       "      <td>0.035089</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.062017</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.188279</td>\n",
       "      <td>0.125269</td>\n",
       "      <td>0.072816</td>\n",
       "      <td>0.059098</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>0.044340</td>\n",
       "      <td>0.035597</td>\n",
       "      <td>0.037681</td>\n",
       "      <td>0.037852</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.002697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>41</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.149116</td>\n",
       "      <td>0.099783</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>0.056202</td>\n",
       "      <td>0.043803</td>\n",
       "      <td>0.038519</td>\n",
       "      <td>0.037750</td>\n",
       "      <td>0.042077</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.063421</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.164037</td>\n",
       "      <td>0.107957</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.059684</td>\n",
       "      <td>0.048925</td>\n",
       "      <td>0.048507</td>\n",
       "      <td>0.038162</td>\n",
       "      <td>0.039565</td>\n",
       "      <td>0.039611</td>\n",
       "      <td>0.068222</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.150753</td>\n",
       "      <td>0.099805</td>\n",
       "      <td>0.064574</td>\n",
       "      <td>0.055185</td>\n",
       "      <td>0.043135</td>\n",
       "      <td>0.037153</td>\n",
       "      <td>0.032977</td>\n",
       "      <td>0.033688</td>\n",
       "      <td>0.036519</td>\n",
       "      <td>0.061532</td>\n",
       "      <td>0.001578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.101426</td>\n",
       "      <td>0.063052</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>0.045483</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.039012</td>\n",
       "      <td>0.039742</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>0.065113</td>\n",
       "      <td>0.001737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>-</td>\n",
       "      <td>46</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>0.096893</td>\n",
       "      <td>0.069058</td>\n",
       "      <td>0.054916</td>\n",
       "      <td>0.044137</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>0.036653</td>\n",
       "      <td>0.041031</td>\n",
       "      <td>0.038019</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.161919</td>\n",
       "      <td>0.099279</td>\n",
       "      <td>0.064913</td>\n",
       "      <td>0.049414</td>\n",
       "      <td>0.045881</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>0.036927</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.042944</td>\n",
       "      <td>0.064919</td>\n",
       "      <td>0.001697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Window Size            \\\n",
       "   mean rank cut_off_freq EMA_span SMA_winsize   type         125       250   \n",
       "0         10            -        -           -      -    0.164775  0.107527   \n",
       "1          5           41        -           -  Naive    0.159846  0.098326   \n",
       "2          7           49        -           -   Real    0.159401  0.099102   \n",
       "3          2            -       25           -  Naive    0.150082  0.100466   \n",
       "4         11            -        9           -   Real    0.188279  0.125269   \n",
       "5          4            -        -          41  Naive    0.149116  0.099783   \n",
       "6          9            -        -           1   Real    0.164037  0.107957   \n",
       "7          1           24       30           -  Naive    0.150753  0.099805   \n",
       "8          8           40        3           -   Real    0.163043  0.101426   \n",
       "9          3           34        -          46  Naive    0.145163  0.096893   \n",
       "10         6           26        -           2   Real    0.161919  0.099279   \n",
       "\n",
       "                                                                          \\\n",
       "         500       750      1000      1250      1500      1750      2000   \n",
       "0   0.067537  0.059697  0.048925  0.048507  0.038162  0.039565  0.039611   \n",
       "1   0.063561  0.053899  0.044065  0.043750  0.036337  0.034686  0.039778   \n",
       "2   0.063275  0.053091  0.046486  0.043368  0.039396  0.036425  0.044870   \n",
       "3   0.064342  0.054128  0.045664  0.039005  0.033745  0.035089  0.035630   \n",
       "4   0.072816  0.059098  0.047191  0.044340  0.035597  0.037681  0.037852   \n",
       "5   0.066577  0.056202  0.043803  0.038519  0.037750  0.042077  0.036963   \n",
       "6   0.067550  0.059684  0.048925  0.048507  0.038162  0.039565  0.039611   \n",
       "7   0.064574  0.055185  0.043135  0.037153  0.032977  0.033688  0.036519   \n",
       "8   0.063052  0.049367  0.045483  0.042616  0.039012  0.039742  0.042278   \n",
       "9   0.069058  0.054916  0.044137  0.038067  0.036653  0.041031  0.038019   \n",
       "10  0.064913  0.049414  0.045881  0.044907  0.036927  0.038084  0.042944   \n",
       "\n",
       "                        \n",
       "        mean  variance  \n",
       "0   0.068256  0.001781  \n",
       "1   0.063805  0.001686  \n",
       "2   0.065046  0.001613  \n",
       "3   0.062017  0.001540  \n",
       "4   0.072014  0.002697  \n",
       "5   0.063421  0.001443  \n",
       "6   0.068222  0.001767  \n",
       "7   0.061532  0.001578  \n",
       "8   0.065113  0.001737  \n",
       "9   0.062660  0.001347  \n",
       "10  0.064919  0.001697  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=return_and_save_final_result_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.164775</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.067537</td>\n",
       "      <td>0.059697</td>\n",
       "      <td>0.048925</td>\n",
       "      <td>0.089692</td>\n",
       "      <td>0.002252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.159846</td>\n",
       "      <td>0.098326</td>\n",
       "      <td>0.063561</td>\n",
       "      <td>0.053899</td>\n",
       "      <td>0.044065</td>\n",
       "      <td>0.083939</td>\n",
       "      <td>0.002219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.159401</td>\n",
       "      <td>0.099102</td>\n",
       "      <td>0.063275</td>\n",
       "      <td>0.053091</td>\n",
       "      <td>0.046486</td>\n",
       "      <td>0.084271</td>\n",
       "      <td>0.002176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>25</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.150082</td>\n",
       "      <td>0.100466</td>\n",
       "      <td>0.064342</td>\n",
       "      <td>0.054128</td>\n",
       "      <td>0.045664</td>\n",
       "      <td>0.082936</td>\n",
       "      <td>0.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>-</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.188279</td>\n",
       "      <td>0.125269</td>\n",
       "      <td>0.072816</td>\n",
       "      <td>0.059098</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>0.098530</td>\n",
       "      <td>0.003405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>41</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.149116</td>\n",
       "      <td>0.099783</td>\n",
       "      <td>0.066577</td>\n",
       "      <td>0.056202</td>\n",
       "      <td>0.043803</td>\n",
       "      <td>0.083096</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.164037</td>\n",
       "      <td>0.107957</td>\n",
       "      <td>0.067550</td>\n",
       "      <td>0.059684</td>\n",
       "      <td>0.048925</td>\n",
       "      <td>0.089631</td>\n",
       "      <td>0.002228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.150753</td>\n",
       "      <td>0.099805</td>\n",
       "      <td>0.064574</td>\n",
       "      <td>0.055185</td>\n",
       "      <td>0.043135</td>\n",
       "      <td>0.082690</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.101426</td>\n",
       "      <td>0.063052</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>0.045483</td>\n",
       "      <td>0.084474</td>\n",
       "      <td>0.002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>-</td>\n",
       "      <td>46</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.145163</td>\n",
       "      <td>0.096893</td>\n",
       "      <td>0.069058</td>\n",
       "      <td>0.054916</td>\n",
       "      <td>0.044137</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.001637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.161919</td>\n",
       "      <td>0.099279</td>\n",
       "      <td>0.064913</td>\n",
       "      <td>0.049414</td>\n",
       "      <td>0.045881</td>\n",
       "      <td>0.084281</td>\n",
       "      <td>0.002329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Window Size            \\\n",
       "   mean rank cut_off_freq EMA_span SMA_winsize   type         125       250   \n",
       "0         10            -        -           -      -    0.164775  0.107527   \n",
       "1          5           41        -           -  Naive    0.159846  0.098326   \n",
       "2          6           49        -           -   Real    0.159401  0.099102   \n",
       "3          3            -       25           -  Naive    0.150082  0.100466   \n",
       "4         11            -        9           -   Real    0.188279  0.125269   \n",
       "5          4            -        -          41  Naive    0.149116  0.099783   \n",
       "6          9            -        -           1   Real    0.164037  0.107957   \n",
       "7          2           24       30           -  Naive    0.150753  0.099805   \n",
       "8          8           40        3           -   Real    0.163043  0.101426   \n",
       "9          1           34        -          46  Naive    0.145163  0.096893   \n",
       "10         7           26        -           2   Real    0.161919  0.099279   \n",
       "\n",
       "                                                      \n",
       "         500       750      1000      mean  variance  \n",
       "0   0.067537  0.059697  0.048925  0.089692  0.002252  \n",
       "1   0.063561  0.053899  0.044065  0.083939  0.002219  \n",
       "2   0.063275  0.053091  0.046486  0.084271  0.002176  \n",
       "3   0.064342  0.054128  0.045664  0.082936  0.001845  \n",
       "4   0.072816  0.059098  0.047191  0.098530  0.003405  \n",
       "5   0.066577  0.056202  0.043803  0.083096  0.001794  \n",
       "6   0.067550  0.059684  0.048925  0.089631  0.002228  \n",
       "7   0.064574  0.055185  0.043135  0.082690  0.001894  \n",
       "8   0.063052  0.049367  0.045483  0.084474  0.002418  \n",
       "9   0.069058  0.054916  0.044137  0.082034  0.001637  \n",
       "10  0.064913  0.049414  0.045881  0.084281  0.002329  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=return_and_save_final_result_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST_NN, save_file_suffix=\"-max1000\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Relative improvment of EER per window for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df=return_and_save_final_relative_result_df_as_json(df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round numbers\n",
    "df.style.format(STYLER_ERR_FORMAT_DICT).hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_df.style.format(STYLER_IMPROVEMENT_FORMAT_DICT).hide(axis='index').to_latex()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Gini coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\"></th>\n",
       "      <th colspan=\"9\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>cut_off_freq</th>\n",
       "      <th>EMA_span</th>\n",
       "      <th>SMA_winsize</th>\n",
       "      <th>type</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>1250</th>\n",
       "      <th>1500</th>\n",
       "      <th>1750</th>\n",
       "      <th>2000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.505542</td>\n",
       "      <td>0.648686</td>\n",
       "      <td>0.760365</td>\n",
       "      <td>0.802483</td>\n",
       "      <td>0.824444</td>\n",
       "      <td>0.837377</td>\n",
       "      <td>0.846027</td>\n",
       "      <td>0.853184</td>\n",
       "      <td>0.854115</td>\n",
       "      <td>0.770247</td>\n",
       "      <td>0.014135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.519781</td>\n",
       "      <td>0.648594</td>\n",
       "      <td>0.755737</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.817226</td>\n",
       "      <td>0.829894</td>\n",
       "      <td>0.849773</td>\n",
       "      <td>0.856780</td>\n",
       "      <td>0.859871</td>\n",
       "      <td>0.770671</td>\n",
       "      <td>0.013268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.519788</td>\n",
       "      <td>0.645630</td>\n",
       "      <td>0.755237</td>\n",
       "      <td>0.798820</td>\n",
       "      <td>0.800549</td>\n",
       "      <td>0.823963</td>\n",
       "      <td>0.854829</td>\n",
       "      <td>0.846497</td>\n",
       "      <td>0.849403</td>\n",
       "      <td>0.766080</td>\n",
       "      <td>0.012773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>25</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.576245</td>\n",
       "      <td>0.673661</td>\n",
       "      <td>0.762083</td>\n",
       "      <td>0.797733</td>\n",
       "      <td>0.829241</td>\n",
       "      <td>0.833064</td>\n",
       "      <td>0.856024</td>\n",
       "      <td>0.847971</td>\n",
       "      <td>0.871685</td>\n",
       "      <td>0.783079</td>\n",
       "      <td>0.009678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.469574</td>\n",
       "      <td>0.605745</td>\n",
       "      <td>0.719450</td>\n",
       "      <td>0.790035</td>\n",
       "      <td>0.808972</td>\n",
       "      <td>0.838947</td>\n",
       "      <td>0.849311</td>\n",
       "      <td>0.858400</td>\n",
       "      <td>0.851103</td>\n",
       "      <td>0.754615</td>\n",
       "      <td>0.018127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>41</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.668115</td>\n",
       "      <td>0.756799</td>\n",
       "      <td>0.788865</td>\n",
       "      <td>0.821333</td>\n",
       "      <td>0.835681</td>\n",
       "      <td>0.862674</td>\n",
       "      <td>0.848944</td>\n",
       "      <td>0.854848</td>\n",
       "      <td>0.781185</td>\n",
       "      <td>0.008742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.506022</td>\n",
       "      <td>0.648311</td>\n",
       "      <td>0.760350</td>\n",
       "      <td>0.802472</td>\n",
       "      <td>0.824444</td>\n",
       "      <td>0.837377</td>\n",
       "      <td>0.846027</td>\n",
       "      <td>0.853184</td>\n",
       "      <td>0.854115</td>\n",
       "      <td>0.770256</td>\n",
       "      <td>0.014115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>-</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.681948</td>\n",
       "      <td>0.771622</td>\n",
       "      <td>0.795331</td>\n",
       "      <td>0.830572</td>\n",
       "      <td>0.835501</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.856070</td>\n",
       "      <td>0.869509</td>\n",
       "      <td>0.785989</td>\n",
       "      <td>0.008959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.511157</td>\n",
       "      <td>0.640560</td>\n",
       "      <td>0.754012</td>\n",
       "      <td>0.810120</td>\n",
       "      <td>0.811535</td>\n",
       "      <td>0.838678</td>\n",
       "      <td>0.824275</td>\n",
       "      <td>0.844133</td>\n",
       "      <td>0.835455</td>\n",
       "      <td>0.763325</td>\n",
       "      <td>0.013048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>-</td>\n",
       "      <td>46</td>\n",
       "      <td>Naive</td>\n",
       "      <td>0.608996</td>\n",
       "      <td>0.673289</td>\n",
       "      <td>0.749378</td>\n",
       "      <td>0.790327</td>\n",
       "      <td>0.816545</td>\n",
       "      <td>0.839589</td>\n",
       "      <td>0.868439</td>\n",
       "      <td>0.867799</td>\n",
       "      <td>0.862823</td>\n",
       "      <td>0.786354</td>\n",
       "      <td>0.008573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>Real</td>\n",
       "      <td>0.517772</td>\n",
       "      <td>0.643776</td>\n",
       "      <td>0.751348</td>\n",
       "      <td>0.803055</td>\n",
       "      <td>0.809384</td>\n",
       "      <td>0.829675</td>\n",
       "      <td>0.845695</td>\n",
       "      <td>0.831326</td>\n",
       "      <td>0.843836</td>\n",
       "      <td>0.763985</td>\n",
       "      <td>0.012590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Window Size            \\\n",
       "   mean rank cut_off_freq EMA_span SMA_winsize   type         125       250   \n",
       "0          5            -        -           -      -    0.505542  0.648686   \n",
       "1          7           41        -           -  Naive    0.519781  0.648594   \n",
       "2          4           49        -           -   Real    0.519788  0.645630   \n",
       "3          9            -       25           -  Naive    0.576245  0.673661   \n",
       "4          1            -        9           -   Real    0.469574  0.605745   \n",
       "5          8            -        -          41  Naive    0.593407  0.668115   \n",
       "6          6            -        -           1   Real    0.506022  0.648311   \n",
       "7         10           24       30           -  Naive    0.585105  0.681948   \n",
       "8          2           40        3           -   Real    0.511157  0.640560   \n",
       "9         11           34        -          46  Naive    0.608996  0.673289   \n",
       "10         3           26        -           2   Real    0.517772  0.643776   \n",
       "\n",
       "                                                                          \\\n",
       "         500       750      1000      1250      1500      1750      2000   \n",
       "0   0.760365  0.802483  0.824444  0.837377  0.846027  0.853184  0.854115   \n",
       "1   0.755737  0.798387  0.817226  0.829894  0.849773  0.856780  0.859871   \n",
       "2   0.755237  0.798820  0.800549  0.823963  0.854829  0.846497  0.849403   \n",
       "3   0.762083  0.797733  0.829241  0.833064  0.856024  0.847971  0.871685   \n",
       "4   0.719450  0.790035  0.808972  0.838947  0.849311  0.858400  0.851103   \n",
       "5   0.756799  0.788865  0.821333  0.835681  0.862674  0.848944  0.854848   \n",
       "6   0.760350  0.802472  0.824444  0.837377  0.846027  0.853184  0.854115   \n",
       "7   0.771622  0.795331  0.830572  0.835501  0.848243  0.856070  0.869509   \n",
       "8   0.754012  0.810120  0.811535  0.838678  0.824275  0.844133  0.835455   \n",
       "9   0.749378  0.790327  0.816545  0.839589  0.868439  0.867799  0.862823   \n",
       "10  0.751348  0.803055  0.809384  0.829675  0.845695  0.831326  0.843836   \n",
       "\n",
       "                        \n",
       "        mean  variance  \n",
       "0   0.770247  0.014135  \n",
       "1   0.770671  0.013268  \n",
       "2   0.766080  0.012773  \n",
       "3   0.783079  0.009678  \n",
       "4   0.754615  0.018127  \n",
       "5   0.781185  0.008742  \n",
       "6   0.770256  0.014115  \n",
       "7   0.785989  0.008959  \n",
       "8   0.763325  0.013048  \n",
       "9   0.786354  0.008573  \n",
       "10  0.763985  0.012590  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_result_df=return_and_save_final_Gini_df_as_json(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "gini_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_and_save_final_relative_gini_result_df_as_json(gini_result_df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, \n",
    "                                                      exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row number 4 is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Overlap experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 EER df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WACA-OCSVM'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_EXP_RESULTS_PATH\n",
    "EXP_PATH_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "      <th colspan=\"9\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>overlap</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>1250</th>\n",
       "      <th>1500</th>\n",
       "      <th>1750</th>\n",
       "      <th>2000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.171562</td>\n",
       "      <td>0.108484</td>\n",
       "      <td>0.071861</td>\n",
       "      <td>0.055913</td>\n",
       "      <td>0.049753</td>\n",
       "      <td>0.043611</td>\n",
       "      <td>0.041243</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.046741</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.164886</td>\n",
       "      <td>0.107955</td>\n",
       "      <td>0.068620</td>\n",
       "      <td>0.058621</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.047963</td>\n",
       "      <td>0.041235</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.070011</td>\n",
       "      <td>0.001689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.170094</td>\n",
       "      <td>0.112850</td>\n",
       "      <td>0.064678</td>\n",
       "      <td>0.055099</td>\n",
       "      <td>0.052323</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.041368</td>\n",
       "      <td>0.046835</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.001879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.174460</td>\n",
       "      <td>0.105926</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>0.051262</td>\n",
       "      <td>0.050612</td>\n",
       "      <td>0.044464</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.046068</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>0.069793</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.169819</td>\n",
       "      <td>0.109314</td>\n",
       "      <td>0.071778</td>\n",
       "      <td>0.053086</td>\n",
       "      <td>0.041081</td>\n",
       "      <td>0.042019</td>\n",
       "      <td>0.038565</td>\n",
       "      <td>0.037831</td>\n",
       "      <td>0.040370</td>\n",
       "      <td>0.067096</td>\n",
       "      <td>0.002030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.168778</td>\n",
       "      <td>0.105664</td>\n",
       "      <td>0.064366</td>\n",
       "      <td>0.055810</td>\n",
       "      <td>0.052536</td>\n",
       "      <td>0.044056</td>\n",
       "      <td>0.042309</td>\n",
       "      <td>0.041481</td>\n",
       "      <td>0.041282</td>\n",
       "      <td>0.068476</td>\n",
       "      <td>0.001828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.165801</td>\n",
       "      <td>0.112279</td>\n",
       "      <td>0.066714</td>\n",
       "      <td>0.054735</td>\n",
       "      <td>0.048011</td>\n",
       "      <td>0.043973</td>\n",
       "      <td>0.042675</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0.043162</td>\n",
       "      <td>0.068773</td>\n",
       "      <td>0.001829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.165969</td>\n",
       "      <td>0.111795</td>\n",
       "      <td>0.069393</td>\n",
       "      <td>0.055423</td>\n",
       "      <td>0.044547</td>\n",
       "      <td>0.046618</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.035903</td>\n",
       "      <td>0.042831</td>\n",
       "      <td>0.068601</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.171565</td>\n",
       "      <td>0.105887</td>\n",
       "      <td>0.071643</td>\n",
       "      <td>0.056766</td>\n",
       "      <td>0.046951</td>\n",
       "      <td>0.046049</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>0.042840</td>\n",
       "      <td>0.069085</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.165884</td>\n",
       "      <td>0.105895</td>\n",
       "      <td>0.068199</td>\n",
       "      <td>0.058484</td>\n",
       "      <td>0.050174</td>\n",
       "      <td>0.041524</td>\n",
       "      <td>0.040952</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>0.067648</td>\n",
       "      <td>0.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.169893</td>\n",
       "      <td>0.107243</td>\n",
       "      <td>0.073365</td>\n",
       "      <td>0.052665</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.048765</td>\n",
       "      <td>0.042915</td>\n",
       "      <td>0.043918</td>\n",
       "      <td>0.038976</td>\n",
       "      <td>0.069751</td>\n",
       "      <td>0.001863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.167784</td>\n",
       "      <td>0.107125</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>0.056985</td>\n",
       "      <td>0.046266</td>\n",
       "      <td>0.045837</td>\n",
       "      <td>0.041852</td>\n",
       "      <td>0.039912</td>\n",
       "      <td>0.038642</td>\n",
       "      <td>0.067773</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.164535</td>\n",
       "      <td>0.108622</td>\n",
       "      <td>0.065176</td>\n",
       "      <td>0.057462</td>\n",
       "      <td>0.051981</td>\n",
       "      <td>0.045671</td>\n",
       "      <td>0.041795</td>\n",
       "      <td>0.040236</td>\n",
       "      <td>0.045770</td>\n",
       "      <td>0.069028</td>\n",
       "      <td>0.001723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.165323</td>\n",
       "      <td>0.111113</td>\n",
       "      <td>0.065408</td>\n",
       "      <td>0.060792</td>\n",
       "      <td>0.049578</td>\n",
       "      <td>0.047451</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>0.038256</td>\n",
       "      <td>0.040423</td>\n",
       "      <td>0.068687</td>\n",
       "      <td>0.001823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.165648</td>\n",
       "      <td>0.107127</td>\n",
       "      <td>0.067052</td>\n",
       "      <td>0.058859</td>\n",
       "      <td>0.051576</td>\n",
       "      <td>0.043784</td>\n",
       "      <td>0.039247</td>\n",
       "      <td>0.037365</td>\n",
       "      <td>0.038116</td>\n",
       "      <td>0.067642</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.167183</td>\n",
       "      <td>0.104799</td>\n",
       "      <td>0.066352</td>\n",
       "      <td>0.059439</td>\n",
       "      <td>0.046161</td>\n",
       "      <td>0.046883</td>\n",
       "      <td>0.043922</td>\n",
       "      <td>0.042337</td>\n",
       "      <td>0.044148</td>\n",
       "      <td>0.069025</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.167202</td>\n",
       "      <td>0.109969</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.060883</td>\n",
       "      <td>0.051162</td>\n",
       "      <td>0.044034</td>\n",
       "      <td>0.040419</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>0.068944</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.169013</td>\n",
       "      <td>0.105738</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.057197</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.045285</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.040167</td>\n",
       "      <td>0.069613</td>\n",
       "      <td>0.001844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.165535</td>\n",
       "      <td>0.105986</td>\n",
       "      <td>0.069854</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.048815</td>\n",
       "      <td>0.044790</td>\n",
       "      <td>0.040574</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>0.041564</td>\n",
       "      <td>0.068980</td>\n",
       "      <td>0.001767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.167608</td>\n",
       "      <td>0.107026</td>\n",
       "      <td>0.068261</td>\n",
       "      <td>0.055976</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>0.045185</td>\n",
       "      <td>0.038171</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.068360</td>\n",
       "      <td>0.001835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.169672</td>\n",
       "      <td>0.109041</td>\n",
       "      <td>0.067301</td>\n",
       "      <td>0.059793</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>0.048735</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>0.040734</td>\n",
       "      <td>0.044619</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.001821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.168979</td>\n",
       "      <td>0.109252</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.055699</td>\n",
       "      <td>0.048325</td>\n",
       "      <td>0.047635</td>\n",
       "      <td>0.042878</td>\n",
       "      <td>0.039510</td>\n",
       "      <td>0.039780</td>\n",
       "      <td>0.068691</td>\n",
       "      <td>0.001886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.168662</td>\n",
       "      <td>0.108460</td>\n",
       "      <td>0.069027</td>\n",
       "      <td>0.060982</td>\n",
       "      <td>0.047218</td>\n",
       "      <td>0.044450</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>0.041232</td>\n",
       "      <td>0.041575</td>\n",
       "      <td>0.069507</td>\n",
       "      <td>0.001847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.170435</td>\n",
       "      <td>0.110749</td>\n",
       "      <td>0.069060</td>\n",
       "      <td>0.060147</td>\n",
       "      <td>0.049893</td>\n",
       "      <td>0.046093</td>\n",
       "      <td>0.043180</td>\n",
       "      <td>0.041903</td>\n",
       "      <td>0.040611</td>\n",
       "      <td>0.070230</td>\n",
       "      <td>0.001899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Window Size                                          \\\n",
       "   mean rank overlap         125       250       500       750      1000   \n",
       "0         22    0.01    0.171562  0.108484  0.071861  0.055913  0.049753   \n",
       "1         20    0.05    0.164886  0.107955  0.068620  0.058621  0.050303   \n",
       "2         23    0.09    0.170094  0.112850  0.064678  0.055099  0.052323   \n",
       "3         19    0.13    0.174460  0.105926  0.065517  0.051262  0.050612   \n",
       "4          1    0.17    0.169819  0.109314  0.071778  0.053086  0.041081   \n",
       "5          6    0.21    0.168778  0.105664  0.064366  0.055810  0.052536   \n",
       "6         10    0.25    0.165801  0.112279  0.066714  0.054735  0.048011   \n",
       "7          7    0.29    0.165969  0.111795  0.069393  0.055423  0.044547   \n",
       "8         15    0.33    0.171565  0.105887  0.071643  0.056766  0.046951   \n",
       "9          3    0.37    0.165884  0.105895  0.068199  0.058484  0.050174   \n",
       "10        18    0.41    0.169893  0.107243  0.073365  0.052665  0.050022   \n",
       "11         4    0.45    0.167784  0.107125  0.065551  0.056985  0.046266   \n",
       "12        14    0.49    0.164535  0.108622  0.065176  0.057462  0.051981   \n",
       "13         8    0.53    0.165323  0.111113  0.065408  0.060792  0.049578   \n",
       "14         2    0.57    0.165648  0.107127  0.067052  0.058859  0.051576   \n",
       "15        13    0.61    0.167183  0.104799  0.066352  0.059439  0.046161   \n",
       "16        11    0.65    0.167202  0.109969  0.068158  0.060883  0.051162   \n",
       "17        17    0.69    0.169013  0.105738  0.075310  0.057197  0.050000   \n",
       "18        12    0.73    0.165535  0.105986  0.069854  0.064239  0.048815   \n",
       "19         5    0.77    0.167608  0.107026  0.068261  0.055976  0.042912   \n",
       "20        24    0.81    0.169672  0.109041  0.067301  0.059793  0.050185   \n",
       "21         9    0.85    0.168979  0.109252  0.066162  0.055699  0.048325   \n",
       "22        16    0.89    0.168662  0.108460  0.069027  0.060982  0.047218   \n",
       "23        21    0.93    0.170435  0.110749  0.069060  0.060147  0.049893   \n",
       "\n",
       "                                                                \n",
       "        1250      1500      1750      2000      mean  variance  \n",
       "0   0.043611  0.041243  0.044444  0.046741  0.070401  0.001890  \n",
       "1   0.042810  0.047963  0.041235  0.047710  0.070011  0.001689  \n",
       "2   0.049774  0.040790  0.041368  0.046835  0.070423  0.001879  \n",
       "3   0.044464  0.044000  0.046068  0.045825  0.069793  0.001929  \n",
       "4   0.042019  0.038565  0.037831  0.040370  0.067096  0.002030  \n",
       "5   0.044056  0.042309  0.041481  0.041282  0.068476  0.001828  \n",
       "6   0.043973  0.042675  0.041605  0.043162  0.068773  0.001829  \n",
       "7   0.046618  0.044932  0.035903  0.042831  0.068601  0.001860  \n",
       "8   0.046049  0.038889  0.041176  0.042840  0.069085  0.001927  \n",
       "9   0.041524  0.040952  0.038807  0.038912  0.067648  0.001819  \n",
       "10  0.048765  0.042915  0.043918  0.038976  0.069751  0.001863  \n",
       "11  0.045837  0.041852  0.039912  0.038642  0.067773  0.001864  \n",
       "12  0.045671  0.041795  0.040236  0.045770  0.069028  0.001723  \n",
       "13  0.047451  0.039841  0.038256  0.040423  0.068687  0.001823  \n",
       "14  0.043784  0.039247  0.037365  0.038116  0.067642  0.001833  \n",
       "15  0.046883  0.043922  0.042337  0.044148  0.069025  0.001749  \n",
       "16  0.044034  0.040419  0.038507  0.040159  0.068944  0.001864  \n",
       "17  0.045285  0.042903  0.040905  0.040167  0.069613  0.001844  \n",
       "18  0.044790  0.040574  0.039467  0.041564  0.068980  0.001767  \n",
       "19  0.045802  0.045185  0.038171  0.044295  0.068360  0.001835  \n",
       "20  0.048735  0.044418  0.040734  0.044619  0.070500  0.001821  \n",
       "21  0.047635  0.042878  0.039510  0.039780  0.068691  0.001886  \n",
       "22  0.044450  0.043953  0.041232  0.041575  0.069507  0.001847  \n",
       "23  0.046093  0.043180  0.041903  0.040611  0.070230  0.001899  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_df=return_and_save_final_result_df_as_json_overlap(final_exp_results_path=FINAL_EXP_RESULTS_PATH, exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "overlap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 relative EER df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "      <th colspan=\"9\" halign=\"left\">Window Size</th>\n",
       "      <th colspan=\"2\" halign=\"left\"></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean rank</th>\n",
       "      <th>overlap</th>\n",
       "      <th>125</th>\n",
       "      <th>250</th>\n",
       "      <th>500</th>\n",
       "      <th>750</th>\n",
       "      <th>1000</th>\n",
       "      <th>1250</th>\n",
       "      <th>1500</th>\n",
       "      <th>1750</th>\n",
       "      <th>2000</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.891380</td>\n",
       "      <td>0.487737</td>\n",
       "      <td>4.510314</td>\n",
       "      <td>-4.843249</td>\n",
       "      <td>-1.105346</td>\n",
       "      <td>1.835894</td>\n",
       "      <td>-16.292495</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>-2.074629</td>\n",
       "      <td>0.553921</td>\n",
       "      <td>10.653613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.855665</td>\n",
       "      <td>-4.025105</td>\n",
       "      <td>9.995358</td>\n",
       "      <td>1.455721</td>\n",
       "      <td>-5.165802</td>\n",
       "      <td>-14.130691</td>\n",
       "      <td>1.098995</td>\n",
       "      <td>6.923077</td>\n",
       "      <td>-0.201700</td>\n",
       "      <td>-0.031361</td>\n",
       "      <td>0.586465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-1.688966</td>\n",
       "      <td>2.357714</td>\n",
       "      <td>8.827770</td>\n",
       "      <td>8.318547</td>\n",
       "      <td>-1.726184</td>\n",
       "      <td>-1.955526</td>\n",
       "      <td>-6.683772</td>\n",
       "      <td>-3.653846</td>\n",
       "      <td>1.959372</td>\n",
       "      <td>0.864654</td>\n",
       "      <td>-2.055329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.015793</td>\n",
       "      <td>-0.765650</td>\n",
       "      <td>0.115352</td>\n",
       "      <td>5.054806</td>\n",
       "      <td>17.429280</td>\n",
       "      <td>3.651805</td>\n",
       "      <td>6.494548</td>\n",
       "      <td>14.880952</td>\n",
       "      <td>13.629160</td>\n",
       "      <td>4.695016</td>\n",
       "      <td>-7.401615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.622717</td>\n",
       "      <td>2.599275</td>\n",
       "      <td>10.429312</td>\n",
       "      <td>0.184528</td>\n",
       "      <td>-5.592670</td>\n",
       "      <td>-1.021130</td>\n",
       "      <td>-2.584613</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>11.678654</td>\n",
       "      <td>2.735006</td>\n",
       "      <td>3.303074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.358124</td>\n",
       "      <td>-3.498486</td>\n",
       "      <td>7.162284</td>\n",
       "      <td>2.106791</td>\n",
       "      <td>3.501516</td>\n",
       "      <td>-0.829956</td>\n",
       "      <td>-3.470886</td>\n",
       "      <td>6.388889</td>\n",
       "      <td>7.655736</td>\n",
       "      <td>2.313295</td>\n",
       "      <td>3.266099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.259807</td>\n",
       "      <td>-3.052713</td>\n",
       "      <td>3.433465</td>\n",
       "      <td>0.876539</td>\n",
       "      <td>10.464619</td>\n",
       "      <td>-6.895597</td>\n",
       "      <td>-8.942980</td>\n",
       "      <td>19.218750</td>\n",
       "      <td>8.365406</td>\n",
       "      <td>2.556906</td>\n",
       "      <td>1.637229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>2.393220</td>\n",
       "      <td>0.303223</td>\n",
       "      <td>-1.526193</td>\n",
       "      <td>5.632754</td>\n",
       "      <td>-5.590941</td>\n",
       "      <td>5.708788</td>\n",
       "      <td>7.352941</td>\n",
       "      <td>8.346540</td>\n",
       "      <td>1.869528</td>\n",
       "      <td>-1.926508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.37</td>\n",
       "      <td>3.309370</td>\n",
       "      <td>2.385950</td>\n",
       "      <td>5.095996</td>\n",
       "      <td>-4.598896</td>\n",
       "      <td>-0.845223</td>\n",
       "      <td>4.785236</td>\n",
       "      <td>0.705581</td>\n",
       "      <td>12.685185</td>\n",
       "      <td>16.749208</td>\n",
       "      <td>3.911003</td>\n",
       "      <td>3.756128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.973162</td>\n",
       "      <td>1.143557</td>\n",
       "      <td>-2.093508</td>\n",
       "      <td>5.808416</td>\n",
       "      <td>-0.540067</td>\n",
       "      <td>-11.818825</td>\n",
       "      <td>-4.052207</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>16.612287</td>\n",
       "      <td>0.923296</td>\n",
       "      <td>1.457431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.202282</td>\n",
       "      <td>1.252635</td>\n",
       "      <td>8.780955</td>\n",
       "      <td>-1.918145</td>\n",
       "      <td>7.008249</td>\n",
       "      <td>-5.102863</td>\n",
       "      <td>-1.475305</td>\n",
       "      <td>10.198413</td>\n",
       "      <td>17.326994</td>\n",
       "      <td>3.734003</td>\n",
       "      <td>1.395782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.096060</td>\n",
       "      <td>-0.127893</td>\n",
       "      <td>9.302209</td>\n",
       "      <td>-2.771425</td>\n",
       "      <td>-4.478908</td>\n",
       "      <td>-4.723992</td>\n",
       "      <td>-1.337149</td>\n",
       "      <td>9.469697</td>\n",
       "      <td>2.076904</td>\n",
       "      <td>1.951201</td>\n",
       "      <td>8.847621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>3.636611</td>\n",
       "      <td>-2.423897</td>\n",
       "      <td>8.979072</td>\n",
       "      <td>-8.726332</td>\n",
       "      <td>0.352011</td>\n",
       "      <td>-8.804796</td>\n",
       "      <td>3.399615</td>\n",
       "      <td>13.923611</td>\n",
       "      <td>13.515961</td>\n",
       "      <td>2.434601</td>\n",
       "      <td>3.563849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.447389</td>\n",
       "      <td>1.250782</td>\n",
       "      <td>6.691005</td>\n",
       "      <td>-5.270352</td>\n",
       "      <td>-3.664009</td>\n",
       "      <td>-0.395937</td>\n",
       "      <td>4.839744</td>\n",
       "      <td>15.929487</td>\n",
       "      <td>18.452422</td>\n",
       "      <td>3.920022</td>\n",
       "      <td>3.041042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.552201</td>\n",
       "      <td>3.396292</td>\n",
       "      <td>7.665485</td>\n",
       "      <td>-6.307074</td>\n",
       "      <td>7.219889</td>\n",
       "      <td>-7.503495</td>\n",
       "      <td>-6.493605</td>\n",
       "      <td>4.741379</td>\n",
       "      <td>5.546751</td>\n",
       "      <td>1.954902</td>\n",
       "      <td>7.507716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.541169</td>\n",
       "      <td>-1.369189</td>\n",
       "      <td>5.153175</td>\n",
       "      <td>-8.889738</td>\n",
       "      <td>-2.832207</td>\n",
       "      <td>-0.969261</td>\n",
       "      <td>1.998582</td>\n",
       "      <td>13.359375</td>\n",
       "      <td>14.081956</td>\n",
       "      <td>2.070499</td>\n",
       "      <td>1.420966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.485540</td>\n",
       "      <td>2.530946</td>\n",
       "      <td>-4.799417</td>\n",
       "      <td>-2.296922</td>\n",
       "      <td>-0.496278</td>\n",
       "      <td>-3.837988</td>\n",
       "      <td>-4.023151</td>\n",
       "      <td>7.962963</td>\n",
       "      <td>14.063698</td>\n",
       "      <td>1.119567</td>\n",
       "      <td>2.449296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.513022</td>\n",
       "      <td>2.302648</td>\n",
       "      <td>2.792722</td>\n",
       "      <td>-14.891773</td>\n",
       "      <td>1.885856</td>\n",
       "      <td>-2.702508</td>\n",
       "      <td>1.621919</td>\n",
       "      <td>11.199187</td>\n",
       "      <td>11.075894</td>\n",
       "      <td>2.018345</td>\n",
       "      <td>6.524631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.304768</td>\n",
       "      <td>1.343783</td>\n",
       "      <td>5.008795</td>\n",
       "      <td>-0.113476</td>\n",
       "      <td>13.749154</td>\n",
       "      <td>-5.024770</td>\n",
       "      <td>-9.557409</td>\n",
       "      <td>14.114583</td>\n",
       "      <td>5.233567</td>\n",
       "      <td>2.899981</td>\n",
       "      <td>2.916430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.101666</td>\n",
       "      <td>-0.513346</td>\n",
       "      <td>6.345345</td>\n",
       "      <td>-6.939571</td>\n",
       "      <td>-0.868486</td>\n",
       "      <td>-11.748054</td>\n",
       "      <td>-7.696312</td>\n",
       "      <td>8.347701</td>\n",
       "      <td>4.539946</td>\n",
       "      <td>-0.139649</td>\n",
       "      <td>3.674704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.505673</td>\n",
       "      <td>-0.708251</td>\n",
       "      <td>7.929503</td>\n",
       "      <td>0.382571</td>\n",
       "      <td>2.870264</td>\n",
       "      <td>-9.225654</td>\n",
       "      <td>-3.962900</td>\n",
       "      <td>11.103604</td>\n",
       "      <td>14.892036</td>\n",
       "      <td>2.429359</td>\n",
       "      <td>0.223009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.690291</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>3.942880</td>\n",
       "      <td>-9.066738</td>\n",
       "      <td>5.094940</td>\n",
       "      <td>-1.922542</td>\n",
       "      <td>-6.569068</td>\n",
       "      <td>7.227723</td>\n",
       "      <td>11.051606</td>\n",
       "      <td>1.270858</td>\n",
       "      <td>2.276511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.656747</td>\n",
       "      <td>-2.087842</td>\n",
       "      <td>3.897863</td>\n",
       "      <td>-7.573414</td>\n",
       "      <td>-0.280654</td>\n",
       "      <td>-5.691511</td>\n",
       "      <td>-4.694772</td>\n",
       "      <td>5.717300</td>\n",
       "      <td>13.114394</td>\n",
       "      <td>0.243214</td>\n",
       "      <td>-0.461846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Window Size                                             \\\n",
       "   mean rank overlap         125       250        500        750       1000   \n",
       "0         22    0.01    0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "1         20    0.05    3.891380  0.487737   4.510314  -4.843249  -1.105346   \n",
       "2         23    0.09    0.855665 -4.025105   9.995358   1.455721  -5.165802   \n",
       "3         19    0.13   -1.688966  2.357714   8.827770   8.318547  -1.726184   \n",
       "4          1    0.17    1.015793 -0.765650   0.115352   5.054806  17.429280   \n",
       "5          6    0.21    1.622717  2.599275  10.429312   0.184528  -5.592670   \n",
       "6         10    0.25    3.358124 -3.498486   7.162284   2.106791   3.501516   \n",
       "7          7    0.29    3.259807 -3.052713   3.433465   0.876539  10.464619   \n",
       "8         15    0.33   -0.001844  2.393220   0.303223  -1.526193   5.632754   \n",
       "9          3    0.37    3.309370  2.385950   5.095996  -4.598896  -0.845223   \n",
       "10        18    0.41    0.973162  1.143557  -2.093508   5.808416  -0.540067   \n",
       "11         4    0.45    2.202282  1.252635   8.780955  -1.918145   7.008249   \n",
       "12        14    0.49    4.096060 -0.127893   9.302209  -2.771425  -4.478908   \n",
       "13         8    0.53    3.636611 -2.423897   8.979072  -8.726332   0.352011   \n",
       "14         2    0.57    3.447389  1.250782   6.691005  -5.270352  -3.664009   \n",
       "15        13    0.61    2.552201  3.396292   7.665485  -6.307074   7.219889   \n",
       "16        11    0.65    2.541169 -1.369189   5.153175  -8.889738  -2.832207   \n",
       "17        17    0.69    1.485540  2.530946  -4.799417  -2.296922  -0.496278   \n",
       "18        12    0.73    3.513022  2.302648   2.792722 -14.891773   1.885856   \n",
       "19         5    0.77    2.304768  1.343783   5.008795  -0.113476  13.749154   \n",
       "20        24    0.81    1.101666 -0.513346   6.345345  -6.939571  -0.868486   \n",
       "21         9    0.85    1.505673 -0.708251   7.929503   0.382571   2.870264   \n",
       "22        16    0.89    1.690291  0.021587   3.942880  -9.066738   5.094940   \n",
       "23        21    0.93    0.656747 -2.087842   3.897863  -7.573414  -0.280654   \n",
       "\n",
       "                                                                     \n",
       "         1250       1500       1750       2000      mean   variance  \n",
       "0    0.000000   0.000000   0.000000   0.000000  0.000000   0.000000  \n",
       "1    1.835894 -16.292495   7.222222  -2.074629  0.553921  10.653613  \n",
       "2  -14.130691   1.098995   6.923077  -0.201700 -0.031361   0.586465  \n",
       "3   -1.955526  -6.683772  -3.653846   1.959372  0.864654  -2.055329  \n",
       "4    3.651805   6.494548  14.880952  13.629160  4.695016  -7.401615  \n",
       "5   -1.021130  -2.584613   6.666667  11.678654  2.735006   3.303074  \n",
       "6   -0.829956  -3.470886   6.388889   7.655736  2.313295   3.266099  \n",
       "7   -6.895597  -8.942980  19.218750   8.365406  2.556906   1.637229  \n",
       "8   -5.590941   5.708788   7.352941   8.346540  1.869528  -1.926508  \n",
       "9    4.785236   0.705581  12.685185  16.749208  3.911003   3.756128  \n",
       "10 -11.818825  -4.052207   1.184211  16.612287  0.923296   1.457431  \n",
       "11  -5.102863  -1.475305  10.198413  17.326994  3.734003   1.395782  \n",
       "12  -4.723992  -1.337149   9.469697   2.076904  1.951201   8.847621  \n",
       "13  -8.804796   3.399615  13.923611  13.515961  2.434601   3.563849  \n",
       "14  -0.395937   4.839744  15.929487  18.452422  3.920022   3.041042  \n",
       "15  -7.503495  -6.493605   4.741379   5.546751  1.954902   7.507716  \n",
       "16  -0.969261   1.998582  13.359375  14.081956  2.070499   1.420966  \n",
       "17  -3.837988  -4.023151   7.962963  14.063698  1.119567   2.449296  \n",
       "18  -2.702508   1.621919  11.199187  11.075894  2.018345   6.524631  \n",
       "19  -5.024770  -9.557409  14.114583   5.233567  2.899981   2.916430  \n",
       "20 -11.748054  -7.696312   8.347701   4.539946 -0.139649   3.674704  \n",
       "21  -9.225654  -3.962900  11.103604  14.892036  2.429359   0.223009  \n",
       "22  -1.922542  -6.569068   7.227723  11.051606  1.270858   2.276511  \n",
       "23  -5.691511  -4.694772   5.717300  13.114394  0.243214  -0.461846  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_overlap_df=return_and_save_final_relative_result_df_as_json_overlap(overlap_df, base_case_index=0, final_exp_results_path=FINAL_EXP_RESULTS_PATH, \n",
    "                                                                     exp_path_name=EXP_PATH_NAME, window_size_lst=WINDOW_SIZE_LST)\n",
    "relative_overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97]\n"
     ]
    }
   ],
   "source": [
    "print(OVERLAP_EXP_RANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
