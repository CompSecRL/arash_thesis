{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset [link](https://can01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrive.google.com%2Fdrive%2Ffolders%2F1-6sd6E3cL8uWdNeO4xiXxLbTSYXSTiVr%3Fusp%3Dsharing&data=04%7C01%7Carash.gholami%40queensu.ca%7C92b180b5b67d475fb70e08d87b7f4305%7Cd61ecb3b38b142d582c4efb2838b925c%7C1%7C0%7C637395133804367020%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=1ieR3E8llMblC0QMBtx1%2FpHS71RQuCxzdNQLmH0HJVU%3D&reserved=0)\n",
    "\n",
    "Explanation: There are **49** users' data here. Naming is in the format of Username_ExperimentNumber. Please also note that it is unprocessed raw data, which includes a lot of noise etc. \n",
    "\n",
    "Experiment-1: **20** participants are involved in this task and the participants were asked to type **a story** from **a set** of short and simple stories from the American Literature https://americanliterature.com/100-great-short-stories for **four minutes**. The story was chosen randomly by the participants.\n",
    "\n",
    "Experiment-2: 20 participants are involved in this task and for this data set, all the participants were asked to type the **same text** https://en.wikipedia.org/wiki/The_Adventures_of_Tom_Sawyer for **four minutes**. For each participant, almost the same amount of data is collected as Experiment-1. This dataset is important to be able to measure the quality of the features. The collection of this dataset is quite realistic since in a real case the users could be also asked to type a given text during their CA sessions. \n",
    "\n",
    "Experiment-3: The participants are asked to type **10 different pangram sentences**. Pangrams sentences contain** all 26 letters** of the alphabet. This data set is used to test how the **letter distribution** of text affects the result.\n",
    "\n",
    "Experiment-4: **34** participants are involved in this task and the participants were instructed to imitate someone else's typing pattern by watching the prerecorded video of the other person. For these experiments, one of the participants was recorded on video while typing a short and simple sentence for **15 seconds** from a perspective that the hand motions, smartwatch, keyboard, and the screen could be seen. Although it was not required, the perspective allowed to infer what the victim was typing by watching. This dataset was primarily used to analyze the **attacking scenarios**. It is left to the participant to type the exact same text or imitate the hand movement of the victim.\n",
    "\n",
    "-----------------------\n",
    "\n",
    "I realized that you have mostly 4s and 10s as values on column A, but I also found 2s. What does column A represent? \n",
    "A represents the sensor type:\n",
    " \n",
    "**10 for the accelerometer\n",
    "4 for the gyroscope**\n",
    "2 for the magnetic field sensor\n",
    "\n",
    "You can find more info about sensors and constant values that are used to define the sensor type in these links:\n",
    "- https://developer.android.com/guide/topics/sensors/sensors_overview\n",
    "- https://developer.android.com/reference/android/hardware/Sensor#TYPE_LINEAR_ACCELERATION\n",
    "\n",
    "Normally, I only collected and used accelerometer and gyroscope sensor data. Magnetometer data should not be in the dataset. If there is, that means it is an **outlier**.\n",
    " \n",
    "Is column B the time stamp, is it recorded at 100HZ?\n",
    "\n",
    "In an android app, you can set the sampling rate \"SENSOR_DELAY_NORMAL, SENSOR_DELAY_UI, SENSOR_DELAY_GAME, or SENSOR_DELAY_FASTEST \" \n",
    "\n",
    "As far as I remember I used **\"SENSOR_DELAY_FASTEST\" for all sensors**, but in practice, I had a lot of issues regarding this. They **don't give a constant sampling rate**. Every time I used they were giving different sampling rates. They were giving different sampling rates for two sessions of the same user, for different users, or for different sensors. Therefore, I would recommend using the one in the practice, which you can calculate using the timestamp and the sample count. \n",
    "\n",
    "On the paper you said you have recorded both accelerometer and gyro data; but you seem to only have one of them at a time on columns C, D, and F. I am guessing 10 on column A represents accelerometer and 4 gyro, but I could be wrong. \n",
    "Also, some rows have more columns, and start with 11 on column A. What do those represent?\n",
    "Please see the explanation above. \n",
    " \n",
    "\n",
    "In short, I would really appreciate it if you could let me know information I need to know for working with the data.\n",
    "\n",
    "Also, as these sensors were giving me a lot of headaches because they are really not stable, I needed to perform a lot of preprocessing. I **cleaned the outliers** before further processing. I also applied some other filtering techniques such as **moving average** to obtain more smooth data. Moreover, I needed to **clean the part the users are not performing typing operation from the beginning and end**, which you can see if you plot the values, i.e., the **user stops meaning no value and then big deviations, where the user takes off the smartwatch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:37.236923Z",
     "iopub.status.busy": "2022-03-30T07:53:37.236372Z",
     "iopub.status.idle": "2022-03-30T07:53:37.37419Z",
     "shell.execute_reply": "2022-03-30T07:53:37.373223Z",
     "shell.execute_reply.started": "2022-03-30T07:53:37.23689Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "CORES = -1\n",
    "SEED = 567\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:37.377864Z",
     "iopub.status.busy": "2022-03-30T07:53:37.377517Z",
     "iopub.status.idle": "2022-03-30T07:53:52.695539Z",
     "shell.execute_reply": "2022-03-30T07:53:52.694393Z",
     "shell.execute_reply.started": "2022-03-30T07:53:37.377829Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "# !pip install python-docx\n",
    "# !pip install antropy\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import dataclasses\n",
    "import math as math\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV\n",
    "import statsmodels.stats.api as sms\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import asdict\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import random\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, accuracy_score, make_scorer, auc\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold # Feature selector\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import iqr\n",
    "from scipy.stats import median_absolute_deviation\n",
    "from scipy.stats import mode\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_widths\n",
    "# from scipy.special import entr\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc\n",
    "# import antropy as ant\n",
    "import time\n",
    "# import docx\n",
    "\n",
    "# Global utitlity functions are in separate notebook\n",
    "# import utility_functions as uf\n",
    "%run ../usr/lib/utility_functions/utility_functions.ipynb\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"Seed was set to: {SEED}\")\n",
    "\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:52.706623Z",
     "iopub.status.busy": "2022-03-30T07:53:52.706251Z",
     "iopub.status.idle": "2022-03-30T07:53:52.729218Z",
     "shell.execute_reply": "2022-03-30T07:53:52.727872Z",
     "shell.execute_reply.started": "2022-03-30T07:53:52.706589Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class ExperimentParameters:\n",
    "    \"\"\"Contains all relevant parameters to run an experiment.\"\"\"\n",
    "\n",
    "    name: str  # Name of Parameter set. Used as identifier for charts etc.\n",
    "    frequency: int\n",
    "    max_subjects: int\n",
    "    max_test_subjects: int\n",
    "    seconds_per_subject_train: float\n",
    "    seconds_per_subject_test: float\n",
    "    task_types: list  # Limit scenarios to [1, 3, 5] for sitting or [2, 4, 6] for walking, or don't limit (None)\n",
    "    window_size: int  # After resampling\n",
    "    step_width: int  # After resampling\n",
    "    scaler: str  # {\"std\", \"robust\", \"minmax\"}\n",
    "    scaler_scope: str  # {\"subject\", \"session\"}\n",
    "    scaler_global: bool  # fit transform scale on all data (True) or fit on training only (False)\n",
    "    ocsvm_nu: float  # Best value found in random search, used for final model\n",
    "    ocsvm_gamma: float  # Best value found in random search, used for final model\n",
    "    feature_cols: list  # Columns used as features\n",
    "    exclude_subjects: list  # Don't load data from those users\n",
    "        \n",
    "    # Calculated values\n",
    "    def __post_init__(self):\n",
    "        # HDF key of table:\n",
    "        self.table_name = f\"sensors_{self.frequency}hz\"\n",
    "\n",
    "        # Number of samples per _session_ used for training:\n",
    "        self.samples_per_subject_train = math.ceil(\n",
    "            (self.seconds_per_subject_train * 100)\n",
    "            / (100 / self.frequency)\n",
    "            / self.window_size\n",
    "        )\n",
    "\n",
    "        # Number of samples per _session_ used for testing:\n",
    "        self.samples_per_subject_test = math.ceil(\n",
    "            (self.seconds_per_subject_test * 100)\n",
    "            / (100 / self.frequency)\n",
    "            / self.window_size\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "# INSTANCES\n",
    "# ===========================================================\n",
    "\n",
    "# NAIVE_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_MINMAX_OCSVM = ExperimentParameters(\n",
    "    name=\"NAIVE-MINMAX_OCSVM\",\n",
    "    frequency=100,\n",
    "    max_subjects=90,\n",
    "    max_test_subjects=30,\n",
    "    seconds_per_subject_train=67.5,\n",
    "    seconds_per_subject_test=67.5,    \n",
    "    task_types=None,\n",
    "    window_size=50,\n",
    "    step_width=50,\n",
    "    scaler=\"minmax\",\n",
    "    scaler_scope=\"subject\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.086,\n",
    "    ocsvm_gamma=0.091,\n",
    "    feature_cols=[\n",
    "        \"EMA_x_a\",\n",
    "        \"EMA_y_a\",\n",
    "        \"EMA_z_a\",\n",
    "        \"EMA_x_g\",\n",
    "        \"EMA_y_g\",\n",
    "        \"EMA_z_g\",\n",
    "    ],\n",
    "    exclude_subjects=[],\n",
    ")\n",
    "\n",
    "# VALID_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "VALID_MINMAX_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-MINMAX-OCSVM\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.165,\n",
    "    ocsvm_gamma=0.039,\n",
    ")\n",
    "\n",
    "# NAIVE_ROBUST_APPROACH\n",
    "# -----------------------------------------------------------\n",
    "NAIVE_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"NAIVE-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=True,\n",
    "    ocsvm_nu=0.153,\n",
    "    ocsvm_gamma=0.091,  # below median, selected by chart\n",
    ")\n",
    "\n",
    "# ROBUST_APPROACH (VALID)\n",
    "# -----------------------------------------------------------\n",
    "VALID_ROBUST_OCSVM = dataclasses.replace(\n",
    "    NAIVE_MINMAX_OCSVM,\n",
    "    name=\"VALID-ROBUST-OCSVM\",\n",
    "    scaler=\"robust\",\n",
    "    scaler_global=False,\n",
    "    ocsvm_nu=0.098,\n",
    "    ocsvm_gamma=0.003,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:52.734852Z",
     "iopub.status.busy": "2022-03-30T07:53:52.73405Z",
     "iopub.status.idle": "2022-03-30T07:53:52.750037Z",
     "shell.execute_reply": "2022-03-30T07:53:52.7486Z",
     "shell.execute_reply.started": "2022-03-30T07:53:52.734791Z"
    }
   },
   "outputs": [],
   "source": [
    "# utils_plot_randomsearch_results(df_results, n_top=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:52.753408Z",
     "iopub.status.busy": "2022-03-30T07:53:52.752872Z",
     "iopub.status.idle": "2022-03-30T07:53:52.76644Z",
     "shell.execute_reply": "2022-03-30T07:53:52.765483Z",
     "shell.execute_reply.started": "2022-03-30T07:53:52.753362Z"
    }
   },
   "outputs": [],
   "source": [
    "P = VALID_ROBUST_OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:52.768372Z",
     "iopub.status.busy": "2022-03-30T07:53:52.767721Z",
     "iopub.status.idle": "2022-03-30T07:53:52.810876Z",
     "shell.execute_reply": "2022-03-30T07:53:52.809958Z",
     "shell.execute_reply.started": "2022-03-30T07:53:52.768331Z"
    }
   },
   "outputs": [],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:52.812979Z",
     "iopub.status.busy": "2022-03-30T07:53:52.812491Z",
     "iopub.status.idle": "2022-03-30T07:53:52.820712Z",
     "shell.execute_reply": "2022-03-30T07:53:52.819443Z",
     "shell.execute_reply.started": "2022-03-30T07:53:52.812927Z"
    }
   },
   "outputs": [],
   "source": [
    "utils_eer_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset for Valid/Test  \n",
    "In two splits: one used during hyperparameter optimization, and one used during testing.\n",
    "\n",
    "The split is done along the subjects: All sessions of a single subject will either be in the validation split or in the testing split, never in both.\n",
    "\n",
    "They did a 30 60 split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping Raw Features.\n",
    "We have our own function of windows for this. Do this for both training and testing.\n",
    "\n",
    "# Extracting time and frequency based features.\n",
    "Again, we have a function for this. Do this for both training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization \n",
    "\n",
    "I do not find any reaqsonable explaination how to use a cross-validation as we are talking about anomaly detection.\n",
    "\n",
    "I am using the experiment 1 data as train, and experiment 2 data as validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SVM in a real-world Scenario with multiple genuine users and intruders\n",
    "Source: https://datascience.stackexchange.com/questions/23623/what-is-the-best-way-to-classify-data-not-belonging-to-set-of-classes\n",
    "\n",
    "Stage 1: \n",
    "    Use one-class SVM to assign those images that do not belong to the set of predefined classes as the 9-th class.\n",
    "\n",
    "Stage 2:\n",
    "    For those images that passes through your filter, let the multi-class SVM assign them to one of the 8 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:53:52.823207Z",
     "iopub.status.busy": "2022-03-30T07:53:52.822557Z",
     "iopub.status.idle": "2022-03-30T07:54:11.51279Z",
     "shell.execute_reply": "2022-03-30T07:54:11.51143Z",
     "shell.execute_reply.started": "2022-03-30T07:53:52.823158Z"
    }
   },
   "outputs": [],
   "source": [
    "user_ids = [1, 2, 3, 4, 5, 6, 7, 8, 19, 21, 22, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49]\n",
    "begin_idx=500\n",
    "end_idx=-500\n",
    "min_len = 21000\n",
    "\n",
    "df_exps_dict = load_data_frames(user_ids, begin_idx, end_idx, min_len)\n",
    "dfList_exp1, dfList_exp2 = df_exps_dict['dfList_exp1'], df_exps_dict['dfList_exp2']\n",
    "# print(\"Loading exp1 data:\")\n",
    "# dfList_exp1 = []\n",
    "# for i in r:\n",
    "#     dic = getDataStats1(i, begin_idx=begin_idx, end_idx=end_idx)\n",
    "    \n",
    "#     if(dic['accel']<min_len):\n",
    "#         raise Exception(\"The Stream is shorter than {}\".format(min_len))\n",
    "    \n",
    "#     dfList_exp1 = dfList_exp1 + [dic['df'].reset_index(drop=True)]\n",
    "\n",
    "    \n",
    "# print(\"Loading exp2 data:\")\n",
    "# dfList_exp2 = []\n",
    "# for i in r:\n",
    "#     dic = getDataStats2(i, begin_idx=begin_idx, end_idx=end_idx)\n",
    "    \n",
    "#     if(dic['accel']<min_len):\n",
    "#         raise Exception(\"The Stream is shorter than {}\".format(min_len))\n",
    "    \n",
    "#     dfList_exp2 = dfList_exp2 + [dic['df'].reset_index(drop=True)]\n",
    "# #     dfList = dfList + [dic['df']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:54:11.514735Z",
     "iopub.status.busy": "2022-03-30T07:54:11.514303Z",
     "iopub.status.idle": "2022-03-30T07:54:11.521644Z",
     "shell.execute_reply": "2022-03-30T07:54:11.520692Z",
     "shell.execute_reply.started": "2022-03-30T07:54:11.514699Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.choice(range(5), 5, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:55:15.665213Z",
     "iopub.status.busy": "2022-03-30T07:55:15.664551Z",
     "iopub.status.idle": "2022-03-30T07:55:15.672524Z",
     "shell.execute_reply": "2022-03-30T07:55:15.671467Z",
     "shell.execute_reply.started": "2022-03-30T07:55:15.665177Z"
    }
   },
   "outputs": [],
   "source": [
    "randomized_data_idx = list(range(len(user_ids)))\n",
    "random.shuffle(randomized_data_idx)\n",
    "split_idx = 2 * (len(randomized_data_idx)//3) + 1\n",
    "train_set = randomized_data_idx[: split_idx]\n",
    "test_set = randomized_data_idx[split_idx: ]\n",
    "print(f\"train_set: {train_set}\\ntest_set: {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:55:17.597826Z",
     "iopub.status.busy": "2022-03-30T07:55:17.597434Z",
     "iopub.status.idle": "2022-03-30T07:56:15.015627Z",
     "shell.execute_reply": "2022-03-30T07:56:15.014545Z",
     "shell.execute_reply.started": "2022-03-30T07:55:17.597795Z"
    }
   },
   "outputs": [],
   "source": [
    "# preparing train data\n",
    "# train_set = r\n",
    "dfList_exp1_train, dfList_exp2_train = [dfList_exp1[i] for i in train_set], [dfList_exp2[i] for i in train_set]\n",
    "print(f\"len(dfList_exp1_train): {len(dfList_exp1_train)}\")\n",
    "print(f\"len(dfList_exp2_train): {len(dfList_exp2_train)}\")\n",
    "XExpTrainDict = MakeXExpDic(dfList_exp1_train, dfList_exp2_train, window_size = 250, step = 250, numSamplePoints= 21000)\n",
    "X_exp1_train_dic, X_exp2_train_dic = XExpTrainDict[\"X_exp1_dic\"], XExpTrainDict[\"X_exp2_dic\"]\n",
    "\n",
    "# preparing test data\n",
    "dfList_exp1_test, dfList_exp2_test = [dfList_exp1[i] for i in test_set], [dfList_exp2[i] for i in test_set]\n",
    "print(f\"len(dfList_exp1_test): {len(dfList_exp1_test)}\")\n",
    "print(f\"len(dfList_exp2_test): {len(dfList_exp2_test)}\")\n",
    "XExpTestDict = MakeXExpDic(dfList_exp1_test, dfList_exp2_test, window_size = 250, step = 250, numSamplePoints= 21000)\n",
    "X_exp1_test_dic, X_exp2_test_dic = XExpTestDict[\"X_exp1_dic\"], XExpTestDict[\"X_exp2_dic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:56:15.018436Z",
     "iopub.status.busy": "2022-03-30T07:56:15.018064Z",
     "iopub.status.idle": "2022-03-30T07:56:15.023986Z",
     "shell.execute_reply": "2022-03-30T07:56:15.02302Z",
     "shell.execute_reply.started": "2022-03-30T07:56:15.018403Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"train_set: {train_set}\")\n",
    "print(f\"X_exp1_train_dic: {X_exp1_train_dic.keys()}\")\n",
    "print(f\"X_exp2_train_dic: {X_exp2_train_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:56:15.025976Z",
     "iopub.status.busy": "2022-03-30T07:56:15.025651Z",
     "iopub.status.idle": "2022-03-30T07:56:15.039043Z",
     "shell.execute_reply": "2022-03-30T07:56:15.038089Z",
     "shell.execute_reply.started": "2022-03-30T07:56:15.025945Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"test_set: {test_set}\")\n",
    "print(f\"X_exp1_test_dic: {X_exp1_test_dic.keys()}\")\n",
    "print(f\"X_exp2_test_dic: {X_exp2_test_dic.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T07:59:51.658705Z",
     "iopub.status.busy": "2022-03-30T07:59:51.658158Z",
     "iopub.status.idle": "2022-03-30T08:17:20.719566Z",
     "shell.execute_reply": "2022-03-30T08:17:20.71669Z",
     "shell.execute_reply.started": "2022-03-30T07:59:51.658669Z"
    }
   },
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "#     \"model__gamma\": np.logspace(-3, 3), \n",
    "    \"model__contamination\": np.linspace(0.0001, 0.3),\n",
    "#     'scaler': [StandardScaler(), MinMaxScaler(),\n",
    "#         Normalizer(), MaxAbsScaler()],\n",
    "#     \"selector__threshold\": np.linspace(0, 2, num=1000),\n",
    "\n",
    "}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "df_results = None  # Will be filled with randomsearch scores\n",
    "\n",
    "\n",
    "# Don't need to loop over to find the best PCA.\n",
    "for run in tqdm(range(1)):\n",
    "#     df_results[run] = {}\n",
    "    \n",
    "    for owner_idx in tqdm(\n",
    "        range(len(train_set)),\n",
    "        desc=\"Owner\",\n",
    "    ):\n",
    "        run_seed = SEED + run\n",
    "        train_dic, valid_test_dic = X_exp2_train_dic, X_exp1_train_dic\n",
    "        X_vals_owner_idx = utils_create_cv_splits(owner_idx, train_dic, valid_test_dic, seed=run_seed)\n",
    "#         X_train = X_vals_owner_idx['X_train']\n",
    "#          = X.reshape(X.shape[-3], -1)  # flatten windows\n",
    "        X_test_regular = X_vals_owner_idx['X_test_regular'].copy()\n",
    "        X_test_anomalous = X_vals_owner_idx['X_test_anomalous'].copy()\n",
    "        \n",
    "#         print(X_vals_owner_idx['cv_splits'])\n",
    "        cv_splits = X_vals_owner_idx['cv_splits']\n",
    "        \n",
    "        pca = PCA(n_components = run)\n",
    "#         X_train = pca.fit_transform(X_train)\n",
    "#         X_test_regular = pca.transform(X_test_regular)\n",
    "#         X_test_anomalous = pca.transform(X_test_anomalous)\n",
    "        \n",
    "#         pca_fs.add_user_pca(owner_idx, pca)\n",
    "        \n",
    "        clf = IsolationForest(random_state=run_seed)\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "#                             ('scaler', StandardScaler()), \n",
    "                            ('scaler', Normalizer()),\n",
    "#                              ('pca', pca), \n",
    "#                              ('selector', VarianceThreshold()), \n",
    "                             ('model', clf)\n",
    "                            ])\n",
    "        \n",
    "        # random serach usees 5-folld cv by default. Probably need to remove it.\n",
    "        random_search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=param_dist,\n",
    "            cv=cv_splits,\n",
    "            n_iter=80,\n",
    "            n_jobs=CORES,\n",
    "            refit=False,\n",
    "            scoring={\"eer\": utils_eer_scorer, \"accuracy\": \"accuracy\"},\n",
    "            verbose=0,\n",
    "            return_train_score=False,\n",
    "            iid=False,\n",
    "            error_score=\"raise\",\n",
    "            random_state=run_seed\n",
    "        )\n",
    "#         print(X_train.shape)\n",
    "#         print(X_test_anomalous.shape)\n",
    "\n",
    "        \n",
    "        random_search.fit(X_vals_owner_idx['X_train'], X_vals_owner_idx['y_train'])\n",
    "        impostors = [idx for idx in range(len(train_set)) if idx != owner_idx]\n",
    "\n",
    "        df_report = utils_cv_report(random_search, owner_idx, impostors)\n",
    "        df_report[\"run\"] = run\n",
    "        df_results = pd.concat([df_results, df_report], sort=False)\n",
    "        \n",
    "\n",
    "\n",
    "train_pca_results = df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:17:27.38056Z",
     "iopub.status.busy": "2022-03-30T08:17:27.380142Z",
     "iopub.status.idle": "2022-03-30T08:17:27.391883Z",
     "shell.execute_reply": "2022-03-30T08:17:27.390488Z",
     "shell.execute_reply.started": "2022-03-30T08:17:27.380522Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df_results[df_results[\"rank_test_eer\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T07:54:11.642593Z",
     "iopub.status.idle": "2022-03-30T07:54:11.643037Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df_results[df_results[\"owner\"] == 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:17:30.521154Z",
     "iopub.status.busy": "2022-03-30T08:17:30.520582Z",
     "iopub.status.idle": "2022-03-30T08:17:30.560608Z",
     "shell.execute_reply": "2022-03-30T08:17:30.559537Z",
     "shell.execute_reply.started": "2022-03-30T08:17:30.5211Z"
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    df_results[df_results[\"rank_test_eer\"] == 1]\n",
    "    .sort_values(\"mean_test_eer\")\n",
    "    .head(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T07:54:11.645341Z",
     "iopub.status.idle": "2022-03-30T07:54:11.645771Z"
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    df_results[df_results[\"rank_test_eer\"] == 1][\n",
    "        [\n",
    "            \"mean_fit_time\",\n",
    "            \"param_model__nu\",\n",
    "            \"param_model__gamma\",\n",
    "            \"mean_test_accuracy\",\n",
    "            \"std_test_accuracy\",\n",
    "            \"mean_test_eer\",\n",
    "            \"std_test_eer\",\n",
    "        ]\n",
    "    ].describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-30T07:54:11.646594Z",
     "iopub.status.idle": "2022-03-30T07:54:11.647047Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = utils_plot_randomsearch_results(df_results, n_top=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T04:44:46.143074Z",
     "iopub.status.busy": "2022-03-30T04:44:46.142703Z",
     "iopub.status.idle": "2022-03-30T04:44:46.147835Z",
     "shell.execute_reply": "2022-03-30T04:44:46.146793Z",
     "shell.execute_reply.started": "2022-03-30T04:44:46.143043Z"
    }
   },
   "outputs": [],
   "source": [
    "# P.ocsvm_nu, P.ocsvm_gamma = 0.098, 0.002\n",
    "P.ocsvm_nu, P.ocsvm_gamma = 0.031, 0.080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T04:44:47.333377Z",
     "iopub.status.busy": "2022-03-30T04:44:47.333014Z",
     "iopub.status.idle": "2022-03-30T04:44:47.348907Z",
     "shell.execute_reply": "2022-03-30T04:44:47.347992Z",
     "shell.execute_reply.started": "2022-03-30T04:44:47.333347Z"
    }
   },
   "outputs": [],
   "source": [
    "utils_ppp(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T07:31:16.187319Z",
     "iopub.status.idle": "2022-03-29T07:31:16.187721Z"
    }
   },
   "outputs": [],
   "source": [
    "# utils_plot_acc_eer_dist(df_plot, \"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T07:31:16.188496Z",
     "iopub.status.idle": "2022-03-29T07:31:16.18888Z"
    }
   },
   "outputs": [],
   "source": [
    "# utils_plot_acc_eer_dist(df_results, \"Test EER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:19:35.958805Z",
     "iopub.status.busy": "2022-03-30T08:19:35.95836Z",
     "iopub.status.idle": "2022-03-30T08:21:05.817266Z",
     "shell.execute_reply": "2022-03-30T08:21:05.815815Z",
     "shell.execute_reply.started": "2022-03-30T08:19:35.958772Z"
    }
   },
   "outputs": [],
   "source": [
    "contamination = 0.0245816\n",
    "test_df_results = None  # Will be filled with randomsearch scores\n",
    "for run in tqdm(range(5)):\n",
    "\n",
    "\n",
    "    for owner_idx in tqdm(\n",
    "        range(len(test_set)),\n",
    "        desc=\"Owner\",\n",
    "    ):\n",
    "\n",
    "        \n",
    "        run_seed = SEED + run\n",
    "        train_dic, valid_test_dic = X_exp2_test_dic, X_exp1_test_dic\n",
    "        X_vals_owner_idx = utils_create_cv_splits(owner_idx, train_dic, valid_test_dic, seed=run_seed)\n",
    "#         X_train = X_vals_owner_idx['X_train']\n",
    "#          = X.reshape(X.shape[-3], -1)  # flatten windows\n",
    "        X_test_regular = X_vals_owner_idx['X_test_regular']\n",
    "        X_test_anomalous = X_vals_owner_idx['X_test_anomalous']\n",
    "#         print(X_vals_owner_idx)\n",
    "#         break\n",
    "#         np.random.shuffle(X_train)\n",
    "#         np.random.shuffle(X_test_regular)\n",
    "#         np.random.shuffle(X_test_anomalous)\n",
    "#         print(X_vals_owner_idx['cv_splits'])\n",
    "        train_test_cv_splits = X_vals_owner_idx['cv_splits']\n",
    "        \n",
    "        \n",
    "#         pca = PCA(n_components = run)\n",
    "#         X_train = pca.fit_transform(X_train)\n",
    "#         X_test_regular = pca.transform(X_test_regular)\n",
    "#         X_test_anomalous = pca.transform(X_test_anomalous)\n",
    "        \n",
    "        clf = IsolationForest(contamination=contamination, random_state=run_seed)\n",
    "        pipeline = Pipeline([\n",
    "#             Normalizer, MaxAbsScaler,\n",
    "#                             ('scaler', StandardScaler()), \n",
    "#                              ('scaler', RobustScaler()),\n",
    "#                              ('scaler', MaxAbsScaler()),\n",
    "                            ('scaler', Normalizer()),#best result\n",
    "#                             ('scaler', PowerTransformer()),\n",
    "#                              ('pca', pca), \n",
    "#                              ('selector', VarianceThreshold()), \n",
    "                             ('model', clf)\n",
    "                            ])\n",
    "        \n",
    "        scores = cross_validate(\n",
    "            pipeline,\n",
    "            X_vals_owner_idx['X_train'],\n",
    "            X_vals_owner_idx['y_train'],\n",
    "            cv=train_test_cv_splits,\n",
    "            scoring={\n",
    "                \"eer\": utils_eer_scorer,\n",
    "                \"accuracy\": \"accuracy\",\n",
    "                \"precision\": \"precision\",\n",
    "                \"recall\": \"recall\",\n",
    "            },\n",
    "            n_jobs=CORES,\n",
    "            verbose=0,\n",
    "            return_train_score=True,\n",
    "        )\n",
    "        \n",
    "        df_score = pd.DataFrame(scores)\n",
    "        df_score[\"owner\"] = owner_idx\n",
    "        df_score[\"train_eer\"] = df_score[\"train_eer\"].abs()  # Revert scorer's signflip\n",
    "        df_score[\"test_eer\"] = df_score[\"test_eer\"].abs()\n",
    "        test_df_results = pd.concat([test_df_results, df_score], axis=0)\n",
    "        \n",
    "\n",
    "test_df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:21:14.111774Z",
     "iopub.status.busy": "2022-03-30T08:21:14.111007Z",
     "iopub.status.idle": "2022-03-30T08:21:14.12175Z",
     "shell.execute_reply": "2022-03-30T08:21:14.120891Z",
     "shell.execute_reply.started": "2022-03-30T08:21:14.111732Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df_plot = test_df_results.rename(\n",
    "    columns={\"test_accuracy\": \"Test Accuracy\", \"test_eer\": \"Test EER\", \"owner\": \"Owner\"}\n",
    ").astype({\"Owner\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:21:15.752068Z",
     "iopub.status.busy": "2022-03-30T08:21:15.751693Z",
     "iopub.status.idle": "2022-03-30T08:21:15.759967Z",
     "shell.execute_reply": "2022-03-30T08:21:15.758859Z",
     "shell.execute_reply.started": "2022-03-30T08:21:15.752038Z"
    }
   },
   "outputs": [],
   "source": [
    "MAGENTA = (202/255, 18/255, 125/255)\n",
    "# Define a style I use a lot for boxplots:\n",
    "utils_boxplot_style = dict(\n",
    "    color=\"tab:blue\",\n",
    "    linewidth=0.5,\n",
    "    saturation=1,\n",
    "    width=0.7,\n",
    "    flierprops=dict(\n",
    "        marker=\"o\", markersize=2, markerfacecolor=\"none\", markeredgewidth=0.5\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define a style I use a lot for lineplots:\n",
    "utils_lineplot_style = dict(\n",
    "    color=\"tab:blue\", linewidth=0.5, marker=\"o\", markersize=3, markeredgewidth=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:21:16.528253Z",
     "iopub.status.busy": "2022-03-30T08:21:16.527723Z",
     "iopub.status.idle": "2022-03-30T08:21:16.531692Z",
     "shell.execute_reply": "2022-03-30T08:21:16.530971Z",
     "shell.execute_reply.started": "2022-03-30T08:21:16.52822Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_df_plot[test_df_plot[\"Owner\"]==\"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:21:17.319406Z",
     "iopub.status.busy": "2022-03-30T08:21:17.318868Z",
     "iopub.status.idle": "2022-03-30T08:21:17.711513Z",
     "shell.execute_reply": "2022-03-30T08:21:17.710453Z",
     "shell.execute_reply.started": "2022-03-30T08:21:17.319372Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = utils_plot_acc_eer_dist(test_df_plot, \"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-30T08:21:17.713946Z",
     "iopub.status.busy": "2022-03-30T08:21:17.71363Z",
     "iopub.status.idle": "2022-03-30T08:21:18.027677Z",
     "shell.execute_reply": "2022-03-30T08:21:18.026833Z",
     "shell.execute_reply.started": "2022-03-30T08:21:17.713916Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = utils_plot_acc_eer_dist(test_df_plot, \"Test EER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T07:31:16.232613Z",
     "iopub.status.idle": "2022-03-29T07:31:16.233016Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "total = None\n",
    "for k in tqdm(test_pca_results):\n",
    "    total = list(test_pca_results[k][\"total\"].values())\n",
    "    data.append([k] + total)\n",
    "    \n",
    "# Create the pandas DataFrame\n",
    "columns = [\"pca_n_components\"] + list(test_pca_results[k][\"total\"].keys())\n",
    "df = pd.DataFrame(data, columns = columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T07:31:16.234008Z",
     "iopub.status.idle": "2022-03-29T07:31:16.234436Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "ax.set_title('different pca_n_component values on test_set')\n",
    "g = sns.lineplot(x=df.pca_n_components, y=df.FAR, label = 'FAR', ax = ax)\n",
    "g = sns.lineplot(x=df.pca_n_components, y=df.FRR, label = 'FRR', ax = ax)\n",
    "g = sns.lineplot(x=df.pca_n_components, y=df.train_err_rate, label = 'train_err_rate', ax = ax)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# g.set_xticks(y_ticks)\n",
    "ax.set_xlabel('n_components')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T07:31:16.23541Z",
     "iopub.status.idle": "2022-03-29T07:31:16.235848Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T07:31:16.237033Z",
     "iopub.status.idle": "2022-03-29T07:31:16.237464Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "total = None\n",
    "for k in tqdm(train_pca_results):\n",
    "    total = list(train_pca_results[k][\"total\"].values())\n",
    "    data.append([k] + total)\n",
    "    \n",
    "# Create the pandas DataFrame\n",
    "columns = [\"pca_n_components\"] + list(train_pca_results[k][\"total\"].keys())\n",
    "df = pd.DataFrame(data, columns = columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-29T07:31:16.238345Z",
     "iopub.status.idle": "2022-03-29T07:31:16.238785Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "ax.set_title('different pca_n_component values on train_set')\n",
    "g = sns.lineplot(x=df.pca_n_components, y=df.FAR, label = 'FAR', ax = ax)\n",
    "g = sns.lineplot(x=df.pca_n_components, y=df.FRR, label = 'FRR', ax = ax)\n",
    "g = sns.lineplot(x=df.pca_n_components, y=df.train_err_rate, label = 'train_err_rate', ax = ax)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# g.set_xticks(y_ticks)\n",
    "ax.set_xlabel('n_components')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
