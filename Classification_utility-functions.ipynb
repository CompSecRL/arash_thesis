{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "d975284c-a069-40d8-9847-9465d0ac4f47",
    "_uuid": "b6bb54c3-ff29-436c-8f5e-b3a13b9f5153",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_MODE = 0 # Testing macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "3ae86968-b273-4857-a4fd-537b178d854b",
    "_uuid": "bcec77b5-0738-4d15-8aad-f6b59b3ac023",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "\u001b[32mSEED and CONSTANTS imported\u001b[0m\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "setup complete\n",
      "Python 3.9.10\n",
      "\u001b[32mUtility functions imported\u001b[0m\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "\u001b[32mSEED and CONSTANTS imported\u001b[0m\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "utility_functions imports setup complete\n",
      "Python 3.9.10\n",
      "\u001b[32mPreprocessing utility functions imported\u001b[0m\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "\u001b[32mSEED and CONSTANTS imported\u001b[0m\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "utility_functions imports setup complete\n",
      "Python 3.9.10\n",
      "\u001b[32mNeural Networks utility functions imported\u001b[0m\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "\u001b[32mSEED and CONSTANTS imported\u001b[0m\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "setup complete\n",
      "Python 3.9.10\n",
      "\u001b[32mUtility functions imported\u001b[0m\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "\u001b[32mSEED and CONSTANTS imported\u001b[0m\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "utility_functions imports setup complete\n",
      "Python 3.9.10\n",
      "\u001b[32mPreprocessing utility functions imported\u001b[0m\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "\u001b[32mSEED and CONSTANTS imported\u001b[0m\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "utility_functions imports setup complete\n",
      "Python 3.9.10\n",
      "\u001b[32mWACA utility functions imported\u001b[0m\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.9/site-packages (23.1)\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "\u001b[32mSEED and CONSTANTS imported\u001b[0m\n",
      "\u001b[32mSEED: 567\u001b[0m\n",
      "utility_functions imports setup complete\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors, LocalOutlierFactor\n",
    "import numpy as np # linear algebraf\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "%run ./NN_utility-functions.ipynb\n",
    "%run ./WACA_utility-functions.ipynb\n",
    "%run ./SEED-CONSTANTS.ipynb\n",
    "\n",
    "\n",
    "print(f\"\\x1b[32mSEED: {SEED}\\x1b[0m\")\n",
    "# Global utitlity functions are in separate notebook\n",
    "if TEST_MODE: print(\"setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.10\n",
      "\u001b[31m\"red\"\u001b[0m\n",
      "\u001b[32m\"green\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_X_exp_dicts(deep_X_exp_dic, WACA_X_exp_dic):\n",
    "    \n",
    "    union_dic = {}\n",
    "    for user in deep_X_exp_dic:\n",
    "        union_dic[user] = {\"profile_windows\": np.concatenate([WACA_X_exp_dic[user][\"profile_windows\"], deep_X_exp_dic[user][\"profile_windows\"]], axis=1),\n",
    "                           'unknown_users_dict':{}}\n",
    "        \n",
    "        for unknown_user in deep_X_exp_dic[user]['unknown_users_dict']:\n",
    "            union_dic[user]['unknown_users_dict'][unknown_user] = np.concatenate([WACA_X_exp_dic[user][\"unknown_users_dict\"][unknown_user], \n",
    "                                                                               deep_X_exp_dic[user][\"unknown_users_dict\"][unknown_user]], axis=1)\n",
    "            \n",
    "    return union_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not used in all files, check where and how its used\n",
    "def plot_EER_distro(EER_distro_df, discription, save_file_name=None):\n",
    "    y_col = \"EER\"\n",
    "    figsize=(30, 6)\n",
    "    fontsize=11\n",
    "    n_subject = len(EER_distro_df.columns)\n",
    "    mean_col = EER_distro_df[y_col].mean()\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=180)\n",
    "    ax = sns.boxplot(x=\"owner\", y=y_col, data=EER_distro_df)#, **utils_boxplot_style)\n",
    "    ax.set_ylim((0, 1))\n",
    "    sns.swarmplot(x=\"owner\", y=y_col, data=EER_distro_df, color=\".25\")\n",
    "\n",
    "    plt.plot(\n",
    "        [-0.6, figsize[0] + 0.6],\n",
    "        [mean_col, mean_col],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1,\n",
    "        color=MAGENTA,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.text(n_subject + 0.6, mean_col, f\"mean\", fontsize=fontsize, color=MAGENTA)\n",
    "    plt.text(\n",
    "        n_subject + 0.6, mean_col - 0.04, f\"{mean_col:.3f}\", fontsize=fontsize, color=MAGENTA\n",
    "    )\n",
    "    plt.xticks(rotation=45)\n",
    "    fig.tight_layout()\n",
    "    plt.title(discription)\n",
    "    \n",
    "    plt.savefig(f'{save_file_name}.png', bbox_inches='tight')\n",
    "    print(f\"Overall mean: {mean_col:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NearestNeighbors classfier, hyperparam optimization and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_EER_distro_df(X_exp_dic, n_neighbors, exp_config, algorithm='brute', verbose=0):\n",
    "    columns = ['owner', \"adv_user_id\", \"EER\"]\n",
    "    EER_distro_df = pd.DataFrame(columns = columns)\n",
    "    for owner in X_exp_dic.keys():\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=n_neighbors, algorithm=algorithm, p=exp_config.p).fit(X_exp_dic[owner][\"profile_windows\"])\n",
    "        \n",
    "        # n_neighbors=n_neighbors+1 since for the owner the first neighbor is the point itself and we drop that\n",
    "        dist_profile_windows, profile_windows_dist_indices = nbrs.kneighbors(X_exp_dic[owner][\"profile_windows\"], n_neighbors=n_neighbors+1)\n",
    "        dist_profile_windows, profile_windows_dist_indices = dist_profile_windows[:, 1:], profile_windows_dist_indices[:, 1:]\n",
    "        dist_profile_windows = dist_profile_windows.mean(axis=1).reshape(dist_profile_windows.shape[0], 1)\n",
    "        ## scaler = MinMaxScaler(clip=True).fit(dist_profile_windows)\n",
    "    \n",
    "\n",
    "        distFRR, FRR_indices = nbrs.kneighbors(X_exp_dic[owner][\"unknown_users_dict\"][owner], n_neighbors=n_neighbors)\n",
    "        distFRR = distFRR.mean(axis=1).reshape(distFRR.shape[0], 1)\n",
    "        for adv_user_id in X_exp_dic.keys():\n",
    "\n",
    "            if adv_user_id != owner:\n",
    "                # print(f\"adv_user_id: {adv_user_id}, owner: {owner}\")\n",
    "                distFAR, FAR_indices = nbrs.kneighbors(X_exp_dic[owner][\"unknown_users_dict\"][adv_user_id], n_neighbors=n_neighbors)\n",
    "                # print(distFAR)\n",
    "                \n",
    "                \n",
    "                # should axis be 1?\n",
    "                # can i do this with profile data?\n",
    "                distFAR = distFAR.mean(axis=1).reshape(distFAR.shape[0], 1)\n",
    "                # print(distFAR)\n",
    "\n",
    "                \n",
    "                ## scaled_distFRR, scaled_distFAR = scaler.transform(distFRR), scaler.transform(distFAR)\n",
    "\n",
    "\n",
    "                y_true = [1]*distFRR.shape[0] + [-1]*distFAR.shape[0]\n",
    "                ## y_pred = 1-np.concatenate([scaled_distFRR, scaled_distFAR]).ravel() \n",
    "                \n",
    "                y_score = -1*np.concatenate([distFRR, distFAR]).ravel() \n",
    "                \n",
    "                equal_error_rate(y_true, y_score)\n",
    "                temp_eer, tres = equal_error_rate(y_true, y_score, return_threshold=True)\n",
    "                ## temp_eer, tres = utils_eer(y_true, y_pred, return_threshold=True)\n",
    "\n",
    "                if verbose: print(f\"EER: {temp_eer:.9f}, owner_id: {owner}, adv_user_id: {adv_user_id}, Threshold: {tres:.9f}\")\n",
    "\n",
    "                new_row = pd.DataFrame([[owner, adv_user_id, temp_eer]], columns=columns)\n",
    "                EER_distro_df = pd.concat([EER_distro_df, new_row])\n",
    "                \n",
    "                \n",
    "    \n",
    "    return EER_distro_df\n",
    "\n",
    "\n",
    "\n",
    "def calculate_EER_different_window_sizes_optimize_num_neighbors(dfList_dict, window_size_lst, train_set, exp_config, extract_features_func_dict, overlap, n_neighbors_params):\n",
    "    \n",
    "    dfList_exp1=dfList_dict[\"dfList_exp1\"]\n",
    "    dfList_exp2=dfList_dict[\"dfList_exp2\"]\n",
    "    dfList_exp1_user_47=dfList_dict[\"dfList_exp1_user_47\"]\n",
    "    dfList_exp2_user_47=dfList_dict[\"dfList_exp2_user_47\"]\n",
    "    EER_distro_df_dict = {}\n",
    "    columns = ['window_size', \"step_width\", \"Mean_EER\", \"best_n_neighbors\"]\n",
    "    Mean_EER_df = pd.DataFrame(columns = columns)\n",
    "    for window_size in tqdm(window_size_lst):\n",
    "        print(f\"window_size: {window_size}\")\n",
    "\n",
    "        step_width = int(window_size * (1-overlap))\n",
    "\n",
    "#         X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=get_raw_windows(dfList_exp1, dfList_exp2, window_size, step_width, train_set, exp_config.scaler, \n",
    "#                                                                                             exp_config.num_sample_points_per_exp, \n",
    "#                                                                                             EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "#                                                                                             SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "#                                                                                             Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "#                                                                                             verbose=0)\n",
    "\n",
    "#         X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47=get_raw_windows_user_47(dfList_exp1_user_47, dfList_exp2_user_47, \n",
    "#                                                                                                                             window_size, step_width, scaler=exp_config.scaler, \n",
    "#                                                                                                                             num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "#                                                                                                                             EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "#                                                                                                                             SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "#                                                                                                                             Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "#                                                                                                                             verbose=0)\n",
    "\n",
    "#         X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=append_user_47_to_data(X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict, exp_config.user_ids, \n",
    "#                                                                                                    X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47, \n",
    "#                                                                                                    verbose=0)\n",
    "        \n",
    "        extract_features_func=extract_features_func_dict[window_size]\n",
    "        \n",
    "        X_exp_train_dic = calculate_X_exp_dict(dfList_exp1=dfList_exp1,\n",
    "                                               dfList_exp2=dfList_exp2,\n",
    "                                               dfList_exp1_user_47=dfList_exp1_user_47, \n",
    "                                               dfList_exp2_user_47=dfList_exp2_user_47,\n",
    "                                               window_size=window_size,\n",
    "                                               step_width=step_width,\n",
    "                                               user_idx_set=train_set,\n",
    "                                               exp_config=exp_config,\n",
    "                                               extract_features_func=extract_features_func,\n",
    "                                               verbose=0)\n",
    "        \n",
    "        # X_exp_train_dic = extract_features_func(X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict, scaler_clip=exp_config.scaler_clip)\n",
    "\n",
    "\n",
    "        mean_eer_dict = {}\n",
    "        for n_neighbors in n_neighbors_params:\n",
    "            EER_distro_df = make_EER_distro_df(X_exp_train_dic, n_neighbors=n_neighbors, algorithm='brute', exp_config=exp_config, verbose=0)\n",
    "            EER_distro_df_dict[f\"window_size: {window_size}, step_width: {step_width}\"] = EER_distro_df\n",
    "\n",
    "            y_col = \"EER\"\n",
    "            mean_col = EER_distro_df[y_col].mean()\n",
    "            # print(EER_distro_df)\n",
    "            mean_eer_dict[n_neighbors] = mean_col\n",
    "            \n",
    "        # print(mean_eer_dict)\n",
    "        best_n_neighbors = min(mean_eer_dict, key=mean_eer_dict.get)\n",
    "        Mean_EER = mean_eer_dict[best_n_neighbors]\n",
    "\n",
    "        new_row = pd.DataFrame([[window_size, step_width, Mean_EER, best_n_neighbors]], columns=columns)\n",
    "        Mean_EER_df = pd.concat([Mean_EER_df, new_row])\n",
    "        # enablePrint()\n",
    "    return Mean_EER_df\n",
    "\n",
    "\n",
    "def calculate_EER_different_window_sizes_test(dfList_dict, window_size_lst, test_set, exp_config, extract_features_func_dict, overlap, best_param_df):\n",
    "    dfList_exp1=dfList_dict[\"dfList_exp1\"]\n",
    "    dfList_exp2=dfList_dict[\"dfList_exp2\"]\n",
    "    EER_distro_df_dict = {}\n",
    "    columns = ['window_size', \"step_width\", \"Mean_EER\", \"best_n_neighbors\"]\n",
    "    # adding Gini coef column\n",
    "    columns+=[\"Gini_coef\"]\n",
    "    Mean_EER_df = pd.DataFrame(columns = columns)\n",
    "    for window_size in tqdm(window_size_lst):\n",
    "        print(f\"window_size: {window_size}\")\n",
    "        step_width = int(window_size * (1-overlap))\n",
    "        \n",
    "        \n",
    "        # X_test_exp1_dict, X_test_exp2_dict, fitted_scaler_test_exp2_dict=get_raw_windows(dfList_exp1, dfList_exp2, window_size, step_width, test_set, exp_config.scaler, \n",
    "        #                                                                                  exp_config.num_sample_points_per_exp, EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "        #                                                                                  SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "        #                                                                                  Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "        #                                                                                  verbose=0)\n",
    "\n",
    "        extract_features_func=extract_features_func_dict[window_size]\n",
    "        \n",
    "        X_exp_test_dic = calculate_X_exp_dict(dfList_exp1=dfList_exp1,\n",
    "                                              dfList_exp2=dfList_exp2,\n",
    "                                              dfList_exp1_user_47=dfList_exp1_user_47, \n",
    "                                              dfList_exp2_user_47=dfList_exp2_user_47,\n",
    "                                              window_size=window_size,\n",
    "                                              step_width=step_width,\n",
    "                                              user_idx_set=test_set,\n",
    "                                              exp_config=exp_config,\n",
    "                                              extract_features_func=extract_features_func,\n",
    "                                              verbose=0)\n",
    "        \n",
    "        # X_exp_test_dic = extract_features_func(X_test_exp1_dict, X_test_exp2_dict, fitted_scaler_test_exp2_dict, scaler_clip=exp_config.scaler_clip)\n",
    "        \n",
    "\n",
    "        \n",
    "        best_n_neighbors = int(best_param_df[best_param_df.window_size==window_size].best_n_neighbors) # maybe replace with items() \n",
    "        EER_distro_df = make_EER_distro_df(X_exp_test_dic, n_neighbors=best_n_neighbors, exp_config=exp_config)\n",
    "        EER_distro_df_dict[f\"window_size: {window_size}, step_width: {step_width}\"] = EER_distro_df\n",
    "\n",
    "        y_col = \"EER\"\n",
    "        mean_col = EER_distro_df[y_col].mean()\n",
    "        Mean_EER = mean_col\n",
    "        \n",
    "        gini_coef=gini(EER_distro_df[y_col].to_numpy())\n",
    "\n",
    "        new_row = pd.DataFrame([[window_size, step_width, Mean_EER, best_n_neighbors, gini_coef]], columns=columns)\n",
    "        Mean_EER_df = pd.concat([Mean_EER_df, new_row])\n",
    "        # enablePrint()\n",
    "        \n",
    "    return Mean_EER_df#, EER_distro_df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCSVM classfier, hyperparam optimization and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer_threshold(y_true, y_score):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    # Find the point where FPR is closest to FNR\n",
    "    eer_index = np.argmin(np.abs(fpr - fnr))\n",
    "    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n",
    "    return thresholds[eer_index]\n",
    "\n",
    "def utils_eer_scorer5(estimator, X, y_true):\n",
    "    y_score = estimator.decision_function(X)\n",
    "    eer = equal_error_rate(y_true, y_score)\n",
    "    return eer\n",
    "\n",
    "def accuracy_scorer2(estimator, X, y_true):\n",
    "    # Calculate the EER threshold using the decision function scores\n",
    "    y_score = estimator.decision_function(X)\n",
    "    threshold = eer_threshold(y_true, y_score)\n",
    "\n",
    "    # Make predictions using the EER threshold\n",
    "    y_pred = np.where(y_score >= threshold, 1, -1)\n",
    "\n",
    "    # Calculate the confusion matrix and accuracy\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return accuracy\n",
    "\n",
    "def precision_scorer(estimator, X, y_true):\n",
    "    # Calculate the EER threshold using the decision function scores\n",
    "    y_score = estimator.decision_function(X)\n",
    "    threshold = eer_threshold(y_true, y_score)\n",
    "\n",
    "    # Make predictions using the EER threshold\n",
    "    y_pred = np.where(y_score >= threshold, 1, -1)\n",
    "\n",
    "    # Calculate the confusion matrix and precision\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "def recall_scorer(estimator, X, y_true):\n",
    "    # Calculate the EER threshold using the decision function scores\n",
    "    y_score = estimator.decision_function(X)\n",
    "    threshold = eer_threshold(y_true, y_score)\n",
    "\n",
    "    # Make predictions using the EER threshold\n",
    "    y_pred = np.where(y_score >= threshold, 1, -1)\n",
    "\n",
    "    # Calculate the confusion matrix and recall\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall\n",
    "\n",
    "def f1_score_scorer(estimator, X, y_true):\n",
    "    # Calculate the EER threshold using the decision function scores\n",
    "    y_score = estimator.decision_function(X)\n",
    "    threshold = eer_threshold(y_true, y_score)\n",
    "\n",
    "    # Make predictions using the EER threshold\n",
    "    y_pred = np.where(y_score >= threshold, 1, -1)\n",
    "\n",
    "    # Calculate the confusion matrix and F1-score\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "\n",
    "def accuracy_scorer(estimator, X, y):\n",
    "    # Get the predicted labels\n",
    "    y_pred = estimator.predict(X)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def equal_error_rate(y_true, y_score, return_threshold=False):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    # Find the point where FPR is closest to FNR\n",
    "    eer_index = np.argmin(np.abs(fpr - fnr))\n",
    "    \n",
    "    \n",
    "#     #-----\n",
    "#     print(f\"len(thresholds): {len(thresholds)}\")\n",
    "#     print(fpr[eer_index]-fnr[eer_index])\n",
    "\n",
    "#     # Plot ROC curve\n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     plt.plot(thresholds, fpr, color='blue', lw=lw, label='FAR')\n",
    "#     plt.plot(thresholds, fnr, color='darkorange', lw=lw, label='FRR')\n",
    "#     plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "#     plt.xlim([min(thresholds), max(thresholds)])\n",
    "#     plt.ylim([0.0, 1.05])\n",
    "#     plt.xlabel('threshold')\n",
    "#     plt.ylabel('error rate')\n",
    "#     plt.title('Err vs Thres')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()\n",
    "#     # -----\n",
    "    \n",
    "    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n",
    "    \n",
    "    if return_threshold:\n",
    "        return eer, thresholds[eer_index]\n",
    "\n",
    "    return eer\n",
    "\n",
    "# def utils_eer_scorer4(estimator, X, y):\n",
    "#     y_pred = estimator.decision_function(X)\n",
    "#     return equal_error_rate(y, y_pred)\n",
    "\n",
    "utils_eer_scorer4 = make_scorer(equal_error_rate, greater_is_better=False, needs_threshold=True) # OMG needs_threshold=True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def utils_eer3(y_true, y_pred, return_threshold=False):\n",
    "    \"\"\"Calculate the Equal Error Rate.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array-like): The true binary labels (1 for normal and -1 for anomalous).\n",
    "    y_pred (array-like): The predicted anomaly scores from OneClassSVM.\n",
    "    return_threshold (bool, optional): If True, the threshold value where EER is achieved will be returned.\n",
    "\n",
    "    Returns:\n",
    "    float: The equal error rate value.\n",
    "    float, optional: The threshold value where EER is achieved, if `return_threshold` is set to True.\n",
    "    \"\"\"\n",
    "    # Calculate the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=1)\n",
    "\n",
    "    # Calculate the False Negative Rate (FNR)\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # Find the point where FPR is closest to FNR\n",
    "    eer_index = np.argmin(np.abs(fpr - fnr))\n",
    "    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n",
    "\n",
    "    if return_threshold:\n",
    "        threshold = thresholds[eer_index]\n",
    "        return eer, threshold\n",
    "\n",
    "    return eer\n",
    "utils_eer_scorer3 = make_scorer(utils_eer3, greater_is_better=False, needs_threshold=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# source: https://github.com/dynobo/ContinAuth/blob/master/notebooks/utils.ipynb\n",
    "def utils_eer(y_true, y_pred, return_threshold=False):\n",
    "    \"\"\"Calculate the Equal Error Rate.\n",
    "\n",
    "    Based on https://stackoverflow.com/a/49555212, https://yangcha.github.io/EER-ROC/\n",
    "    and https://scikit-learn.org/stable/modules/model_evaluation.html#implementing-your-own-scoring-object\n",
    "\n",
    "    Arguments:\n",
    "        y_true {np.array}  -- Actual labels\n",
    "        y_pred {np.array}  -- Predicted labels or probability\n",
    "        \n",
    "    Returns:\n",
    "        float              -- Equal Error Rate        \n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)  # Calculated threshold, not needed for score\n",
    "    if return_threshold:\n",
    "        return eer, thresh\n",
    "    else:\n",
    "        return eer\n",
    "utils_eer_scorer = make_scorer(utils_eer, greater_is_better=False)#, needs_threshold=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_owner_classifier_train_valid(owner_key, X_exp_train_dic, seed, run, param_dist, cores, exp_config, verbose=0):\n",
    "    run_seed = seed + run\n",
    "    train_dic, valid_test_dic = { owner_key: X_exp_train_dic[owner_key][\"profile_windows\"]}, X_exp_train_dic[owner_key][\"unknown_users_dict\"] \n",
    "\n",
    "    X_vals_owner_idx = utils_create_cv_splits(owner_key, train_dic, valid_test_dic, seed=run_seed, verbose=verbose-1) #check\n",
    "\n",
    "    # X_test_regular = X_vals_owner_idx['X_test_regular'].copy()\n",
    "    # X_test_anomalous = X_vals_owner_idx['X_test_anomalous'].copy()\n",
    "\n",
    "    cv_splits = X_vals_owner_idx['cv_splits']\n",
    "\n",
    "    if exp_config.classifier==\"OCSVM\":\n",
    "        clf = OneClassSVM(kernel=exp_config.ocsvm_kernel, \n",
    "                          verbose=0)\n",
    "        \n",
    "    elif exp_config.classifier==\"IF\":\n",
    "        clf = IsolationForest(random_state=run_seed, \n",
    "                              n_jobs=cores, \n",
    "                              verbose=max(0, verbose-1))\n",
    "        \n",
    "    elif exp_config.classifier==\"LOF\":\n",
    "        # Create the LOF estimator with novelty detection enabled\n",
    "        clf = LocalOutlierFactor(novelty=True, \n",
    "                                 algorithm=\"brute\", \n",
    "                                 metric=exp_config.LOF_metric, \n",
    "                                 p=exp_config.p,\n",
    "                                 n_jobs=cores)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Unspecified classifier!\")\n",
    "        \n",
    "\n",
    "    pipeline = Pipeline([\n",
    "#                             ('scaler', StandardScaler()), \n",
    "                        # ('scaler', get_new_scaler_dict[P.scaler]()), \n",
    "#                             ('scaler', Normalizer()),\n",
    "#                              ('pca', pca), \n",
    "#                              ('selector', VarianceThreshold()), \n",
    "                         ('model', clf)\n",
    "                        ])\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_dist,\n",
    "        cv=cv_splits,\n",
    "#             n_iter=120,\n",
    "        n_iter=80,\n",
    "#             n_iter=480,\n",
    "        n_jobs=cores,\n",
    "        refit=False,\n",
    "        scoring={\"eer\": utils_eer_scorer4, \"accuracy\": accuracy_scorer2},\n",
    "        verbose=verbose,\n",
    "        return_train_score=False,\n",
    "        # iid=False, #invalid arg in sklearn 1.0.2\n",
    "        error_score=\"raise\",\n",
    "        random_state=run_seed\n",
    "    )\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=param_dist,\n",
    "#             cv=cv_splits,\n",
    "#             n_jobs=cores,\n",
    "#             refit=False,\n",
    "#             scoring={\"eer\": utils_eer_scorer, \"accuracy\": \"accuracy\"},\n",
    "#             verbose=1,\n",
    "#             return_train_score=False,\n",
    "#             iid=False,\n",
    "#             error_score=\"raise\",\n",
    "#         )\n",
    "#         print(X_train.shape)\n",
    "#         print(X_test_anomalous.shape)\n",
    "\n",
    "\n",
    "    search.fit(X_vals_owner_idx['X_train'], X_vals_owner_idx['y_train'])\n",
    "    impostors = [user_key for user_key in X_exp_train_dic.keys() if user_key != owner_key]\n",
    "\n",
    "    df_report = utils_cv_report(search, owner_key, impostors) # check\n",
    "    df_report[\"run\"] = run\n",
    "    \n",
    "    return df_report #{\"df_report\": df_report, \"owner_key\": owner_key}\n",
    "\n",
    "\n",
    "# non parallel is fast enough so i did not use this one. Needs double checking for correcteness before using\n",
    "def evaluate_owner_classifier_train_test(owner_key, X_exp_test_dic, seed, run, cores, exp_config, verbose=0):\n",
    "    run_seed = seed + run\n",
    "    train_dic, valid_test_dic = { owner_key: X_exp_test_dic[owner_key][\"profile_windows\"]}, X_exp_test_dic[owner_key][\"unknown_users_dict\"] \n",
    "\n",
    "    X_vals_owner_idx = utils_create_cv_splits(owner_key, train_dic, valid_test_dic, seed=run_seed, verbose=verbose-1)\n",
    "\n",
    "    train_test_cv_splits = X_vals_owner_idx['cv_splits']\n",
    "\n",
    "    \n",
    "    # X_test_regular = X_vals_owner_idx['X_test_regular'].copy()\n",
    "    # X_test_anomalous = X_vals_owner_idx['X_test_anomalous'].copy()\n",
    "\n",
    "#         print(X_vals_owner_idx['cv_splits'])\n",
    "#         pca = PCA(n_components = run+3)\n",
    "#         X_train = pca.fit_transform(X_train)\n",
    "#         X_test_regular = pca.transform(X_test_regular)\n",
    "#         X_test_anomalous = pca.transform(X_test_anomalous)\n",
    "\n",
    "#         pca_fs.add_user_pca(owner_idx, pca)\n",
    "\n",
    "    if exp_config.classifier==\"OCSVM\":\n",
    "        clf = svm.OneClassSVM(kernel=exp_config.ocsvm_kernel, nu=exp_config.ocsvm_nu, gamma=exp_config.ocsvm_gamma, verbose=0)\n",
    "        \n",
    "    elif exp_config.classifier==\"IF\":\n",
    "        clf = IsolationForest(n_estimators = exp_config.median_n_estimators, \n",
    "                              max_samples = exp_config.median_max_samples, \n",
    "                              contamination = exp_config.median_contamination, \n",
    "                              max_features = exp_config.median_max_features, \n",
    "                              random_state=run_seed, n_jobs=cores, verbose=max(0, verbose-1))\n",
    "    \n",
    "    elif exp_config.classifier==\"LOF\":\n",
    "        # Create the LOF estimator with novelty detection enabled\n",
    "        clf = LocalOutlierFactor(novelty=True, \n",
    "                                 algorithm=\"brute\", \n",
    "                                 metric=exp_config.LOF_metric, \n",
    "                                 p=exp_config.p,\n",
    "                                 n_neighbors=exp_config.median_n_neighbors, \n",
    "                                 contamination = exp_config.median_contamination, \n",
    "                                 n_jobs=cores)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Unspecified classifier!\")\n",
    "        \n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "                        # ('scaler', get_new_scaler_dict[P.scaler]()), \n",
    "#                             ('scaler2', Normalizer()),#best result\n",
    "#                              ('pca', pca), \n",
    "#                              ('selector', VarianceThreshold()), \n",
    "                        ('model', clf)\n",
    "                        ])\n",
    "\n",
    "    \n",
    "    scores = cross_validate(\n",
    "        pipeline,\n",
    "        X_vals_owner_idx['X_train'],\n",
    "        X_vals_owner_idx['y_train'],\n",
    "        cv=train_test_cv_splits,\n",
    "        scoring={\n",
    "            \"eer\": utils_eer_scorer4,\n",
    "            \"accuracy\": accuracy_scorer2,\n",
    "            \"precision\": precision_scorer,\n",
    "            \"recall\": recall_scorer,\n",
    "            \"f1_score\": f1_score_scorer,\n",
    "        },\n",
    "        n_jobs=cores,\n",
    "        verbose=verbose,\n",
    "        return_train_score=False, # train eer is meaningless\n",
    "    )\n",
    "\n",
    "    impostors = [user_key for user_key in X_exp_test_dic.keys() if user_key != owner_key]\n",
    "    df_score = pd.DataFrame(scores)\n",
    "    df_score[\"owner\"] = owner_key\n",
    "    # df_score[\"train_eer\"] = df_score[\"train_eer\"].abs()  # train eer is meaningless\n",
    "    df_score[\"test_eer\"] = df_score[\"test_eer\"].abs()\n",
    "    df_score[\"run\"] = run\n",
    "    df_score[\"impostors\"] = impostors\n",
    "    \n",
    "    return df_score\n",
    "\n",
    "def parallel_find_best_hyperparams(X_exp_train_dic, param_dist, exp_config, cores, verbose=0):\n",
    "    \n",
    "    df_results = None  # Will be filled with randomsearch scores\n",
    "\n",
    "    for run in tqdm(range(3)):\n",
    "\n",
    "        with parallel_backend('loky', n_jobs=-1):\n",
    "            df_reports = Parallel(n_jobs=-1, verbose=verbose)(delayed(evaluate_owner_classifier_train_valid)(owner_key, X_exp_train_dic, SEED, run, \n",
    "                                                                                                         param_dist, cores=cores, exp_config=exp_config) \n",
    "                                                          for owner_key in tqdm(\n",
    "                                                              X_exp_train_dic.keys(),\n",
    "                                                              desc=f\"run: {run}\",\n",
    "                                                          ))\n",
    "        df_results = pd.concat([df_results] + df_reports, sort=False, ignore_index=True)\n",
    "\n",
    "\n",
    "    if exp_config.classifier==\"OCSVM\":\n",
    "        result_dict = utils_plot_randomsearch_results(df_results, n_top=1, plot=False)\n",
    "        \n",
    "    elif exp_config.classifier==\"IF\":\n",
    "        result_dict = utils_plot_randomsearch_results_IF(df_results, n_top=1, plot=False)\n",
    "        \n",
    "    elif exp_config.classifier==\"LOF\":\n",
    "        result_dict = utils_plot_randomsearch_results_LOF(df_results, n_top=1, plot=False)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Unspecified classifier\")\n",
    "        \n",
    "    return result_dict\n",
    "        \n",
    "def parallel_evaluation_classifier_train_test(X_exp_dic, exp_config, cores, verbose=0):\n",
    "    \"\"\"\n",
    "    return mean_test_EER_df\n",
    "    \"\"\"\n",
    "    test_df_results = None  # Will be filled with randomsearch scores\n",
    "    for run in tqdm(range(5)):\n",
    "\n",
    "        with parallel_backend('loky', n_jobs=-1):\n",
    "            df_score = Parallel(n_jobs=-1, verbose=verbose)(delayed(evaluate_owner_classifier_train_test)(owner_key, X_exp_dic, SEED, run, \n",
    "                                                                                                      cores=cores, exp_config=exp_config, verbose=0) \n",
    "                                                        for owner_key in tqdm(\n",
    "                                                            X_exp_dic.keys(),\n",
    "                                                            desc=f\"run: {run}\",\n",
    "                                                        ))\n",
    "        test_df_results = pd.concat([test_df_results] + df_score, sort=False, ignore_index=True, axis=0)\n",
    "\n",
    "\n",
    "    mean_test_EER=test_df_results.groupby(['owner', 'impostors'], sort=False)[['fit_time', 'score_time', 'test_eer', 'test_accuracy', \n",
    "                                                                               'test_precision', 'test_recall', \"test_f1_score\"]].mean().reset_index()\n",
    "\n",
    "\n",
    "    return mean_test_EER\n",
    "\n",
    "def calculate_X_exp_dict(dfList_exp1,\n",
    "                         dfList_exp2,\n",
    "                         dfList_exp1_user_47, \n",
    "                         dfList_exp2_user_47,\n",
    "                         window_size,\n",
    "                         step_width,\n",
    "                         user_idx_set,\n",
    "                         exp_config,\n",
    "                         extract_features_func,\n",
    "                         # min_max_scaler=None,\n",
    "                         verbose=0):\n",
    "    \n",
    "    # get user set of all users in the current phase\n",
    "    user_idx_set=set(user_idx_set)\n",
    "    \n",
    "    # separate user 47 which has 29 index by default from the other users as 47 has shorter time series\n",
    "    if 29 in user_idx_set:\n",
    "        \n",
    "        user_idx_set_without_user_47 = user_idx_set - {29}\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        user_idx_set_without_user_47 = user_idx_set\n",
    "    \n",
    "    # if this is for SCNN exp, this version has a min_max_scaler unlike WACA\n",
    "    if exp_config.is_NN:\n",
    "        print(\"NN preprocessing\")\n",
    "        \n",
    "        X_exp1_dict, X_exp2_dict, \\\n",
    "        fitted_scaler_exp2_dict, fitted_min_max_scaler_exp2_dict=get_raw_windows_NN(\\\n",
    "                                                                                    dfList_exp1=dfList_exp1, \n",
    "                                                                                    dfList_exp2=dfList_exp2, \n",
    "                                                                                    window_size=window_size, \n",
    "                                                                                    step_width=step_width, \n",
    "                                                                                    user_idx_set=user_idx_set_without_user_47, \n",
    "                                                                                    scaler=exp_config.scaler, \n",
    "                                                                                    min_max_scaler=True,\n",
    "                                                                                    num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "                                                                                    EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "                                                                                    SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "                                                                                    Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "                                                                                    verbose=verbose)\n",
    "\n",
    "        # if user 47 is present in the current phase, extract its data and then merge it with other users data\n",
    "        if 29 in user_idx_set:\n",
    "            \n",
    "            X_exp1_dict_user_47, X_exp2_dict_user_47, \\\n",
    "            fitted_scaler_exp2_dict_user_47, \\\n",
    "            fitted_min_max_scaler_exp2_dict_user_47=get_raw_windows_user_47_NN(\\\n",
    "                                                                               dfList_exp1_user_47=dfList_exp1_user_47, \n",
    "                                                                               dfList_exp2_user_47=dfList_exp2_user_47, \n",
    "                                                                               window_size=window_size, \n",
    "                                                                               step_width=step_width, \n",
    "                                                                               scaler=exp_config.scaler, \n",
    "                                                                               min_max_scaler=True,\n",
    "                                                                               num_sample_points_per_exp=exp_config.num_sample_points_per_exp,\n",
    "                                                                               EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "                                                                               SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "                                                                               Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "                                                                               verbose=verbose)\n",
    "\n",
    "            X_exp1_dict, X_exp2_dict, \\\n",
    "            fitted_scaler_exp2_dict, \\\n",
    "            fitted_min_max_scaler_exp2_dict=append_user_47_to_data_NN(\\\n",
    "                                                                      X_exp1_dict=X_exp1_dict, \n",
    "                                                                      X_exp2_dict=X_exp2_dict,\n",
    "                                                                      fitted_scaler_exp2_dict=fitted_scaler_exp2_dict, \n",
    "                                                                      all_user_set=user_idx_set_without_user_47,\n",
    "                                                                      X_exp1_dict_user_47=X_exp1_dict_user_47, \n",
    "                                                                      X_exp2_dict_user_47=X_exp2_dict_user_47, \n",
    "                                                                      fitted_scaler_exp2_dict_user_47=fitted_scaler_exp2_dict_user_47, \n",
    "                                                                      fitted_min_max_scaler_exp2_dict=fitted_min_max_scaler_exp2_dict, \n",
    "                                                                      fitted_min_max_scaler_exp2_dict_user_47=fitted_min_max_scaler_exp2_dict_user_47,\n",
    "                                                                      verbose=verbose)\n",
    "        \n",
    "\n",
    "\n",
    "        X_features_dict = extract_features_func(X_exp1_dic=X_exp1_dict, \n",
    "                                                X_exp2_dic=X_exp2_dict, \n",
    "                                                fitted_scaler_classifier_exp2_dic=fitted_scaler_exp2_dict, \n",
    "                                                fitted_min_max_scaler_exp2_dict=fitted_min_max_scaler_exp2_dict,\n",
    "                                                scaler_clip=exp_config.scaler_clip)\n",
    "        \n",
    "    # if this is for a WACA exp\n",
    "    else:\n",
    "        \n",
    "        print(\"WACA preprocessing\")\n",
    "        \n",
    "        X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict=get_raw_windows(\\\n",
    "                                                                          dfList_exp1=dfList_exp1, \n",
    "                                                                          dfList_exp2=dfList_exp2, \n",
    "                                                                          window_size=window_size, \n",
    "                                                                          step_width=step_width, \n",
    "                                                                          user_idx_set=user_idx_set_without_user_47, \n",
    "                                                                          scaler=exp_config.scaler, \n",
    "                                                                          num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "                                                                          EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "                                                                          SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "                                                                          Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "                                                                          verbose=verbose)\n",
    "\n",
    "        # if user 47 is present in the current phase, extract its data and then merge it with other users data\n",
    "        if 29 in user_idx_set:\n",
    "            \n",
    "            X_exp1_dict_user_47, X_exp2_dict_user_47,\\\n",
    "            fitted_scaler_exp2_dict_user_47=get_raw_windows_user_47(dfList_exp1_user_47=dfList_exp1_user_47, \n",
    "                                                                    dfList_exp2_user_47=dfList_exp2_user_47, \n",
    "                                                                    window_size=window_size, \n",
    "                                                                    step_width=step_width, \n",
    "                                                                    scaler=exp_config.scaler, \n",
    "                                                                    num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "                                                                    EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "                                                                    SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "                                                                    Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "                                                                    verbose=verbose)\n",
    "\n",
    "            X_exp1_dict, X_exp2_dict, fitted_scaler_exp2_dict=append_user_47_to_data(X_exp1_dict=X_exp1_dict, \n",
    "                                                                                     X_exp2_dict=X_exp2_dict, \n",
    "                                                                                     fitted_scaler_exp2_dict=fitted_scaler_exp2_dict, \n",
    "                                                                                     all_user_set=user_idx_set_without_user_47, \n",
    "                                                                                     X_exp1_dict_user_47=X_exp1_dict_user_47, \n",
    "                                                                                     X_exp2_dict_user_47=X_exp2_dict_user_47, \n",
    "                                                                                     fitted_scaler_exp2_dict_user_47=fitted_scaler_exp2_dict_user_47, \n",
    "                                                                                     verbose=verbose)\n",
    "\n",
    "        X_features_dict = extract_features_func(X_exp1_dic=X_exp1_dict, \n",
    "                                                X_exp2_dic=X_exp2_dict, \n",
    "                                                fitted_scaler_classifier_exp2_dic=fitted_scaler_exp2_dict, \n",
    "                                                scaler_clip=exp_config.scaler_clip)\n",
    "\n",
    "\n",
    "    return X_features_dict\n",
    "    \n",
    "    \n",
    "def calculate_EER_different_window_sizes_train_OCSVM_IF_LOF(dfList_dict, window_size_lst, train_set, exp_config, extract_features_func_dict, overlap, param_dist, verbose=0):\n",
    "    \n",
    "    dfList_exp1=dfList_dict[\"dfList_exp1\"]\n",
    "    dfList_exp2=dfList_dict[\"dfList_exp2\"]\n",
    "    dfList_exp1_user_47=dfList_dict[\"dfList_exp1_user_47\"]\n",
    "    dfList_exp2_user_47=dfList_dict[\"dfList_exp2_user_47\"]\n",
    "    EER_distro_df_dict = {}\n",
    "    \n",
    "    if exp_config.classifier==\"OCSVM\":\n",
    "        columns = ['window_size', \"step_width\", \"Mean_EER\", \"median_nu\", \"median_gamma\"]\n",
    "\n",
    "    elif exp_config.classifier==\"IF\":\n",
    "        columns = ['window_size', \"step_width\", \"Mean_EER\", \"median_n_estimators\", \"median_max_samples\", \"median_contamination\", \"median_max_features\"]\n",
    "        \n",
    "    elif exp_config.classifier==\"LOF\":\n",
    "        columns = ['window_size', \"step_width\", \"Mean_EER\", \"median_n_neighbors\", \"median_contamination\"]\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Unspecified classifier\")\n",
    "    \n",
    "    Mean_EER_df = pd.DataFrame(columns = columns)\n",
    "    for window_size in tqdm(window_size_lst):\n",
    "        print(f\"window_size: {window_size}\")\n",
    "\n",
    "        step_width = int(window_size * (1-overlap))\n",
    "\n",
    "#         X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=get_raw_windows(dfList_exp1, dfList_exp2, window_size, step_width, train_set, exp_config.scaler, \n",
    "#                                                                                             exp_config.num_sample_points_per_exp, \n",
    "#                                                                                             EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "#                                                                                             SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "#                                                                                             Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "#                                                                                             verbose=0)\n",
    "\n",
    "#         X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47=get_raw_windows_user_47(dfList_exp1_user_47, dfList_exp2_user_47, \n",
    "#                                                                                                                             window_size, step_width, scaler=exp_config.scaler, \n",
    "#                                                                                                                             num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "#                                                                                                                             EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "#                                                                                                                             SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "#                                                                                                                             Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "#                                                                                                                             verbose=0)\n",
    "\n",
    "#         X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict=append_user_47_to_data(X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_train_exp2_dict, exp_config.user_ids, \n",
    "#                                                                                                    X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, fitted_scaler_train_exp2_dict_user_47, \n",
    "#                                                                                                    verbose=0)\n",
    "\n",
    "# ###added----\n",
    "#         X_train_exp1_dict, X_train_exp2_dict, \\\n",
    "#         fitted_scaler_train_exp2_dict, fitted_min_max_scaler_train_exp2_dict=get_raw_windows_NN(\\\n",
    "#                                                                                                 dfList_exp1=dfList_exp1, \n",
    "#                                                                                                 dfList_exp2=dfList_exp2, \n",
    "#                                                                                                 window_size=window_size, \n",
    "#                                                                                                 step_width=step_width, \n",
    "#                                                                                                 user_idx_set=train_set, \n",
    "#                                                                                                 scaler=exp_config.scaler, \n",
    "#                                                                                                 min_max_scaler=True,\n",
    "#                                                                                                 num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "#                                                                                                 EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "#                                                                                                 SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "#                                                                                                 Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "#                                                                                                 verbose=0)\n",
    "\n",
    "#         X_train_exp1_dict_user_47, X_train_exp2_dict_user_47, \\\n",
    "#         fitted_scaler_train_exp2_dict_user_47, \\\n",
    "#         fitted_min_max_scaler_train_exp2_dict_user_47=get_raw_windows_user_47_NN(\\\n",
    "#                                                                                  dfList_exp1_user_47=dfList_exp1_user_47, \n",
    "#                                                                                  dfList_exp2_user_47=dfList_exp2_user_47, \n",
    "#                                                                                  window_size=window_size, \n",
    "#                                                                                  step_width=step_width, \n",
    "#                                                                                  scaler=exp_config.scaler, \n",
    "#                                                                                  min_max_scaler=True,\n",
    "#                                                                                  num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "#                                                                                  EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "#                                                                                  SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "#                                                                                  Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "#                                                                                  verbose=0)\n",
    "\n",
    "#         X_train_exp1_dict, X_train_exp2_dict, \\\n",
    "#         fitted_scaler_train_exp2_dict, \\\n",
    "#         fitted_min_max_scaler_train_exp2_dict=append_user_47_to_data_NN(\\\n",
    "#                                                                   X_exp1_dict=X_train_exp1_dict, \n",
    "#                                                                   X_exp2_dict=X_train_exp2_dict, \n",
    "#                                                                   fitted_scaler_exp2_dict=fitted_scaler_train_exp2_dict, \n",
    "#                                                                   all_user_set=exp_config.user_ids, \n",
    "#                                                                   X_exp1_dict_user_47=X_train_exp1_dict_user_47, \n",
    "#                                                                   X_exp2_dict_user_47=X_train_exp2_dict_user_47, \n",
    "#                                                                   fitted_scaler_exp2_dict_user_47=fitted_scaler_train_exp2_dict_user_47, \n",
    "#                                                                   fitted_min_max_scaler_exp2_dict=fitted_min_max_scaler_train_exp2_dict, \n",
    "#                                                                   fitted_min_max_scaler_exp2_dict_user_47=fitted_min_max_scaler_train_exp2_dict_user_47,\n",
    "#                                                                   verbose=0)\n",
    "        \n",
    "# ###added----\n",
    "\n",
    "\n",
    "        extract_features_func=extract_features_func_dict[window_size]\n",
    "    \n",
    "        X_exp_train_dic = calculate_X_exp_dict(dfList_exp1=dfList_exp1,\n",
    "                                               dfList_exp2=dfList_exp2,\n",
    "                                               dfList_exp1_user_47=dfList_exp1_user_47, \n",
    "                                               dfList_exp2_user_47=dfList_exp2_user_47,\n",
    "                                               window_size=window_size,\n",
    "                                               step_width=step_width,\n",
    "                                               user_idx_set=train_set,\n",
    "                                               exp_config=exp_config,\n",
    "                                               extract_features_func=extract_features_func,\n",
    "                                               verbose=0)\n",
    "\n",
    "        # X_exp_train_dic = extract_features_func(X_train_exp1_dict, X_train_exp2_dict, fitted_scaler_classifier_exp2_dic=fitted_scaler_train_exp2_dict, \n",
    "        #                                         fitted_min_max_scaler_exp2_dict=fitted_min_max_scaler_train_exp2_dict,#added\n",
    "        #                                         scaler_clip=exp_config.scaler_clip)\n",
    "\n",
    "\n",
    "        result_dict = parallel_find_best_hyperparams(X_exp_train_dic, param_dist, exp_config, cores=exp_config.train_cores, verbose=verbose)\n",
    "        \n",
    "        if exp_config.classifier==\"OCSVM\":\n",
    "            exp_config.ocsvm_nu, exp_config.ocsvm_gamma = result_dict[\"median_nu\"], result_dict[\"median_gamma\"]\n",
    "\n",
    "        elif exp_config.classifier==\"IF\":\n",
    "            exp_config.median_n_estimators, exp_config.median_max_samples, exp_config.median_contamination, exp_config.median_max_features = \\\n",
    "            result_dict[\"median_n_estimators\"], result_dict[\"median_max_samples\"], result_dict[\"median_contamination\"], result_dict[\"median_max_features\"]\n",
    "            \n",
    "            exp_config.median_n_estimators = np.int64(np.round(exp_config.median_n_estimators))\n",
    "        \n",
    "        elif exp_config.classifier==\"LOF\":\n",
    "            exp_config.median_n_neighbors, exp_config.median_contamination = result_dict[\"median_n_neighbors\"], result_dict[\"median_contamination\"]\n",
    "            \n",
    "            exp_config.median_n_neighbors = np.int64(np.round(exp_config.median_n_neighbors))\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Unspecified classifier\")\n",
    "        \n",
    "        \n",
    "        Mean_valid_EER_df_results = parallel_evaluation_classifier_train_test(X_exp_train_dic, exp_config, cores=exp_config.train_cores, verbose=verbose)\n",
    "        Mean_EER = Mean_valid_EER_df_results.test_eer.mean()\n",
    "\n",
    "        \n",
    "        if exp_config.classifier==\"OCSVM\":\n",
    "            new_row = pd.DataFrame([[window_size, step_width, Mean_EER, exp_config.ocsvm_nu, exp_config.ocsvm_gamma]], columns=columns)\n",
    "\n",
    "        elif exp_config.classifier==\"IF\":\n",
    "            new_row = pd.DataFrame([[window_size, step_width, Mean_EER, exp_config.median_n_estimators, exp_config.median_max_samples, \n",
    "                                     exp_config.median_contamination, exp_config.median_max_features]], columns=columns)\n",
    "            \n",
    "        elif exp_config.classifier==\"LOF\":\n",
    "            new_row = pd.DataFrame([[window_size, step_width, Mean_EER, exp_config.median_n_neighbors, exp_config.median_contamination]], columns=columns)\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Unspecified classifier\")\n",
    "        \n",
    "        Mean_EER_df = pd.concat([Mean_EER_df, new_row])\n",
    "\n",
    "\n",
    "    return Mean_EER_df\n",
    "\n",
    "\n",
    "def calculate_EER_different_window_sizes_test_OCSVM_IF_LOF(dfList_dict, window_size_lst, test_set, exp_config, extract_features_func_dict, overlap, best_param_df, verbose=0):\n",
    "    dfList_exp1=dfList_dict[\"dfList_exp1\"]\n",
    "    dfList_exp2=dfList_dict[\"dfList_exp2\"]\n",
    "    EER_distro_df_dict = {}\n",
    "\n",
    "    if exp_config.classifier==\"OCSVM\":\n",
    "        columns = ['window_size', \"step_width\", \"Mean_EER\", \"median_nu\", \"median_gamma\"]\n",
    "\n",
    "    elif exp_config.classifier==\"IF\":\n",
    "        columns = ['window_size', \"step_width\", \"Mean_EER\", \"median_n_estimators\", \"median_max_samples\", \"median_contamination\", \"median_max_features\"]\n",
    "\n",
    "    elif exp_config.classifier==\"LOF\":\n",
    "        columns = ['window_size', \"step_width\", \"Mean_EER\", \"median_n_neighbors\", \"median_contamination\"]\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Unspecified classifier\")\n",
    "    \n",
    "    # adding Gini coef column\n",
    "    columns+=[\"Gini_coef\"]\n",
    "    \n",
    "    Mean_EER_df = pd.DataFrame(columns = columns)\n",
    "    for window_size in tqdm(window_size_lst):\n",
    "        print(f\"window_size: {window_size}\")\n",
    "        step_width = int(window_size * (1-overlap))\n",
    "        \n",
    "        \n",
    "#         X_test_exp1_dict, X_test_exp2_dict, fitted_scaler_test_exp2_dict=get_raw_windows(dfList_exp1, dfList_exp2, window_size, step_width, test_set, exp_config.scaler, \n",
    "#                                                                                          exp_config.num_sample_points_per_exp, EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "#                                                                                          SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "#                                                                                          Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "#                                                                                          verbose=0)\n",
    "\n",
    "        \n",
    "#         extract_features_func=extract_features_func_dict[window_size]\n",
    "        \n",
    "#         X_exp_test_dic = extract_features_func(X_test_exp1_dict, X_test_exp2_dict, fitted_scaler_test_exp2_dict, scaler_clip=exp_config.scaler_clip)\n",
    "\n",
    "###---added\n",
    "        # X_test_exp1_dict, X_test_exp2_dict, \\\n",
    "        # fitted_scaler_test_exp2_dict, fitted_min_max_scaler_test_exp2_dict=get_raw_windows_NN(\\\n",
    "        #                                                                                         dfList_exp1=dfList_exp1, \n",
    "        #                                                                                         dfList_exp2=dfList_exp2, \n",
    "        #                                                                                         window_size=window_size, \n",
    "        #                                                                                         step_width=step_width, \n",
    "        #                                                                                         user_idx_set=test_set, \n",
    "        #                                                                                         scaler=exp_config.scaler, \n",
    "        #                                                                                         min_max_scaler=True,\n",
    "        #                                                                                         num_sample_points_per_exp=exp_config.num_sample_points_per_exp, \n",
    "        #                                                                                         EMA_per_win_span=exp_config.EMA_per_win_span, \n",
    "        #                                                                                         SMA_per_win_winsize=exp_config.SMA_per_win_winsize,\n",
    "        #                                                                                         Butter_per_win_argdict=exp_config.Butter_per_win_argdict, \n",
    "        #                                                                                         verbose=0)\n",
    "\n",
    "\n",
    "        extract_features_func=extract_features_func_dict[window_size]\n",
    "        \n",
    "        X_exp_test_dic = calculate_X_exp_dict(dfList_exp1=dfList_exp1,\n",
    "                                              dfList_exp2=dfList_exp2,\n",
    "                                              dfList_exp1_user_47=dfList_exp1_user_47, \n",
    "                                              dfList_exp2_user_47=dfList_exp2_user_47,\n",
    "                                              window_size=window_size,\n",
    "                                              step_width=step_width,\n",
    "                                              user_idx_set=test_set,\n",
    "                                              exp_config=exp_config,\n",
    "                                              extract_features_func=extract_features_func,\n",
    "                                              verbose=0)\n",
    "\n",
    "        # X_exp_test_dic = extract_features_func(X_test_exp1_dict, X_test_exp2_dict, fitted_scaler_classifier_exp2_dic=fitted_scaler_test_exp2_dict, \n",
    "        #                                         fitted_min_max_scaler_exp2_dict=fitted_min_max_scaler_test_exp2_dict,\n",
    "        #                                         scaler_clip=exp_config.scaler_clip)\n",
    "###---added\n",
    "        \n",
    "        \n",
    "        winsize_best_param_df = best_param_df[best_param_df.window_size==window_size]\n",
    "        if exp_config.classifier==\"OCSVM\":\n",
    "            exp_config.ocsvm_nu, exp_config.ocsvm_gamma = winsize_best_param_df.median_nu.item(), winsize_best_param_df.median_gamma.item()\n",
    "\n",
    "        elif exp_config.classifier==\"IF\":\n",
    "            exp_config.median_n_estimators, exp_config.median_max_samples, exp_config.median_contamination, exp_config.median_max_features = \\\n",
    "            winsize_best_param_df.median_n_estimators.item(), winsize_best_param_df.median_max_samples.item(), winsize_best_param_df.median_contamination.item(), \\\n",
    "            winsize_best_param_df.median_max_features.item()\n",
    "            \n",
    "        elif exp_config.classifier==\"LOF\":\n",
    "            exp_config.median_n_neighbors, exp_config.median_contamination= winsize_best_param_df.median_n_neighbors.item(), winsize_best_param_df.median_contamination.item()\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Unspecified classifier\")\n",
    "            \n",
    "            \n",
    "        Mean_test_EER_df_results = parallel_evaluation_classifier_train_test(X_exp_test_dic, exp_config, cores=exp_config.test_cores, verbose=verbose)\n",
    "        Mean_EER = Mean_test_EER_df_results.test_eer.mean()\n",
    "        \n",
    "        gini_coef=gini(Mean_test_EER_df_results.test_eer.to_numpy())\n",
    "\n",
    "\n",
    "        if exp_config.classifier==\"OCSVM\":\n",
    "            new_row = pd.DataFrame([[window_size, step_width, Mean_EER, exp_config.ocsvm_nu, exp_config.ocsvm_gamma, gini_coef]], columns=columns)\n",
    "\n",
    "        elif exp_config.classifier==\"IF\":\n",
    "            new_row = pd.DataFrame([[window_size, step_width, Mean_EER, exp_config.median_n_estimators, exp_config.median_max_samples, \n",
    "                                     exp_config.median_contamination, exp_config.median_max_features, gini_coef]], columns=columns)\n",
    "            \n",
    "        elif exp_config.classifier==\"LOF\":\n",
    "            new_row = pd.DataFrame([[window_size, step_width, Mean_EER, exp_config.median_n_neighbors, exp_config.median_contamination, gini_coef]], columns=columns)\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Unspecified classifier\")\n",
    "        \n",
    "        Mean_EER_df = pd.concat([Mean_EER_df, new_row])\n",
    "\n",
    "\n",
    "    return Mean_EER_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "adb215c0-9999-4e8f-a64f-1ce0bef9da1a",
    "_uuid": "696cb33f-f151-4447-8e46-7018e15cc5be",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def OneClassSVMSets(k, X_exp1_dic, X_exp2_dic, cv=5):\n",
    "    '''\n",
    "    return the required sets for an OCSVM trained on the user with key. \n",
    "    X_train: X data from X_exp1_dic[k]\n",
    "    X_test_regular: X data from X_exp2_dic[k]\n",
    "    X_test_anomalous: X data from X_exp2_dic[!k]\n",
    "    '''\n",
    "    \n",
    "    if k not in  X_exp1_dic:\n",
    "        raise Exception(\"invalid key for dic\")\n",
    "        \n",
    "    \n",
    "    X_pos = X_exp1_dic[k]\n",
    "#     X_neg = np.concatenate([X_exp1_dic[key] for key in X_exp1_dic.keys() if key != k], axis=0)\n",
    "    X_test_regular = X_exp2_dic[k]\n",
    "    X_test_anomalous = np.concatenate([X_exp2_dic[key] for key in X_exp2_dic.keys() if key != k], axis=0)\n",
    "    \n",
    "    \n",
    "#     n, m = len(Xpos), len(Xneg)\n",
    "    np.random.shuffle(X_neg)\n",
    "    print((X_neg.shape[0], X_pos.shape[0]))\n",
    "    X_neg = X_neg[np.random.choice(X_neg.shape[0], size=X_pos.shape[0], replace=False), :]\n",
    "    print(X_pos.shape, X_neg.shape)\n",
    "    # Creating (train, test) tuples of indices for k-folds cross-validation\n",
    "    # We split the positive class (normal data) as we only want the positive examples in the training set.\n",
    "    \n",
    "    train_splits = KFold(n_splits=cv, shuffle=True).split(X_pos)\n",
    "    anomalous_splits = KFold(n_splits=cv, shuffle=True).split(X_neg)\n",
    "\n",
    "#     print(len(train_splits), len(anomalous_splits))\n",
    "    # Negative examples (abnormal data) are added to the test set (see https://stackoverflow.com/a/58459322/3673842)\n",
    "    y_train = np.concatenate([np.repeat(1.0, len(X_pos)), np.repeat(-1.0, len(X_neg))])\n",
    "    X_train = np.concatenate([X_pos, X_neg], axis=0)\n",
    "    \n",
    "    # https://github.com/steppi/adeft/blob/anomaly_detection/adeft/modeling/find_anomalies.py#L170\n",
    "    cv_splits = ((train, np.concatenate((test, anom_test + X_pos.shape[0]), axis = 0))\n",
    "                  for (train, test), (_, anom_test)\n",
    "                  in zip(train_splits, anomalous_splits))\n",
    "    \n",
    "    return {\"X_train\": X_train, \"y_train\": y_train, \"X_test_regular\": X_test_regular, \"X_test_anomalous\": X_test_anomalous, \"cv_splits\": cv_splits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "478e1e7e-68bd-4f32-94a8-e2aa98381323",
    "_uuid": "59ce837f-6626-42f9-bd8c-ac2fdf93c5c2"
   },
   "source": [
    "# utils_create_cv_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "1cfaf4af-a653-485b-be5b-c28d2797798f",
    "_uuid": "38ee9619-b1c4-40d6-9980-1809d1775875",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def utils_create_cv_splits(owner_key, train_dic, valid_test_dic, seed, verbose=0):\n",
    "    '''\n",
    "    return the required sets for an OCSVM trained on the user with key. \n",
    "    X_train: X data from train_dic[k], comes from exp2\n",
    "    X_test_regular: X data from valid_test_dic[k], comes from exp1\n",
    "    X_test_anomalous: X data from valid_test_dic[!k], comes from exp1\n",
    "    \n",
    "    Create cross-validation mask with train-valid pairs.\n",
    "    \n",
    "    See e.g. https://stackoverflow.com/a/37591377\n",
    "    \n",
    "    Arguments:\n",
    "        cv_mask {np.ndarray} --\n",
    "        \n",
    "    Return:\n",
    "        {list} -- List of tuple: (<train indices>, <valid indices>)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    if owner_key not in  train_dic:\n",
    "        raise Exception(\"invalid key for dic\")\n",
    "    \n",
    "        \n",
    "    X_pos = train_dic[owner_key].copy()\n",
    "    X_test_regular = valid_test_dic[owner_key].copy()\n",
    "    X_test_anomalous = np.concatenate([valid_test_dic[key] for key in valid_test_dic.keys() if key != owner_key], axis=0).copy()\n",
    "    \n",
    "    train_idx_owner = np.arange(X_pos.shape[0])\n",
    "    valid_idx_owner = np.arange(X_test_regular.shape[0]) + train_idx_owner.shape[0]\n",
    "    \n",
    "    if verbose>0: print(f\"owner: {owner_key} train_idx range: {train_idx_owner[0]}, {train_idx_owner[-1]}\")\n",
    "    if verbose>0: print(f\"owner: {owner_key} valid_idx range: {valid_idx_owner[0]}, {valid_idx_owner[-1]}\")\n",
    "    np.random.seed(seed + owner_key)\n",
    "    np.random.shuffle(train_idx_owner)\n",
    "    \n",
    "    np.random.seed(seed + owner_key)\n",
    "    np.random.shuffle(valid_idx_owner)\n",
    "\n",
    "    \n",
    "    cv_splits = []\n",
    "    base_idx = train_idx_owner.shape[0] + valid_idx_owner.shape[0]\n",
    "    if verbose>0: print(f\"owner key: {owner_key}\")\n",
    "    for key in valid_test_dic.keys():\n",
    "        \n",
    "        if key != owner_key:\n",
    "            # Impostor validation indices\n",
    "            valid_idx_impostor = np.arange(valid_test_dic[key].shape[0]) + base_idx\n",
    "            if verbose>0: print(f\"imposter: {key} valid_idx range: {valid_idx_impostor[0]}, {valid_idx_impostor[-1]}\")\n",
    "\n",
    "            # Balance classes\n",
    "            min_samples = min(valid_idx_owner.shape[0], valid_idx_impostor.shape[0])\n",
    "            np.random.seed(seed + key)\n",
    "            valid_idx_owner_samp = np.random.choice(\n",
    "                valid_idx_owner, size=min_samples, replace=False\n",
    "            )\n",
    "            np.random.seed(seed + key)\n",
    "            valid_idx_impostor_samp = np.random.choice(\n",
    "                valid_idx_impostor, size=min_samples, replace=False\n",
    "            )\n",
    "\n",
    "            # Concat owner & impostor validation indices\n",
    "            valid_idx_both = np.hstack([valid_idx_owner_samp, valid_idx_impostor_samp])\n",
    "\n",
    "            # Add train/valid pair to cv\n",
    "            cv_splits.append((list(train_idx_owner), list(valid_idx_both)))\n",
    "            \n",
    "            base_idx += valid_idx_impostor.shape[0]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_train = np.concatenate([np.repeat(1.0, X_pos.shape[0]), np.repeat(1.0, X_test_regular.shape[0]), np.repeat(-1.0, X_test_anomalous.shape[0])])\n",
    "    X_train = np.concatenate([X_pos, X_test_regular, X_test_anomalous], axis=0)\n",
    "    \n",
    "    \n",
    "    return {\"X_train\": X_train, \"y_train\": y_train, \"X_test_regular\": X_test_regular, \"X_test_anomalous\": X_test_anomalous, \"cv_splits\": cv_splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_cell_guid": "6abc81ef-9648-4c12-95c7-d8af54bd1923",
    "_uuid": "03caeebf-831e-40bd-8724-6eeeb713e63b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if TEST_MODE:\n",
    "    # Mask Explained:\n",
    "    # -2 => Training data (owner)\n",
    "    # -1 => Validation data (owner)\n",
    "    # 0+ => Validation impostors\n",
    "    #              Indices:    0   1   2   3   4   5  6  7  8  9  10 11 12 13 14 15\n",
    "    dummy_cv_mask = np.array([-2, -2, -1, -1, -1, -1, 0, 0, 0, 1, 1, 1, 2, 2, 2, -2])\n",
    "\n",
    "    # Generate tuples of training data and validation data, one tuple for each impostor (0, 1, 2).\n",
    "    # Training data (1st list in tuple) contains only indices of owner training data (-2)\n",
    "    # Validation data (2nd list in tuple) contains  indices of validation data from owner (-1) and\n",
    "    # from a single impostor (0+), each 50 %\n",
    "    splits = utils_create_cv_splits(dummy_cv_mask, seed=123)\n",
    "    [print(s) for s in splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9f0938b3-dc22-4b9b-9418-3be1a44595e3",
    "_uuid": "04c3c832-4264-44b4-b076-195e0d551630"
   },
   "source": [
    "# utils_cv_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_cv_report(random_search, owner, impostors, verbose=0):\n",
    "    \"\"\"Transform the random_search.cv_results_ into nice formatted dataframe.\"\"\"\n",
    "    # Create report\n",
    "    df_report = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "    # Add owner information\n",
    "    df_report[\"owner\"] = owner\n",
    "\n",
    "    # Drop uninteressting columns\n",
    "    drop_columns = [col for col in df_report.columns if \"_train_\" in col]\n",
    "    drop_columns = drop_columns + [col for col in df_report.columns if col.startswith(\"split\") and (col.endswith(\"recall\") or col.endswith(\"precision\") or col.endswith(\"f1\") or col.endswith(\"roc_auc\"))]\n",
    "    drop_columns = drop_columns + [\"params\"]\n",
    "    df_report = df_report.drop(columns=drop_columns)\n",
    "\n",
    "    # Flip sign of eer (revert flip by sklearn scorer)\n",
    "    eer_columns = [col for col in df_report.columns if col.endswith(\"_eer\")]\n",
    "    df_report[eer_columns] = df_report[eer_columns].abs()\n",
    "    \n",
    "    # Rename split result columns with impostor-ids used in split\n",
    "    rename_cols = {}\n",
    "    for idx, impostor in enumerate(impostors):\n",
    "        if verbose: print(f\"idx: {idx}, impostor: {impostor}\")\n",
    "        to_rename_cols = [col for col in df_report.columns if col.startswith(f\"split{idx}\")]\n",
    "        for col in to_rename_cols:\n",
    "            rename_cols[col] = str(impostor)+col[len(f\"split{idx}\"):]\n",
    "    df_report = df_report.rename(columns=rename_cols)      \n",
    "\n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_MODE:\n",
    "    print(\"Performing Dummy RandomSearch...\")\n",
    "    from sklearn import svm, datasets\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    iris = datasets.load_iris()\n",
    "    parameters = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 2, 3, 4, 5, 6, 7, 10]}\n",
    "    svc = svm.SVC(gamma=\"scale\")\n",
    "    clf = RandomizedSearchCV(svc, parameters, cv=3, iid=False)\n",
    "    clf.fit(iris.data, iris.target)\n",
    "    print(\"Create report:\")\n",
    "    df_temp = utils_cv_report(clf, \"owner x\", [\"impo_1\", \"impo_2\", \"impo_3\"])\n",
    "    display(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_plot_randomsearch_results(df_results, n_top=1, h1_min_max_scale_tuple=(-.1, 1.1, \"linear\"), h2_min_max_scale_tuple=(1e-9, 1e3, \"log\"), plot=False):\n",
    "    # Prepare data for plotting\n",
    "    sorted_df_results=df_results[(df_results[\"rank_test_eer\"] <= n_top)].sort_values(by=['owner', 'run', 'param_model__nu', \"param_model__gamma\"], ascending=[True, True, True, True])\n",
    "    groupted_df_results = sorted_df_results[(sorted_df_results[\"rank_test_eer\"] <= n_top)].groupby(['owner', 'run']).first()\n",
    "    \n",
    "    \n",
    "    df_plot = groupted_df_results[groupted_df_results[\"rank_test_eer\"] <= n_top].rename(\n",
    "        columns={\n",
    "            \"param_model__nu\": r\"$\\nu$\",\n",
    "            \"param_model__gamma\": r\"$\\gamma$\",\n",
    "            \"mean_test_accuracy\": \"Mean Test Acc.\",\n",
    "            \"mean_test_eer\": \"Mean Test EER\",\n",
    "        }\n",
    "    )\n",
    "    df_plot[\"Mean Test EER\"] = df_plot[\"Mean Test EER\"] * -1  # Because fewer is more\n",
    "    \n",
    "    median_nu = df_plot[r\"$\\nu$\"].median()\n",
    "    median_gamma = df_plot[r\"$\\gamma$\"].median()\n",
    "    \n",
    "    fig=None\n",
    "    if plot:\n",
    "        fig = utils_plot_2d_hyperparam_selection(h1_name=r\"$\\nu$\", h1_val=median_nu, h2_name=r\"$\\gamma$\", h2_val=median_gamma, df_plot=df_plot, \n",
    "                                                 h1_min_max_scale_tuple=h1_min_max_scale_tuple, h2_min_max_scale_tuple=h2_min_max_scale_tuple)\n",
    "\n",
    "    return {\"median_nu\": median_nu, \"median_gamma\": median_gamma, \"fig\": fig}\n",
    "\n",
    "\n",
    "def utils_plot_randomsearch_results_IF(df_results, n_top=1, plot=False):\n",
    "    \n",
    "    sorted_df_results=df_results[(df_results[\"rank_test_eer\"] <= n_top)].sort_values(\n",
    "        by=['owner', 'run', 'param_model__n_estimators', \"param_model__max_samples\", \"param_model__contamination\", \"param_model__max_features\"], \n",
    "        ascending=[True, True, True, True, True, True])\n",
    "    groupted_df_results = sorted_df_results[(sorted_df_results[\"rank_test_eer\"] <= n_top)].groupby(['owner', 'run']).first()\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    df_plot = df_results[df_results[\"rank_test_eer\"] <= n_top].rename(\n",
    "        columns={\n",
    "                \"param_model__n_estimators\": \"n_estimators\",\n",
    "                \"param_model__max_samples\": \"max_samples\",\n",
    "                \"param_model__contamination\": \"contamination\",\n",
    "                \"param_model__max_features\": \"max_features\",\n",
    "                \"mean_test_accuracy\": \"Mean Test Acc.\",\n",
    "                \"mean_test_eer\": \"Mean Test EER\",\n",
    "        }\n",
    "    )\n",
    "    df_plot[\"Mean Test EER\"] = df_plot[\"Mean Test EER\"] * -1  # Because fewer is more\n",
    "\n",
    "    median_n_estimators = df_plot[\"n_estimators\"].median()\n",
    "    median_max_samples = df_plot[\"max_samples\"].median()\n",
    "    median_contamination = df_plot[\"contamination\"].median()\n",
    "    median_max_features = df_plot[\"max_features\"].median()\n",
    "    \n",
    "    figures=None\n",
    "    if plot:\n",
    "        figures = []\n",
    "        figures.append(utils_plot_2d_hyperparam_selection(\"n_estimators\", median_n_estimators, \"max_samples\", median_max_samples, df_plot,\n",
    "                                                         h1_min_max_scale_tuple=(-10, 500, \"linear\"), h2_min_max_scale_tuple=(-.1, 1.1, \"linear\")))\n",
    "        figures.append(utils_plot_2d_hyperparam_selection(\"n_estimators\", median_n_estimators, \"contamination\", median_contamination, df_plot,\n",
    "                                                         h1_min_max_scale_tuple=(-10, 500, \"linear\"), h2_min_max_scale_tuple=(-.1, 1.1, \"linear\")))\n",
    "        figures.append(utils_plot_2d_hyperparam_selection(\"n_estimators\", median_n_estimators, \"max_features\", median_max_features, df_plot,\n",
    "                                                         h1_min_max_scale_tuple=(-10, 500, \"linear\"), h2_min_max_scale_tuple=(-.1, 1.1, \"linear\")))\n",
    "        figures.append(utils_plot_2d_hyperparam_selection(\"max_samples\", median_max_samples, \"contamination\", median_contamination, df_plot,\n",
    "                                                         h1_min_max_scale_tuple=(-.1, 1.1, \"linear\"), h2_min_max_scale_tuple=(-.1, 1.1, \"linear\")))\n",
    "        figures.append(utils_plot_2d_hyperparam_selection(\"max_samples\", median_max_samples, \"max_features\", median_max_features, df_plot,\n",
    "                                                         h1_min_max_scale_tuple=(-.1, 1.1, \"linear\"), h2_min_max_scale_tuple=(-.1, 1.1, \"linear\")))\n",
    "        figures.append(utils_plot_2d_hyperparam_selection(\"contamination\", median_contamination, \"max_features\", median_max_features, df_plot,\n",
    "                                                         h1_min_max_scale_tuple=(-.1, 1.1, \"linear\"), h2_min_max_scale_tuple=(-.1, 1.1, \"linear\")))\n",
    "    \n",
    "\n",
    "    return {\"median_n_estimators\": median_n_estimators, \"median_max_samples\": median_max_samples, \"median_contamination\": median_contamination, \n",
    "            \"median_max_features\": median_max_features, \"figures\": figures}\n",
    "\n",
    "def utils_plot_randomsearch_results_LOF(df_results, n_top=1, plot=False):\n",
    "    \n",
    "    sorted_df_results=df_results[(df_results[\"rank_test_eer\"] <= n_top)].sort_values(\n",
    "        by=['owner', 'run', 'param_model__n_neighbors', \"param_model__contamination\"], \n",
    "        ascending=[True, True, True, True])\n",
    "    groupted_df_results = sorted_df_results[(sorted_df_results[\"rank_test_eer\"] <= n_top)].groupby(['owner', 'run']).first()\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    df_plot = df_results[df_results[\"rank_test_eer\"] <= n_top].rename(\n",
    "        columns={\n",
    "                \"param_model__n_neighbors\": \"n_neighbors\",\n",
    "                \"param_model__contamination\": \"contamination\",\n",
    "                \"mean_test_accuracy\": \"Mean Test Acc.\",\n",
    "                \"mean_test_eer\": \"Mean Test EER\",\n",
    "        }\n",
    "    )\n",
    "    df_plot[\"Mean Test EER\"] = df_plot[\"Mean Test EER\"] * -1  # Because fewer is more\n",
    "\n",
    "    median_n_neighbors = df_plot[\"n_neighbors\"].median()\n",
    "    median_contamination = df_plot[\"contamination\"].median()\n",
    "\n",
    "    \n",
    "    fig=None\n",
    "    if plot:\n",
    "        fig=utils_plot_2d_hyperparam_selection(\"n_neighbors\", median_n_neighbors, \"contamination\", median_contamination, df_plot,\n",
    "                                               h1_min_max_scale_tuple=(-5, 50, \"linear\"), h2_min_max_scale_tuple=(-.1, 1.1, \"linear\"))\n",
    "    \n",
    "\n",
    "    return {\"median_n_neighbors\": median_n_neighbors, \"median_contamination\": median_contamination, \"fig\": fig}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_plot_2d_hyperparam_selection(h1_name, h1_val, h2_name, h2_val, df_plot, \n",
    "                                       h1_min_max_scale_tuple=(None, None, \"linear\"), h2_min_max_scale_tuple=(None, None, \"log\")):\n",
    "    \n",
    "    h1_min, h1_max, h1_scale = h1_min_max_scale_tuple\n",
    "    h2_min, h2_max, h2_scale = h2_min_max_scale_tuple\n",
    "    \n",
    "    \n",
    "    if h2_scale==\"log\":\n",
    "        h2_text_y = h2_val * np.power(h2_max / h2_min, 0.06)\n",
    "        h2_text_2_y = h2_val * np.power(h2_max / h2_min, 0.02)\n",
    "        \n",
    "        h1_text_y = h2_val * np.power(h2_max / h2_min, 0.26)\n",
    "        h1_text_2_y = h2_val * np.power(h2_max / h2_min, 0.22)\n",
    "    \n",
    "    elif h2_scale==\"linear\":\n",
    "        h2_text_y = h2_val+ 0.07 * (h2_max - h2_min)\n",
    "        h2_text_2_y = h2_val + 0.02 * (h2_max - h2_min)\n",
    "        \n",
    "        h1_text_y = h2_val+ 0.17 * (h2_max - h2_min)\n",
    "        h1_text_2_y = h2_val + 0.12 * (h2_max - h2_min)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Need to specify h2_scale\")\n",
    "    \n",
    "    \n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(5.473 / 1.3, 2), dpi=180)\n",
    "    g = sns.scatterplot(\n",
    "        x=h1_name,\n",
    "        y=h2_name,\n",
    "        data=df_plot,\n",
    "        size=\"Mean Test EER\",\n",
    "        sizes=(7, 60),\n",
    "        hue=\"Mean Test EER\",\n",
    "        alpha=1,\n",
    "        #        palette=\"Blues\",\n",
    "        linewidth=0,\n",
    "    )\n",
    "\n",
    "    # Format Legend labels\n",
    "    leg = g.get_legend()\n",
    "    new_handles = [h for h in leg.legendHandles]\n",
    "    new_labels = []\n",
    "    for i, handle in enumerate(leg.legendHandles):\n",
    "        label = handle.get_label()\n",
    "        print(f'{i}, {label}')\n",
    "        if ord(label[0]) == 8722:\n",
    "            label = '-' + label[1:]\n",
    "            \n",
    "        try:\n",
    "            new_labels.append(f\"{abs(float(label)):.3f}\")\n",
    "\n",
    "        except ValueError:\n",
    "            new_labels.append(\"\")\n",
    "\n",
    "    # Plot mean values\n",
    "    plt.plot(\n",
    "        [h1_min-0.01, h1_max+0.01],\n",
    "        [h2_val, h2_val],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        alpha=0.7,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        0.23,\n",
    "        h2_text_y,\n",
    "        f\"median({h2_name})\",\n",
    "        fontsize=6,\n",
    "        color=\"black\",\n",
    "        alpha=0.9,\n",
    "    )\n",
    "    plt.text(\n",
    "        0.23,\n",
    "        h2_text_2_y,\n",
    "        f\"{h2_val:.9f}\",\n",
    "        fontsize=5,\n",
    "        color=\"black\",\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "    plt.plot(\n",
    "        [h1_val, h1_val],\n",
    "        [h2_min, h2_max],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=0.8,\n",
    "        alpha=0.7,\n",
    "        color=\"black\",\n",
    "    )\n",
    "    plt.text(\n",
    "        h1_val + 0.005, h1_text_y, f\"median({h1_name})\", fontsize=6, color=\"black\", alpha=0.9\n",
    "    )\n",
    "    plt.text(\n",
    "        h1_val + 0.005, h1_text_2_y, f\"{h1_val:.9f}\", fontsize=5, color=\"black\", alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Adjust axes & legend\n",
    "    \n",
    "    plt.xlim(h1_min, h1_max)\n",
    "    plt.xscale(h1_scale)\n",
    "    \n",
    "    plt.ylim(h2_min, h2_max)\n",
    "    plt.yscale(h2_scale)\n",
    "    \n",
    "#     print(new_handles)\n",
    "    print(new_labels)\n",
    "    plt.legend(\n",
    "        new_handles,\n",
    "        new_labels,\n",
    "        bbox_to_anchor=(1.02, 1),\n",
    "        loc=2,\n",
    "        borderaxespad=0.0,\n",
    "        title=\"Mean EER per Owner\\n(Validation Results)\",\n",
    "        title_fontsize=5,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/11159436/multiple-figures-in-a-single-window\n",
    "def arrange_figures(figures, nrows = 1, ncols=1):\n",
    "    \"\"\"Plot a dictionary of figures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    figures : <title, figure> dictionary\n",
    "    ncols : number of columns of subplots wanted in the display\n",
    "    nrows : number of rows of subplots wanted in the figure\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows)\n",
    "    for ind,title in enumerate(figures):\n",
    "        axeslist.ravel()[ind].imshow(figures[title], cmap=plt.gray())\n",
    "        axeslist.ravel()[ind].set_title(title)\n",
    "        axeslist.ravel()[ind].set_axis_off()\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "b7fd521d-f17e-4894-84c3-4d3ab3655c44",
    "_uuid": "081f655b-dd63-4dc9-8b08-9cb0f7982129",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def utils_plot_acc_eer_dist(df_plot, y_col):\n",
    "    n_subject = len(df_plot[\"Owner\"].unique()) - 1\n",
    "    mean_col = df_plot[y_col].mean()\n",
    "\n",
    "    fig = plt.figure(figsize=(5.473, 2), dpi=180)\n",
    "    ax = sns.boxplot(x=\"Owner\", y=y_col, data=df_plot, **utils_boxplot_style)\n",
    "    ax.set_ylim((0, 1))\n",
    "\n",
    "    plt.plot(\n",
    "        [-0.6, n_subject + 0.6],\n",
    "        [mean_col, mean_col],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=1,\n",
    "        color=MAGENTA,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.text(n_subject + 0.6, mean_col, f\"mean\", fontsize=6, color=MAGENTA)\n",
    "    plt.text(\n",
    "        n_subject + 0.6, mean_col - 0.04, f\"{mean_col:.3f}\", fontsize=4.5, color=MAGENTA\n",
    "    )\n",
    "    plt.xticks(rotation=45)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    print(f\"Overall mean: {mean_col:.4f}\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "# X_vals_owner_idx['X_train']\n",
    "def utils_plot_acc_eer_dist_thesis(EER_distro_df, y_col, discription, save_file_name=None, boxplot_color=\"springgreen\"):\n",
    "\n",
    "    sns.set(err_distro_rc)\n",
    "    n_subject = len(EER_distro_df['owner'].unique())+1\n",
    "    mean_col = EER_distro_df[y_col].mean()\n",
    "    fig = plt.figure()\n",
    "    ax = sns.boxplot(x=\"owner\", y=y_col, data=EER_distro_df, color=boxplot_color)#, **utils_boxplot_style)\n",
    "    \n",
    "    # Select which box you want to change    \n",
    "    mybox = ax.patches[4]\n",
    "\n",
    "    ax.set_ylim((0, 1))\n",
    "    sns.swarmplot(x=\"owner\", y=y_col, data=EER_distro_df, color=\".25\")\n",
    "    \n",
    "\n",
    "    plt.plot(\n",
    "        [-0.5, n_subject -1.5],\n",
    "        [mean_col, mean_col],\n",
    "        linestyle=\"dashed\",\n",
    "        linewidth=2,\n",
    "        color=MAGENTA,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.text(n_subject/2, mean_col + 0.01, f\"mean\", fontsize=err_distro_rc[\"ytick.labelsize\"], color=MAGENTA)\n",
    "    plt.text(\n",
    "        n_subject/2, mean_col - 0.04, f\"{mean_col:.3f}\", fontsize=err_distro_rc[\"ytick.labelsize\"], color=MAGENTA\n",
    "    )\n",
    "    plt.xticks(rotation=45)\n",
    "    fig.tight_layout()\n",
    "    plt.title(discription)\n",
    "    \n",
    "    ax.set_xlabel(\"owner id\")\n",
    "    ax.set_ylabel(f\"Mean {y_col}\")\n",
    "    \n",
    "    plt.savefig(f'{save_file_name}', bbox_inches='tight')\n",
    "    print(f\"Overall mean: {mean_col:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_cell_guid": "230b6da5-a942-4634-a5cc-6e3a07d81646",
    "_uuid": "df80a643-53d2-4d31-9dc2-437d83a306eb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# if TEST_MODE:\n",
    "#     print(\"Performing Dummy RandomSearch...\")\n",
    "#     from sklearn import svm, datasets\n",
    "#     from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#     iris = datasets.load_iris()\n",
    "#     parameters = {\"kernel\": (\"linear\", \"rbf\"), \"C\": [1, 2, 3, 4, 5, 6, 7, 10]}\n",
    "#     svc = svm.SVC(gamma=\"scale\")\n",
    "#     clf = RandomizedSearchCV(svc, parameters, cv=3, iid=False)\n",
    "#     clf.fit(iris.data, iris.target)\n",
    "#     print(\"Create report:\")\n",
    "#     df_temp = utils_cv_report(clf, \"owner x\", [\"impo_1\", \"impo_2\", \"impo_3\"])\n",
    "#     display(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eer_per_window_size_col_df(df, key_column, window_size_lst):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Calculate the mean and variance of EER for each unique Key\n",
    "    agg_df = df.groupby(key_column)['Mean_EER'].agg(['mean', 'var']).reset_index()\n",
    "\n",
    "    # Pivot the original DataFrame\n",
    "    pivot_df = df.pivot_table(index=key_column, columns='window_size', values='Mean_EER').reset_index()\n",
    "\n",
    "    # Concatenate the pivoted DataFrame with the mean and variance columns\n",
    "    df = pd.concat([pivot_df, agg_df[['mean', 'var']]], axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    columns = [('Window Size', col) if col in window_size_lst else (\"\", col) for col in df.columns]\n",
    "    multiindex_columns = pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "    df.columns = multiindex_columns\n",
    "    \n",
    "    sorted_df = df.sort_values((\"\", 'mean'), ascending=True).reset_index(drop=True)\n",
    "    sorted_df.index.name=\"mean rank\"\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "# Iterate through the dictionary and add the key as a new column 'Key' in each DataFrame\n",
    "def make_raw_exp_df_results(EER_df_dict, key_column):\n",
    "    \n",
    "    dfs = []\n",
    "    for key, df in EER_df_dict.items():\n",
    "        df=df.copy()\n",
    "        \n",
    "        try:\n",
    "            df[key_column] = key\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"the number of columns in key_column must match the number of elements of dict key!\")\n",
    "            print(f\"len(key_column): {len(key_column)} != len(key): {len(key)}\")\n",
    "            print(f\"type(key_column): {type(key_column)}, type(key): {type(key)}\")\n",
    "            return\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all the DataFrames\n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_and_save_final_result_df_as_json(final_exp_results_path, exp_path_name, window_size_lst):\n",
    "    window_size_cols=[('Window Size', winsize) for winsize in window_size_lst]\n",
    "    preprocessing_methods=[\"Naive\", \"Realworld-per_unknown_window\"]\n",
    "    smoothing_methods=[\"Butterworth\", \"EMA\", \"SMA\", \"Butter+EMA\", \"Butter+SMA\"]\n",
    "    concate_df_lst=[]\n",
    "    \n",
    "    \n",
    "    test_file_name=f\"{final_exp_results_path}/{exp_path_name}/None_Mean_EER_None_df_test_dict.txt\"\n",
    "    eer_per_window_size_col_df = pd.read_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json').drop([\"('', 'mean')\", \"('', 'var')\"], axis=1)#\"('index', '')\", \n",
    "    # print(eer_per_window_size_col_df)\n",
    "    # Convert the string representation of tuples back to tuples\n",
    "    idx_tuples = [eval(i) for i in eer_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "    # Convert list of tuples back to a MultiIndex\n",
    "    multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "    eer_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "    eer_per_window_size_col_df[(\"\", 'type')] = 'None'\n",
    "    \n",
    "    concate_df_lst.append(eer_per_window_size_col_df)\n",
    "            \n",
    "            \n",
    "    for sm in smoothing_methods:\n",
    "        for pm in preprocessing_methods:\n",
    "            test_file_name=f\"{final_exp_results_path}/{exp_path_name}/{sm}_Mean_EER_{pm}_df_test_dict.txt\"\n",
    "            eer_per_window_size_col_df = pd.read_json(f'{test_file_name[:-4]}_eer_per_window_size_col_df.json').drop([\"('', 'mean')\", \"('', 'var')\"], axis=1)#\"('index', '')\", \n",
    "            # print(eer_per_window_size_col_df)\n",
    "            # Convert the string representation of tuples back to tuples\n",
    "            idx_tuples = [eval(i) for i in eer_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "            # Convert list of tuples back to a MultiIndex\n",
    "            multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "            eer_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "            if pm ==\"Realworld-per_unknown_window\":\n",
    "                pm=\"Real\"\n",
    "            eer_per_window_size_col_df[(\"\", 'type')] = f'{pm}'\n",
    "\n",
    "            concate_df_lst.append(eer_per_window_size_col_df)\n",
    "\n",
    "    df = pd.concat(concate_df_lst)\n",
    "    # # add a new column 'Mean' which is the mean of each row across the columns '125', '1500', and '2000'\n",
    "    # df['Mean'] = df[['125', '1500', '2000']].mean(axis=1)\n",
    "    df=df[[\n",
    "        (           '', 'cut_off_freq'),\n",
    "        (           '',     'EMA_span'),\n",
    "        (           '',  'SMA_winsize'),\n",
    "        (           '', 'type'),\n",
    "        ]+window_size_cols]\n",
    "\n",
    "    df = df.fillna(DASH_MACRO_NUM).reset_index(drop=True)\n",
    "\n",
    "    df[(\"\", 'cut_off_freq')] = df[(\"\", 'cut_off_freq')].astype(np.int64)\n",
    "    df[(\"\", 'EMA_span')] = df[(\"\", 'EMA_span')].astype(np.int64)\n",
    "    df[(\"\", 'SMA_winsize')] = df[(\"\", 'SMA_winsize')].astype(np.int64)\n",
    "\n",
    "    df[(\"\", \"mean\")] = df[window_size_cols].mean(axis=1)\n",
    "    df[(\"\", \"variance\")] = df[window_size_cols].var(axis=1)\n",
    "\n",
    "    df[(\"\", 'mean rank')] = df[(\"\", \"mean\")].rank(method='min').astype(np.int64)\n",
    "    cols = list(df.columns)\n",
    "    df = df[[cols[-1]] + cols[:-1]]\n",
    "\n",
    "    df.replace(DASH_MACRO_NUM, \"-\", inplace=True)\n",
    "\n",
    "    df.to_json(f\"{final_exp_results_path}/{exp_path_name}/{exp_path_name}-df.json\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def return_and_save_final_relative_result_df_as_json(df, base_case_index, final_exp_results_path, exp_path_name, window_size_lst):\n",
    "    window_size_cols=[('Window Size', winsize) for winsize in window_size_lst]\n",
    "    # columns you want to apply the operation to\n",
    "    selected_columns = window_size_cols+[(\"\", \"mean\"), (\"\", \"variance\")]\n",
    "\n",
    "    # apply the operation to selected columns\n",
    "    df_selected = df[selected_columns]\n",
    "    # get the other columns\n",
    "    df_others = df.drop(columns=selected_columns)\n",
    "\n",
    "    # Convert the DataFrame to percentage improvement relative to base case\n",
    "    df_relative = df_selected.loc[base_case_index].subtract(df_selected)\n",
    "\n",
    "    # Convert to percentage improvement\n",
    "    df_relative = df_relative.divide(df_selected.loc[base_case_index], axis=1) * 100\n",
    "\n",
    "    # concatenate the dataframes along the column axis\n",
    "    df_relative = pd.concat([df_others, df_relative], axis=1)\n",
    "    \n",
    "    df_relative.to_json(f\"{final_exp_results_path}/{exp_path_name}/{exp_path_name}-relative_df.json\")\n",
    "    \n",
    "    return df_relative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Gini_per_window_size_col_df(df, window_size_lst):\n",
    "    df = df.copy()\n",
    "    cols=df.columns\n",
    "\n",
    "\n",
    "    if \"cut_off_freq\" in cols and \"EMA_span\" in cols:\n",
    "        key_column=[\"cut_off_freq\", \"EMA_span\"]\n",
    "        \n",
    "    elif \"cut_off_freq\" in cols and \"SMA_winsize\" in cols:\n",
    "        key_column=[\"cut_off_freq\", \"SMA_winsize\"]\n",
    "        \n",
    "    elif \"EMA_span\" in cols:\n",
    "        key_column=[\"EMA_span\"]\n",
    "        \n",
    "    elif \"SMA_winsize\" in cols: \n",
    "        key_column=[\"SMA_winsize\"]\n",
    "        \n",
    "    elif \"cut_off_freq\" in cols:\n",
    "        key_column=[\"cut_off_freq\"]\n",
    "\n",
    "    \n",
    "    # Calculate the mean and variance of Gini_coef for each unique Key\n",
    "    agg_df = df.groupby(key_column)['Gini_coef'].agg(['mean', 'var']).reset_index()\n",
    "\n",
    "    # Pivot the original DataFrame\n",
    "    pivot_df = df.pivot_table(index=key_column, columns='window_size', values='Gini_coef').reset_index()\n",
    "\n",
    "    # Concatenate the pivoted DataFrame with the mean and variance columns\n",
    "    df = pd.concat([pivot_df, agg_df[['mean', 'var']]], axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    columns = [('Window Size', col) if col in window_size_lst else (\"\", col) for col in df.columns]\n",
    "    multiindex_columns = pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "    df.columns = multiindex_columns\n",
    "    \n",
    "    sorted_df = df.sort_values((\"\", 'mean'), ascending=True).reset_index(drop=True)\n",
    "    sorted_df.index.name=\"mean rank\"\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "def return_and_save_final_Gini_df_as_json(final_exp_results_path, exp_path_name, window_size_lst):\n",
    "    window_size_cols=[('Window Size', winsize) for winsize in window_size_lst]\n",
    "    preprocessing_methods=[\"Naive\", \"Realworld-per_unknown_window\"]\n",
    "    smoothing_methods=[\"Butterworth\", \"EMA\", \"SMA\", \"Butter+EMA\", \"Butter+SMA\"]\n",
    "    concate_df_lst=[]\n",
    "    \n",
    "    \n",
    "    test_file_name=f\"{final_exp_results_path}/{exp_path_name}/None_Mean_EER_None_df_test_dict.txt\"\n",
    "    raw_result_df = pd.read_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "    gini_per_window_size_col_df=make_Gini_per_window_size_col_df(raw_result_df, window_size_lst)\n",
    "\n",
    "    # print(eer_per_window_size_col_df)\n",
    "#     # Convert the string representation of tuples back to tuples\n",
    "#     idx_tuples = [eval(i) for i in gini_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "#     # Convert list of tuples back to a MultiIndex\n",
    "#     multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "#     gini_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "    gini_per_window_size_col_df[(\"\", 'type')] = 'None'\n",
    "    \n",
    "    concate_df_lst.append(gini_per_window_size_col_df)\n",
    "            \n",
    "            \n",
    "    for sm in smoothing_methods:\n",
    "        for pm in preprocessing_methods:\n",
    "            test_file_name=f\"{final_exp_results_path}/{exp_path_name}/{sm}_Mean_EER_{pm}_df_test_dict.txt\"\n",
    "            \n",
    "            raw_result_df = pd.read_json(f'{test_file_name[:-4]}_raw_df.json')\n",
    "            gini_per_window_size_col_df=make_Gini_per_window_size_col_df(raw_result_df, window_size_lst)\n",
    "            \n",
    "            # print(eer_per_window_size_col_df)\n",
    "            # Convert the string representation of tuples back to tuples\n",
    "#             idx_tuples = [eval(i) for i in gini_per_window_size_col_df.columns.tolist()]\n",
    "\n",
    "#             # Convert list of tuples back to a MultiIndex\n",
    "#             multiindex_columns = pd.MultiIndex.from_tuples(idx_tuples)\n",
    "\n",
    "#             gini_per_window_size_col_df.columns = multiindex_columns\n",
    "\n",
    "            if pm ==\"Realworld-per_unknown_window\":\n",
    "                pm=\"Real\"\n",
    "            gini_per_window_size_col_df[(\"\", 'type')] = f'{pm}'\n",
    "\n",
    "            concate_df_lst.append(gini_per_window_size_col_df)\n",
    "\n",
    "    df = pd.concat(concate_df_lst)\n",
    "    # # add a new column 'Mean' which is the mean of each row across the columns '125', '1500', and '2000'\n",
    "    # df['Mean'] = df[['125', '1500', '2000']].mean(axis=1)\n",
    "    df=df[[\n",
    "        (           '', 'cut_off_freq'),\n",
    "        (           '',     'EMA_span'),\n",
    "        (           '',  'SMA_winsize'),\n",
    "        (           '', 'type'),\n",
    "        ]+window_size_cols]\n",
    "\n",
    "    df = df.fillna(DASH_MACRO_NUM).reset_index(drop=True)\n",
    "\n",
    "    df[(\"\", 'cut_off_freq')] = df[(\"\", 'cut_off_freq')].astype(np.int64)\n",
    "    df[(\"\", 'EMA_span')] = df[(\"\", 'EMA_span')].astype(np.int64)\n",
    "    df[(\"\", 'SMA_winsize')] = df[(\"\", 'SMA_winsize')].astype(np.int64)\n",
    "\n",
    "    df[(\"\", \"mean\")] = df[window_size_cols].mean(axis=1)\n",
    "    df[(\"\", \"variance\")] = df[window_size_cols].var(axis=1)\n",
    "\n",
    "    df[(\"\", 'mean rank')] = df[(\"\", \"mean\")].rank(method='min').astype(np.int64)\n",
    "    cols = list(df.columns)\n",
    "    df = df[[cols[-1]] + cols[:-1]]\n",
    "\n",
    "    df.replace(DASH_MACRO_NUM, \"-\", inplace=True)\n",
    "\n",
    "    df.to_json(f\"{final_exp_results_path}/{exp_path_name}/{exp_path_name}-gini-df.json\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def return_and_save_final_relative_gini_result_df_as_json(df, base_case_index, final_exp_results_path, exp_path_name, window_size_lst):\n",
    "    window_size_cols=[('Window Size', winsize) for winsize in window_size_lst]\n",
    "    # columns you want to apply the operation to\n",
    "    selected_columns = window_size_cols+[(\"\", \"mean\"), (\"\", \"variance\")]\n",
    "\n",
    "    # apply the operation to selected columns\n",
    "    df_selected = df[selected_columns]\n",
    "    # get the other columns\n",
    "    df_others = df.drop(columns=selected_columns)\n",
    "\n",
    "    # Convert the DataFrame to percentage improvement relative to base case\n",
    "    df_relative = df_selected.loc[base_case_index].subtract(df_selected)\n",
    "\n",
    "    # Convert to percentage improvement\n",
    "    df_relative = df_relative.divide(df_selected.loc[base_case_index], axis=1) * 100\n",
    "\n",
    "    # concatenate the dataframes along the column axis\n",
    "    df_relative = pd.concat([df_others, df_relative], axis=1)\n",
    "    \n",
    "    df_relative.to_json(f\"{final_exp_results_path}/{exp_path_name}/{exp_path_name}-gini-relative_df.json\")\n",
    "    \n",
    "    return df_relative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\u001b[32mClassification utility functions imported\u001b[0m--------------------\n"
     ]
    }
   ],
   "source": [
    "print(20*'-' + \"\\x1b[32mClassification utility functions imported\\x1b[0m\" + 20*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"cut_off_freq\"]\n",
    "[\"cut_off_freq\", \"EMA_span\"]\n",
    "[\"EMA_span\"]\n",
    "[\"SMA_winsize\"]\n",
    "[\"cut_off_freq\", \"SMA_winsize\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
